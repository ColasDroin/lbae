{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1\n",
    "Raw data export into np.memaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load important modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'pages', 'app.py', 'assets', 'config.py', 'index.py', 'main.py', 'TODO.py', 'notebooks', 'modules', '__pycache__']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<threadpoolctl.threadpool_limits at 0x7f6ef8556610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard modules\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Move to root directory for easier module handling\n",
    "os.chdir(\"../..\")\n",
    "print(os.listdir(\".\"))\n",
    "from notebooks.data_processing.modules.maldi_conversion import process_raw_data\n",
    "from notebooks.data_processing.modules.lookup_tables import process_lookup_tables\n",
    "from modules.tools.misc import delete_all_files_in_folder\n",
    "\n",
    "# multithreading/multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "# set thread limit\n",
    "threadpool_limits(16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of raw data filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 20210210_MouseBrainCMC_S1AA1_2Dpixelmode_322x231_Att25_25um\n",
      "2 20210211_MouseBrainCMC_S2AB5_2Dpixelmode_370x214_Att25_25um\n",
      "3 20210213_MouseBrainCMC_S3AC4_2Dpixelmode_371x195_Att25_25um\n",
      "4 20210214_MouseBrainCMC_S4AD3_2Dpixelmode_354x228_Att25_25um\n",
      "5 20210218_MouseBrainCMC_S5AE3_2Dpixelmode_396x272_Att25_25um\n",
      "6 20210219_MouseBrainCMC_S6AE3_2Dpixelmode_423x282_Att25_25um\n",
      "7 20210220_MouseBrainCMC_S7AF5_2Dpixelmode_427x263_Att25_25um\n",
      "8 20210531_MouseBrainCMC_S8_duplicate_2Dpixelmode_430x285_Att30_25um\n",
      "9 20210224_MouseBrainCMC_S9AH4_2Dpixelmode_467x278_Att25_25um\n",
      "10 20210210_MouseBrainCMC_S10(brain2_20)_394x282_Att30_25um\n",
      "11 20210301_MouseBrainCMC_S11AK5_2Dpixelmode_448x277_Att25_25um\n",
      "12 20210303_MouseBrainCMC_S12AL1_2Dpixelmode_393x266_Att25_25um\n",
      "13 20210304_MouseBrainCMC_S13AM1_2Dpixelmode_413x310_Att25_25um\n",
      "14 20210305_MouseBrainCMC_S14AN1_2Dpixelmode_409x285_Att25_25um\n",
      "15 20210313_MouseBrainCMC_S15AO2_2Dpixelmode_451x292_Att25_25um\n",
      "16 20210530_MouseBrainCMC_S16_duplicate_2Dpixelmode_454x295_Att30_25um\n",
      "17 20210319_MouseBrainCMC_S17AQ2_2Dpixelmode_450x287_Att30_25um\n",
      "18 20210323_MouseBrainCMC_S18AR4_2Dpixelmode_474x291_Att30_25um\n",
      "19 20210325_MouseBrainCMC_S19AS4_2Dpixelmode_396x232_Att30_25um\n",
      "20 20210330_MouseBrainCMC_S20AT3_2Dpixelmode_396x266_Att30_25um\n",
      "21 20210408_MouseBrainCMC_S21AU4_2Dpixelmode_394x215_Att30_25um\n",
      "22 20210409_MouseBrainCMC_S22AV1_2Dpixelmode_416x207_Att30_25um\n",
      "23 20210412_MouseBrainCMC_S23AZ1_2Dpixelmode_360x260_Att30_25um\n",
      "24 20210413_MouseBrainCMC_S24_3_2Dpixelmode_327x328_Att30_25um\n",
      "25 20210414_MouseBrainCMC_S25_2_2Dpixelmode_358x238_Att30_25um\n",
      "26 20210419_MouseBrainCMC_S26_3_2Dpixelmode_340x248_Att30_25um\n",
      "27 20210603_MouseBrainCMC_S27_duplicate_2Dpixelmode_372x272_Att30_25um\n",
      "28 20210423_MouseBrainCMC_S28_3_2Dpixelmode_390x244_Att30_25um\n",
      "29 20210424_MouseBrainCMC_S29_5_2Dpixelmode_330x277_Att30_25um\n",
      "30 20210429_MouseBrainCMC_S30_5_2Dpixelmode_367x278_Att30_25um\n",
      "31 20210501_MouseBrainCMC_S31_3_2Dpixelmode_355x239_Att30_25um\n",
      "32 20210504_MouseBrainCMC_S32_3_2Dpixelmode_298x230_Att30_25um\n"
     ]
    }
   ],
   "source": [
    "# Load filenames\n",
    "l_t_names = sorted(\n",
    "    [\n",
    "        [\n",
    "            int(name.split(\"MouseBrainCMC_S\")[1].split(\"_\")[0].split(\"A\")[0].split(\"(\")[0]),\n",
    "            \"/data/lipidatlas/data/data_raw/\" + name + \"/\" + name,\n",
    "        ]\n",
    "        for name in os.listdir(\"/data/lipidatlas/data/data_raw/\")\n",
    "        if \"MouseBrain\" in name\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Correct for duplicates\n",
    "for t_names_1, t_names_2 in zip(l_t_names[:-1], l_t_names[1:]):\n",
    "    if t_names_2[0] == t_names_1[0]:\n",
    "        t_names_2.append(\"bis\")\n",
    "        print(\"WARNING: duplicate for slice \" + str(t_names_1[0]))\n",
    "\n",
    "# Remove slices that have already been processed\n",
    "path = \"notebooks/data_processing/data/temp/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "remove_already_loaded = False\n",
    "if remove_already_loaded:\n",
    "    existing_names = [int(name.split(\"_\")[1]) for name in os.listdir(path) if \"slice\" in name]\n",
    "    l_t_names = [x for x in l_t_names if x[0] not in existing_names]\n",
    "\n",
    "# Print the final list of names\n",
    "for t_names in l_t_names:\n",
    "    print(t_names[0], t_names[1].split(\"/\")[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process raw data into numpy arrays with multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing = False\n",
    "if multiprocessing:\n",
    "    with Pool(processes=12) as pool:\n",
    "        [x for x in pool.imap_unordered(extract_raw_data, l_t_names)]\n",
    "else:\n",
    "    # Normal (single-processed) map\n",
    "    [x for x in map(extract_raw_data, l_t_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The mzML file containts more than the expected74382 spectra. The tailing 25 spectra will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files : /data/lipidatlas/data/data_raw/20210210_MouseBrainCMC_S1AA1_2Dpixelmode_322x231_Att25_25um/20210210_MouseBrainCMC_S1AA1_2Dpixelmode_322x231_Att25_25um\n",
      "[Warning] Not index found and build_index_from_scratch is False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Sprectra at resolution 1e-05: 100%|██████████| 74382/74382 [00:35<00:00, 2097.70it/s]\n",
      "Loading the m/z values at resolution 1e-05: 100%|██████████| 74382/74382 [00:32<00:00, 2315.62it/s]\n",
      "WARNING:root:The sparsified dense matrix S has never been computed. Please wait while it's being generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and sorting dataframes\n",
      "Compute and normalize pixels values according to TIC\n",
      "Filtering out noise and matrix peaks\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Lipid with foldername with mz = 880.6279 was in df_match.csv but not in ranges.vsc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_136234/525708185.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Normal (single-processed) map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_raw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_t_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_136234/525708185.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Normal (single-processed) map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_raw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_t_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/lbae/lbae/notebooks/data_processing/modules/maldi_conversion.py\u001b[0m in \u001b[0;36mprocess_raw_data\u001b[0;34m(t_index_path, do_filter_peaks, standardize_lipid_values, save, return_result, output_path)\u001b[0m\n\u001b[1;32m    670\u001b[0m             ) = get_standardized_values(slice_index)\n\u001b[1;32m    671\u001b[0m             \u001b[0;31m# Standardize values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m             array_high_res = standardize_values(\n\u001b[0m\u001b[1;32m    673\u001b[0m                 \u001b[0marray_high_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0marray_pixel_indexes_high_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lbae/lbae/notebooks/data_processing/modules/maldi_conversion.py\u001b[0m in \u001b[0;36mstandardize_values\u001b[0;34m(array_spectra, array_pixel_indexes, array_peaks, array_mz_lipids, l_lipids_float, arrays_before_transfo, arrays_after_transfo)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfactor_precision\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mrows_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzt_mz_peaks_lipid_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_peaks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_lipids_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_mz_lipids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows_to_keep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_lipids_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lbae/lbae/notebooks/data_processing/modules/maldi_conversion.py\u001b[0m in \u001b[0;36mgzt_mz_peaks_lipid_annotation\u001b[0;34m(array_peaks, l_lipids_float, array_mz_lipids, precision)\u001b[0m\n\u001b[1;32m    497\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                 raise Exception(\n\u001b[0m\u001b[1;32m    500\u001b[0m                     \u001b[0;34m\"Lipid with foldername with mz = \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m                     \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmz_lipid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Lipid with foldername with mz = 880.6279 was in df_match.csv but not in ranges.vsc"
     ]
    }
   ],
   "source": [
    "multiprocessing = False\n",
    "if multiprocessing:\n",
    "    with Pool(processes=12) as pool:\n",
    "        [x for x in pool.imap_unordered(process_raw_data, l_t_names)]\n",
    "else:\n",
    "    # Normal (single-processed) map\n",
    "    [x for x in map(process_raw_data, l_t_names)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/annotations/df_match.csv\", sep=\",\")\n",
    "\n",
    "# Drop the columns that we won't use afterwards\n",
    "df = df.drop([\"molecule_ID\", \"concentration\",], axis=1,)\n",
    "\n",
    "# Keep only the current section\n",
    "df = df[df[\"section_ix\"] == 1 - 1]\n",
    "\n",
    "array_mz_lipids = np.array(df[[\"mz_estimated\", \"mz_estimated_total\"]], dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing = True\n",
    "if multiprocessing:\n",
    "    # Multiprocessing\n",
    "    with Pool(processes=12) as pool:\n",
    "        [x for x in pool.map(process_lookup_tables, l_t_names)]\n",
    "else:\n",
    "    # Normal (single-processed) map\n",
    "    [x for x in map(process_lookup_tables, l_t_names)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record everything and clean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record everything in memap files and a pickled dictonnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"data/whole_dataset/\"\n",
    "input_folder = \"notebooks/data_processing/data/temp/\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "dic_slices = {}\n",
    "# Loop over slice files\n",
    "for slice_name in os.listdir(input_folder):\n",
    "\n",
    "    # Extract slice index\n",
    "    slice_index = int(slice_name.split(\"_\")[1])\n",
    "\n",
    "    # Load slice arrays\n",
    "    npzfile = np.load(input_folder + slice_name)\n",
    "    array_pixel_indexes_high_res = npzfile[\"array_pixel_indexes_high_res\"]\n",
    "    array_spectra_high_res = npzfile[\"array_spectra_high_res\"]\n",
    "    array_averaged_mz_intensity_low_res = npzfile[\"array_averaged_mz_intensity_low_res\"]\n",
    "    array_averaged_mz_intensity_high_res = npzfile[\"array_averaged_mz_intensity_high_res\"]\n",
    "    image_shape = npzfile[\"image_shape\"]\n",
    "    divider_lookup = npzfile[\"divider_lookup\"]\n",
    "    lookup_table_spectra_high_res = npzfile[\"lookup_table_spectra_high_res\"]\n",
    "    cumulated_image_lookup_table_high_res = npzfile[\"cumulated_image_lookup_table_high_res\"]\n",
    "    lookup_table_averaged_spectrum_high_res = npzfile[\"lookup_table_averaged_spectrum_high_res\"]\n",
    "\n",
    "    # Print array size\n",
    "    # print size used by each array in mb\n",
    "    print(round(array_pixel_indexes_high_res.nbytes / 1024 / 1024, 2))\n",
    "    print(round(array_spectra_high_res.nbytes / 1024 / 1024, 2))\n",
    "    print(round(array_averaged_mz_intensity_low_res.nbytes / 1024 / 1024, 2))\n",
    "    print(round(array_averaged_mz_intensity_high_res.nbytes / 1024 / 1024, 2))\n",
    "    print(round(lookup_table_spectra_high_res.nbytes / 1024 / 1024, 2))\n",
    "    print(round(cumulated_image_lookup_table_high_res.nbytes / 1024 / 1024, 2))\n",
    "    print(round(lookup_table_averaged_spectrum_high_res.nbytes / 1024 / 1024, 2))\n",
    "\n",
    "    # Register the lightweights files in a pickled dictionnary\n",
    "    dic_slices[slice_index] = {\n",
    "        \"image_shape\": image_shape,\n",
    "        \"divider_lookup\": divider_lookup,\n",
    "        \"array_avg_spectrum_downsampled\": array_averaged_mz_intensity_low_res,\n",
    "        \"array_lookup_pixels\": array_pixel_indexes_high_res,\n",
    "        \"array_lookup_mz_avg\": lookup_table_averaged_spectrum_high_res,\n",
    "    }\n",
    "\n",
    "    # Build a memap for each of the heavier files to save RAM, save the corresponding shape in the \n",
    "    # pickled dictionnary\n",
    "    fp = np.memmap(\n",
    "        output_folder + \"array_spectra_\" + str(slice_index) + \".mmap\",\n",
    "        dtype=\"float32\",\n",
    "        mode=\"w+\",\n",
    "        shape=array_spectra_high_res.shape,\n",
    "    )\n",
    "    fp[:] = array_spectra_high_res[:]\n",
    "    fp.flush()\n",
    "    dic_slices[slice_index][\"array_spectra_shape\"] = array_spectra_high_res.shape\n",
    "\n",
    "    fp = np.memmap(\n",
    "        output_folder + \"array_avg_spectrum_\" + str(slice_index) + \".mmap\",\n",
    "        dtype=\"float32\",\n",
    "        mode=\"w+\",\n",
    "        shape=array_averaged_mz_intensity_high_res.shape,\n",
    "    )\n",
    "    fp[:] = array_averaged_mz_intensity_high_res[:]\n",
    "    fp.flush()\n",
    "    dic_slices[slice_index][\"array_avg_spectrum_shape\"] = array_averaged_mz_intensity_high_res.shape\n",
    "\n",
    "    fp = np.memmap(\n",
    "        output_folder + \"array_lookup_mz_\" + str(slice_index) + \".mmap\",\n",
    "        dtype=\"int32\",\n",
    "        mode=\"w+\",\n",
    "        shape=lookup_table_spectra_high_res.shape,\n",
    "    )\n",
    "    fp[:] = lookup_table_spectra_high_res[:]\n",
    "    fp.flush()\n",
    "    dic_slices[slice_index][\"array_lookup_mz_shape\"] = lookup_table_spectra_high_res.shape\n",
    "\n",
    "    fp = np.memmap(\n",
    "        output_folder + \"array_cumulated_lookup_mz_image_\" + str(slice_index) + \".mmap\",\n",
    "        dtype=\"float32\",\n",
    "        mode=\"w+\",\n",
    "        shape=cumulated_image_lookup_table_high_res.shape,\n",
    "    )\n",
    "    fp[:] = cumulated_image_lookup_table_high_res[:]\n",
    "    fp.flush()\n",
    "    dic_slices[slice_index][\n",
    "        \"array_cumulated_lookup_mz_image_shape\"\n",
    "    ] = cumulated_image_lookup_table_high_res.shape\n",
    "\n",
    "# Pickle the dict of lightweight data\n",
    "with open(output_folder + \"light_arrays.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(dic_slices, handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean temporary folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = False\n",
    "if clean:\n",
    "    delete_all_files_in_folder(input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! Quick fix for array_avg_low_res (to be deleted later)\n",
    "# from modules.tools.spectra import reduce_resolution_sorted_array_spectra\n",
    "# from modules.maldi_data import MaldiData\n",
    "# output_folder = \"data/whole_dataset/\"\n",
    "# with open(output_folder + \"light_arrays.pickle\", \"rb\") as handle:\n",
    "#         dic_light  = pickle.load(handle)\n",
    "\n",
    "# data = MaldiData()\n",
    "# for i in range(1,33):\n",
    "#         #print(len(dic_light[i][\"array_avg_spectrum_downsampled\"]))\n",
    "#         array_averaged_mz_intensity_low_res = reduce_resolution_sorted_array_spectra(\n",
    "#         data.get_array_avg_spectrum(slice_index=i), resolution=10 ** -2\n",
    "#     )\n",
    "#         dic_light[i][\"array_avg_spectrum_downsampled\"] = array_averaged_mz_intensity_low_res\n",
    "\n",
    "# # Pickle the dict of lightweight data\n",
    "# with open(output_folder + \"light_arrays.pickle\", \"wb\") as handle:\n",
    "#     pickle.dump(dic_light, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c1aa729cc35b9a783763c24c4069d7da678acf641f89d4e1df25bf02079ad65"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
