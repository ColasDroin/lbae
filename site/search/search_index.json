{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Lipid Brain Atlas Explorer technical documentation Please use the navigation bar on the left, or the search field on top to navigate through the documentation. Please check the repository of the project here for more information about the project.","title":"Welcome page"},{"location":"#welcome-to-the-lipid-brain-atlas-explorer-technical-documentation","text":"Please use the navigation bar on the left, or the search field on top to navigate through the documentation. Please check the repository of the project here for more information about the project.","title":"Welcome to the Lipid Brain Atlas Explorer technical documentation"},{"location":"app/","text":"In this module, the app is instantiated with a given server and cache config. Three global variables shared across all user sessions are also instantiated: data, atlas and figures.","title":"app"},{"location":"index_py/","text":"This module is where the app layout is created: the main container, the sidebar and the different pages. All the dcc.store, used to store client data across pages, are created here. It is also here that the URL routing is done. hide_slider ( pathname ) This callback is used to hide the slider div when the user is on a page that does not need it. Source code in lbae/index.py 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 @app . callback ( Output ( \"main-paper-slider\" , \"class_name\" ), Input ( \"url\" , \"pathname\" ), prevent_initial_call = False ) def hide_slider ( pathname ): \"\"\"This callback is used to hide the slider div when the user is on a page that does not need it. \"\"\" # Pages in which the slider is displayed l_path_with_slider = [ \"/load-slice\" , \"/lipid-selection\" , \"/region-analysis\" , \"/3D-exploration\" , \"/gene-data\" , ] # Set the content according to the current pathname if pathname in l_path_with_slider : return \"\" else : return \"d-none\" hide_slider_but_leave_brain ( pathname ) This callback is used to hide the slider but leave brain chips when needed. Source code in lbae/index.py 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 @app . callback ( Output ( \"main-slider-1\" , \"style\" ), Output ( \"main-slider-2\" , \"style\" ), Output ( \"main-text-slider\" , \"style\" ), Input ( \"url\" , \"pathname\" ), prevent_initial_call = False , ) def hide_slider_but_leave_brain ( pathname ): \"\"\"This callback is used to hide the slider but leave brain chips when needed.\"\"\" # Pages in which the slider is displayed l_path_without_slider_but_with_brain = [ \"/3D-exploration\" , \"/gene-data\" , ] # Set the content according to the current pathname if pathname in l_path_without_slider_but_with_brain : return { \"visibility\" : \"hidden\" }, { \"visibility\" : \"hidden\" }, { \"visibility\" : \"hidden\" } else : return {}, {}, {} hide_useless_slider ( brain , value_1 , value_2 ) This callback is used to update the slider indices with the selected brain. Source code in lbae/index.py 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 @app . callback ( Output ( \"main-slider-1\" , \"class_name\" ), Output ( \"main-slider-2\" , \"class_name\" ), Output ( \"main-slider-1\" , \"value\" ), Output ( \"main-slider-2\" , \"value\" ), Input ( \"main-brain\" , \"value\" ), State ( \"main-slider-1\" , \"value\" ), State ( \"main-slider-2\" , \"value\" ), prevent_initial_call = False , ) def hide_useless_slider ( brain , value_1 , value_2 ): \"\"\"This callback is used to update the slider indices with the selected brain.\"\"\" if brain == \"brain_1\" : value_1 = value_2 - data . get_slice_list ( indices = \"brain_1\" )[ - 1 ] return \"mt-2 mr-5 ml-2 mb-1 w-50\" , \"mt-2 mr-5 ml-2 mb-1 w-50 d-none\" , value_1 , value_2 elif brain == \"brain_2\" : value_2 = value_1 + data . get_slice_list ( indices = \"brain_1\" )[ - 1 ] return \"mt-2 mr-5 ml-2 mb-1 w-50 d-none\" , \"mt-2 mr-5 ml-2 mb-1 w-50\" , value_1 , value_2 render_page_content ( pathname , slice_index , brain ) This callback is used as a URL router. Source code in lbae/index.py 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 @app . callback ( Output ( \"content\" , \"children\" ), Output ( \"empty-content\" , \"children\" ), Input ( \"url\" , \"pathname\" ), State ( \"main-slider\" , \"data\" ), State ( \"main-brain\" , \"value\" ), ) def render_page_content ( pathname , slice_index , brain ): \"\"\"This callback is used as a URL router.\"\"\" # Keep track of the page in the console if pathname is not None : logging . info ( \"Page\" + pathname + \" has been selected\" + logmem ()) # Set the content according to the current pathname if pathname == \"/\" : page = home . layout elif pathname == \"/load-slice\" : page = load_slice . return_layout ( basic_config , slice_index ) elif pathname == \"/lipid-selection\" : page = lipid_selection . return_layout ( basic_config , slice_index ) elif pathname == \"/region-analysis\" : page = region_analysis . return_layout ( basic_config , slice_index ) elif pathname == \"/3D-exploration\" : page = threeD_exploration . return_layout ( basic_config , slice_index ) elif pathname == \"/gene-data\" : page = scRNAseq . return_layout ( basic_config , slice_index , brain ) else : # If the user tries to reach a different page, return a 404 message page = dmc . Center ( dmc . Alert ( title = \"404: Not found\" , children = f \"The pathname { pathname } was not recognised...\" , color = \"red\" , class_name = \"mt-5\" , ), class_name = \"mt-5\" , ) return page , \"\" return_main_content () This function compute the elements of the app that are shared across pages, including all the dcc.store. Returns: Type Description html . Div A div containing the corresponding elements. Source code in lbae/index.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def return_main_content (): \"\"\"This function compute the elements of the app that are shared across pages, including all the dcc.store. Returns: (html.Div): A div containing the corresponding elements. \"\"\" # List of empty lipid indexes for the dropdown of page 4, assuming brain 1 is initially selected empty_lipid_list = [ - 1 for i in data . get_slice_list ( indices = \"brain_1\" )] # Record session id in case sessions need to be individualized session_id = str ( uuid . uuid4 ()) # Define static content main_content = html . Div ( children = [ # To handle url since multi-page app dcc . Location ( id = \"url\" , refresh = False ), # Record session id, useful to trigger callbacks at initialization dcc . Store ( id = \"session-id\" , data = session_id ), # Record the slider index dcc . Store ( id = \"main-slider\" , data = 1 ), # Record the state of the range sliders for low and high resolution spectra in page 2 dcc . Store ( id = \"boundaries-low-resolution-mz-plot\" ), dcc . Store ( id = \"boundaries-high-resolution-mz-plot\" ), # Record the lipids selected in page 2 dcc . Store ( id = \"page-2-selected-lipid-1\" , data =- 1 ), dcc . Store ( id = \"page-2-selected-lipid-2\" , data =- 1 ), dcc . Store ( id = \"page-2-selected-lipid-3\" , data =- 1 ), dcc . Store ( id = \"page-2-last-selected-lipids\" , data = []), # Record the lipids selected in page 4 dcc . Store ( id = \"page-4-selected-lipid-1\" , data = empty_lipid_list ), dcc . Store ( id = \"page-4-selected-lipid-2\" , data = empty_lipid_list ), dcc . Store ( id = \"page-4-selected-lipid-3\" , data = empty_lipid_list ), dcc . Store ( id = \"page-4-last-selected-regions\" , data = []), dcc . Store ( id = \"page-4-selected-region-1\" , data = \"\" ), dcc . Store ( id = \"page-4-selected-region-2\" , data = \"\" ), dcc . Store ( id = \"page-4-selected-region-3\" , data = \"\" ), dcc . Store ( id = \"page-4-last-selected-lipids\" , data = []), # Record the shapes drawn in page 3 dcc . Store ( id = \"dcc-store-color-mask\" , data = []), dcc . Store ( id = \"dcc-store-reset\" , data = False ), dcc . Store ( id = \"dcc-store-shapes-and-masks\" , data = []), dcc . Store ( id = \"dcc-store-list-idx-lipids\" , data = []), # Record the annotated paths drawn in page 3 dcc . Store ( id = \"page-3-dcc-store-path-heatmap\" ), dcc . Store ( id = \"page-3-dcc-store-basic-figure\" , data = True ), # Record the computed spectra drawn in page 3 dcc . Store ( id = \"dcc-store-list-mz-spectra\" , data = []), # Record the lipids expressed in the region in page 3 dcc . Store ( id = \"page-3-dcc-store-lipids-region\" , data = []), # Actual app layout html . Div ( children = [ sidebar . layout , html . Div ( id = \"content\" ), dmc . Center ( id = \"main-paper-slider\" , style = { \"position\" : \"fixed\" , \"bottom\" : \"1rem\" , \"height\" : \"3rem\" , \"left\" : \"7rem\" , \"right\" : \"1rem\" , \"background-color\" : \"rgba(0, 0, 0, 0.0)\" , }, children = [ dmc . Text ( id = \"main-text-slider\" , children = \"Rostro-caudal coordinate (mm): \" , class_name = \"pr-4\" , size = \"sm\" , ), dmc . Slider ( id = \"main-slider-1\" , min = data . get_slice_list ( indices = \"brain_1\" )[ 0 ], max = data . get_slice_list ( indices = \"brain_1\" )[ - 1 ], step = 1 , marks = [ { \"value\" : slice_index , # Use x coordinate for label \"label\" : \" {:.2f} \" . format ( atlas . l_original_coor [ slice_index - 1 ][ 0 , 0 ][ 0 ] ), } for slice_index in data . get_slice_list ( indices = \"brain_1\" )[:: 3 ] ], size = \"xs\" , value = data . get_slice_list ( indices = \"brain_1\" )[ 0 ], color = \"cyan\" , class_name = \"mt-2 mr-5 ml-2 mb-1 w-50\" , ), dmc . Slider ( id = \"main-slider-2\" , min = data . get_slice_list ( indices = \"brain_2\" )[ 0 ], max = data . get_slice_list ( indices = \"brain_2\" )[ - 1 ], step = 1 , marks = [ { \"value\" : slice_index , # Use x coordinate for label \"label\" : \" {:.2f} \" . format ( atlas . l_original_coor [ slice_index - 1 ][ 0 , 0 ][ 0 ] ), } for slice_index in data . get_slice_list ( indices = \"brain_2\" )[:: 3 ] ], size = \"xs\" , value = data . get_slice_list ( indices = \"brain_2\" )[ 0 ], color = \"cyan\" , class_name = \"mt-2 mr-5 ml-2 mb-1 w-50 d-none\" , ), dmc . Chips ( id = \"main-brain\" , data = [ { \"value\" : \"brain_1\" , \"label\" : \"Brain 1\" }, { \"value\" : \"brain_2\" , \"label\" : \"Brain 2\" }, ], value = \"brain_1\" , class_name = \"pl-2 pt-1\" , color = \"cyan\" , ), ], ), # Documentation in a bottom drawer dmc . Drawer ( children = return_documentation ( app ), id = \"documentation-offcanvas\" , # title=\"LBAE documentation\", opened = False , padding = \"md\" , size = \"85vh\" , position = \"bottom\" , ), # Spinner when switching pages dbc . Spinner ( id = \"main-spinner\" , color = \"light\" , children = html . Div ( id = \"empty-content\" ), fullscreen = True , fullscreen_style = { \"left\" : \"6rem\" , \"background-color\" : \"#1d1c1f\" }, spinner_style = { \"width\" : \"6rem\" , \"height\" : \"6rem\" }, delay_hide = 100 , ), ], ), ], ) return main_content return_validation_layout ( main_content , initial_slice = 1 , brain = 'brain_1' ) This function compute the layout of the app, including the main container, the sidebar and the different pages. Parameters: Name Type Description Default main_content html . Div A div containing the elements of the app that are shared across pages. required initial_slice int Index of the slice to be displayed at launch. 1 Returns: Type Description html . Div A div containing the layout of the app. Source code in lbae/index.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 def return_validation_layout ( main_content , initial_slice = 1 , brain = \"brain_1\" ): \"\"\"This function compute the layout of the app, including the main container, the sidebar and the different pages. Args: main_content (html.Div): A div containing the elements of the app that are shared across pages. initial_slice (int): Index of the slice to be displayed at launch. Returns: (html.Div): A div containing the layout of the app. \"\"\" return html . Div ( [ main_content , home . layout , load_slice . return_layout ( basic_config , initial_slice ), lipid_selection . return_layout ( basic_config , initial_slice ), region_analysis . return_layout ( basic_config , initial_slice ), threeD_exploration . return_layout ( basic_config , initial_slice ), scRNAseq . return_layout ( basic_config , initial_slice , brain ), ] ) toggle_collapse ( n1 , is_open ) This callback triggers the modal windows that toggles the documentation when clicking on the corresponding button. Source code in lbae/index.py 268 269 270 271 272 273 274 275 276 277 278 279 280 @app . callback ( Output ( \"documentation-offcanvas\" , \"opened\" ), [ Input ( \"sidebar-documentation\" , \"n_clicks\" ), ], [ State ( \"documentation-offcanvas\" , \"opened\" )], ) def toggle_collapse ( n1 , is_open ): \"\"\"This callback triggers the modal windows that toggles the documentation when clicking on the corresponding button.\"\"\" if n1 : return not is_open return is_open","title":"index"},{"location":"index_py/#index.hide_slider","text":"This callback is used to hide the slider div when the user is on a page that does not need it. Source code in lbae/index.py 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 @app . callback ( Output ( \"main-paper-slider\" , \"class_name\" ), Input ( \"url\" , \"pathname\" ), prevent_initial_call = False ) def hide_slider ( pathname ): \"\"\"This callback is used to hide the slider div when the user is on a page that does not need it. \"\"\" # Pages in which the slider is displayed l_path_with_slider = [ \"/load-slice\" , \"/lipid-selection\" , \"/region-analysis\" , \"/3D-exploration\" , \"/gene-data\" , ] # Set the content according to the current pathname if pathname in l_path_with_slider : return \"\" else : return \"d-none\"","title":"hide_slider()"},{"location":"index_py/#index.hide_slider_but_leave_brain","text":"This callback is used to hide the slider but leave brain chips when needed. Source code in lbae/index.py 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 @app . callback ( Output ( \"main-slider-1\" , \"style\" ), Output ( \"main-slider-2\" , \"style\" ), Output ( \"main-text-slider\" , \"style\" ), Input ( \"url\" , \"pathname\" ), prevent_initial_call = False , ) def hide_slider_but_leave_brain ( pathname ): \"\"\"This callback is used to hide the slider but leave brain chips when needed.\"\"\" # Pages in which the slider is displayed l_path_without_slider_but_with_brain = [ \"/3D-exploration\" , \"/gene-data\" , ] # Set the content according to the current pathname if pathname in l_path_without_slider_but_with_brain : return { \"visibility\" : \"hidden\" }, { \"visibility\" : \"hidden\" }, { \"visibility\" : \"hidden\" } else : return {}, {}, {}","title":"hide_slider_but_leave_brain()"},{"location":"index_py/#index.hide_useless_slider","text":"This callback is used to update the slider indices with the selected brain. Source code in lbae/index.py 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 @app . callback ( Output ( \"main-slider-1\" , \"class_name\" ), Output ( \"main-slider-2\" , \"class_name\" ), Output ( \"main-slider-1\" , \"value\" ), Output ( \"main-slider-2\" , \"value\" ), Input ( \"main-brain\" , \"value\" ), State ( \"main-slider-1\" , \"value\" ), State ( \"main-slider-2\" , \"value\" ), prevent_initial_call = False , ) def hide_useless_slider ( brain , value_1 , value_2 ): \"\"\"This callback is used to update the slider indices with the selected brain.\"\"\" if brain == \"brain_1\" : value_1 = value_2 - data . get_slice_list ( indices = \"brain_1\" )[ - 1 ] return \"mt-2 mr-5 ml-2 mb-1 w-50\" , \"mt-2 mr-5 ml-2 mb-1 w-50 d-none\" , value_1 , value_2 elif brain == \"brain_2\" : value_2 = value_1 + data . get_slice_list ( indices = \"brain_1\" )[ - 1 ] return \"mt-2 mr-5 ml-2 mb-1 w-50 d-none\" , \"mt-2 mr-5 ml-2 mb-1 w-50\" , value_1 , value_2","title":"hide_useless_slider()"},{"location":"index_py/#index.render_page_content","text":"This callback is used as a URL router. Source code in lbae/index.py 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 @app . callback ( Output ( \"content\" , \"children\" ), Output ( \"empty-content\" , \"children\" ), Input ( \"url\" , \"pathname\" ), State ( \"main-slider\" , \"data\" ), State ( \"main-brain\" , \"value\" ), ) def render_page_content ( pathname , slice_index , brain ): \"\"\"This callback is used as a URL router.\"\"\" # Keep track of the page in the console if pathname is not None : logging . info ( \"Page\" + pathname + \" has been selected\" + logmem ()) # Set the content according to the current pathname if pathname == \"/\" : page = home . layout elif pathname == \"/load-slice\" : page = load_slice . return_layout ( basic_config , slice_index ) elif pathname == \"/lipid-selection\" : page = lipid_selection . return_layout ( basic_config , slice_index ) elif pathname == \"/region-analysis\" : page = region_analysis . return_layout ( basic_config , slice_index ) elif pathname == \"/3D-exploration\" : page = threeD_exploration . return_layout ( basic_config , slice_index ) elif pathname == \"/gene-data\" : page = scRNAseq . return_layout ( basic_config , slice_index , brain ) else : # If the user tries to reach a different page, return a 404 message page = dmc . Center ( dmc . Alert ( title = \"404: Not found\" , children = f \"The pathname { pathname } was not recognised...\" , color = \"red\" , class_name = \"mt-5\" , ), class_name = \"mt-5\" , ) return page , \"\"","title":"render_page_content()"},{"location":"index_py/#index.return_main_content","text":"This function compute the elements of the app that are shared across pages, including all the dcc.store. Returns: Type Description html . Div A div containing the corresponding elements. Source code in lbae/index.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def return_main_content (): \"\"\"This function compute the elements of the app that are shared across pages, including all the dcc.store. Returns: (html.Div): A div containing the corresponding elements. \"\"\" # List of empty lipid indexes for the dropdown of page 4, assuming brain 1 is initially selected empty_lipid_list = [ - 1 for i in data . get_slice_list ( indices = \"brain_1\" )] # Record session id in case sessions need to be individualized session_id = str ( uuid . uuid4 ()) # Define static content main_content = html . Div ( children = [ # To handle url since multi-page app dcc . Location ( id = \"url\" , refresh = False ), # Record session id, useful to trigger callbacks at initialization dcc . Store ( id = \"session-id\" , data = session_id ), # Record the slider index dcc . Store ( id = \"main-slider\" , data = 1 ), # Record the state of the range sliders for low and high resolution spectra in page 2 dcc . Store ( id = \"boundaries-low-resolution-mz-plot\" ), dcc . Store ( id = \"boundaries-high-resolution-mz-plot\" ), # Record the lipids selected in page 2 dcc . Store ( id = \"page-2-selected-lipid-1\" , data =- 1 ), dcc . Store ( id = \"page-2-selected-lipid-2\" , data =- 1 ), dcc . Store ( id = \"page-2-selected-lipid-3\" , data =- 1 ), dcc . Store ( id = \"page-2-last-selected-lipids\" , data = []), # Record the lipids selected in page 4 dcc . Store ( id = \"page-4-selected-lipid-1\" , data = empty_lipid_list ), dcc . Store ( id = \"page-4-selected-lipid-2\" , data = empty_lipid_list ), dcc . Store ( id = \"page-4-selected-lipid-3\" , data = empty_lipid_list ), dcc . Store ( id = \"page-4-last-selected-regions\" , data = []), dcc . Store ( id = \"page-4-selected-region-1\" , data = \"\" ), dcc . Store ( id = \"page-4-selected-region-2\" , data = \"\" ), dcc . Store ( id = \"page-4-selected-region-3\" , data = \"\" ), dcc . Store ( id = \"page-4-last-selected-lipids\" , data = []), # Record the shapes drawn in page 3 dcc . Store ( id = \"dcc-store-color-mask\" , data = []), dcc . Store ( id = \"dcc-store-reset\" , data = False ), dcc . Store ( id = \"dcc-store-shapes-and-masks\" , data = []), dcc . Store ( id = \"dcc-store-list-idx-lipids\" , data = []), # Record the annotated paths drawn in page 3 dcc . Store ( id = \"page-3-dcc-store-path-heatmap\" ), dcc . Store ( id = \"page-3-dcc-store-basic-figure\" , data = True ), # Record the computed spectra drawn in page 3 dcc . Store ( id = \"dcc-store-list-mz-spectra\" , data = []), # Record the lipids expressed in the region in page 3 dcc . Store ( id = \"page-3-dcc-store-lipids-region\" , data = []), # Actual app layout html . Div ( children = [ sidebar . layout , html . Div ( id = \"content\" ), dmc . Center ( id = \"main-paper-slider\" , style = { \"position\" : \"fixed\" , \"bottom\" : \"1rem\" , \"height\" : \"3rem\" , \"left\" : \"7rem\" , \"right\" : \"1rem\" , \"background-color\" : \"rgba(0, 0, 0, 0.0)\" , }, children = [ dmc . Text ( id = \"main-text-slider\" , children = \"Rostro-caudal coordinate (mm): \" , class_name = \"pr-4\" , size = \"sm\" , ), dmc . Slider ( id = \"main-slider-1\" , min = data . get_slice_list ( indices = \"brain_1\" )[ 0 ], max = data . get_slice_list ( indices = \"brain_1\" )[ - 1 ], step = 1 , marks = [ { \"value\" : slice_index , # Use x coordinate for label \"label\" : \" {:.2f} \" . format ( atlas . l_original_coor [ slice_index - 1 ][ 0 , 0 ][ 0 ] ), } for slice_index in data . get_slice_list ( indices = \"brain_1\" )[:: 3 ] ], size = \"xs\" , value = data . get_slice_list ( indices = \"brain_1\" )[ 0 ], color = \"cyan\" , class_name = \"mt-2 mr-5 ml-2 mb-1 w-50\" , ), dmc . Slider ( id = \"main-slider-2\" , min = data . get_slice_list ( indices = \"brain_2\" )[ 0 ], max = data . get_slice_list ( indices = \"brain_2\" )[ - 1 ], step = 1 , marks = [ { \"value\" : slice_index , # Use x coordinate for label \"label\" : \" {:.2f} \" . format ( atlas . l_original_coor [ slice_index - 1 ][ 0 , 0 ][ 0 ] ), } for slice_index in data . get_slice_list ( indices = \"brain_2\" )[:: 3 ] ], size = \"xs\" , value = data . get_slice_list ( indices = \"brain_2\" )[ 0 ], color = \"cyan\" , class_name = \"mt-2 mr-5 ml-2 mb-1 w-50 d-none\" , ), dmc . Chips ( id = \"main-brain\" , data = [ { \"value\" : \"brain_1\" , \"label\" : \"Brain 1\" }, { \"value\" : \"brain_2\" , \"label\" : \"Brain 2\" }, ], value = \"brain_1\" , class_name = \"pl-2 pt-1\" , color = \"cyan\" , ), ], ), # Documentation in a bottom drawer dmc . Drawer ( children = return_documentation ( app ), id = \"documentation-offcanvas\" , # title=\"LBAE documentation\", opened = False , padding = \"md\" , size = \"85vh\" , position = \"bottom\" , ), # Spinner when switching pages dbc . Spinner ( id = \"main-spinner\" , color = \"light\" , children = html . Div ( id = \"empty-content\" ), fullscreen = True , fullscreen_style = { \"left\" : \"6rem\" , \"background-color\" : \"#1d1c1f\" }, spinner_style = { \"width\" : \"6rem\" , \"height\" : \"6rem\" }, delay_hide = 100 , ), ], ), ], ) return main_content","title":"return_main_content()"},{"location":"index_py/#index.return_validation_layout","text":"This function compute the layout of the app, including the main container, the sidebar and the different pages. Parameters: Name Type Description Default main_content html . Div A div containing the elements of the app that are shared across pages. required initial_slice int Index of the slice to be displayed at launch. 1 Returns: Type Description html . Div A div containing the layout of the app. Source code in lbae/index.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 def return_validation_layout ( main_content , initial_slice = 1 , brain = \"brain_1\" ): \"\"\"This function compute the layout of the app, including the main container, the sidebar and the different pages. Args: main_content (html.Div): A div containing the elements of the app that are shared across pages. initial_slice (int): Index of the slice to be displayed at launch. Returns: (html.Div): A div containing the layout of the app. \"\"\" return html . Div ( [ main_content , home . layout , load_slice . return_layout ( basic_config , initial_slice ), lipid_selection . return_layout ( basic_config , initial_slice ), region_analysis . return_layout ( basic_config , initial_slice ), threeD_exploration . return_layout ( basic_config , initial_slice ), scRNAseq . return_layout ( basic_config , initial_slice , brain ), ] )","title":"return_validation_layout()"},{"location":"index_py/#index.toggle_collapse","text":"This callback triggers the modal windows that toggles the documentation when clicking on the corresponding button. Source code in lbae/index.py 268 269 270 271 272 273 274 275 276 277 278 279 280 @app . callback ( Output ( \"documentation-offcanvas\" , \"opened\" ), [ Input ( \"sidebar-documentation\" , \"n_clicks\" ), ], [ State ( \"documentation-offcanvas\" , \"opened\" )], ) def toggle_collapse ( n1 , is_open ): \"\"\"This callback triggers the modal windows that toggles the documentation when clicking on the corresponding button.\"\"\" if n1 : return not is_open return is_open","title":"toggle_collapse()"},{"location":"main/","text":"This script is used to run the app and setup logging settings. To run the app with gunicorn, use the following command in the main lbae folder: gunicorn main:server -b:8050 --worker-class gevent --threads 4 --workers=1 Or, to run the app ignoring hangup signals, i.e. not stopping when disconnecting from the server: nohup gunicorn main:server -b:8050 --worker-class gevent --threads 4 --workers=1 & The app will then run on http://cajal.epfl.ch:8050/ . Note that we only use one worker, as each additional worker will drastically increase the memory usage. To kill gunicorn from a linux server (if it doesn't want to die, and respawn automatically), use the following command: pkill -P1 gunicorn For a faster app, please install orjson with pip before launching the app: pip install orjson WARNING: because of a bug, Dash version >2.5.1 make long_callbacks not work anymore. because of a bug with the shelvedb, the app precomputations must be computed with Linux (not OS X).","title":"main"},{"location":"modules/atlas/","text":"This class is used to do the interface between the data coming from acquisitions (MALDI), and the Allen Brain Atlas, including the mapping with the Common Coordinate Framework v3 (CCFv3). Atlas Class used to do the interface between the data coming from acquisitions (MALDI), and the Allen Brain Atlas. Private attributes (starting with an underscore) are described as properties. Attributes: Name Type Description resolution int Resolution of the atlas. data MaldiData Used to manipulate the raw MALDI data. storage Storage Used to access the shelve database. bg_atlas BrainGlobeAtlas Used to query the Allen Brain Atlas. subsampling_block int Set the subsampling of the atlas in the longitudinal direction, to decrease the memory usage. labels Labels Used to load string annotation for contour plot, for each voxel. dic_acronym_children_id dict Dictionnary that associates, to each structure (acronym), the set of ids (int) of all of its children. array_coordinates_warped_data np . ndarray An array that contains, for each slice and each pixel coordinate, the corresponding coordinates in the CCFv3. image_shape np . ndarray An array that contains two integer values: the height and width of the slice images after warping/upscaling (these values are identical for all slices). l_nodes list Along with l_parents (below), this list of nodes can be used to rebuild the complete hierarchy of structures of the Allen Brain atlas. l_parents list See l_nodes above. dic_name_acronym dict A dictionnary that associates, to each brain region/structure name, a specific id (acronym, i.e. short label). dic_acronym_name dict A dictionnary that associates, to each brain region/structure acronym, a specific name. array_projection_correspondence_corrected np . ndarray An array that contains encodes the warping/upscaling transformation of the data. l_original_coor list(np.ndarray A list of arrays that contains the coordinates of the original data in the CCFv3. dic_existing_masks dict A dictionnary of existing masks per slice, which associates slice index (key) to a set of masks acronyms. Properties array_projection_corrected (np.ndarray): A three-dimensional array which contains the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. list_projected_atlas_borders_arrays (list(np.ndarray)): A list of arrays, one per slice, which contains the atlas borders projected on our data. Methods init (maldi_data, resolution=25, sample=False): Initialize the Atlas class. compute_dic_acronym_children_id(): Recursively compute a dictionnary that associates brain structures to the set of their children. compute_hierarchy_list(): Compute, for each children (node) structure, the corresponding parent, to build a list associating child/parent for all structures, and also compute dictionnaries that associate structure acronyms to their complete name in the process. compute_array_projection(nearest_neighbour_correction=False, atlas_correction=False): Compute three arrays relating the original coordinates of our data to their projection in the CCFv3. compute_projection_parameters(): Compute the parameters used to map the 3D coordinates of the CCFv3 to the the 2D (tiled) slices. compute_list_projected_atlas_borders_figures(): Compute an array of projected atlas borders. prepare_and_compute_array_images_atlas(zero_out_of_annotation=False): Wrapper for compute_array_images_atlas. get_atlas_mask(structure): Compute a mask for the structure given as argument. compute_spectrum_data(slice_index, projected_mask=None, mask_name=None, slice_coor_rescaled=None, MAIA_correction=False, cache_flask=None): Compute the averaged spectral data for a given slice and a given mask. save_all_projected_masks_and_spectra(force_update=False, cache_flask=None, sample=False): Save all the (2D) masks and corresponding averaged spectral data, for all the slices. get_projected_mask_and_spectrum(slice_index, mask_name, MAIA_correction=False): Get the projected mask and corresponding averaged spectral data for a given mask and slice. Source code in modules/atlas.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 class Atlas : \"\"\"Class used to do the interface between the data coming from acquisitions (MALDI), and the Allen Brain Atlas. Private attributes (starting with an underscore) are described as properties. Attributes: resolution (int): Resolution of the atlas. data (MaldiData): Used to manipulate the raw MALDI data. storage (Storage): Used to access the shelve database. bg_atlas (BrainGlobeAtlas): Used to query the Allen Brain Atlas. subsampling_block (int): Set the subsampling of the atlas in the longitudinal direction, to decrease the memory usage. labels (Labels): Used to load string annotation for contour plot, for each voxel. dic_acronym_children_id (dict): Dictionnary that associates, to each structure (acronym), the set of ids (int) of all of its children. array_coordinates_warped_data (np.ndarray): An array that contains, for each slice and each pixel coordinate, the corresponding coordinates in the CCFv3. image_shape (np.ndarray): An array that contains two integer values: the height and width of the slice images after warping/upscaling (these values are identical for all slices). l_nodes (list): Along with l_parents (below), this list of nodes can be used to rebuild the complete hierarchy of structures of the Allen Brain atlas. l_parents (list): See l_nodes above. dic_name_acronym (dict): A dictionnary that associates, to each brain region/structure name, a specific id (acronym, i.e. short label). dic_acronym_name (dict): A dictionnary that associates, to each brain region/structure acronym, a specific name. array_projection_correspondence_corrected (np.ndarray): An array that contains encodes the warping/upscaling transformation of the data. l_original_coor (list(np.ndarray)): A list of arrays that contains the coordinates of the original data in the CCFv3. dic_existing_masks (dict): A dictionnary of existing masks per slice, which associates slice index (key) to a set of masks acronyms. Properties: array_projection_corrected (np.ndarray): A three-dimensional array which contains the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. list_projected_atlas_borders_arrays (list(np.ndarray)): A list of arrays, one per slice, which contains the atlas borders projected on our data. Methods: __init__(maldi_data, resolution=25, sample=False): Initialize the Atlas class. compute_dic_acronym_children_id(): Recursively compute a dictionnary that associates brain structures to the set of their children. compute_hierarchy_list(): Compute, for each children (node) structure, the corresponding parent, to build a list associating child/parent for all structures, and also compute dictionnaries that associate structure acronyms to their complete name in the process. compute_array_projection(nearest_neighbour_correction=False, atlas_correction=False): Compute three arrays relating the original coordinates of our data to their projection in the CCFv3. compute_projection_parameters(): Compute the parameters used to map the 3D coordinates of the CCFv3 to the the 2D (tiled) slices. compute_list_projected_atlas_borders_figures(): Compute an array of projected atlas borders. prepare_and_compute_array_images_atlas(zero_out_of_annotation=False): Wrapper for compute_array_images_atlas. get_atlas_mask(structure): Compute a mask for the structure given as argument. compute_spectrum_data(slice_index, projected_mask=None, mask_name=None, slice_coor_rescaled=None, MAIA_correction=False, cache_flask=None): Compute the averaged spectral data for a given slice and a given mask. save_all_projected_masks_and_spectra(force_update=False, cache_flask=None, sample=False): Save all the (2D) masks and corresponding averaged spectral data, for all the slices. get_projected_mask_and_spectrum(slice_index, mask_name, MAIA_correction=False): Get the projected mask and corresponding averaged spectral data for a given mask and slice. \"\"\" # ============================================================================================== # --- Constructor # ============================================================================================== def __init__ ( self , maldi_data , storage , resolution = 25 , sample = False ): \"\"\"Initialize the class Atlas. Args: maldi_data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. storage (Storage): Used to access the shelve database. resolution (int): Resolution of the atlas. Default to 25. sample (bool): If True, only a fraction of the precomputations are made (for debug). Default to False. \"\"\" logging . info ( \"Initializing Atlas object\" + logmem ()) # Resolution of the atlas, to be chosen among 10um, 25um or 100um if resolution in ( 10 , 25 , 100 ): self . resolution = resolution else : logging . warning ( \"The resolution you chose is not available, using the default of 25um\" ) self . resolution = 25 # Attribute to easily access the data and the shelve db self . data = maldi_data self . storage = storage # Correct atlas resolution to 100 if sampled app if maldi_data . _sample_data : logging . info ( \"Atlas resolution set to 100um as the sampled data is used.\" ) self . resolution = 100 # Load or download the atlas if it's the first time BrainGlobeAtlas is used if maldi_data . _sample_data : brainglobe_dir = \"data_sample/atlas/\" else : brainglobe_dir = \"data/atlas/\" os . makedirs ( brainglobe_dir , exist_ok = True ) self . bg_atlas = BrainGlobeAtlas ( \"allen_mouse_\" + str ( self . resolution ) + \"um\" , brainglobe_dir = brainglobe_dir , check_latest = False , ) # Correct path for resolution appendix = \"_v1.2\" if self . resolution == 100 else \"\" # Remove the meshes in the sampled app as they're not used if maldi_data . _sample_data and \"meshes\" in os . listdir ( brainglobe_dir + \"allen_mouse_\" + str ( self . resolution ) + \"um\" + appendix ): shutil . rmtree ( brainglobe_dir + \"allen_mouse_\" + str ( self . resolution ) + \"um\" + appendix + \"/meshes\" ) # When computing an array of figures with a slider to explore the atlas, subsample in the # longitudinal direction, otherwise it's too heavy self . subsampling_block = 20 # Load string annotation for contour plot, for each voxel. # These objects are heavy (~300mb) as they force the loading of annotations from the core # Atlas class. But they shouldn't be memory-mapped as they are called when hovering and # require very fast response from the server self . labels = Labels ( self . bg_atlas , force_init = True ) # Compute a dictionnary that associates to each structure (acronym) the set of ids (int) of # all of its children. Used only in page_4_plot_graph_volume, but it's very light (~3mb) so # no problem using it as an attribute self . dic_acronym_children_id = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"dic_acronym_children_id\" , force_update = False , compute_function = self . compute_dic_acronym_children_id , ) # Load array of coordinates for warped data (can't be loaded on the fly from shelve as used # with hovering). Weights ~225mb if maldi_data . _sample_data : with np . load ( \"data_sample/tiff_files/coordinates_warped_data.npz\" ) as handle : self . array_coordinates_warped_data = handle [ \"array_coordinates_warped_data\" ] else : self . array_coordinates_warped_data = skimage . io . imread ( \"data/tiff_files/coordinates_warped_data.tif\" ) # Record shape of the warped data self . image_shape = list ( self . array_coordinates_warped_data . shape [ 1 : - 1 ]) # Record dict that associate brain region (complete string) to specific id (short label), # along with graph of structures (l_nodes and l_parents). Although the treemap graph is # precomputed, the two dics of name and acronyms are relatively lightweight and are used in # many different place, so they shouldn't be used a properties ( self . l_nodes , self . l_parents , self . dic_name_acronym , self . dic_acronym_name , ) = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"hierarchy\" , force_update = False , compute_function = self . compute_hierarchy_list , ) # Array_projection_corrected is used a lot for lipid expression plots, as it encodes the # warping transformation of the data. Therefore it shouldn't be used a as a property. # Weights ~150mb # * The type is np.int16, and can't be reduced anymore as values are sometimes above 400 self . array_projection_correspondence_corrected = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"arrays_projection_corrected\" , force_update = False , compute_function = self . compute_array_projection , nearest_neighbour_correction = True , atlas_correction = True , )[ 1 ] # Load arrays of original images coordinates. It is used everytime a 3D object is computed. # Weights ~50mb self . l_original_coor = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"arrays_projection_corrected\" , force_update = False , compute_function = self . compute_array_projection , nearest_neighbour_correction = True , atlas_correction = True , )[ 2 ] # Dictionnary of existing masks per slice, which associates slice index (key) to a set of # masks acronyms if self . storage . check_shelved_object ( \"atlas/atlas_objects\" , \"dic_existing_masks\" ): self . dic_existing_masks = self . storage . load_shelved_object ( \"atlas/atlas_objects\" , \"dic_existing_masks\" ) else : logging . info ( \"The dictionnary of available mask per slice has not been computed yet. \" + \"Doing it now, this may take several hours.\" ) # Since this function is called at startup, no data locking is needed self . save_all_projected_masks_and_spectra ( cache_flask = None , sample = sample ) # These attributes are defined later as properties as they are only used during # precomputations self . _array_projection_corrected = None self . _list_projected_atlas_borders_arrays = None logging . info ( \"Atlas object instantiated\" + logmem ()) # ============================================================================================== # --- Properties # ============================================================================================== @property def array_projection_corrected ( self ): \"\"\"Load arrays of images using atlas projection. It's a property to save memory as it is only used with objects that should also be precomputed. Returns: (np.ndarray): A three-dimensional array which contains the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. \"\"\" if self . _array_projection_corrected is None : logging . info ( \"array_projection_corrected is being loaded. This should only happen during\" \" precomputations.\" + logmem () ) self . _array_projection_corrected = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"arrays_projection_corrected\" , force_update = False , compute_function = self . compute_array_projection , nearest_neighbour_correction = True , atlas_correction = True , )[ 0 ] return self . _array_projection_corrected @property def list_projected_atlas_borders_arrays ( self ): \"\"\"Load array of projected atlas borders (i.e. image of atlas annotations). It's a property to save memory as it is only used with objects that should also be precomputed. Returns: (list(np.ndarray)): A list of arrays, one per slice, which contains the atlas borders projected on our data. \"\"\" if self . _list_projected_atlas_borders_arrays is None : logging . info ( \"list_projected_atlas_borders_arrays is being loaded. This should only happen\" \" during precomputations.\" + logmem () ) self . _list_projected_atlas_borders_arrays = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"list_projected_atlas_borders_arrays\" , force_update = False , compute_function = self . compute_list_projected_atlas_borders_figures , ) return self . _list_projected_atlas_borders_arrays # ============================================================================================== # --- Methods # ============================================================================================== def compute_dic_acronym_children_id ( self ): \"\"\"Recursively compute a dictionnary that associates brain structures to the set of their children. Returns: (dict): A dictionnary that associate to each structure (acronym) the set of ids (int) of all of its children. \"\"\" # Recursive function to compute the parent of each structure def fill_dic_acronym_children_id ( dic_acronym_children_id , l_id_leaves ): older_leave_id = l_id_leaves [ 0 ] acronym = self . bg_atlas . structures [ older_leave_id ][ \"acronym\" ] for id_leave in l_id_leaves : # Fill dic with current acronym and id if acronym in dic_acronym_children_id : dic_acronym_children_id [ acronym ] . add ( id_leave ) else : dic_acronym_children_id [ acronym ] = set ([ id_leave ]) # While root is not reached, climb back the ancestor tree if len ( self . bg_atlas . structures [ older_leave_id ][ \"structure_id_path\" ]) >= 2 : id_parent = self . bg_atlas . structures [ older_leave_id ][ \"structure_id_path\" ][ - 2 ] dic_acronym_children_id = fill_dic_acronym_children_id ( dic_acronym_children_id , [ id_parent ] + l_id_leaves ) return dic_acronym_children_id # Initialize dictionnary as empty dic_acronym_children_id = {} # Loop over each structure for id in set ( self . bg_atlas . annotation . flatten ()): if id != 0 : # Fill the dictionnary by climbing up the hierarchy structure dic_acronym_children_id = fill_dic_acronym_children_id ( dic_acronym_children_id , [ id ] ) return dic_acronym_children_id def compute_hierarchy_list ( self ): \"\"\"Compute, for each children (node), the corresponding parent, to build a list associating child/parent for all structures, and also compute dictionnaries that associate structure acronyms to their complete name in the process. Returns: (list(str)): List of children (node) names. (list(str)): List of parent names. (dict): A dictionnary that associate structure name to its acronym. (dict): A dictionnary that associate structure acronym to its name. \"\"\" # Create a list of parents for all ancestors l_nodes = [] l_parents = [] dic_name_acronym = {} dic_acronym_name = {} idx = 0 # Loop over each structure for x , v in self . bg_atlas . structures . items (): # Keep only a very restrained amount of structures if sample data if ( self . data . _sample_data and len ( self . bg_atlas . get_structure_ancestors ( v [ \"acronym\" ])) > 1 ): continue if len ( self . bg_atlas . get_structure_ancestors ( v [ \"acronym\" ])) > 0 : ancestor_acronym = self . bg_atlas . get_structure_ancestors ( v [ \"acronym\" ])[ - 1 ] ancestor_name = self . bg_atlas . structures [ ancestor_acronym ][ \"name\" ] else : ancestor_name = \"\" current_name = self . bg_atlas . structures [ x ][ \"name\" ] l_nodes . append ( current_name ) l_parents . append ( ancestor_name ) # Register the name/acronym association for each structure dic_name_acronym [ current_name ] = v [ \"acronym\" ] dic_acronym_name [ v [ \"acronym\" ]] = current_name return l_nodes , l_parents , dic_name_acronym , dic_acronym_name def compute_array_projection ( self , nearest_neighbour_correction = False , atlas_correction = False ): \"\"\"Compute three arrays relating the original coordinates of our data to their projection in the CCFv3. Args: nearest_neighbour_correction (bool, optional): If True, the gaps due to the warping and upscaling of the projection are filled with a heuristic method. Defaults to False. atlas_correction (bool, optional): If True, the pixels that are outside of any annotated region are zeroed out. Defaults to False. Returns: (np.ndarray, np.ndarray, list(np.ndarray)): The first array is a high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, which acts as a mapping table. The list contains the arrays of original coordinates, for each slice. \"\"\" # Start with empty array array_projection = np . zeros ( self . array_coordinates_warped_data . shape [: - 1 ], dtype = np . int16 ) array_projection_filling = np . zeros ( array_projection . shape , dtype = np . int16 ) # This array makes the correspondence between the original data coordinates and the new ones array_projection_correspondence = np . zeros ( array_projection . shape + ( 2 ,), dtype = np . int16 ) array_projection_correspondence . fill ( - 1 ) # List of orginal coordinates l_original_coor = [] l_transform_parameters = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"l_transform_parameters\" , force_update = False , compute_function = self . compute_projection_parameters , ) for i in range ( array_projection . shape [ 0 ]): # Get transform parameters a , u , v = l_transform_parameters [ i ] # Load corresponding slice and coor if self . data . _sample_data : path = \"data_sample/tiff_files/coordinates_original_data/\" else : path = \"data/tiff_files/coordinates_original_data/\" filename = ( path + [ x for x in os . listdir ( path ) if str ( i + 1 ) == x . split ( \"_\" )[ 1 ] . split ( \"-\" )[ 0 ]][ 0 ] ) if self . data . _sample_data : original_coor = np . load ( filename ) else : original_coor = skimage . io . imread ( filename ) l_original_coor . append ( original_coor ) if self . data . _sample_data : path = \"data_sample/tiff_files/original_data/\" else : path = \"data/tiff_files/original_data/\" filename = ( path + [ x for x in os . listdir ( path ) if str ( i + 1 ) == x . split ( \"slice_\" )[ 1 ] . split ( \".tiff\" )[ 0 ] ][ 0 ] ) original_slice = np . array ( skimage . io . imread ( filename ), dtype = np . uint8 ) # Keep only last channel if not self . data . _sample_data : original_slice = original_slice [:, :, 2 ] # Map back the pixel from the atlas coordinates array_projection , array_projection_correspondence = fill_array_projection ( i , array_projection , array_projection_filling , array_projection_correspondence , original_coor , self . resolution , a , u , v , original_slice , self . array_coordinates_warped_data [ i ], self . bg_atlas . annotation , nearest_neighbour_correction = nearest_neighbour_correction , atlas_correction = atlas_correction , sample_data = self . data . _sample_data , ) return array_projection , array_projection_correspondence , l_original_coor def compute_projection_parameters ( self ): \"\"\"Compute the parameters used to map the 3D coordinates of the CCFv3 to the the 2D (tiled) slices. Returns: (list((float,float,float))): A list of tuples, each with three parameters, that allow to map the 3D coordinates of the CCFv3 to the tiled planes representing the slices. One per slice. \"\"\" l_transform_parameters = [] for slice_index in range ( self . array_coordinates_warped_data . shape [ 0 ]): a_atlas , u_atlas , v_atlas = solve_plane_equation ( self . array_coordinates_warped_data [ slice_index ] ) l_transform_parameters . append (( a_atlas , u_atlas , v_atlas )) return l_transform_parameters def compute_list_projected_atlas_borders_figures ( self ): \"\"\"Compute an array of projected atlas borders (i.e. image of atlas annotations). Returns: (list(np.ndarray)): A list of arrays, one per slice, which contains the atlas borders projected on our data. \"\"\" l_array_images = [] # Load array of atlas images corresponding to our data and how it is projected ( array_projected_images_atlas , array_projected_simplified_id , ) = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"array_images_atlas\" , force_update = False , compute_function = self . prepare_and_compute_array_images_atlas , zero_out_of_annotation = True , ) # Loop over slice, compute image every time for slice_index in range ( array_projected_simplified_id . shape [ 0 ]): contours = ( array_projected_simplified_id [ slice_index , 1 :, 1 :] - array_projected_simplified_id [ slice_index , : - 1 , : - 1 ] ) contours = np . clip ( contours ** 2 , 0 , 1 ) contours = np . pad ( contours , (( 1 , 0 ), ( 1 , 0 ))) # Do some cleaning on the sides contours [:, : 10 ] = 0 contours [:, - 10 :] = 0 contours [: 10 , :] = 0 contours [ - 10 :, :] = 0 # Compute a matplolib figure and export it as image (it's a hack but it does the job) fig = plt . figure ( frameon = False ) dpi = 100 fig . set_size_inches ( contours . shape [ 1 ] / dpi , contours . shape [ 0 ] / dpi ) ax = fig . add_axes ([ 0 , 0 , 1 , 1 ]) ax . axis ( \"off\" ) prefix = \"data:image/png;base64,\" plt . contour ( contours , colors = \"orange\" , antialiased = True , linewidths = 0.2 , origin = \"image\" ) with BytesIO () as stream : plt . savefig ( stream , format = \"png\" , dpi = dpi ) plt . close () img = imread ( io . BytesIO ( stream . getvalue ())) l_array_images . append ( img ) return l_array_images # * This is quite long to execute (~10mn) def prepare_and_compute_array_images_atlas ( self , zero_out_of_annotation = False ): \"\"\"This function is mainly a wrapper for compute_array_images_atlas. It is needed as the computation of an array of simplified structures ids can't be compiled with numba. Args: zero_out_of_annotation (bool, optional): If True, the pixels outside of the atlas annotations are zero-ed out. Defaults to False. Returns: (np.ndarray, np.ndarray): The first array is basically a list of atlas images corresponding to the slices acquired during the MALDI acquisition. The second array is the corresponding set of annotations. \"\"\" # Compute an array of simplified structures ids simplified_atlas_annotation = compute_simplified_atlas_annotation ( self . bg_atlas . annotation ) # Compute the actual array of atlas images return compute_array_images_atlas ( self . array_coordinates_warped_data , simplified_atlas_annotation , self . bg_atlas . reference , self . resolution , zero_out_of_annotation = zero_out_of_annotation , ) def get_atlas_mask ( self , structure ): \"\"\"Compute a mask for the structure given as argument. The brain regions corresponding to the structure id or any of its descendants are set to the id of the structure. The rest is set to 0. Args: structure (str): Structure (brain region) acronym. Returns: (np.ndarray): A 3D mask with the same shape as the array of annotations from the atlas, where all elements are zeros except for the requested structure. \"\"\" logging . info ( 'Getting mask for structure \" {} \"' . format ( structure )) # Get id of the parent structure structure_id = self . bg_atlas . structures [ structure ][ \"id\" ] # Get list of descendants descendants = self . bg_atlas . get_structure_descendants ( structure ) # Build empty mask for 3D array of atlas annotations mask_stack = np . zeros ( self . bg_atlas . shape , self . bg_atlas . annotation . dtype ) # Compute a list of ids (parent + children) we want to keep in the final annotation l_id = [ self . bg_atlas . structures [ descendant ][ \"id\" ] for descendant in descendants ] + [ structure_id ] # Do the masking mask_stack [ np . isin ( self . bg_atlas . annotation , l_id )] = structure_id logging . info ( 'Mask computed for structure \" {} \"' . format ( structure )) return mask_stack def compute_spectrum_data ( self , slice_index , projected_mask = None , mask_name = None , slice_coor_rescaled = None , MAIA_correction = False , cache_flask = None , ): \"\"\"This function computes the averaged spectral data for a given slice and a given mask, the latter being provided either as a mask name, either as an array (at least one of the two must not be None). If the mask is provided as an array, the corresponding array of slice coordinates (slice_coor_rescaled) must be provided. Args: slice_index (int): Index of the requested slice. projected_mask (np.ndarray, optional): A two-dimensional array representing the projected mask on the requested slice. Defaults to None. mask_name (str, optional): Acronym of the requestes mask. Defaults to None. slice_coor_rescaled (np.ndarray, optional): The array of coordinates in the CCFv3 for the current slice. Defaults to None. MAIA_correction (bool, optional): If True, the MAIA corrected version of the MALDI data is used for computation (if it exists). Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (np.ndarray): A 2D numpy array containing the averaged spectral data of the pixels in the requested mask of the requested slice. First row contains m/z values, second row contains the averaged intensities. \"\"\" # Control that a mask can be provided one way or the other if projected_mask is None and mask_name is None : print ( \"Either a mask or a mask name must be provided\" ) return None # If a mask name has been provided, get the corresponding mask array elif mask_name is not None : if slice_coor_rescaled is None : slice_coor_rescaled = np . asarray ( ( self . array_coordinates_warped_data [ slice_index , :, :] * 1000 / self . resolution ) . round ( 0 ), dtype = np . int16 , ) stack_mask = self . get_atlas_mask ( self . dic_name_acronym [ mask_name ]) projected_mask = project_atlas_mask ( stack_mask , slice_coor_rescaled , self . bg_atlas . reference . shape ) # Get the list of rows containing the pixels to average original_shape = self . data . get_image_shape ( slice_index + 1 ) mask_remapped = np . zeros ( original_shape , dtype = np . uint8 ) list_index_bound_rows , list_index_bound_column_per_row = get_array_rows_from_atlas_mask ( projected_mask , mask_remapped , self . array_projection_correspondence_corrected [ slice_index ], ) if np . sum ( list_index_bound_rows ) == 0 : print ( \"No selection could be found for current mask\" ) grah_scattergl_data = None else : # Do the average grah_scattergl_data = compute_thread_safe_function ( compute_spectrum_per_row_selection , cache_flask , self . data , slice_index + 1 , list_index_bound_rows , list_index_bound_column_per_row , self . data . get_array_spectra ( slice_index + 1 ), self . data . get_array_lookup_pixels ( slice_index + 1 ), original_shape , self . data . get_array_peaks_transformed_lipids ( slice_index + 1 ), self . data . get_array_corrective_factors ( slice_index + 1 ) . astype ( np . float32 ), zeros_extend = False , apply_correction = MAIA_correction , ) return grah_scattergl_data def save_all_projected_masks_and_spectra ( self , force_update = False , cache_flask = None , sample = False ): \"\"\"This function saves all the (2D) masks and corresponding averaged spectral data, for all the slices. Args: force_update (bool, optional): If True, the function will not overwrite existing files. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. sample (bool, optional): If True, only a tiny sample of the masks will be processed (for debug). Defaults to False. \"\"\" # Path atlas for shelving path_atlas = \"atlas/atlas_objects\" # Sample for debug if sample : logging . warning ( \"Only a sample of the masks and spectra will be computed!\" ) # Define a dictionnary that contains all the masks that exist for every slice dic_existing_masks = {} # Define a dictionnary to save the result of the function slice by slice if self . storage . check_shelved_object ( path_atlas , \"dic_processed_temp\" ): dic_processed_temp = self . storage . load_shelved_object ( path_atlas , \"dic_processed_temp\" , ) else : dic_processed_temp = {} for slice_index in range ( self . data . get_slice_number ()): # Break the loop after the first slice if sample is True if sample and slice_index > 1 : break logging . info ( \"Starting slice \" + str ( slice_index )) slice_coor_rescaled = np . asarray ( ( self . array_coordinates_warped_data [ slice_index , :, :] * 1000 / self . resolution ) . round ( 0 ), dtype = np . int16 , ) dic_existing_masks [ slice_index ] = set ([]) # Check if the slice has already been processed if slice_index not in dic_processed_temp : dic_processed_temp [ slice_index ] = set ([]) # Get hierarchical tree of brain structures n_computed = 0 for mask_name , id_mask in self . dic_name_acronym . items (): if id_mask not in dic_processed_temp [ slice_index ]: # Break the loop after a few computations if sample is True if sample and n_computed > 1 : break if ( not ( self . storage . check_shelved_object ( path_atlas , \"mask_and_spectrum_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ) and self . storage . check_shelved_object ( path_atlas , \"mask_and_spectrum_MAIA_corrected_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ) ) or force_update ): # get the array corresponding to the projected mask stack_mask = self . get_atlas_mask ( id_mask ) # Project the mask onto high resolution data projected_mask = project_atlas_mask ( stack_mask , slice_coor_rescaled , self . bg_atlas . reference . shape ) if np . sum ( projected_mask ) == 0 : logging . info ( \"The structure \" + mask_name + \" is not present in slice \" + str ( slice_index ) ) # Mask doesn't exist, so it considered processed dic_processed_temp [ slice_index ] . add ( id_mask ) continue # Compute average spectrum in the mask grah_scattergl_data = self . compute_spectrum_data ( slice_index , projected_mask , MAIA_correction = False , cache_flask = cache_flask , ) # Add mask to the list of existing masks dic_existing_masks [ slice_index ] . add ( id_mask ) dic_processed_temp [ slice_index ] . add ( id_mask ) # Dump the mask and data with shelve self . storage . dump_shelved_object ( path_atlas , \"mask_and_spectrum_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ( projected_mask , grah_scattergl_data ), ) # Same with MAIA corrected data grah_scattergl_data = self . compute_spectrum_data ( slice_index , projected_mask , MAIA_correction = True , cache_flask = cache_flask , ) self . storage . dump_shelved_object ( path_atlas , \"mask_and_spectrum_MAIA_corrected_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ( projected_mask , grah_scattergl_data ), ) else : # Add computed masks to the dics of computed masks dic_existing_masks [ slice_index ] . add ( id_mask ) dic_processed_temp [ slice_index ] . add ( id_mask ) n_computed += 1 else : n_computed += 1 logging . info ( 'Mask \"' + mask_name + '\" already processed' ) # Dump the dictionnary of processed masks with shelve after every slice self . storage . dump_shelved_object ( path_atlas , \"dic_processed_temp\" , dic_processed_temp , ) if not sample : # Dump the dictionnary of existing masks with shelve self . storage . dump_shelved_object ( path_atlas , \"dic_existing_masks\" , dic_existing_masks , ) logging . info ( \"Projected masks and spectra have all been computed.\" ) self . dic_existing_masks = dic_existing_masks def get_projected_mask_and_spectrum ( self , slice_index , mask_name , MAIA_correction = False ): \"\"\"This function is used to get the projected mask and corresponding averaged spectral data for a given mask and a given slice. Args: slice_index (int): Index of the requested slice. mask_name (str): Acronym of the requested mask. MAIA_correction (bool, optional): If True, the MAIA corrected version of the MALDI data is used for computation (if it exists). Defaults to False. Returns: (np.ndarray, np.ndarray): The first array is represents the projected 2D mask on the requested slice. The second array corresponds to the corresponding averaged spectral data (first row is m/z values, second row is averaged intensities). \"\"\" id_mask = self . dic_name_acronym [ mask_name ] if MAIA_correction : filename = ( \"mask_and_spectrum_MAIA_corrected_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ) ) else : filename = \"mask_and_spectrum_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ) logging . info ( \"Loading \" + mask_name + \" for slice \" + str ( slice_index ) + \" from shelve file.\" ) try : return self . storage . load_shelved_object ( \"atlas/atlas_objects\" , filename ) except : logging . warning ( \"The mask and spectrum data could not be found for \" + mask_name + \" for slice \" + str ( slice_index ) + \". Make sure the files have been precomputed and that you checked the mask\" + \" was present in self.dic_existing_masks\" ) return None __init__ ( maldi_data , storage , resolution = 25 , sample = False ) Initialize the class Atlas. Parameters: Name Type Description Default maldi_data MaldiData MaldiData object, used to manipulate the raw MALDI data. required storage Storage Used to access the shelve database. required resolution int Resolution of the atlas. Default to 25. 25 sample bool If True, only a fraction of the precomputations are made (for debug). Default to False. False Source code in modules/atlas.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 def __init__ ( self , maldi_data , storage , resolution = 25 , sample = False ): \"\"\"Initialize the class Atlas. Args: maldi_data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. storage (Storage): Used to access the shelve database. resolution (int): Resolution of the atlas. Default to 25. sample (bool): If True, only a fraction of the precomputations are made (for debug). Default to False. \"\"\" logging . info ( \"Initializing Atlas object\" + logmem ()) # Resolution of the atlas, to be chosen among 10um, 25um or 100um if resolution in ( 10 , 25 , 100 ): self . resolution = resolution else : logging . warning ( \"The resolution you chose is not available, using the default of 25um\" ) self . resolution = 25 # Attribute to easily access the data and the shelve db self . data = maldi_data self . storage = storage # Correct atlas resolution to 100 if sampled app if maldi_data . _sample_data : logging . info ( \"Atlas resolution set to 100um as the sampled data is used.\" ) self . resolution = 100 # Load or download the atlas if it's the first time BrainGlobeAtlas is used if maldi_data . _sample_data : brainglobe_dir = \"data_sample/atlas/\" else : brainglobe_dir = \"data/atlas/\" os . makedirs ( brainglobe_dir , exist_ok = True ) self . bg_atlas = BrainGlobeAtlas ( \"allen_mouse_\" + str ( self . resolution ) + \"um\" , brainglobe_dir = brainglobe_dir , check_latest = False , ) # Correct path for resolution appendix = \"_v1.2\" if self . resolution == 100 else \"\" # Remove the meshes in the sampled app as they're not used if maldi_data . _sample_data and \"meshes\" in os . listdir ( brainglobe_dir + \"allen_mouse_\" + str ( self . resolution ) + \"um\" + appendix ): shutil . rmtree ( brainglobe_dir + \"allen_mouse_\" + str ( self . resolution ) + \"um\" + appendix + \"/meshes\" ) # When computing an array of figures with a slider to explore the atlas, subsample in the # longitudinal direction, otherwise it's too heavy self . subsampling_block = 20 # Load string annotation for contour plot, for each voxel. # These objects are heavy (~300mb) as they force the loading of annotations from the core # Atlas class. But they shouldn't be memory-mapped as they are called when hovering and # require very fast response from the server self . labels = Labels ( self . bg_atlas , force_init = True ) # Compute a dictionnary that associates to each structure (acronym) the set of ids (int) of # all of its children. Used only in page_4_plot_graph_volume, but it's very light (~3mb) so # no problem using it as an attribute self . dic_acronym_children_id = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"dic_acronym_children_id\" , force_update = False , compute_function = self . compute_dic_acronym_children_id , ) # Load array of coordinates for warped data (can't be loaded on the fly from shelve as used # with hovering). Weights ~225mb if maldi_data . _sample_data : with np . load ( \"data_sample/tiff_files/coordinates_warped_data.npz\" ) as handle : self . array_coordinates_warped_data = handle [ \"array_coordinates_warped_data\" ] else : self . array_coordinates_warped_data = skimage . io . imread ( \"data/tiff_files/coordinates_warped_data.tif\" ) # Record shape of the warped data self . image_shape = list ( self . array_coordinates_warped_data . shape [ 1 : - 1 ]) # Record dict that associate brain region (complete string) to specific id (short label), # along with graph of structures (l_nodes and l_parents). Although the treemap graph is # precomputed, the two dics of name and acronyms are relatively lightweight and are used in # many different place, so they shouldn't be used a properties ( self . l_nodes , self . l_parents , self . dic_name_acronym , self . dic_acronym_name , ) = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"hierarchy\" , force_update = False , compute_function = self . compute_hierarchy_list , ) # Array_projection_corrected is used a lot for lipid expression plots, as it encodes the # warping transformation of the data. Therefore it shouldn't be used a as a property. # Weights ~150mb # * The type is np.int16, and can't be reduced anymore as values are sometimes above 400 self . array_projection_correspondence_corrected = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"arrays_projection_corrected\" , force_update = False , compute_function = self . compute_array_projection , nearest_neighbour_correction = True , atlas_correction = True , )[ 1 ] # Load arrays of original images coordinates. It is used everytime a 3D object is computed. # Weights ~50mb self . l_original_coor = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"arrays_projection_corrected\" , force_update = False , compute_function = self . compute_array_projection , nearest_neighbour_correction = True , atlas_correction = True , )[ 2 ] # Dictionnary of existing masks per slice, which associates slice index (key) to a set of # masks acronyms if self . storage . check_shelved_object ( \"atlas/atlas_objects\" , \"dic_existing_masks\" ): self . dic_existing_masks = self . storage . load_shelved_object ( \"atlas/atlas_objects\" , \"dic_existing_masks\" ) else : logging . info ( \"The dictionnary of available mask per slice has not been computed yet. \" + \"Doing it now, this may take several hours.\" ) # Since this function is called at startup, no data locking is needed self . save_all_projected_masks_and_spectra ( cache_flask = None , sample = sample ) # These attributes are defined later as properties as they are only used during # precomputations self . _array_projection_corrected = None self . _list_projected_atlas_borders_arrays = None logging . info ( \"Atlas object instantiated\" + logmem ()) array_projection_corrected () property Load arrays of images using atlas projection. It's a property to save memory as it is only used with objects that should also be precomputed. Returns: Type Description np . ndarray A three-dimensional array which contains the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. Source code in modules/atlas.py 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 @property def array_projection_corrected ( self ): \"\"\"Load arrays of images using atlas projection. It's a property to save memory as it is only used with objects that should also be precomputed. Returns: (np.ndarray): A three-dimensional array which contains the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. \"\"\" if self . _array_projection_corrected is None : logging . info ( \"array_projection_corrected is being loaded. This should only happen during\" \" precomputations.\" + logmem () ) self . _array_projection_corrected = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"arrays_projection_corrected\" , force_update = False , compute_function = self . compute_array_projection , nearest_neighbour_correction = True , atlas_correction = True , )[ 0 ] return self . _array_projection_corrected compute_array_projection ( nearest_neighbour_correction = False , atlas_correction = False ) Compute three arrays relating the original coordinates of our data to their projection in the CCFv3. Parameters: Name Type Description Default nearest_neighbour_correction bool If True, the gaps due to the warping and upscaling of the projection are filled with a heuristic method. Defaults to False. False atlas_correction bool If True, the pixels that are outside of any annotated region are zeroed out. Defaults to False. False Returns: Type Description np . ndarray , np . ndarray , list ( np . ndarray ) The first array is a high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, which acts as a mapping table. The list contains the arrays of original coordinates, for each slice. Source code in modules/atlas.py 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 def compute_array_projection ( self , nearest_neighbour_correction = False , atlas_correction = False ): \"\"\"Compute three arrays relating the original coordinates of our data to their projection in the CCFv3. Args: nearest_neighbour_correction (bool, optional): If True, the gaps due to the warping and upscaling of the projection are filled with a heuristic method. Defaults to False. atlas_correction (bool, optional): If True, the pixels that are outside of any annotated region are zeroed out. Defaults to False. Returns: (np.ndarray, np.ndarray, list(np.ndarray)): The first array is a high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, which acts as a mapping table. The list contains the arrays of original coordinates, for each slice. \"\"\" # Start with empty array array_projection = np . zeros ( self . array_coordinates_warped_data . shape [: - 1 ], dtype = np . int16 ) array_projection_filling = np . zeros ( array_projection . shape , dtype = np . int16 ) # This array makes the correspondence between the original data coordinates and the new ones array_projection_correspondence = np . zeros ( array_projection . shape + ( 2 ,), dtype = np . int16 ) array_projection_correspondence . fill ( - 1 ) # List of orginal coordinates l_original_coor = [] l_transform_parameters = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"l_transform_parameters\" , force_update = False , compute_function = self . compute_projection_parameters , ) for i in range ( array_projection . shape [ 0 ]): # Get transform parameters a , u , v = l_transform_parameters [ i ] # Load corresponding slice and coor if self . data . _sample_data : path = \"data_sample/tiff_files/coordinates_original_data/\" else : path = \"data/tiff_files/coordinates_original_data/\" filename = ( path + [ x for x in os . listdir ( path ) if str ( i + 1 ) == x . split ( \"_\" )[ 1 ] . split ( \"-\" )[ 0 ]][ 0 ] ) if self . data . _sample_data : original_coor = np . load ( filename ) else : original_coor = skimage . io . imread ( filename ) l_original_coor . append ( original_coor ) if self . data . _sample_data : path = \"data_sample/tiff_files/original_data/\" else : path = \"data/tiff_files/original_data/\" filename = ( path + [ x for x in os . listdir ( path ) if str ( i + 1 ) == x . split ( \"slice_\" )[ 1 ] . split ( \".tiff\" )[ 0 ] ][ 0 ] ) original_slice = np . array ( skimage . io . imread ( filename ), dtype = np . uint8 ) # Keep only last channel if not self . data . _sample_data : original_slice = original_slice [:, :, 2 ] # Map back the pixel from the atlas coordinates array_projection , array_projection_correspondence = fill_array_projection ( i , array_projection , array_projection_filling , array_projection_correspondence , original_coor , self . resolution , a , u , v , original_slice , self . array_coordinates_warped_data [ i ], self . bg_atlas . annotation , nearest_neighbour_correction = nearest_neighbour_correction , atlas_correction = atlas_correction , sample_data = self . data . _sample_data , ) return array_projection , array_projection_correspondence , l_original_coor compute_dic_acronym_children_id () Recursively compute a dictionnary that associates brain structures to the set of their children. Returns: Type Description dict A dictionnary that associate to each structure (acronym) the set of ids (int) of all of its children. Source code in modules/atlas.py 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 def compute_dic_acronym_children_id ( self ): \"\"\"Recursively compute a dictionnary that associates brain structures to the set of their children. Returns: (dict): A dictionnary that associate to each structure (acronym) the set of ids (int) of all of its children. \"\"\" # Recursive function to compute the parent of each structure def fill_dic_acronym_children_id ( dic_acronym_children_id , l_id_leaves ): older_leave_id = l_id_leaves [ 0 ] acronym = self . bg_atlas . structures [ older_leave_id ][ \"acronym\" ] for id_leave in l_id_leaves : # Fill dic with current acronym and id if acronym in dic_acronym_children_id : dic_acronym_children_id [ acronym ] . add ( id_leave ) else : dic_acronym_children_id [ acronym ] = set ([ id_leave ]) # While root is not reached, climb back the ancestor tree if len ( self . bg_atlas . structures [ older_leave_id ][ \"structure_id_path\" ]) >= 2 : id_parent = self . bg_atlas . structures [ older_leave_id ][ \"structure_id_path\" ][ - 2 ] dic_acronym_children_id = fill_dic_acronym_children_id ( dic_acronym_children_id , [ id_parent ] + l_id_leaves ) return dic_acronym_children_id # Initialize dictionnary as empty dic_acronym_children_id = {} # Loop over each structure for id in set ( self . bg_atlas . annotation . flatten ()): if id != 0 : # Fill the dictionnary by climbing up the hierarchy structure dic_acronym_children_id = fill_dic_acronym_children_id ( dic_acronym_children_id , [ id ] ) return dic_acronym_children_id compute_hierarchy_list () Compute, for each children (node), the corresponding parent, to build a list associating child/parent for all structures, and also compute dictionnaries that associate structure acronyms to their complete name in the process. Returns: Type Description list ( str ) List of children (node) names. list ( str ) List of parent names. dict A dictionnary that associate structure name to its acronym. dict A dictionnary that associate structure acronym to its name. Source code in modules/atlas.py 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 def compute_hierarchy_list ( self ): \"\"\"Compute, for each children (node), the corresponding parent, to build a list associating child/parent for all structures, and also compute dictionnaries that associate structure acronyms to their complete name in the process. Returns: (list(str)): List of children (node) names. (list(str)): List of parent names. (dict): A dictionnary that associate structure name to its acronym. (dict): A dictionnary that associate structure acronym to its name. \"\"\" # Create a list of parents for all ancestors l_nodes = [] l_parents = [] dic_name_acronym = {} dic_acronym_name = {} idx = 0 # Loop over each structure for x , v in self . bg_atlas . structures . items (): # Keep only a very restrained amount of structures if sample data if ( self . data . _sample_data and len ( self . bg_atlas . get_structure_ancestors ( v [ \"acronym\" ])) > 1 ): continue if len ( self . bg_atlas . get_structure_ancestors ( v [ \"acronym\" ])) > 0 : ancestor_acronym = self . bg_atlas . get_structure_ancestors ( v [ \"acronym\" ])[ - 1 ] ancestor_name = self . bg_atlas . structures [ ancestor_acronym ][ \"name\" ] else : ancestor_name = \"\" current_name = self . bg_atlas . structures [ x ][ \"name\" ] l_nodes . append ( current_name ) l_parents . append ( ancestor_name ) # Register the name/acronym association for each structure dic_name_acronym [ current_name ] = v [ \"acronym\" ] dic_acronym_name [ v [ \"acronym\" ]] = current_name return l_nodes , l_parents , dic_name_acronym , dic_acronym_name compute_list_projected_atlas_borders_figures () Compute an array of projected atlas borders (i.e. image of atlas annotations). Returns: Type Description list ( np . ndarray ) A list of arrays, one per slice, which contains the atlas borders projected on our data. Source code in modules/atlas.py 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 def compute_list_projected_atlas_borders_figures ( self ): \"\"\"Compute an array of projected atlas borders (i.e. image of atlas annotations). Returns: (list(np.ndarray)): A list of arrays, one per slice, which contains the atlas borders projected on our data. \"\"\" l_array_images = [] # Load array of atlas images corresponding to our data and how it is projected ( array_projected_images_atlas , array_projected_simplified_id , ) = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"array_images_atlas\" , force_update = False , compute_function = self . prepare_and_compute_array_images_atlas , zero_out_of_annotation = True , ) # Loop over slice, compute image every time for slice_index in range ( array_projected_simplified_id . shape [ 0 ]): contours = ( array_projected_simplified_id [ slice_index , 1 :, 1 :] - array_projected_simplified_id [ slice_index , : - 1 , : - 1 ] ) contours = np . clip ( contours ** 2 , 0 , 1 ) contours = np . pad ( contours , (( 1 , 0 ), ( 1 , 0 ))) # Do some cleaning on the sides contours [:, : 10 ] = 0 contours [:, - 10 :] = 0 contours [: 10 , :] = 0 contours [ - 10 :, :] = 0 # Compute a matplolib figure and export it as image (it's a hack but it does the job) fig = plt . figure ( frameon = False ) dpi = 100 fig . set_size_inches ( contours . shape [ 1 ] / dpi , contours . shape [ 0 ] / dpi ) ax = fig . add_axes ([ 0 , 0 , 1 , 1 ]) ax . axis ( \"off\" ) prefix = \"data:image/png;base64,\" plt . contour ( contours , colors = \"orange\" , antialiased = True , linewidths = 0.2 , origin = \"image\" ) with BytesIO () as stream : plt . savefig ( stream , format = \"png\" , dpi = dpi ) plt . close () img = imread ( io . BytesIO ( stream . getvalue ())) l_array_images . append ( img ) return l_array_images compute_projection_parameters () Compute the parameters used to map the 3D coordinates of the CCFv3 to the the 2D (tiled) slices. Returns: Type Description list ( float , float , float ) A list of tuples, each with three parameters, that allow to map the 3D coordinates of the CCFv3 to the tiled planes representing the slices. One per slice. Source code in modules/atlas.py 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 def compute_projection_parameters ( self ): \"\"\"Compute the parameters used to map the 3D coordinates of the CCFv3 to the the 2D (tiled) slices. Returns: (list((float,float,float))): A list of tuples, each with three parameters, that allow to map the 3D coordinates of the CCFv3 to the tiled planes representing the slices. One per slice. \"\"\" l_transform_parameters = [] for slice_index in range ( self . array_coordinates_warped_data . shape [ 0 ]): a_atlas , u_atlas , v_atlas = solve_plane_equation ( self . array_coordinates_warped_data [ slice_index ] ) l_transform_parameters . append (( a_atlas , u_atlas , v_atlas )) return l_transform_parameters compute_spectrum_data ( slice_index , projected_mask = None , mask_name = None , slice_coor_rescaled = None , MAIA_correction = False , cache_flask = None ) This function computes the averaged spectral data for a given slice and a given mask, the latter being provided either as a mask name, either as an array (at least one of the two must not be None). If the mask is provided as an array, the corresponding array of slice coordinates (slice_coor_rescaled) must be provided. Parameters: Name Type Description Default slice_index int Index of the requested slice. required projected_mask np . ndarray A two-dimensional array representing the projected mask on the requested slice. Defaults to None. None mask_name str Acronym of the requestes mask. Defaults to None. None slice_coor_rescaled np . ndarray The array of coordinates in the CCFv3 for the current slice. Defaults to None. None MAIA_correction bool If True, the MAIA corrected version of the MALDI data is used for computation (if it exists). Defaults to False. False cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description np . ndarray A 2D numpy array containing the averaged spectral data of the pixels in the requested mask of the requested slice. First row contains m/z values, second row contains the averaged intensities. Source code in modules/atlas.py 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 def compute_spectrum_data ( self , slice_index , projected_mask = None , mask_name = None , slice_coor_rescaled = None , MAIA_correction = False , cache_flask = None , ): \"\"\"This function computes the averaged spectral data for a given slice and a given mask, the latter being provided either as a mask name, either as an array (at least one of the two must not be None). If the mask is provided as an array, the corresponding array of slice coordinates (slice_coor_rescaled) must be provided. Args: slice_index (int): Index of the requested slice. projected_mask (np.ndarray, optional): A two-dimensional array representing the projected mask on the requested slice. Defaults to None. mask_name (str, optional): Acronym of the requestes mask. Defaults to None. slice_coor_rescaled (np.ndarray, optional): The array of coordinates in the CCFv3 for the current slice. Defaults to None. MAIA_correction (bool, optional): If True, the MAIA corrected version of the MALDI data is used for computation (if it exists). Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (np.ndarray): A 2D numpy array containing the averaged spectral data of the pixels in the requested mask of the requested slice. First row contains m/z values, second row contains the averaged intensities. \"\"\" # Control that a mask can be provided one way or the other if projected_mask is None and mask_name is None : print ( \"Either a mask or a mask name must be provided\" ) return None # If a mask name has been provided, get the corresponding mask array elif mask_name is not None : if slice_coor_rescaled is None : slice_coor_rescaled = np . asarray ( ( self . array_coordinates_warped_data [ slice_index , :, :] * 1000 / self . resolution ) . round ( 0 ), dtype = np . int16 , ) stack_mask = self . get_atlas_mask ( self . dic_name_acronym [ mask_name ]) projected_mask = project_atlas_mask ( stack_mask , slice_coor_rescaled , self . bg_atlas . reference . shape ) # Get the list of rows containing the pixels to average original_shape = self . data . get_image_shape ( slice_index + 1 ) mask_remapped = np . zeros ( original_shape , dtype = np . uint8 ) list_index_bound_rows , list_index_bound_column_per_row = get_array_rows_from_atlas_mask ( projected_mask , mask_remapped , self . array_projection_correspondence_corrected [ slice_index ], ) if np . sum ( list_index_bound_rows ) == 0 : print ( \"No selection could be found for current mask\" ) grah_scattergl_data = None else : # Do the average grah_scattergl_data = compute_thread_safe_function ( compute_spectrum_per_row_selection , cache_flask , self . data , slice_index + 1 , list_index_bound_rows , list_index_bound_column_per_row , self . data . get_array_spectra ( slice_index + 1 ), self . data . get_array_lookup_pixels ( slice_index + 1 ), original_shape , self . data . get_array_peaks_transformed_lipids ( slice_index + 1 ), self . data . get_array_corrective_factors ( slice_index + 1 ) . astype ( np . float32 ), zeros_extend = False , apply_correction = MAIA_correction , ) return grah_scattergl_data get_atlas_mask ( structure ) Compute a mask for the structure given as argument. The brain regions corresponding to the structure id or any of its descendants are set to the id of the structure. The rest is set to 0. Parameters: Name Type Description Default structure str Structure (brain region) acronym. required Returns: Type Description np . ndarray A 3D mask with the same shape as the array of annotations from the atlas, where all elements are zeros except for the requested structure. Source code in modules/atlas.py 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 def get_atlas_mask ( self , structure ): \"\"\"Compute a mask for the structure given as argument. The brain regions corresponding to the structure id or any of its descendants are set to the id of the structure. The rest is set to 0. Args: structure (str): Structure (brain region) acronym. Returns: (np.ndarray): A 3D mask with the same shape as the array of annotations from the atlas, where all elements are zeros except for the requested structure. \"\"\" logging . info ( 'Getting mask for structure \" {} \"' . format ( structure )) # Get id of the parent structure structure_id = self . bg_atlas . structures [ structure ][ \"id\" ] # Get list of descendants descendants = self . bg_atlas . get_structure_descendants ( structure ) # Build empty mask for 3D array of atlas annotations mask_stack = np . zeros ( self . bg_atlas . shape , self . bg_atlas . annotation . dtype ) # Compute a list of ids (parent + children) we want to keep in the final annotation l_id = [ self . bg_atlas . structures [ descendant ][ \"id\" ] for descendant in descendants ] + [ structure_id ] # Do the masking mask_stack [ np . isin ( self . bg_atlas . annotation , l_id )] = structure_id logging . info ( 'Mask computed for structure \" {} \"' . format ( structure )) return mask_stack get_projected_mask_and_spectrum ( slice_index , mask_name , MAIA_correction = False ) This function is used to get the projected mask and corresponding averaged spectral data for a given mask and a given slice. Parameters: Name Type Description Default slice_index int Index of the requested slice. required mask_name str Acronym of the requested mask. required MAIA_correction bool If True, the MAIA corrected version of the MALDI data is used for computation (if it exists). Defaults to False. False Returns: Type Description np . ndarray , np . ndarray The first array is represents the projected 2D mask on the requested slice. The second array corresponds to the corresponding averaged spectral data (first row is m/z values, second row is averaged intensities). Source code in modules/atlas.py 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 def get_projected_mask_and_spectrum ( self , slice_index , mask_name , MAIA_correction = False ): \"\"\"This function is used to get the projected mask and corresponding averaged spectral data for a given mask and a given slice. Args: slice_index (int): Index of the requested slice. mask_name (str): Acronym of the requested mask. MAIA_correction (bool, optional): If True, the MAIA corrected version of the MALDI data is used for computation (if it exists). Defaults to False. Returns: (np.ndarray, np.ndarray): The first array is represents the projected 2D mask on the requested slice. The second array corresponds to the corresponding averaged spectral data (first row is m/z values, second row is averaged intensities). \"\"\" id_mask = self . dic_name_acronym [ mask_name ] if MAIA_correction : filename = ( \"mask_and_spectrum_MAIA_corrected_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ) ) else : filename = \"mask_and_spectrum_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ) logging . info ( \"Loading \" + mask_name + \" for slice \" + str ( slice_index ) + \" from shelve file.\" ) try : return self . storage . load_shelved_object ( \"atlas/atlas_objects\" , filename ) except : logging . warning ( \"The mask and spectrum data could not be found for \" + mask_name + \" for slice \" + str ( slice_index ) + \". Make sure the files have been precomputed and that you checked the mask\" + \" was present in self.dic_existing_masks\" ) return None list_projected_atlas_borders_arrays () property Load array of projected atlas borders (i.e. image of atlas annotations). It's a property to save memory as it is only used with objects that should also be precomputed. Returns: Type Description list ( np . ndarray ) A list of arrays, one per slice, which contains the atlas borders projected on our data. Source code in modules/atlas.py 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 @property def list_projected_atlas_borders_arrays ( self ): \"\"\"Load array of projected atlas borders (i.e. image of atlas annotations). It's a property to save memory as it is only used with objects that should also be precomputed. Returns: (list(np.ndarray)): A list of arrays, one per slice, which contains the atlas borders projected on our data. \"\"\" if self . _list_projected_atlas_borders_arrays is None : logging . info ( \"list_projected_atlas_borders_arrays is being loaded. This should only happen\" \" during precomputations.\" + logmem () ) self . _list_projected_atlas_borders_arrays = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"list_projected_atlas_borders_arrays\" , force_update = False , compute_function = self . compute_list_projected_atlas_borders_figures , ) return self . _list_projected_atlas_borders_arrays prepare_and_compute_array_images_atlas ( zero_out_of_annotation = False ) This function is mainly a wrapper for compute_array_images_atlas. It is needed as the computation of an array of simplified structures ids can't be compiled with numba. Parameters: Name Type Description Default zero_out_of_annotation bool If True, the pixels outside of the atlas annotations are zero-ed out. Defaults to False. False Returns: Type Description np . ndarray , np . ndarray The first array is basically a list of atlas images corresponding to the slices acquired during the MALDI acquisition. The second array is the corresponding set of annotations. Source code in modules/atlas.py 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 def prepare_and_compute_array_images_atlas ( self , zero_out_of_annotation = False ): \"\"\"This function is mainly a wrapper for compute_array_images_atlas. It is needed as the computation of an array of simplified structures ids can't be compiled with numba. Args: zero_out_of_annotation (bool, optional): If True, the pixels outside of the atlas annotations are zero-ed out. Defaults to False. Returns: (np.ndarray, np.ndarray): The first array is basically a list of atlas images corresponding to the slices acquired during the MALDI acquisition. The second array is the corresponding set of annotations. \"\"\" # Compute an array of simplified structures ids simplified_atlas_annotation = compute_simplified_atlas_annotation ( self . bg_atlas . annotation ) # Compute the actual array of atlas images return compute_array_images_atlas ( self . array_coordinates_warped_data , simplified_atlas_annotation , self . bg_atlas . reference , self . resolution , zero_out_of_annotation = zero_out_of_annotation , ) save_all_projected_masks_and_spectra ( force_update = False , cache_flask = None , sample = False ) This function saves all the (2D) masks and corresponding averaged spectral data, for all the slices. Parameters: Name Type Description Default force_update bool If True, the function will not overwrite existing files. Defaults to False. False cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None sample bool If True, only a tiny sample of the masks will be processed (for debug). Defaults to False. False Source code in modules/atlas.py 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 def save_all_projected_masks_and_spectra ( self , force_update = False , cache_flask = None , sample = False ): \"\"\"This function saves all the (2D) masks and corresponding averaged spectral data, for all the slices. Args: force_update (bool, optional): If True, the function will not overwrite existing files. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. sample (bool, optional): If True, only a tiny sample of the masks will be processed (for debug). Defaults to False. \"\"\" # Path atlas for shelving path_atlas = \"atlas/atlas_objects\" # Sample for debug if sample : logging . warning ( \"Only a sample of the masks and spectra will be computed!\" ) # Define a dictionnary that contains all the masks that exist for every slice dic_existing_masks = {} # Define a dictionnary to save the result of the function slice by slice if self . storage . check_shelved_object ( path_atlas , \"dic_processed_temp\" ): dic_processed_temp = self . storage . load_shelved_object ( path_atlas , \"dic_processed_temp\" , ) else : dic_processed_temp = {} for slice_index in range ( self . data . get_slice_number ()): # Break the loop after the first slice if sample is True if sample and slice_index > 1 : break logging . info ( \"Starting slice \" + str ( slice_index )) slice_coor_rescaled = np . asarray ( ( self . array_coordinates_warped_data [ slice_index , :, :] * 1000 / self . resolution ) . round ( 0 ), dtype = np . int16 , ) dic_existing_masks [ slice_index ] = set ([]) # Check if the slice has already been processed if slice_index not in dic_processed_temp : dic_processed_temp [ slice_index ] = set ([]) # Get hierarchical tree of brain structures n_computed = 0 for mask_name , id_mask in self . dic_name_acronym . items (): if id_mask not in dic_processed_temp [ slice_index ]: # Break the loop after a few computations if sample is True if sample and n_computed > 1 : break if ( not ( self . storage . check_shelved_object ( path_atlas , \"mask_and_spectrum_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ) and self . storage . check_shelved_object ( path_atlas , \"mask_and_spectrum_MAIA_corrected_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ) ) or force_update ): # get the array corresponding to the projected mask stack_mask = self . get_atlas_mask ( id_mask ) # Project the mask onto high resolution data projected_mask = project_atlas_mask ( stack_mask , slice_coor_rescaled , self . bg_atlas . reference . shape ) if np . sum ( projected_mask ) == 0 : logging . info ( \"The structure \" + mask_name + \" is not present in slice \" + str ( slice_index ) ) # Mask doesn't exist, so it considered processed dic_processed_temp [ slice_index ] . add ( id_mask ) continue # Compute average spectrum in the mask grah_scattergl_data = self . compute_spectrum_data ( slice_index , projected_mask , MAIA_correction = False , cache_flask = cache_flask , ) # Add mask to the list of existing masks dic_existing_masks [ slice_index ] . add ( id_mask ) dic_processed_temp [ slice_index ] . add ( id_mask ) # Dump the mask and data with shelve self . storage . dump_shelved_object ( path_atlas , \"mask_and_spectrum_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ( projected_mask , grah_scattergl_data ), ) # Same with MAIA corrected data grah_scattergl_data = self . compute_spectrum_data ( slice_index , projected_mask , MAIA_correction = True , cache_flask = cache_flask , ) self . storage . dump_shelved_object ( path_atlas , \"mask_and_spectrum_MAIA_corrected_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ( projected_mask , grah_scattergl_data ), ) else : # Add computed masks to the dics of computed masks dic_existing_masks [ slice_index ] . add ( id_mask ) dic_processed_temp [ slice_index ] . add ( id_mask ) n_computed += 1 else : n_computed += 1 logging . info ( 'Mask \"' + mask_name + '\" already processed' ) # Dump the dictionnary of processed masks with shelve after every slice self . storage . dump_shelved_object ( path_atlas , \"dic_processed_temp\" , dic_processed_temp , ) if not sample : # Dump the dictionnary of existing masks with shelve self . storage . dump_shelved_object ( path_atlas , \"dic_existing_masks\" , dic_existing_masks , ) logging . info ( \"Projected masks and spectra have all been computed.\" ) self . dic_existing_masks = dic_existing_masks","title":"atlas"},{"location":"modules/atlas/#modules.atlas.Atlas","text":"Class used to do the interface between the data coming from acquisitions (MALDI), and the Allen Brain Atlas. Private attributes (starting with an underscore) are described as properties. Attributes: Name Type Description resolution int Resolution of the atlas. data MaldiData Used to manipulate the raw MALDI data. storage Storage Used to access the shelve database. bg_atlas BrainGlobeAtlas Used to query the Allen Brain Atlas. subsampling_block int Set the subsampling of the atlas in the longitudinal direction, to decrease the memory usage. labels Labels Used to load string annotation for contour plot, for each voxel. dic_acronym_children_id dict Dictionnary that associates, to each structure (acronym), the set of ids (int) of all of its children. array_coordinates_warped_data np . ndarray An array that contains, for each slice and each pixel coordinate, the corresponding coordinates in the CCFv3. image_shape np . ndarray An array that contains two integer values: the height and width of the slice images after warping/upscaling (these values are identical for all slices). l_nodes list Along with l_parents (below), this list of nodes can be used to rebuild the complete hierarchy of structures of the Allen Brain atlas. l_parents list See l_nodes above. dic_name_acronym dict A dictionnary that associates, to each brain region/structure name, a specific id (acronym, i.e. short label). dic_acronym_name dict A dictionnary that associates, to each brain region/structure acronym, a specific name. array_projection_correspondence_corrected np . ndarray An array that contains encodes the warping/upscaling transformation of the data. l_original_coor list(np.ndarray A list of arrays that contains the coordinates of the original data in the CCFv3. dic_existing_masks dict A dictionnary of existing masks per slice, which associates slice index (key) to a set of masks acronyms. Properties array_projection_corrected (np.ndarray): A three-dimensional array which contains the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. list_projected_atlas_borders_arrays (list(np.ndarray)): A list of arrays, one per slice, which contains the atlas borders projected on our data. Methods init (maldi_data, resolution=25, sample=False): Initialize the Atlas class. compute_dic_acronym_children_id(): Recursively compute a dictionnary that associates brain structures to the set of their children. compute_hierarchy_list(): Compute, for each children (node) structure, the corresponding parent, to build a list associating child/parent for all structures, and also compute dictionnaries that associate structure acronyms to their complete name in the process. compute_array_projection(nearest_neighbour_correction=False, atlas_correction=False): Compute three arrays relating the original coordinates of our data to their projection in the CCFv3. compute_projection_parameters(): Compute the parameters used to map the 3D coordinates of the CCFv3 to the the 2D (tiled) slices. compute_list_projected_atlas_borders_figures(): Compute an array of projected atlas borders. prepare_and_compute_array_images_atlas(zero_out_of_annotation=False): Wrapper for compute_array_images_atlas. get_atlas_mask(structure): Compute a mask for the structure given as argument. compute_spectrum_data(slice_index, projected_mask=None, mask_name=None, slice_coor_rescaled=None, MAIA_correction=False, cache_flask=None): Compute the averaged spectral data for a given slice and a given mask. save_all_projected_masks_and_spectra(force_update=False, cache_flask=None, sample=False): Save all the (2D) masks and corresponding averaged spectral data, for all the slices. get_projected_mask_and_spectrum(slice_index, mask_name, MAIA_correction=False): Get the projected mask and corresponding averaged spectral data for a given mask and slice. Source code in modules/atlas.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 class Atlas : \"\"\"Class used to do the interface between the data coming from acquisitions (MALDI), and the Allen Brain Atlas. Private attributes (starting with an underscore) are described as properties. Attributes: resolution (int): Resolution of the atlas. data (MaldiData): Used to manipulate the raw MALDI data. storage (Storage): Used to access the shelve database. bg_atlas (BrainGlobeAtlas): Used to query the Allen Brain Atlas. subsampling_block (int): Set the subsampling of the atlas in the longitudinal direction, to decrease the memory usage. labels (Labels): Used to load string annotation for contour plot, for each voxel. dic_acronym_children_id (dict): Dictionnary that associates, to each structure (acronym), the set of ids (int) of all of its children. array_coordinates_warped_data (np.ndarray): An array that contains, for each slice and each pixel coordinate, the corresponding coordinates in the CCFv3. image_shape (np.ndarray): An array that contains two integer values: the height and width of the slice images after warping/upscaling (these values are identical for all slices). l_nodes (list): Along with l_parents (below), this list of nodes can be used to rebuild the complete hierarchy of structures of the Allen Brain atlas. l_parents (list): See l_nodes above. dic_name_acronym (dict): A dictionnary that associates, to each brain region/structure name, a specific id (acronym, i.e. short label). dic_acronym_name (dict): A dictionnary that associates, to each brain region/structure acronym, a specific name. array_projection_correspondence_corrected (np.ndarray): An array that contains encodes the warping/upscaling transformation of the data. l_original_coor (list(np.ndarray)): A list of arrays that contains the coordinates of the original data in the CCFv3. dic_existing_masks (dict): A dictionnary of existing masks per slice, which associates slice index (key) to a set of masks acronyms. Properties: array_projection_corrected (np.ndarray): A three-dimensional array which contains the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. list_projected_atlas_borders_arrays (list(np.ndarray)): A list of arrays, one per slice, which contains the atlas borders projected on our data. Methods: __init__(maldi_data, resolution=25, sample=False): Initialize the Atlas class. compute_dic_acronym_children_id(): Recursively compute a dictionnary that associates brain structures to the set of their children. compute_hierarchy_list(): Compute, for each children (node) structure, the corresponding parent, to build a list associating child/parent for all structures, and also compute dictionnaries that associate structure acronyms to their complete name in the process. compute_array_projection(nearest_neighbour_correction=False, atlas_correction=False): Compute three arrays relating the original coordinates of our data to their projection in the CCFv3. compute_projection_parameters(): Compute the parameters used to map the 3D coordinates of the CCFv3 to the the 2D (tiled) slices. compute_list_projected_atlas_borders_figures(): Compute an array of projected atlas borders. prepare_and_compute_array_images_atlas(zero_out_of_annotation=False): Wrapper for compute_array_images_atlas. get_atlas_mask(structure): Compute a mask for the structure given as argument. compute_spectrum_data(slice_index, projected_mask=None, mask_name=None, slice_coor_rescaled=None, MAIA_correction=False, cache_flask=None): Compute the averaged spectral data for a given slice and a given mask. save_all_projected_masks_and_spectra(force_update=False, cache_flask=None, sample=False): Save all the (2D) masks and corresponding averaged spectral data, for all the slices. get_projected_mask_and_spectrum(slice_index, mask_name, MAIA_correction=False): Get the projected mask and corresponding averaged spectral data for a given mask and slice. \"\"\" # ============================================================================================== # --- Constructor # ============================================================================================== def __init__ ( self , maldi_data , storage , resolution = 25 , sample = False ): \"\"\"Initialize the class Atlas. Args: maldi_data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. storage (Storage): Used to access the shelve database. resolution (int): Resolution of the atlas. Default to 25. sample (bool): If True, only a fraction of the precomputations are made (for debug). Default to False. \"\"\" logging . info ( \"Initializing Atlas object\" + logmem ()) # Resolution of the atlas, to be chosen among 10um, 25um or 100um if resolution in ( 10 , 25 , 100 ): self . resolution = resolution else : logging . warning ( \"The resolution you chose is not available, using the default of 25um\" ) self . resolution = 25 # Attribute to easily access the data and the shelve db self . data = maldi_data self . storage = storage # Correct atlas resolution to 100 if sampled app if maldi_data . _sample_data : logging . info ( \"Atlas resolution set to 100um as the sampled data is used.\" ) self . resolution = 100 # Load or download the atlas if it's the first time BrainGlobeAtlas is used if maldi_data . _sample_data : brainglobe_dir = \"data_sample/atlas/\" else : brainglobe_dir = \"data/atlas/\" os . makedirs ( brainglobe_dir , exist_ok = True ) self . bg_atlas = BrainGlobeAtlas ( \"allen_mouse_\" + str ( self . resolution ) + \"um\" , brainglobe_dir = brainglobe_dir , check_latest = False , ) # Correct path for resolution appendix = \"_v1.2\" if self . resolution == 100 else \"\" # Remove the meshes in the sampled app as they're not used if maldi_data . _sample_data and \"meshes\" in os . listdir ( brainglobe_dir + \"allen_mouse_\" + str ( self . resolution ) + \"um\" + appendix ): shutil . rmtree ( brainglobe_dir + \"allen_mouse_\" + str ( self . resolution ) + \"um\" + appendix + \"/meshes\" ) # When computing an array of figures with a slider to explore the atlas, subsample in the # longitudinal direction, otherwise it's too heavy self . subsampling_block = 20 # Load string annotation for contour plot, for each voxel. # These objects are heavy (~300mb) as they force the loading of annotations from the core # Atlas class. But they shouldn't be memory-mapped as they are called when hovering and # require very fast response from the server self . labels = Labels ( self . bg_atlas , force_init = True ) # Compute a dictionnary that associates to each structure (acronym) the set of ids (int) of # all of its children. Used only in page_4_plot_graph_volume, but it's very light (~3mb) so # no problem using it as an attribute self . dic_acronym_children_id = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"dic_acronym_children_id\" , force_update = False , compute_function = self . compute_dic_acronym_children_id , ) # Load array of coordinates for warped data (can't be loaded on the fly from shelve as used # with hovering). Weights ~225mb if maldi_data . _sample_data : with np . load ( \"data_sample/tiff_files/coordinates_warped_data.npz\" ) as handle : self . array_coordinates_warped_data = handle [ \"array_coordinates_warped_data\" ] else : self . array_coordinates_warped_data = skimage . io . imread ( \"data/tiff_files/coordinates_warped_data.tif\" ) # Record shape of the warped data self . image_shape = list ( self . array_coordinates_warped_data . shape [ 1 : - 1 ]) # Record dict that associate brain region (complete string) to specific id (short label), # along with graph of structures (l_nodes and l_parents). Although the treemap graph is # precomputed, the two dics of name and acronyms are relatively lightweight and are used in # many different place, so they shouldn't be used a properties ( self . l_nodes , self . l_parents , self . dic_name_acronym , self . dic_acronym_name , ) = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"hierarchy\" , force_update = False , compute_function = self . compute_hierarchy_list , ) # Array_projection_corrected is used a lot for lipid expression plots, as it encodes the # warping transformation of the data. Therefore it shouldn't be used a as a property. # Weights ~150mb # * The type is np.int16, and can't be reduced anymore as values are sometimes above 400 self . array_projection_correspondence_corrected = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"arrays_projection_corrected\" , force_update = False , compute_function = self . compute_array_projection , nearest_neighbour_correction = True , atlas_correction = True , )[ 1 ] # Load arrays of original images coordinates. It is used everytime a 3D object is computed. # Weights ~50mb self . l_original_coor = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"arrays_projection_corrected\" , force_update = False , compute_function = self . compute_array_projection , nearest_neighbour_correction = True , atlas_correction = True , )[ 2 ] # Dictionnary of existing masks per slice, which associates slice index (key) to a set of # masks acronyms if self . storage . check_shelved_object ( \"atlas/atlas_objects\" , \"dic_existing_masks\" ): self . dic_existing_masks = self . storage . load_shelved_object ( \"atlas/atlas_objects\" , \"dic_existing_masks\" ) else : logging . info ( \"The dictionnary of available mask per slice has not been computed yet. \" + \"Doing it now, this may take several hours.\" ) # Since this function is called at startup, no data locking is needed self . save_all_projected_masks_and_spectra ( cache_flask = None , sample = sample ) # These attributes are defined later as properties as they are only used during # precomputations self . _array_projection_corrected = None self . _list_projected_atlas_borders_arrays = None logging . info ( \"Atlas object instantiated\" + logmem ()) # ============================================================================================== # --- Properties # ============================================================================================== @property def array_projection_corrected ( self ): \"\"\"Load arrays of images using atlas projection. It's a property to save memory as it is only used with objects that should also be precomputed. Returns: (np.ndarray): A three-dimensional array which contains the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. \"\"\" if self . _array_projection_corrected is None : logging . info ( \"array_projection_corrected is being loaded. This should only happen during\" \" precomputations.\" + logmem () ) self . _array_projection_corrected = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"arrays_projection_corrected\" , force_update = False , compute_function = self . compute_array_projection , nearest_neighbour_correction = True , atlas_correction = True , )[ 0 ] return self . _array_projection_corrected @property def list_projected_atlas_borders_arrays ( self ): \"\"\"Load array of projected atlas borders (i.e. image of atlas annotations). It's a property to save memory as it is only used with objects that should also be precomputed. Returns: (list(np.ndarray)): A list of arrays, one per slice, which contains the atlas borders projected on our data. \"\"\" if self . _list_projected_atlas_borders_arrays is None : logging . info ( \"list_projected_atlas_borders_arrays is being loaded. This should only happen\" \" during precomputations.\" + logmem () ) self . _list_projected_atlas_borders_arrays = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"list_projected_atlas_borders_arrays\" , force_update = False , compute_function = self . compute_list_projected_atlas_borders_figures , ) return self . _list_projected_atlas_borders_arrays # ============================================================================================== # --- Methods # ============================================================================================== def compute_dic_acronym_children_id ( self ): \"\"\"Recursively compute a dictionnary that associates brain structures to the set of their children. Returns: (dict): A dictionnary that associate to each structure (acronym) the set of ids (int) of all of its children. \"\"\" # Recursive function to compute the parent of each structure def fill_dic_acronym_children_id ( dic_acronym_children_id , l_id_leaves ): older_leave_id = l_id_leaves [ 0 ] acronym = self . bg_atlas . structures [ older_leave_id ][ \"acronym\" ] for id_leave in l_id_leaves : # Fill dic with current acronym and id if acronym in dic_acronym_children_id : dic_acronym_children_id [ acronym ] . add ( id_leave ) else : dic_acronym_children_id [ acronym ] = set ([ id_leave ]) # While root is not reached, climb back the ancestor tree if len ( self . bg_atlas . structures [ older_leave_id ][ \"structure_id_path\" ]) >= 2 : id_parent = self . bg_atlas . structures [ older_leave_id ][ \"structure_id_path\" ][ - 2 ] dic_acronym_children_id = fill_dic_acronym_children_id ( dic_acronym_children_id , [ id_parent ] + l_id_leaves ) return dic_acronym_children_id # Initialize dictionnary as empty dic_acronym_children_id = {} # Loop over each structure for id in set ( self . bg_atlas . annotation . flatten ()): if id != 0 : # Fill the dictionnary by climbing up the hierarchy structure dic_acronym_children_id = fill_dic_acronym_children_id ( dic_acronym_children_id , [ id ] ) return dic_acronym_children_id def compute_hierarchy_list ( self ): \"\"\"Compute, for each children (node), the corresponding parent, to build a list associating child/parent for all structures, and also compute dictionnaries that associate structure acronyms to their complete name in the process. Returns: (list(str)): List of children (node) names. (list(str)): List of parent names. (dict): A dictionnary that associate structure name to its acronym. (dict): A dictionnary that associate structure acronym to its name. \"\"\" # Create a list of parents for all ancestors l_nodes = [] l_parents = [] dic_name_acronym = {} dic_acronym_name = {} idx = 0 # Loop over each structure for x , v in self . bg_atlas . structures . items (): # Keep only a very restrained amount of structures if sample data if ( self . data . _sample_data and len ( self . bg_atlas . get_structure_ancestors ( v [ \"acronym\" ])) > 1 ): continue if len ( self . bg_atlas . get_structure_ancestors ( v [ \"acronym\" ])) > 0 : ancestor_acronym = self . bg_atlas . get_structure_ancestors ( v [ \"acronym\" ])[ - 1 ] ancestor_name = self . bg_atlas . structures [ ancestor_acronym ][ \"name\" ] else : ancestor_name = \"\" current_name = self . bg_atlas . structures [ x ][ \"name\" ] l_nodes . append ( current_name ) l_parents . append ( ancestor_name ) # Register the name/acronym association for each structure dic_name_acronym [ current_name ] = v [ \"acronym\" ] dic_acronym_name [ v [ \"acronym\" ]] = current_name return l_nodes , l_parents , dic_name_acronym , dic_acronym_name def compute_array_projection ( self , nearest_neighbour_correction = False , atlas_correction = False ): \"\"\"Compute three arrays relating the original coordinates of our data to their projection in the CCFv3. Args: nearest_neighbour_correction (bool, optional): If True, the gaps due to the warping and upscaling of the projection are filled with a heuristic method. Defaults to False. atlas_correction (bool, optional): If True, the pixels that are outside of any annotated region are zeroed out. Defaults to False. Returns: (np.ndarray, np.ndarray, list(np.ndarray)): The first array is a high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, which acts as a mapping table. The list contains the arrays of original coordinates, for each slice. \"\"\" # Start with empty array array_projection = np . zeros ( self . array_coordinates_warped_data . shape [: - 1 ], dtype = np . int16 ) array_projection_filling = np . zeros ( array_projection . shape , dtype = np . int16 ) # This array makes the correspondence between the original data coordinates and the new ones array_projection_correspondence = np . zeros ( array_projection . shape + ( 2 ,), dtype = np . int16 ) array_projection_correspondence . fill ( - 1 ) # List of orginal coordinates l_original_coor = [] l_transform_parameters = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"l_transform_parameters\" , force_update = False , compute_function = self . compute_projection_parameters , ) for i in range ( array_projection . shape [ 0 ]): # Get transform parameters a , u , v = l_transform_parameters [ i ] # Load corresponding slice and coor if self . data . _sample_data : path = \"data_sample/tiff_files/coordinates_original_data/\" else : path = \"data/tiff_files/coordinates_original_data/\" filename = ( path + [ x for x in os . listdir ( path ) if str ( i + 1 ) == x . split ( \"_\" )[ 1 ] . split ( \"-\" )[ 0 ]][ 0 ] ) if self . data . _sample_data : original_coor = np . load ( filename ) else : original_coor = skimage . io . imread ( filename ) l_original_coor . append ( original_coor ) if self . data . _sample_data : path = \"data_sample/tiff_files/original_data/\" else : path = \"data/tiff_files/original_data/\" filename = ( path + [ x for x in os . listdir ( path ) if str ( i + 1 ) == x . split ( \"slice_\" )[ 1 ] . split ( \".tiff\" )[ 0 ] ][ 0 ] ) original_slice = np . array ( skimage . io . imread ( filename ), dtype = np . uint8 ) # Keep only last channel if not self . data . _sample_data : original_slice = original_slice [:, :, 2 ] # Map back the pixel from the atlas coordinates array_projection , array_projection_correspondence = fill_array_projection ( i , array_projection , array_projection_filling , array_projection_correspondence , original_coor , self . resolution , a , u , v , original_slice , self . array_coordinates_warped_data [ i ], self . bg_atlas . annotation , nearest_neighbour_correction = nearest_neighbour_correction , atlas_correction = atlas_correction , sample_data = self . data . _sample_data , ) return array_projection , array_projection_correspondence , l_original_coor def compute_projection_parameters ( self ): \"\"\"Compute the parameters used to map the 3D coordinates of the CCFv3 to the the 2D (tiled) slices. Returns: (list((float,float,float))): A list of tuples, each with three parameters, that allow to map the 3D coordinates of the CCFv3 to the tiled planes representing the slices. One per slice. \"\"\" l_transform_parameters = [] for slice_index in range ( self . array_coordinates_warped_data . shape [ 0 ]): a_atlas , u_atlas , v_atlas = solve_plane_equation ( self . array_coordinates_warped_data [ slice_index ] ) l_transform_parameters . append (( a_atlas , u_atlas , v_atlas )) return l_transform_parameters def compute_list_projected_atlas_borders_figures ( self ): \"\"\"Compute an array of projected atlas borders (i.e. image of atlas annotations). Returns: (list(np.ndarray)): A list of arrays, one per slice, which contains the atlas borders projected on our data. \"\"\" l_array_images = [] # Load array of atlas images corresponding to our data and how it is projected ( array_projected_images_atlas , array_projected_simplified_id , ) = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"array_images_atlas\" , force_update = False , compute_function = self . prepare_and_compute_array_images_atlas , zero_out_of_annotation = True , ) # Loop over slice, compute image every time for slice_index in range ( array_projected_simplified_id . shape [ 0 ]): contours = ( array_projected_simplified_id [ slice_index , 1 :, 1 :] - array_projected_simplified_id [ slice_index , : - 1 , : - 1 ] ) contours = np . clip ( contours ** 2 , 0 , 1 ) contours = np . pad ( contours , (( 1 , 0 ), ( 1 , 0 ))) # Do some cleaning on the sides contours [:, : 10 ] = 0 contours [:, - 10 :] = 0 contours [: 10 , :] = 0 contours [ - 10 :, :] = 0 # Compute a matplolib figure and export it as image (it's a hack but it does the job) fig = plt . figure ( frameon = False ) dpi = 100 fig . set_size_inches ( contours . shape [ 1 ] / dpi , contours . shape [ 0 ] / dpi ) ax = fig . add_axes ([ 0 , 0 , 1 , 1 ]) ax . axis ( \"off\" ) prefix = \"data:image/png;base64,\" plt . contour ( contours , colors = \"orange\" , antialiased = True , linewidths = 0.2 , origin = \"image\" ) with BytesIO () as stream : plt . savefig ( stream , format = \"png\" , dpi = dpi ) plt . close () img = imread ( io . BytesIO ( stream . getvalue ())) l_array_images . append ( img ) return l_array_images # * This is quite long to execute (~10mn) def prepare_and_compute_array_images_atlas ( self , zero_out_of_annotation = False ): \"\"\"This function is mainly a wrapper for compute_array_images_atlas. It is needed as the computation of an array of simplified structures ids can't be compiled with numba. Args: zero_out_of_annotation (bool, optional): If True, the pixels outside of the atlas annotations are zero-ed out. Defaults to False. Returns: (np.ndarray, np.ndarray): The first array is basically a list of atlas images corresponding to the slices acquired during the MALDI acquisition. The second array is the corresponding set of annotations. \"\"\" # Compute an array of simplified structures ids simplified_atlas_annotation = compute_simplified_atlas_annotation ( self . bg_atlas . annotation ) # Compute the actual array of atlas images return compute_array_images_atlas ( self . array_coordinates_warped_data , simplified_atlas_annotation , self . bg_atlas . reference , self . resolution , zero_out_of_annotation = zero_out_of_annotation , ) def get_atlas_mask ( self , structure ): \"\"\"Compute a mask for the structure given as argument. The brain regions corresponding to the structure id or any of its descendants are set to the id of the structure. The rest is set to 0. Args: structure (str): Structure (brain region) acronym. Returns: (np.ndarray): A 3D mask with the same shape as the array of annotations from the atlas, where all elements are zeros except for the requested structure. \"\"\" logging . info ( 'Getting mask for structure \" {} \"' . format ( structure )) # Get id of the parent structure structure_id = self . bg_atlas . structures [ structure ][ \"id\" ] # Get list of descendants descendants = self . bg_atlas . get_structure_descendants ( structure ) # Build empty mask for 3D array of atlas annotations mask_stack = np . zeros ( self . bg_atlas . shape , self . bg_atlas . annotation . dtype ) # Compute a list of ids (parent + children) we want to keep in the final annotation l_id = [ self . bg_atlas . structures [ descendant ][ \"id\" ] for descendant in descendants ] + [ structure_id ] # Do the masking mask_stack [ np . isin ( self . bg_atlas . annotation , l_id )] = structure_id logging . info ( 'Mask computed for structure \" {} \"' . format ( structure )) return mask_stack def compute_spectrum_data ( self , slice_index , projected_mask = None , mask_name = None , slice_coor_rescaled = None , MAIA_correction = False , cache_flask = None , ): \"\"\"This function computes the averaged spectral data for a given slice and a given mask, the latter being provided either as a mask name, either as an array (at least one of the two must not be None). If the mask is provided as an array, the corresponding array of slice coordinates (slice_coor_rescaled) must be provided. Args: slice_index (int): Index of the requested slice. projected_mask (np.ndarray, optional): A two-dimensional array representing the projected mask on the requested slice. Defaults to None. mask_name (str, optional): Acronym of the requestes mask. Defaults to None. slice_coor_rescaled (np.ndarray, optional): The array of coordinates in the CCFv3 for the current slice. Defaults to None. MAIA_correction (bool, optional): If True, the MAIA corrected version of the MALDI data is used for computation (if it exists). Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (np.ndarray): A 2D numpy array containing the averaged spectral data of the pixels in the requested mask of the requested slice. First row contains m/z values, second row contains the averaged intensities. \"\"\" # Control that a mask can be provided one way or the other if projected_mask is None and mask_name is None : print ( \"Either a mask or a mask name must be provided\" ) return None # If a mask name has been provided, get the corresponding mask array elif mask_name is not None : if slice_coor_rescaled is None : slice_coor_rescaled = np . asarray ( ( self . array_coordinates_warped_data [ slice_index , :, :] * 1000 / self . resolution ) . round ( 0 ), dtype = np . int16 , ) stack_mask = self . get_atlas_mask ( self . dic_name_acronym [ mask_name ]) projected_mask = project_atlas_mask ( stack_mask , slice_coor_rescaled , self . bg_atlas . reference . shape ) # Get the list of rows containing the pixels to average original_shape = self . data . get_image_shape ( slice_index + 1 ) mask_remapped = np . zeros ( original_shape , dtype = np . uint8 ) list_index_bound_rows , list_index_bound_column_per_row = get_array_rows_from_atlas_mask ( projected_mask , mask_remapped , self . array_projection_correspondence_corrected [ slice_index ], ) if np . sum ( list_index_bound_rows ) == 0 : print ( \"No selection could be found for current mask\" ) grah_scattergl_data = None else : # Do the average grah_scattergl_data = compute_thread_safe_function ( compute_spectrum_per_row_selection , cache_flask , self . data , slice_index + 1 , list_index_bound_rows , list_index_bound_column_per_row , self . data . get_array_spectra ( slice_index + 1 ), self . data . get_array_lookup_pixels ( slice_index + 1 ), original_shape , self . data . get_array_peaks_transformed_lipids ( slice_index + 1 ), self . data . get_array_corrective_factors ( slice_index + 1 ) . astype ( np . float32 ), zeros_extend = False , apply_correction = MAIA_correction , ) return grah_scattergl_data def save_all_projected_masks_and_spectra ( self , force_update = False , cache_flask = None , sample = False ): \"\"\"This function saves all the (2D) masks and corresponding averaged spectral data, for all the slices. Args: force_update (bool, optional): If True, the function will not overwrite existing files. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. sample (bool, optional): If True, only a tiny sample of the masks will be processed (for debug). Defaults to False. \"\"\" # Path atlas for shelving path_atlas = \"atlas/atlas_objects\" # Sample for debug if sample : logging . warning ( \"Only a sample of the masks and spectra will be computed!\" ) # Define a dictionnary that contains all the masks that exist for every slice dic_existing_masks = {} # Define a dictionnary to save the result of the function slice by slice if self . storage . check_shelved_object ( path_atlas , \"dic_processed_temp\" ): dic_processed_temp = self . storage . load_shelved_object ( path_atlas , \"dic_processed_temp\" , ) else : dic_processed_temp = {} for slice_index in range ( self . data . get_slice_number ()): # Break the loop after the first slice if sample is True if sample and slice_index > 1 : break logging . info ( \"Starting slice \" + str ( slice_index )) slice_coor_rescaled = np . asarray ( ( self . array_coordinates_warped_data [ slice_index , :, :] * 1000 / self . resolution ) . round ( 0 ), dtype = np . int16 , ) dic_existing_masks [ slice_index ] = set ([]) # Check if the slice has already been processed if slice_index not in dic_processed_temp : dic_processed_temp [ slice_index ] = set ([]) # Get hierarchical tree of brain structures n_computed = 0 for mask_name , id_mask in self . dic_name_acronym . items (): if id_mask not in dic_processed_temp [ slice_index ]: # Break the loop after a few computations if sample is True if sample and n_computed > 1 : break if ( not ( self . storage . check_shelved_object ( path_atlas , \"mask_and_spectrum_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ) and self . storage . check_shelved_object ( path_atlas , \"mask_and_spectrum_MAIA_corrected_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ) ) or force_update ): # get the array corresponding to the projected mask stack_mask = self . get_atlas_mask ( id_mask ) # Project the mask onto high resolution data projected_mask = project_atlas_mask ( stack_mask , slice_coor_rescaled , self . bg_atlas . reference . shape ) if np . sum ( projected_mask ) == 0 : logging . info ( \"The structure \" + mask_name + \" is not present in slice \" + str ( slice_index ) ) # Mask doesn't exist, so it considered processed dic_processed_temp [ slice_index ] . add ( id_mask ) continue # Compute average spectrum in the mask grah_scattergl_data = self . compute_spectrum_data ( slice_index , projected_mask , MAIA_correction = False , cache_flask = cache_flask , ) # Add mask to the list of existing masks dic_existing_masks [ slice_index ] . add ( id_mask ) dic_processed_temp [ slice_index ] . add ( id_mask ) # Dump the mask and data with shelve self . storage . dump_shelved_object ( path_atlas , \"mask_and_spectrum_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ( projected_mask , grah_scattergl_data ), ) # Same with MAIA corrected data grah_scattergl_data = self . compute_spectrum_data ( slice_index , projected_mask , MAIA_correction = True , cache_flask = cache_flask , ) self . storage . dump_shelved_object ( path_atlas , \"mask_and_spectrum_MAIA_corrected_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ( projected_mask , grah_scattergl_data ), ) else : # Add computed masks to the dics of computed masks dic_existing_masks [ slice_index ] . add ( id_mask ) dic_processed_temp [ slice_index ] . add ( id_mask ) n_computed += 1 else : n_computed += 1 logging . info ( 'Mask \"' + mask_name + '\" already processed' ) # Dump the dictionnary of processed masks with shelve after every slice self . storage . dump_shelved_object ( path_atlas , \"dic_processed_temp\" , dic_processed_temp , ) if not sample : # Dump the dictionnary of existing masks with shelve self . storage . dump_shelved_object ( path_atlas , \"dic_existing_masks\" , dic_existing_masks , ) logging . info ( \"Projected masks and spectra have all been computed.\" ) self . dic_existing_masks = dic_existing_masks def get_projected_mask_and_spectrum ( self , slice_index , mask_name , MAIA_correction = False ): \"\"\"This function is used to get the projected mask and corresponding averaged spectral data for a given mask and a given slice. Args: slice_index (int): Index of the requested slice. mask_name (str): Acronym of the requested mask. MAIA_correction (bool, optional): If True, the MAIA corrected version of the MALDI data is used for computation (if it exists). Defaults to False. Returns: (np.ndarray, np.ndarray): The first array is represents the projected 2D mask on the requested slice. The second array corresponds to the corresponding averaged spectral data (first row is m/z values, second row is averaged intensities). \"\"\" id_mask = self . dic_name_acronym [ mask_name ] if MAIA_correction : filename = ( \"mask_and_spectrum_MAIA_corrected_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ) ) else : filename = \"mask_and_spectrum_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ) logging . info ( \"Loading \" + mask_name + \" for slice \" + str ( slice_index ) + \" from shelve file.\" ) try : return self . storage . load_shelved_object ( \"atlas/atlas_objects\" , filename ) except : logging . warning ( \"The mask and spectrum data could not be found for \" + mask_name + \" for slice \" + str ( slice_index ) + \". Make sure the files have been precomputed and that you checked the mask\" + \" was present in self.dic_existing_masks\" ) return None","title":"Atlas"},{"location":"modules/atlas/#modules.atlas.Atlas.__init__","text":"Initialize the class Atlas. Parameters: Name Type Description Default maldi_data MaldiData MaldiData object, used to manipulate the raw MALDI data. required storage Storage Used to access the shelve database. required resolution int Resolution of the atlas. Default to 25. 25 sample bool If True, only a fraction of the precomputations are made (for debug). Default to False. False Source code in modules/atlas.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 def __init__ ( self , maldi_data , storage , resolution = 25 , sample = False ): \"\"\"Initialize the class Atlas. Args: maldi_data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. storage (Storage): Used to access the shelve database. resolution (int): Resolution of the atlas. Default to 25. sample (bool): If True, only a fraction of the precomputations are made (for debug). Default to False. \"\"\" logging . info ( \"Initializing Atlas object\" + logmem ()) # Resolution of the atlas, to be chosen among 10um, 25um or 100um if resolution in ( 10 , 25 , 100 ): self . resolution = resolution else : logging . warning ( \"The resolution you chose is not available, using the default of 25um\" ) self . resolution = 25 # Attribute to easily access the data and the shelve db self . data = maldi_data self . storage = storage # Correct atlas resolution to 100 if sampled app if maldi_data . _sample_data : logging . info ( \"Atlas resolution set to 100um as the sampled data is used.\" ) self . resolution = 100 # Load or download the atlas if it's the first time BrainGlobeAtlas is used if maldi_data . _sample_data : brainglobe_dir = \"data_sample/atlas/\" else : brainglobe_dir = \"data/atlas/\" os . makedirs ( brainglobe_dir , exist_ok = True ) self . bg_atlas = BrainGlobeAtlas ( \"allen_mouse_\" + str ( self . resolution ) + \"um\" , brainglobe_dir = brainglobe_dir , check_latest = False , ) # Correct path for resolution appendix = \"_v1.2\" if self . resolution == 100 else \"\" # Remove the meshes in the sampled app as they're not used if maldi_data . _sample_data and \"meshes\" in os . listdir ( brainglobe_dir + \"allen_mouse_\" + str ( self . resolution ) + \"um\" + appendix ): shutil . rmtree ( brainglobe_dir + \"allen_mouse_\" + str ( self . resolution ) + \"um\" + appendix + \"/meshes\" ) # When computing an array of figures with a slider to explore the atlas, subsample in the # longitudinal direction, otherwise it's too heavy self . subsampling_block = 20 # Load string annotation for contour plot, for each voxel. # These objects are heavy (~300mb) as they force the loading of annotations from the core # Atlas class. But they shouldn't be memory-mapped as they are called when hovering and # require very fast response from the server self . labels = Labels ( self . bg_atlas , force_init = True ) # Compute a dictionnary that associates to each structure (acronym) the set of ids (int) of # all of its children. Used only in page_4_plot_graph_volume, but it's very light (~3mb) so # no problem using it as an attribute self . dic_acronym_children_id = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"dic_acronym_children_id\" , force_update = False , compute_function = self . compute_dic_acronym_children_id , ) # Load array of coordinates for warped data (can't be loaded on the fly from shelve as used # with hovering). Weights ~225mb if maldi_data . _sample_data : with np . load ( \"data_sample/tiff_files/coordinates_warped_data.npz\" ) as handle : self . array_coordinates_warped_data = handle [ \"array_coordinates_warped_data\" ] else : self . array_coordinates_warped_data = skimage . io . imread ( \"data/tiff_files/coordinates_warped_data.tif\" ) # Record shape of the warped data self . image_shape = list ( self . array_coordinates_warped_data . shape [ 1 : - 1 ]) # Record dict that associate brain region (complete string) to specific id (short label), # along with graph of structures (l_nodes and l_parents). Although the treemap graph is # precomputed, the two dics of name and acronyms are relatively lightweight and are used in # many different place, so they shouldn't be used a properties ( self . l_nodes , self . l_parents , self . dic_name_acronym , self . dic_acronym_name , ) = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"hierarchy\" , force_update = False , compute_function = self . compute_hierarchy_list , ) # Array_projection_corrected is used a lot for lipid expression plots, as it encodes the # warping transformation of the data. Therefore it shouldn't be used a as a property. # Weights ~150mb # * The type is np.int16, and can't be reduced anymore as values are sometimes above 400 self . array_projection_correspondence_corrected = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"arrays_projection_corrected\" , force_update = False , compute_function = self . compute_array_projection , nearest_neighbour_correction = True , atlas_correction = True , )[ 1 ] # Load arrays of original images coordinates. It is used everytime a 3D object is computed. # Weights ~50mb self . l_original_coor = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"arrays_projection_corrected\" , force_update = False , compute_function = self . compute_array_projection , nearest_neighbour_correction = True , atlas_correction = True , )[ 2 ] # Dictionnary of existing masks per slice, which associates slice index (key) to a set of # masks acronyms if self . storage . check_shelved_object ( \"atlas/atlas_objects\" , \"dic_existing_masks\" ): self . dic_existing_masks = self . storage . load_shelved_object ( \"atlas/atlas_objects\" , \"dic_existing_masks\" ) else : logging . info ( \"The dictionnary of available mask per slice has not been computed yet. \" + \"Doing it now, this may take several hours.\" ) # Since this function is called at startup, no data locking is needed self . save_all_projected_masks_and_spectra ( cache_flask = None , sample = sample ) # These attributes are defined later as properties as they are only used during # precomputations self . _array_projection_corrected = None self . _list_projected_atlas_borders_arrays = None logging . info ( \"Atlas object instantiated\" + logmem ())","title":"__init__()"},{"location":"modules/atlas/#modules.atlas.Atlas.array_projection_corrected","text":"Load arrays of images using atlas projection. It's a property to save memory as it is only used with objects that should also be precomputed. Returns: Type Description np . ndarray A three-dimensional array which contains the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. Source code in modules/atlas.py 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 @property def array_projection_corrected ( self ): \"\"\"Load arrays of images using atlas projection. It's a property to save memory as it is only used with objects that should also be precomputed. Returns: (np.ndarray): A three-dimensional array which contains the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. \"\"\" if self . _array_projection_corrected is None : logging . info ( \"array_projection_corrected is being loaded. This should only happen during\" \" precomputations.\" + logmem () ) self . _array_projection_corrected = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"arrays_projection_corrected\" , force_update = False , compute_function = self . compute_array_projection , nearest_neighbour_correction = True , atlas_correction = True , )[ 0 ] return self . _array_projection_corrected","title":"array_projection_corrected()"},{"location":"modules/atlas/#modules.atlas.Atlas.compute_array_projection","text":"Compute three arrays relating the original coordinates of our data to their projection in the CCFv3. Parameters: Name Type Description Default nearest_neighbour_correction bool If True, the gaps due to the warping and upscaling of the projection are filled with a heuristic method. Defaults to False. False atlas_correction bool If True, the pixels that are outside of any annotated region are zeroed out. Defaults to False. False Returns: Type Description np . ndarray , np . ndarray , list ( np . ndarray ) The first array is a high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, which acts as a mapping table. The list contains the arrays of original coordinates, for each slice. Source code in modules/atlas.py 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 def compute_array_projection ( self , nearest_neighbour_correction = False , atlas_correction = False ): \"\"\"Compute three arrays relating the original coordinates of our data to their projection in the CCFv3. Args: nearest_neighbour_correction (bool, optional): If True, the gaps due to the warping and upscaling of the projection are filled with a heuristic method. Defaults to False. atlas_correction (bool, optional): If True, the pixels that are outside of any annotated region are zeroed out. Defaults to False. Returns: (np.ndarray, np.ndarray, list(np.ndarray)): The first array is a high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, which acts as a mapping table. The list contains the arrays of original coordinates, for each slice. \"\"\" # Start with empty array array_projection = np . zeros ( self . array_coordinates_warped_data . shape [: - 1 ], dtype = np . int16 ) array_projection_filling = np . zeros ( array_projection . shape , dtype = np . int16 ) # This array makes the correspondence between the original data coordinates and the new ones array_projection_correspondence = np . zeros ( array_projection . shape + ( 2 ,), dtype = np . int16 ) array_projection_correspondence . fill ( - 1 ) # List of orginal coordinates l_original_coor = [] l_transform_parameters = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"l_transform_parameters\" , force_update = False , compute_function = self . compute_projection_parameters , ) for i in range ( array_projection . shape [ 0 ]): # Get transform parameters a , u , v = l_transform_parameters [ i ] # Load corresponding slice and coor if self . data . _sample_data : path = \"data_sample/tiff_files/coordinates_original_data/\" else : path = \"data/tiff_files/coordinates_original_data/\" filename = ( path + [ x for x in os . listdir ( path ) if str ( i + 1 ) == x . split ( \"_\" )[ 1 ] . split ( \"-\" )[ 0 ]][ 0 ] ) if self . data . _sample_data : original_coor = np . load ( filename ) else : original_coor = skimage . io . imread ( filename ) l_original_coor . append ( original_coor ) if self . data . _sample_data : path = \"data_sample/tiff_files/original_data/\" else : path = \"data/tiff_files/original_data/\" filename = ( path + [ x for x in os . listdir ( path ) if str ( i + 1 ) == x . split ( \"slice_\" )[ 1 ] . split ( \".tiff\" )[ 0 ] ][ 0 ] ) original_slice = np . array ( skimage . io . imread ( filename ), dtype = np . uint8 ) # Keep only last channel if not self . data . _sample_data : original_slice = original_slice [:, :, 2 ] # Map back the pixel from the atlas coordinates array_projection , array_projection_correspondence = fill_array_projection ( i , array_projection , array_projection_filling , array_projection_correspondence , original_coor , self . resolution , a , u , v , original_slice , self . array_coordinates_warped_data [ i ], self . bg_atlas . annotation , nearest_neighbour_correction = nearest_neighbour_correction , atlas_correction = atlas_correction , sample_data = self . data . _sample_data , ) return array_projection , array_projection_correspondence , l_original_coor","title":"compute_array_projection()"},{"location":"modules/atlas/#modules.atlas.Atlas.compute_dic_acronym_children_id","text":"Recursively compute a dictionnary that associates brain structures to the set of their children. Returns: Type Description dict A dictionnary that associate to each structure (acronym) the set of ids (int) of all of its children. Source code in modules/atlas.py 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 def compute_dic_acronym_children_id ( self ): \"\"\"Recursively compute a dictionnary that associates brain structures to the set of their children. Returns: (dict): A dictionnary that associate to each structure (acronym) the set of ids (int) of all of its children. \"\"\" # Recursive function to compute the parent of each structure def fill_dic_acronym_children_id ( dic_acronym_children_id , l_id_leaves ): older_leave_id = l_id_leaves [ 0 ] acronym = self . bg_atlas . structures [ older_leave_id ][ \"acronym\" ] for id_leave in l_id_leaves : # Fill dic with current acronym and id if acronym in dic_acronym_children_id : dic_acronym_children_id [ acronym ] . add ( id_leave ) else : dic_acronym_children_id [ acronym ] = set ([ id_leave ]) # While root is not reached, climb back the ancestor tree if len ( self . bg_atlas . structures [ older_leave_id ][ \"structure_id_path\" ]) >= 2 : id_parent = self . bg_atlas . structures [ older_leave_id ][ \"structure_id_path\" ][ - 2 ] dic_acronym_children_id = fill_dic_acronym_children_id ( dic_acronym_children_id , [ id_parent ] + l_id_leaves ) return dic_acronym_children_id # Initialize dictionnary as empty dic_acronym_children_id = {} # Loop over each structure for id in set ( self . bg_atlas . annotation . flatten ()): if id != 0 : # Fill the dictionnary by climbing up the hierarchy structure dic_acronym_children_id = fill_dic_acronym_children_id ( dic_acronym_children_id , [ id ] ) return dic_acronym_children_id","title":"compute_dic_acronym_children_id()"},{"location":"modules/atlas/#modules.atlas.Atlas.compute_hierarchy_list","text":"Compute, for each children (node), the corresponding parent, to build a list associating child/parent for all structures, and also compute dictionnaries that associate structure acronyms to their complete name in the process. Returns: Type Description list ( str ) List of children (node) names. list ( str ) List of parent names. dict A dictionnary that associate structure name to its acronym. dict A dictionnary that associate structure acronym to its name. Source code in modules/atlas.py 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 def compute_hierarchy_list ( self ): \"\"\"Compute, for each children (node), the corresponding parent, to build a list associating child/parent for all structures, and also compute dictionnaries that associate structure acronyms to their complete name in the process. Returns: (list(str)): List of children (node) names. (list(str)): List of parent names. (dict): A dictionnary that associate structure name to its acronym. (dict): A dictionnary that associate structure acronym to its name. \"\"\" # Create a list of parents for all ancestors l_nodes = [] l_parents = [] dic_name_acronym = {} dic_acronym_name = {} idx = 0 # Loop over each structure for x , v in self . bg_atlas . structures . items (): # Keep only a very restrained amount of structures if sample data if ( self . data . _sample_data and len ( self . bg_atlas . get_structure_ancestors ( v [ \"acronym\" ])) > 1 ): continue if len ( self . bg_atlas . get_structure_ancestors ( v [ \"acronym\" ])) > 0 : ancestor_acronym = self . bg_atlas . get_structure_ancestors ( v [ \"acronym\" ])[ - 1 ] ancestor_name = self . bg_atlas . structures [ ancestor_acronym ][ \"name\" ] else : ancestor_name = \"\" current_name = self . bg_atlas . structures [ x ][ \"name\" ] l_nodes . append ( current_name ) l_parents . append ( ancestor_name ) # Register the name/acronym association for each structure dic_name_acronym [ current_name ] = v [ \"acronym\" ] dic_acronym_name [ v [ \"acronym\" ]] = current_name return l_nodes , l_parents , dic_name_acronym , dic_acronym_name","title":"compute_hierarchy_list()"},{"location":"modules/atlas/#modules.atlas.Atlas.compute_list_projected_atlas_borders_figures","text":"Compute an array of projected atlas borders (i.e. image of atlas annotations). Returns: Type Description list ( np . ndarray ) A list of arrays, one per slice, which contains the atlas borders projected on our data. Source code in modules/atlas.py 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 def compute_list_projected_atlas_borders_figures ( self ): \"\"\"Compute an array of projected atlas borders (i.e. image of atlas annotations). Returns: (list(np.ndarray)): A list of arrays, one per slice, which contains the atlas borders projected on our data. \"\"\" l_array_images = [] # Load array of atlas images corresponding to our data and how it is projected ( array_projected_images_atlas , array_projected_simplified_id , ) = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"array_images_atlas\" , force_update = False , compute_function = self . prepare_and_compute_array_images_atlas , zero_out_of_annotation = True , ) # Loop over slice, compute image every time for slice_index in range ( array_projected_simplified_id . shape [ 0 ]): contours = ( array_projected_simplified_id [ slice_index , 1 :, 1 :] - array_projected_simplified_id [ slice_index , : - 1 , : - 1 ] ) contours = np . clip ( contours ** 2 , 0 , 1 ) contours = np . pad ( contours , (( 1 , 0 ), ( 1 , 0 ))) # Do some cleaning on the sides contours [:, : 10 ] = 0 contours [:, - 10 :] = 0 contours [: 10 , :] = 0 contours [ - 10 :, :] = 0 # Compute a matplolib figure and export it as image (it's a hack but it does the job) fig = plt . figure ( frameon = False ) dpi = 100 fig . set_size_inches ( contours . shape [ 1 ] / dpi , contours . shape [ 0 ] / dpi ) ax = fig . add_axes ([ 0 , 0 , 1 , 1 ]) ax . axis ( \"off\" ) prefix = \"data:image/png;base64,\" plt . contour ( contours , colors = \"orange\" , antialiased = True , linewidths = 0.2 , origin = \"image\" ) with BytesIO () as stream : plt . savefig ( stream , format = \"png\" , dpi = dpi ) plt . close () img = imread ( io . BytesIO ( stream . getvalue ())) l_array_images . append ( img ) return l_array_images","title":"compute_list_projected_atlas_borders_figures()"},{"location":"modules/atlas/#modules.atlas.Atlas.compute_projection_parameters","text":"Compute the parameters used to map the 3D coordinates of the CCFv3 to the the 2D (tiled) slices. Returns: Type Description list ( float , float , float ) A list of tuples, each with three parameters, that allow to map the 3D coordinates of the CCFv3 to the tiled planes representing the slices. One per slice. Source code in modules/atlas.py 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 def compute_projection_parameters ( self ): \"\"\"Compute the parameters used to map the 3D coordinates of the CCFv3 to the the 2D (tiled) slices. Returns: (list((float,float,float))): A list of tuples, each with three parameters, that allow to map the 3D coordinates of the CCFv3 to the tiled planes representing the slices. One per slice. \"\"\" l_transform_parameters = [] for slice_index in range ( self . array_coordinates_warped_data . shape [ 0 ]): a_atlas , u_atlas , v_atlas = solve_plane_equation ( self . array_coordinates_warped_data [ slice_index ] ) l_transform_parameters . append (( a_atlas , u_atlas , v_atlas )) return l_transform_parameters","title":"compute_projection_parameters()"},{"location":"modules/atlas/#modules.atlas.Atlas.compute_spectrum_data","text":"This function computes the averaged spectral data for a given slice and a given mask, the latter being provided either as a mask name, either as an array (at least one of the two must not be None). If the mask is provided as an array, the corresponding array of slice coordinates (slice_coor_rescaled) must be provided. Parameters: Name Type Description Default slice_index int Index of the requested slice. required projected_mask np . ndarray A two-dimensional array representing the projected mask on the requested slice. Defaults to None. None mask_name str Acronym of the requestes mask. Defaults to None. None slice_coor_rescaled np . ndarray The array of coordinates in the CCFv3 for the current slice. Defaults to None. None MAIA_correction bool If True, the MAIA corrected version of the MALDI data is used for computation (if it exists). Defaults to False. False cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description np . ndarray A 2D numpy array containing the averaged spectral data of the pixels in the requested mask of the requested slice. First row contains m/z values, second row contains the averaged intensities. Source code in modules/atlas.py 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 def compute_spectrum_data ( self , slice_index , projected_mask = None , mask_name = None , slice_coor_rescaled = None , MAIA_correction = False , cache_flask = None , ): \"\"\"This function computes the averaged spectral data for a given slice and a given mask, the latter being provided either as a mask name, either as an array (at least one of the two must not be None). If the mask is provided as an array, the corresponding array of slice coordinates (slice_coor_rescaled) must be provided. Args: slice_index (int): Index of the requested slice. projected_mask (np.ndarray, optional): A two-dimensional array representing the projected mask on the requested slice. Defaults to None. mask_name (str, optional): Acronym of the requestes mask. Defaults to None. slice_coor_rescaled (np.ndarray, optional): The array of coordinates in the CCFv3 for the current slice. Defaults to None. MAIA_correction (bool, optional): If True, the MAIA corrected version of the MALDI data is used for computation (if it exists). Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (np.ndarray): A 2D numpy array containing the averaged spectral data of the pixels in the requested mask of the requested slice. First row contains m/z values, second row contains the averaged intensities. \"\"\" # Control that a mask can be provided one way or the other if projected_mask is None and mask_name is None : print ( \"Either a mask or a mask name must be provided\" ) return None # If a mask name has been provided, get the corresponding mask array elif mask_name is not None : if slice_coor_rescaled is None : slice_coor_rescaled = np . asarray ( ( self . array_coordinates_warped_data [ slice_index , :, :] * 1000 / self . resolution ) . round ( 0 ), dtype = np . int16 , ) stack_mask = self . get_atlas_mask ( self . dic_name_acronym [ mask_name ]) projected_mask = project_atlas_mask ( stack_mask , slice_coor_rescaled , self . bg_atlas . reference . shape ) # Get the list of rows containing the pixels to average original_shape = self . data . get_image_shape ( slice_index + 1 ) mask_remapped = np . zeros ( original_shape , dtype = np . uint8 ) list_index_bound_rows , list_index_bound_column_per_row = get_array_rows_from_atlas_mask ( projected_mask , mask_remapped , self . array_projection_correspondence_corrected [ slice_index ], ) if np . sum ( list_index_bound_rows ) == 0 : print ( \"No selection could be found for current mask\" ) grah_scattergl_data = None else : # Do the average grah_scattergl_data = compute_thread_safe_function ( compute_spectrum_per_row_selection , cache_flask , self . data , slice_index + 1 , list_index_bound_rows , list_index_bound_column_per_row , self . data . get_array_spectra ( slice_index + 1 ), self . data . get_array_lookup_pixels ( slice_index + 1 ), original_shape , self . data . get_array_peaks_transformed_lipids ( slice_index + 1 ), self . data . get_array_corrective_factors ( slice_index + 1 ) . astype ( np . float32 ), zeros_extend = False , apply_correction = MAIA_correction , ) return grah_scattergl_data","title":"compute_spectrum_data()"},{"location":"modules/atlas/#modules.atlas.Atlas.get_atlas_mask","text":"Compute a mask for the structure given as argument. The brain regions corresponding to the structure id or any of its descendants are set to the id of the structure. The rest is set to 0. Parameters: Name Type Description Default structure str Structure (brain region) acronym. required Returns: Type Description np . ndarray A 3D mask with the same shape as the array of annotations from the atlas, where all elements are zeros except for the requested structure. Source code in modules/atlas.py 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 def get_atlas_mask ( self , structure ): \"\"\"Compute a mask for the structure given as argument. The brain regions corresponding to the structure id or any of its descendants are set to the id of the structure. The rest is set to 0. Args: structure (str): Structure (brain region) acronym. Returns: (np.ndarray): A 3D mask with the same shape as the array of annotations from the atlas, where all elements are zeros except for the requested structure. \"\"\" logging . info ( 'Getting mask for structure \" {} \"' . format ( structure )) # Get id of the parent structure structure_id = self . bg_atlas . structures [ structure ][ \"id\" ] # Get list of descendants descendants = self . bg_atlas . get_structure_descendants ( structure ) # Build empty mask for 3D array of atlas annotations mask_stack = np . zeros ( self . bg_atlas . shape , self . bg_atlas . annotation . dtype ) # Compute a list of ids (parent + children) we want to keep in the final annotation l_id = [ self . bg_atlas . structures [ descendant ][ \"id\" ] for descendant in descendants ] + [ structure_id ] # Do the masking mask_stack [ np . isin ( self . bg_atlas . annotation , l_id )] = structure_id logging . info ( 'Mask computed for structure \" {} \"' . format ( structure )) return mask_stack","title":"get_atlas_mask()"},{"location":"modules/atlas/#modules.atlas.Atlas.get_projected_mask_and_spectrum","text":"This function is used to get the projected mask and corresponding averaged spectral data for a given mask and a given slice. Parameters: Name Type Description Default slice_index int Index of the requested slice. required mask_name str Acronym of the requested mask. required MAIA_correction bool If True, the MAIA corrected version of the MALDI data is used for computation (if it exists). Defaults to False. False Returns: Type Description np . ndarray , np . ndarray The first array is represents the projected 2D mask on the requested slice. The second array corresponds to the corresponding averaged spectral data (first row is m/z values, second row is averaged intensities). Source code in modules/atlas.py 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 def get_projected_mask_and_spectrum ( self , slice_index , mask_name , MAIA_correction = False ): \"\"\"This function is used to get the projected mask and corresponding averaged spectral data for a given mask and a given slice. Args: slice_index (int): Index of the requested slice. mask_name (str): Acronym of the requested mask. MAIA_correction (bool, optional): If True, the MAIA corrected version of the MALDI data is used for computation (if it exists). Defaults to False. Returns: (np.ndarray, np.ndarray): The first array is represents the projected 2D mask on the requested slice. The second array corresponds to the corresponding averaged spectral data (first row is m/z values, second row is averaged intensities). \"\"\" id_mask = self . dic_name_acronym [ mask_name ] if MAIA_correction : filename = ( \"mask_and_spectrum_MAIA_corrected_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ) ) else : filename = \"mask_and_spectrum_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ) logging . info ( \"Loading \" + mask_name + \" for slice \" + str ( slice_index ) + \" from shelve file.\" ) try : return self . storage . load_shelved_object ( \"atlas/atlas_objects\" , filename ) except : logging . warning ( \"The mask and spectrum data could not be found for \" + mask_name + \" for slice \" + str ( slice_index ) + \". Make sure the files have been precomputed and that you checked the mask\" + \" was present in self.dic_existing_masks\" ) return None","title":"get_projected_mask_and_spectrum()"},{"location":"modules/atlas/#modules.atlas.Atlas.list_projected_atlas_borders_arrays","text":"Load array of projected atlas borders (i.e. image of atlas annotations). It's a property to save memory as it is only used with objects that should also be precomputed. Returns: Type Description list ( np . ndarray ) A list of arrays, one per slice, which contains the atlas borders projected on our data. Source code in modules/atlas.py 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 @property def list_projected_atlas_borders_arrays ( self ): \"\"\"Load array of projected atlas borders (i.e. image of atlas annotations). It's a property to save memory as it is only used with objects that should also be precomputed. Returns: (list(np.ndarray)): A list of arrays, one per slice, which contains the atlas borders projected on our data. \"\"\" if self . _list_projected_atlas_borders_arrays is None : logging . info ( \"list_projected_atlas_borders_arrays is being loaded. This should only happen\" \" during precomputations.\" + logmem () ) self . _list_projected_atlas_borders_arrays = self . storage . return_shelved_object ( \"atlas/atlas_objects\" , \"list_projected_atlas_borders_arrays\" , force_update = False , compute_function = self . compute_list_projected_atlas_borders_figures , ) return self . _list_projected_atlas_borders_arrays","title":"list_projected_atlas_borders_arrays()"},{"location":"modules/atlas/#modules.atlas.Atlas.prepare_and_compute_array_images_atlas","text":"This function is mainly a wrapper for compute_array_images_atlas. It is needed as the computation of an array of simplified structures ids can't be compiled with numba. Parameters: Name Type Description Default zero_out_of_annotation bool If True, the pixels outside of the atlas annotations are zero-ed out. Defaults to False. False Returns: Type Description np . ndarray , np . ndarray The first array is basically a list of atlas images corresponding to the slices acquired during the MALDI acquisition. The second array is the corresponding set of annotations. Source code in modules/atlas.py 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 def prepare_and_compute_array_images_atlas ( self , zero_out_of_annotation = False ): \"\"\"This function is mainly a wrapper for compute_array_images_atlas. It is needed as the computation of an array of simplified structures ids can't be compiled with numba. Args: zero_out_of_annotation (bool, optional): If True, the pixels outside of the atlas annotations are zero-ed out. Defaults to False. Returns: (np.ndarray, np.ndarray): The first array is basically a list of atlas images corresponding to the slices acquired during the MALDI acquisition. The second array is the corresponding set of annotations. \"\"\" # Compute an array of simplified structures ids simplified_atlas_annotation = compute_simplified_atlas_annotation ( self . bg_atlas . annotation ) # Compute the actual array of atlas images return compute_array_images_atlas ( self . array_coordinates_warped_data , simplified_atlas_annotation , self . bg_atlas . reference , self . resolution , zero_out_of_annotation = zero_out_of_annotation , )","title":"prepare_and_compute_array_images_atlas()"},{"location":"modules/atlas/#modules.atlas.Atlas.save_all_projected_masks_and_spectra","text":"This function saves all the (2D) masks and corresponding averaged spectral data, for all the slices. Parameters: Name Type Description Default force_update bool If True, the function will not overwrite existing files. Defaults to False. False cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None sample bool If True, only a tiny sample of the masks will be processed (for debug). Defaults to False. False Source code in modules/atlas.py 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 def save_all_projected_masks_and_spectra ( self , force_update = False , cache_flask = None , sample = False ): \"\"\"This function saves all the (2D) masks and corresponding averaged spectral data, for all the slices. Args: force_update (bool, optional): If True, the function will not overwrite existing files. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. sample (bool, optional): If True, only a tiny sample of the masks will be processed (for debug). Defaults to False. \"\"\" # Path atlas for shelving path_atlas = \"atlas/atlas_objects\" # Sample for debug if sample : logging . warning ( \"Only a sample of the masks and spectra will be computed!\" ) # Define a dictionnary that contains all the masks that exist for every slice dic_existing_masks = {} # Define a dictionnary to save the result of the function slice by slice if self . storage . check_shelved_object ( path_atlas , \"dic_processed_temp\" ): dic_processed_temp = self . storage . load_shelved_object ( path_atlas , \"dic_processed_temp\" , ) else : dic_processed_temp = {} for slice_index in range ( self . data . get_slice_number ()): # Break the loop after the first slice if sample is True if sample and slice_index > 1 : break logging . info ( \"Starting slice \" + str ( slice_index )) slice_coor_rescaled = np . asarray ( ( self . array_coordinates_warped_data [ slice_index , :, :] * 1000 / self . resolution ) . round ( 0 ), dtype = np . int16 , ) dic_existing_masks [ slice_index ] = set ([]) # Check if the slice has already been processed if slice_index not in dic_processed_temp : dic_processed_temp [ slice_index ] = set ([]) # Get hierarchical tree of brain structures n_computed = 0 for mask_name , id_mask in self . dic_name_acronym . items (): if id_mask not in dic_processed_temp [ slice_index ]: # Break the loop after a few computations if sample is True if sample and n_computed > 1 : break if ( not ( self . storage . check_shelved_object ( path_atlas , \"mask_and_spectrum_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ) and self . storage . check_shelved_object ( path_atlas , \"mask_and_spectrum_MAIA_corrected_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ) ) or force_update ): # get the array corresponding to the projected mask stack_mask = self . get_atlas_mask ( id_mask ) # Project the mask onto high resolution data projected_mask = project_atlas_mask ( stack_mask , slice_coor_rescaled , self . bg_atlas . reference . shape ) if np . sum ( projected_mask ) == 0 : logging . info ( \"The structure \" + mask_name + \" is not present in slice \" + str ( slice_index ) ) # Mask doesn't exist, so it considered processed dic_processed_temp [ slice_index ] . add ( id_mask ) continue # Compute average spectrum in the mask grah_scattergl_data = self . compute_spectrum_data ( slice_index , projected_mask , MAIA_correction = False , cache_flask = cache_flask , ) # Add mask to the list of existing masks dic_existing_masks [ slice_index ] . add ( id_mask ) dic_processed_temp [ slice_index ] . add ( id_mask ) # Dump the mask and data with shelve self . storage . dump_shelved_object ( path_atlas , \"mask_and_spectrum_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ( projected_mask , grah_scattergl_data ), ) # Same with MAIA corrected data grah_scattergl_data = self . compute_spectrum_data ( slice_index , projected_mask , MAIA_correction = True , cache_flask = cache_flask , ) self . storage . dump_shelved_object ( path_atlas , \"mask_and_spectrum_MAIA_corrected_\" + str ( slice_index ) + \"_\" + str ( id_mask ) . replace ( \"/\" , \"\" ), ( projected_mask , grah_scattergl_data ), ) else : # Add computed masks to the dics of computed masks dic_existing_masks [ slice_index ] . add ( id_mask ) dic_processed_temp [ slice_index ] . add ( id_mask ) n_computed += 1 else : n_computed += 1 logging . info ( 'Mask \"' + mask_name + '\" already processed' ) # Dump the dictionnary of processed masks with shelve after every slice self . storage . dump_shelved_object ( path_atlas , \"dic_processed_temp\" , dic_processed_temp , ) if not sample : # Dump the dictionnary of existing masks with shelve self . storage . dump_shelved_object ( path_atlas , \"dic_existing_masks\" , dic_existing_masks , ) logging . info ( \"Projected masks and spectra have all been computed.\" ) self . dic_existing_masks = dic_existing_masks","title":"save_all_projected_masks_and_spectra()"},{"location":"modules/atlas_labels/","text":"This module is used to access the Allen Brain Atlas annotations more easily. Labels Class used to access labels data without having to create new arrays. Attributes: Name Type Description bg_atlas BrainGlobeAtlas BrainGlobeAtlas object, used to query the atlas. Methods init (bg_atlas, force_init=True): Initialize the Labels class. getitem (key): Getter for the curent class. Source code in modules/atlas_labels.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 class Labels : \"\"\"Class used to access labels data without having to create new arrays. Attributes: bg_atlas (BrainGlobeAtlas): BrainGlobeAtlas object, used to query the atlas. Methods: __init__(bg_atlas, force_init=True): Initialize the Labels class. __getitem__(key): Getter for the curent class. \"\"\" def __init__ ( self , bg_atlas , force_init = True ): \"\"\"Initialize the class Labels. Args: bg_atlas (BrainGlobeAtlas): BrainGlobeAtlas object, used to query the atlas. force_init (bool, optional): If True, the arrays of annotations and structures in BrainGlobeAtlas are loaded in memory (this avoids to have them during the first query, but rather when the app is initialized). Defaults to True. \"\"\" self . bg_atlas = bg_atlas if force_init : _ = self . bg_atlas . annotation _ = self . bg_atlas . structures def __getitem__ ( self , key ): \"\"\"Getter for the curent class. For every coordinate (key) passed as a parameter, the corresponding label is returned. Arrays of keys are also compatible. Args: key (tuple): Coordinates of the voxel to query. Returns: (str): Label of the voxel in the Allen Brain Atlas. \"\"\" x = self . bg_atlas . annotation [ key ] if isinstance ( x , np . uint32 ): if x != 0 : return self . bg_atlas . structures [ x ][ \"name\" ] else : return \"undefined\" # an array slice have been provided else : return np . reshape ( [ self . bg_atlas . structures [ i ][ \"name\" ] if i != 0 else \"undefined\" for i in x . flatten () ], x . shape , ) __getitem__ ( key ) Getter for the curent class. For every coordinate (key) passed as a parameter, the corresponding label is returned. Arrays of keys are also compatible. Parameters: Name Type Description Default key tuple Coordinates of the voxel to query. required Returns: Type Description str Label of the voxel in the Allen Brain Atlas. Source code in modules/atlas_labels.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def __getitem__ ( self , key ): \"\"\"Getter for the curent class. For every coordinate (key) passed as a parameter, the corresponding label is returned. Arrays of keys are also compatible. Args: key (tuple): Coordinates of the voxel to query. Returns: (str): Label of the voxel in the Allen Brain Atlas. \"\"\" x = self . bg_atlas . annotation [ key ] if isinstance ( x , np . uint32 ): if x != 0 : return self . bg_atlas . structures [ x ][ \"name\" ] else : return \"undefined\" # an array slice have been provided else : return np . reshape ( [ self . bg_atlas . structures [ i ][ \"name\" ] if i != 0 else \"undefined\" for i in x . flatten () ], x . shape , ) __init__ ( bg_atlas , force_init = True ) Initialize the class Labels. Parameters: Name Type Description Default bg_atlas BrainGlobeAtlas BrainGlobeAtlas object, used to query the atlas. required force_init bool If True, the arrays of annotations and structures in BrainGlobeAtlas are loaded in memory (this avoids to have them during the first query, but rather when the app is initialized). Defaults to True. True Source code in modules/atlas_labels.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , bg_atlas , force_init = True ): \"\"\"Initialize the class Labels. Args: bg_atlas (BrainGlobeAtlas): BrainGlobeAtlas object, used to query the atlas. force_init (bool, optional): If True, the arrays of annotations and structures in BrainGlobeAtlas are loaded in memory (this avoids to have them during the first query, but rather when the app is initialized). Defaults to True. \"\"\" self . bg_atlas = bg_atlas if force_init : _ = self . bg_atlas . annotation _ = self . bg_atlas . structures","title":"atlas_labels"},{"location":"modules/atlas_labels/#modules.atlas_labels.Labels","text":"Class used to access labels data without having to create new arrays. Attributes: Name Type Description bg_atlas BrainGlobeAtlas BrainGlobeAtlas object, used to query the atlas. Methods init (bg_atlas, force_init=True): Initialize the Labels class. getitem (key): Getter for the curent class. Source code in modules/atlas_labels.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 class Labels : \"\"\"Class used to access labels data without having to create new arrays. Attributes: bg_atlas (BrainGlobeAtlas): BrainGlobeAtlas object, used to query the atlas. Methods: __init__(bg_atlas, force_init=True): Initialize the Labels class. __getitem__(key): Getter for the curent class. \"\"\" def __init__ ( self , bg_atlas , force_init = True ): \"\"\"Initialize the class Labels. Args: bg_atlas (BrainGlobeAtlas): BrainGlobeAtlas object, used to query the atlas. force_init (bool, optional): If True, the arrays of annotations and structures in BrainGlobeAtlas are loaded in memory (this avoids to have them during the first query, but rather when the app is initialized). Defaults to True. \"\"\" self . bg_atlas = bg_atlas if force_init : _ = self . bg_atlas . annotation _ = self . bg_atlas . structures def __getitem__ ( self , key ): \"\"\"Getter for the curent class. For every coordinate (key) passed as a parameter, the corresponding label is returned. Arrays of keys are also compatible. Args: key (tuple): Coordinates of the voxel to query. Returns: (str): Label of the voxel in the Allen Brain Atlas. \"\"\" x = self . bg_atlas . annotation [ key ] if isinstance ( x , np . uint32 ): if x != 0 : return self . bg_atlas . structures [ x ][ \"name\" ] else : return \"undefined\" # an array slice have been provided else : return np . reshape ( [ self . bg_atlas . structures [ i ][ \"name\" ] if i != 0 else \"undefined\" for i in x . flatten () ], x . shape , )","title":"Labels"},{"location":"modules/atlas_labels/#modules.atlas_labels.Labels.__getitem__","text":"Getter for the curent class. For every coordinate (key) passed as a parameter, the corresponding label is returned. Arrays of keys are also compatible. Parameters: Name Type Description Default key tuple Coordinates of the voxel to query. required Returns: Type Description str Label of the voxel in the Allen Brain Atlas. Source code in modules/atlas_labels.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def __getitem__ ( self , key ): \"\"\"Getter for the curent class. For every coordinate (key) passed as a parameter, the corresponding label is returned. Arrays of keys are also compatible. Args: key (tuple): Coordinates of the voxel to query. Returns: (str): Label of the voxel in the Allen Brain Atlas. \"\"\" x = self . bg_atlas . annotation [ key ] if isinstance ( x , np . uint32 ): if x != 0 : return self . bg_atlas . structures [ x ][ \"name\" ] else : return \"undefined\" # an array slice have been provided else : return np . reshape ( [ self . bg_atlas . structures [ i ][ \"name\" ] if i != 0 else \"undefined\" for i in x . flatten () ], x . shape , )","title":"__getitem__()"},{"location":"modules/atlas_labels/#modules.atlas_labels.Labels.__init__","text":"Initialize the class Labels. Parameters: Name Type Description Default bg_atlas BrainGlobeAtlas BrainGlobeAtlas object, used to query the atlas. required force_init bool If True, the arrays of annotations and structures in BrainGlobeAtlas are loaded in memory (this avoids to have them during the first query, but rather when the app is initialized). Defaults to True. True Source code in modules/atlas_labels.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , bg_atlas , force_init = True ): \"\"\"Initialize the class Labels. Args: bg_atlas (BrainGlobeAtlas): BrainGlobeAtlas object, used to query the atlas. force_init (bool, optional): If True, the arrays of annotations and structures in BrainGlobeAtlas are loaded in memory (this avoids to have them during the first query, but rather when the app is initialized). Defaults to True. \"\"\" self . bg_atlas = bg_atlas if force_init : _ = self . bg_atlas . annotation _ = self . bg_atlas . structures","title":"__init__()"},{"location":"modules/figures/","text":"This class is used to produce the figures and widgets used in the app, themselves requiring data from the MALDI imaging, and the Allen Brain Atlas, as well as the mapping between the two. Figures This class is used to produce the figures and widgets used in the app. It uses the special attribute slots for faster access to the attributes. Parameters are ignored in the docstring of the listed methods below to save space. Please consult the docstring of the actual methods in the source-code for more information: Attributes: Name Type Description _data MaldiData MaldiData object, used to manipulate the raw MALDI data. _storage Storage Used to access the shelve database. _atlas Atlas Used to manipulate the objects coming from the Allen Brain Atlas. _scRNAseq ScRNAseq Used to manipulate the objects coming from the scRNAseq dataset. dic_normalization_factors dict Dictionnary of normalization factors across slices for MAIA. Methods init (): Initialize the Figures class. compute_array_basic_images(): Computes a three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. compute_figure_basic_image(): Computes a figure representing slices from the TIC or the corresponding image from the atlas. compute_figure_slices_3D(): Computes a figure representing all slices from the maldi data in 3D. get_surface(): Computes a Plotly Surface representing the requested slice in 3D. compute_image_per_lipid(): Allows to query the MALDI data to extract an image representing the intensity of each lipid in the requested slice. compute_normalization_factor_across_slices(): Computes a dictionnary of normalization factors across all slices. build_lipid_heatmap_from_image(): Converts a numpy array into a base64 string, a go.Image, or a Plotly Figure. compute_heatmap_per_mz(): Computes a heatmap of the lipid expressed in the requested slice whose m/z is between the two provided boundaries. compute_heatmap_per_lipid_selection(): Computes a heatmap of the sum of expression of the requested lipids in the requested slice. compute_rgb_array_per_lipid_selection(): Computes a numpy RGB array of expression of the requested lipids in the requested slice. compute_rgb_image_per_lipid_selection(): Similar to compute_heatmap_per_lipid_selection, but computes an RGB image instead of a heatmap. compute_spectrum_low_res(): Returns the full (low-resolution) spectrum of the requested slice. compute_spectrum_high_res(): Returns the full (high-resolution) spectrum of the requested slice between the two provided m/z boundaries. return_empty_spectrum(): Returns an empty spectrum. return_heatmap_lipid(): Either generate a Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. compute_treemaps_figure(): Generates a Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. compute_3D_root_volume(): Generate a go.Isosurface of the Allen Brain root structure, which will be used to enclose the display of lipid expression of other structures in the brain. get_array_of_annotations(): Returns the array of annotations from the Allen Brain Atlas, subsampled to decrease the size of the output. compute_l_array_2D(): Gets the list of expression per slice for all slices for the computation of the 3D brain volume. compute_array_coordinates_3D(): Computes the list of coordinates and expression values for the voxels used in the 3D representation of the brain. compute_3D_volume_figure(): Computes a Plotly Figure containing a go.Volume object representing the expression of the requested lipids in the selected regions. compute_clustergram_figure(): Computes a Plotly Clustergram figure, allowing to cluster and compare the expression of all the MAIA-transformed lipids in the dataset in the selected regions. compute_scatter_3D(): cmputes a figure representing, in a 3D scatter plot, the spots acquired using spatial scRNAseq experiments. compute_barplots_enrichment(): Computes two figures representing, in barplots, the lipid expression in the spots acquired using spatial scRNAseq experiments, as well as how it can be explained by an elastic net regression using gene expression as explaing factors. compute_heatmap_lipid_genes(): Computes a heatmap representing the expression of a given lipid in the MALDI data and the expressions of the selected genes. shelve_arrays_basic_figures(): Shelves in the database all the arrays of basic images computed in compute_figure_basic_image(), across all slices and all types of arrays. shelve_all_l_array_2D(): Precomputes and shelves all the arrays of lipid expression used in a 3D representation of the brain. shelve_all_arrays_annotation(): Precomputes and shelves the array of structure annotation used in a 3D representation of the brain. Source code in modules/figures.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 2599 2600 2601 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 2645 2646 2647 2648 2649 2650 2651 2652 2653 2654 2655 2656 2657 2658 2659 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671 2672 2673 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685 2686 2687 2688 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713 2714 2715 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727 2728 2729 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741 2742 2743 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755 2756 2757 2758 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769 2770 2771 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783 2784 2785 2786 2787 2788 2789 2790 2791 2792 2793 2794 2795 2796 2797 2798 2799 2800 2801 2802 2803 2804 2805 2806 2807 2808 class Figures : \"\"\"This class is used to produce the figures and widgets used in the app. It uses the special attribute __slots__ for faster access to the attributes. Parameters are ignored in the docstring of the listed methods below to save space. Please consult the docstring of the actual methods in the source-code for more information: Attributes: _data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. _storage (Storage): Used to access the shelve database. _atlas (Atlas): Used to manipulate the objects coming from the Allen Brain Atlas. _scRNAseq (ScRNAseq): Used to manipulate the objects coming from the scRNAseq dataset. dic_normalization_factors (dict): Dictionnary of normalization factors across slices for MAIA. Methods: __init__(): Initialize the Figures class. compute_array_basic_images(): Computes a three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. compute_figure_basic_image(): Computes a figure representing slices from the TIC or the corresponding image from the atlas. compute_figure_slices_3D(): Computes a figure representing all slices from the maldi data in 3D. get_surface(): Computes a Plotly Surface representing the requested slice in 3D. compute_image_per_lipid(): Allows to query the MALDI data to extract an image representing the intensity of each lipid in the requested slice. compute_normalization_factor_across_slices(): Computes a dictionnary of normalization factors across all slices. build_lipid_heatmap_from_image(): Converts a numpy array into a base64 string, a go.Image, or a Plotly Figure. compute_heatmap_per_mz(): Computes a heatmap of the lipid expressed in the requested slice whose m/z is between the two provided boundaries. compute_heatmap_per_lipid_selection(): Computes a heatmap of the sum of expression of the requested lipids in the requested slice. compute_rgb_array_per_lipid_selection(): Computes a numpy RGB array of expression of the requested lipids in the requested slice. compute_rgb_image_per_lipid_selection(): Similar to compute_heatmap_per_lipid_selection, but computes an RGB image instead of a heatmap. compute_spectrum_low_res(): Returns the full (low-resolution) spectrum of the requested slice. compute_spectrum_high_res(): Returns the full (high-resolution) spectrum of the requested slice between the two provided m/z boundaries. return_empty_spectrum(): Returns an empty spectrum. return_heatmap_lipid(): Either generate a Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. compute_treemaps_figure(): Generates a Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. compute_3D_root_volume(): Generate a go.Isosurface of the Allen Brain root structure, which will be used to enclose the display of lipid expression of other structures in the brain. get_array_of_annotations(): Returns the array of annotations from the Allen Brain Atlas, subsampled to decrease the size of the output. compute_l_array_2D(): Gets the list of expression per slice for all slices for the computation of the 3D brain volume. compute_array_coordinates_3D(): Computes the list of coordinates and expression values for the voxels used in the 3D representation of the brain. compute_3D_volume_figure(): Computes a Plotly Figure containing a go.Volume object representing the expression of the requested lipids in the selected regions. compute_clustergram_figure(): Computes a Plotly Clustergram figure, allowing to cluster and compare the expression of all the MAIA-transformed lipids in the dataset in the selected regions. compute_scatter_3D(): cmputes a figure representing, in a 3D scatter plot, the spots acquired using spatial scRNAseq experiments. compute_barplots_enrichment(): Computes two figures representing, in barplots, the lipid expression in the spots acquired using spatial scRNAseq experiments, as well as how it can be explained by an elastic net regression using gene expression as explaing factors. compute_heatmap_lipid_genes(): Computes a heatmap representing the expression of a given lipid in the MALDI data and the expressions of the selected genes. shelve_arrays_basic_figures(): Shelves in the database all the arrays of basic images computed in compute_figure_basic_image(), across all slices and all types of arrays. shelve_all_l_array_2D(): Precomputes and shelves all the arrays of lipid expression used in a 3D representation of the brain. shelve_all_arrays_annotation(): Precomputes and shelves the array of structure annotation used in a 3D representation of the brain. \"\"\" __slots__ = [ \"_data\" , \"_atlas\" , \"_scRNAseq\" , \"_storage\" , \"dic_normalization_factors\" ] # ============================================================================================== # --- Constructor # ============================================================================================== def __init__ ( self , maldi_data , storage , atlas , scRNAseq , sample = False ): \"\"\"Initialize the Figures class. Args: maldi_data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. storage (Storage): Used to access the shelve database. atlas (Atlas): Used to manipulate the objects coming from the Allen Brain Atlas. scRNAseq (ScRNAseq): Used to manipulate the objects coming from the scRNAseq dataset. sample (bool, optional): If True, only a fraction of the precomputations are made (for debug). Default to False. \"\"\" logging . info ( \"Initializing Figures object\" + logmem ()) # Attribute to easily access the maldi and allen brain atlas data self . _data = maldi_data self . _atlas = atlas self . _scRNAseq = scRNAseq # attribute to access the shelve database self . _storage = storage # Dic of normalization factors across slices for MAIA normalized lipids self . dic_normalization_factors = self . _storage . return_shelved_object ( \"figures/lipid_selection\" , \"dic_normalization_factors\" , force_update = False , compute_function = self . compute_normalization_factor_across_slices , cache_flask = None , # No cache since launched at startup ) # Check that treemaps has been computed already. If not, compute it and store it. if not self . _storage . check_shelved_object ( \"figures/atlas_page/3D\" , \"treemaps\" ): self . _storage . return_shelved_object ( \"figures/atlas_page/3D\" , \"treemaps\" , force_update = False , compute_function = self . compute_treemaps_figure , ), # Check that 3D slice figures have been computed already. If not, compute it and store it. for brain in [ \"brain_1\" , \"brain_2\" ]: if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"slices_3D_\" + brain ): self . _storage . return_shelved_object ( \"figures/3D_page\" , \"slices_3D\" , force_update = False , compute_function = self . compute_figure_slices_3D , brain = brain , ) # Check that the 3D root volume figure has been computed already. If not, compute it and # store it. if self . _storage . check_shelved_object ( \"figures/scRNAseq_page\" , \"scatter3D\" ): self . _storage . return_shelved_object ( \"figures/scRNAseq_page\" , \"scatter3D\" , force_update = False , compute_function = self . compute_scatter_3D , ) # Check that the 3D scatter plot for scRNAseq data has been computed already. If not, # compute it and store it. if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"volume_root\" ): self . _storage . return_shelved_object ( \"figures/3D_page\" , \"volume_root\" , force_update = False , compute_function = self . compute_3D_root_volume , ) # Check that the base figures for lipid/genes heatmap have been computed already. If not, # compute them and store them. if not self . _storage . check_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid_True\" ) or not self . _storage . check_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid_False\" ): self . _storage . return_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid\" , force_update = False , compute_function = self . compute_heatmap_lipid_genes , brain_1 = False , ), self . _storage . return_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid\" , force_update = False , compute_function = self . compute_heatmap_lipid_genes , brain_1 = True , ), # Check that all basic figures in the load_slice page are present, if not, compute them if not self . _storage . check_shelved_object ( \"figures/load_page\" , \"arrays_basic_figures_computed\" ): self . shelve_arrays_basic_figures () # Check that the lipid distributions for all slices, and both brains, have been computed, if # not, compute them if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"arrays_expression_True_computed\" ): self . shelve_all_l_array_2D ( sample = sample , brain_1 = True ) if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"arrays_expression_False_computed\" ): self . shelve_all_l_array_2D ( sample = sample , brain_1 = False ) # Check that all arrays of annotations have been computed, if not, compute them if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"arrays_annotation_computed\" ): self . shelve_all_arrays_annotation () logging . info ( \"Figures object instantiated\" + logmem ()) # ============================================================================================== # --- Methods used mainly in load_slice # ============================================================================================== def compute_array_basic_images ( self , type_figure = \"warped_data\" ): \"\"\"This function computes and returns a three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. No spectral data is read in the process, as the arrays corresponding to the images are directly stored as tiff files in the dataset. Args: type_figure (str, optional): To be chosen among \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\". Depending on the chosen type, the final array will correspond to either the original images (\"original_data\"), the warped and upscaled images (\"warped_data\"), the warped and upscaled images, whose pixels outside of annotations regions have been zero-ed out (\"projection_corrected\"), or the images from the Allen Brain atlas projected onto the same plane as the corresponding slice from the MALDI data (\"atlas\"). Default to \"warped_data\". Returns: (np.ndarray): A three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. The first dimension corresponds to the slices, the second and third to the images themselves. \"\"\" # Check for all array types if type_figure == \"original_data\" : array_images = self . _data . compute_padded_original_images () elif type_figure == \"warped_data\" : if self . _data . _sample_data : with np . load ( \"data_sample/tiff_files/warped_data.npz\" ) as handle : array_images = handle [ \"array_warped_data\" ] else : array_images = io . imread ( \"data/tiff_files/warped_data.tif\" ) elif type_figure == \"projection_corrected\" : array_images = self . _atlas . array_projection_corrected elif type_figure == \"atlas\" : ( array_projected_images_atlas , array_projected_simplified_id , ) = self . _storage . return_shelved_object ( \"atlas/atlas_objects\" , \"array_images_atlas\" , force_update = False , compute_function = self . _atlas . prepare_and_compute_array_images_atlas , zero_out_of_annotation = True , ) array_images = array_projected_images_atlas else : logging . warning ( 'The type of requested array \" {} \" does not exist.' . format ( type_figure )) return None # If the array is not uint8, convert it to gain space if array_images . dtype != np . uint8 : array_images = np . array ( array_images , dtype = np . uint8 ) return array_images def compute_figure_basic_image ( self , type_figure , index_image , plot_atlas_contours = True , only_contours = False , draw = False ): \"\"\"This function computes and returns a figure representing slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. The data is read directly from the array computed in self.compute_array_basic_images(). Args: type_figure (str): To be chosen among \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\". Depending on the chosen type, the final figure will correspond to either the original images (\"original_data\"), the warped and upscaled images (\"warped_data\"), the warped and upscaled images, whose pixels outside of annotations regions have been zero-ed out (\"projection_corrected\"), or the images from the Allen Brain atlas projected onto the same plane as the corresponding slice from the MALDI data (\"atlas\"). index_image (int): Index of the requested slice image. plot_atlas_contours (bool, optional): If True, the atlas contours annotation is superimposed with the slice image. Defaults to True. only_contours (bool, optional): If True, only output the atlas contours annotation. All the other arugments but plot_atlas_contours (which must be True) get ignored. Defaults to False. draw (bool, optional): If True, the figure can be drawed on (used for region selection, in page region_analysis). Defaults to False. Returns: (go.Figure): A Plotly figure representing the requested slice image of the requested type. \"\"\" # If only boundaries is requested, force the computation of atlas contours if only_contours : plot_atlas_contours = True else : # Get array of images array_images = self . _storage . return_shelved_object ( \"figures/load_page\" , \"array_basic_images\" , force_update = False , compute_function = self . compute_array_basic_images , type_figure = type_figure , ) # Get image at specified index array_image = array_images [ index_image ] # Add the contours if requested if plot_atlas_contours : array_image_atlas = self . _atlas . list_projected_atlas_borders_arrays [ index_image ] else : array_image_atlas = None # Create figure fig = go . Figure () # Compute image from our data if not only the atlas annotations are requested if not only_contours : fig . add_trace ( go . Image ( visible = True , source = convert_image_to_base64 ( array_image , overlay = array_image_atlas , transparent_zeros = True ), hoverinfo = \"none\" , ) ) # Add the labels only if it's not a simple annotation illustration # fig.update_xaxes( # title_text=self._atlas.bg_atlas.space.axis_labels[0][1], title_standoff=0 # ) else : fig . add_trace ( go . Image ( visible = True , source = convert_image_to_base64 ( array_image_atlas , optimize = True , binary = True , type = \"RGBA\" , decrease_resolution_factor = 8 , ), hoverinfo = \"none\" , ) ) # Improve layout fig . update_xaxes ( showticklabels = False ) fig . update_yaxes ( showticklabels = False ) fig . update_layout ( margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), xaxis = dict ( showgrid = False , zeroline = False ), yaxis = dict ( showgrid = False , zeroline = False ), template = \"plotly_dark\" , paper_bgcolor = \"rgba(0,0,0,0)\" , plot_bgcolor = \"rgba(0,0,0,0)\" , ) if draw : fig . update_layout ( dragmode = \"drawclosedpath\" , newshape = dict ( fillcolor = l_colors [ 0 ], opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ) ), autosize = True , ) return fig def compute_figure_slices_3D ( self , reduce_resolution_factor = 20 , brain = \"brain_1\" ): \"\"\"This function computes and returns a figure representing the slices from the maldi data in 3D. Args: reduce_resolution_factor (int, optional): Divides (reduce) the initial resolution of the data. Needed as the resulting figure can be very heavy. Defaults to 20. brain (str, optional): Name of the brain to be used. Defaults to 'brain_1'. Returns: (go.Figure): A Plotly figure representing the slices from the MALDI acquisitions in 3D. \"\"\" # Get transform parameters (a,u,v) for each slice l_transform_parameters = self . _storage . return_shelved_object ( \"atlas/atlas_objects\" , \"l_transform_parameters\" , force_update = False , compute_function = self . _atlas . compute_projection_parameters , ) # Reduce resolution of the slices new_dims = [] n_slices = self . _atlas . array_coordinates_warped_data . shape [ 0 ] d1 = self . _atlas . array_coordinates_warped_data . shape [ 1 ] d2 = self . _atlas . array_coordinates_warped_data . shape [ 2 ] for original_length , new_length in zip ( self . _atlas . array_projection_corrected . shape , ( n_slices , int ( round ( d1 / reduce_resolution_factor )), int ( round ( d2 / reduce_resolution_factor )), ), ): new_dims . append ( np . linspace ( 0 , original_length - 1 , new_length )) coords = np . meshgrid ( * new_dims , indexing = \"ij\" ) array_projection_small = map_coordinates ( self . _atlas . array_projection_corrected , coords ) # Build Figure, with several frames as it will be slidable fig = go . Figure ( frames = [ go . Frame ( data = self . get_surface ( slice_index - 1 , l_transform_parameters , array_projection_small , reduce_resolution_factor , ), name = str ( i + 1 ), ) for i , slice_index in enumerate ( self . _data . get_slice_list ( brain )) ] ) fig . add_trace ( self . get_surface ( self . _data . get_slice_list ( brain )[ 0 ] - 1 , l_transform_parameters , array_projection_small , reduce_resolution_factor , ) ) # Add a slider def frame_args ( duration ): return { \"frame\" : { \"duration\" : duration }, \"mode\" : \"immediate\" , \"fromcurrent\" : True , \"transition\" : { \"duration\" : duration , \"easing\" : \"linear\" }, } sliders = [ { \"pad\" : { \"b\" : 5 , \"t\" : 10 }, \"len\" : 0.9 , \"x\" : 0.05 , \"y\" : 0 , \"steps\" : [ { \"args\" : [[ f . name ], frame_args ( 0 )], \"label\" : str ( k ), \"method\" : \"animate\" , } for k , f in enumerate ( fig . frames ) ], \"currentvalue\" : { \"visible\" : False , }, } ] # Layout fig . update_layout ( scene = dict ( aspectratio = dict ( x = 1.5 , y = 1 , z = 1 ), yaxis = dict ( range = [ 0.0 , 0.35 ], autorange = False , backgroundcolor = \"rgba(0,0,0,0)\" , color = \"grey\" , gridcolor = \"grey\" , ), zaxis = dict ( range = [ 0.2 , - 0.02 ], autorange = False , backgroundcolor = \"rgba(0,0,0,0)\" , color = \"grey\" , gridcolor = \"grey\" , ), xaxis = dict ( range = [ 0.0 , 0.35 ], autorange = False , backgroundcolor = \"rgba(0,0,0,0)\" , color = \"grey\" , gridcolor = \"grey\" , ), ), margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), template = \"plotly_dark\" , sliders = sliders , ) # No display of tick labels as they're wrong anyway fig . update_layout ( scene = dict ( xaxis = dict ( showticklabels = False ), yaxis = dict ( showticklabels = False ), zaxis = dict ( showticklabels = False ), ), paper_bgcolor = \"rgba(0,0,0,0.)\" , plot_bgcolor = \"rgba(0,0,0,0.)\" , ) return fig # Part of this function could probably be compiled with numba with some effort, but there's no # need as it's precomupted in a reasonable time anyway. def get_surface ( self , slice_index , l_transform_parameters , array_projection , reduce_resolution_factor ): \"\"\"This function returns a Plotly Surface representing the requested slice in 3D. Args: slice_index (int): Index of the requested slice. l_transform_parameters (list(np.ndarray)): A list of tuples containing the parameters for the transformation of the slice coordinates from 2D to 3D and conversely. array_projection (np.ndarray): The coordinates of the requested slice in 2D. reduce_resolution_factor (int, optional): Divides (reduce) the initial resolution of the data. Needed as the resulting figure can be very heavy. Defaults to 20. Returns: (go.Surface): A Plotly Surface representing the requested slice in 3D. \"\"\" # Get the parameters for the transformation of the coordinats from 2D to 3D a , u , v = l_transform_parameters [ slice_index ] # Build 3 empty lists, which will contain the 3D coordinates of the requested slice ll_x = [] ll_y = [] ll_z = [] # Loop over the first 2D coordinate of the slice for i , lambd in enumerate ( range ( array_projection [ slice_index ] . shape [ 0 ])): l_x = [] l_y = [] l_z = [] # Loop over the second 2D coordinate of the slice for j , mu in enumerate ( range ( array_projection [ slice_index ] . shape [ 1 ])): # Get rescaled 3D coordinates x_atlas , y_atlas , z_atlas = ( np . array ( slice_to_atlas_transform ( a , u , v , lambd * reduce_resolution_factor , mu * reduce_resolution_factor ) ) * self . _atlas . resolution / 1000 ) l_x . append ( z_atlas ) l_y . append ( x_atlas ) l_z . append ( y_atlas ) # In case the 3D coordinate was not acquired, skip the current coordinate if l_x != []: ll_x . append ( l_x ) ll_y . append ( l_y ) ll_z . append ( l_z ) # Build a 3D surface from the 3D coordinates for the current slice surface = go . Surface ( z = np . array ( ll_z ), x = np . array ( ll_x ), y = np . array ( ll_y ), surfacecolor = array_projection [ slice_index ] . astype ( np . int32 ), cmin = 0 , cmax = 255 , colorscale = \"viridis\" , opacityscale = [[ 0 , 0 ], [ 0.1 , 1 ], [ 1 , 1 ]], showscale = False , ) return surface # ============================================================================================== # --- Methods used mainly in lipid_selection # ============================================================================================== def compute_image_per_lipid ( self , slice_index , lb_mz , hb_mz , RGB_format = True , normalize = True , log = False , projected_image = True , apply_transform = False , lipid_name = \"\" , cache_flask = None , ): \"\"\"This function allows to query the MALDI data to extract an image in the form of a Numpy array representing the intensity of the lipid peaking between the values lb_mz and hb_mz in the spectral data, for the slice slice_index. Args: slice_index (int): Index of the requested slice. lb_mz (float): Lower boundary for the spectral data to query. hb_mz (float): Higher boundary for the spectral data to query. RGB_format (bool, optional): If True, the values in the array are between 0 and 255, given that the data has been normalized beforehand. Else, between 0 and 1. This parameter only makes sense if the data has been normalized beforehand. Defaults to True. normalize (bool, optional): If True, and the lipid has been MAIA transformed (and is provided with the parameter lipid_name) and apply_transform is True, the resulting array is normalized according to a factor computed across all slice. If MAIA has not been applied to the current selection or apply_transform is False, it is normalized according to the 99th percentile. Else, it is not normalized. Defaults to True. log (bool, optional): If True, the resulting array is log-transformed. This is useful in case of low expression. Defaults to False. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. lipid_name (str, optional): Name of the lipid that must be MAIA-transformed, if apply_transform and normalize are True. Defaults to \"\". cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (np.ndarray): An image (in the form of a numpy array) representing the intensity of the lipid peaking between the values lb_mz and hb_mz in the spectral data, for the slice slice_index. \"\"\" logging . info ( \"Entering compute_image_per_lipid\" ) # Get image from raw mass spec data image = compute_thread_safe_function ( compute_image_using_index_and_image_lookup , cache_flask , self . _data , slice_index , lb_mz , hb_mz , self . _data . get_array_spectra ( slice_index ), self . _data . get_array_lookup_pixels ( slice_index ), self . _data . get_image_shape ( slice_index ), self . _data . get_array_lookup_mz ( slice_index ), self . _data . get_array_cumulated_lookup_mz_image ( slice_index ), self . _data . get_divider_lookup ( slice_index ), self . _data . get_array_peaks_transformed_lipids ( slice_index ), self . _data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), apply_transform = apply_transform , ) # Log-transform the image if requested if log : image = np . log ( image + 1 ) # In case of bug, return None if image is None : return None # Normalize the image if requested if normalize : # Normalize across slice if the lipid has been MAIA transformed if ( lipid_name , self . _data . is_brain_1 ( slice_index ), ) in self . dic_normalization_factors and apply_transform : perc = self . dic_normalization_factors [ ( lipid_name , self . _data . is_brain_1 ( slice_index )) ] logging . info ( \"Normalization made with respect to percentile computed across all slices.\" ) else : # Normalize by 99 percentile perc = np . percentile ( image , 99.0 ) if perc == 0 : perc = np . max ( image ) if perc == 0 : perc = 1 image = image / perc image = np . clip ( 0 , 1 , image ) # Turn to RGB format if requested if RGB_format : image *= 255 # Change dtype if normalized and RGB to save space if normalize and RGB_format : image = np . round ( image ) . astype ( np . uint8 ) # Project image into cleaned and higher resolution version if projected_image : image = project_image ( slice_index , image , self . _atlas . array_projection_correspondence_corrected ) return image def compute_normalization_factor_across_slices ( self , cache_flask = None ): \"\"\"This function computes a dictionnary of normalization factors (used for MAIA-transformed lipids) across all slices (99th percentile of expression). Args: cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (dict): A dictionnary associating, for each MAIA-transformed lipid name, the 99th percentile of the intensity across all slices. \"\"\" logging . info ( \"Compute normalization factor across slices for MAIA transformed lipids...\" + \" It may takes a while\" ) # Dictionnnary that will contain the percentile across all slices of a given brain dic_max_percentile = {} # Function to compute the percentile across all slices def _compute_percentile_across_slices ( name , structure , cation , brain_1 ): max_perc = 0 lipid_string = \"\" for slice_index in self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ): # Find lipid location l_lipid_loc = ( self . _data . get_annotations () . index [ ( self . _data . get_annotations ()[ \"name\" ] == name ) & ( self . _data . get_annotations ()[ \"structure\" ] == structure ) & ( self . _data . get_annotations ()[ \"slice\" ] == slice_index ) & ( self . _data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) >= 1 : index = l_lipid_loc [ - 1 ] # get final lipid name lipid_string = name + \"_\" + structure + \"_\" + cation # get lipid bounds lb_mz = float ( self . _data . get_annotations () . iloc [ index ][ \"min\" ]) hb_mz = float ( self . _data . get_annotations () . iloc [ index ][ \"max\" ]) # Get corresponding image image = compute_thread_safe_function ( compute_image_using_index_and_image_lookup , cache_flask , self . _data , slice_index , lb_mz , hb_mz , self . _data . get_array_spectra ( slice_index ), self . _data . get_array_lookup_pixels ( slice_index ), self . _data . get_image_shape ( slice_index ), self . _data . get_array_lookup_mz ( slice_index ), self . _data . get_array_cumulated_lookup_mz_image ( slice_index ), self . _data . get_divider_lookup ( slice_index ), self . _data . get_array_peaks_transformed_lipids ( slice_index ), self . _data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), apply_transform = False , ) # Check 99th percentile for normalization perc = np . percentile ( image , 99.0 ) # perc must be quite small in theory... otherwise it's a bug if perc > max_perc : # and perc<1: max_perc = perc return max_perc , lipid_string # Simulate a click on all MAIA transformed lipids for brain_1 in [ True , False ]: for ( index , ( name , structure , cation , mz ), ) in self . _data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 ) . iterrows (): max_perc , lipid_string = _compute_percentile_across_slices ( name , structure , cation , brain_1 ) # Store max percentile across slices dic_max_percentile [( lipid_string , brain_1 )] = max_perc return dic_max_percentile def build_lipid_heatmap_from_image ( self , image , return_base64_string = False , draw = False , type_image = None , return_go_image = False , ): \"\"\"This function converts a numpy array into a base64 string, which can be returned directly, or itself be turned into a go.Image, which can be returned directly, or be turned into a Plotly Figure, which will be returned. Args: image (np.ndarray): A numpy array representing the image to be converted. Possibly with several channels. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. draw (bool, optional): If True, the user will have the possibility to draw on the resulting Plotly Figure. Defaults to False. type_image (string, optional): The type of the image to be converted to a base64 string. If image_array is in 3D, type must be RGB. If 4D, type must be RGBA. Else, no requirement (None). Defaults to None. return_go_image (bool, optional): If True, the go.Image is returned directly, before being integrated to a Plotly Figure. Defaults to False. Returns: Depending on the inputted arguments, may either return a base64 string, a go.Image, or a Plotly Figure. \"\"\" logging . info ( \"Converting image to string\" ) # Set optimize to False to gain computation time base64_string = convert_image_to_base64 ( image , type = type_image , overlay = None , transparent_zeros = True , optimize = False ) # Either return image directly if return_base64_string : return base64_string # Or compute heatmap as go image if needed logging . info ( \"Converting image to go image\" ) final_image = go . Image ( visible = True , source = base64_string , ) # Potentially return the go image directly if return_go_image : return final_image # Or build ploty graph fig = go . Figure ( final_image ) # Improve graph layout fig . update_layout ( margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), newshape = dict ( fillcolor = dic_colors [ \"blue\" ], opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ) ), xaxis = dict ( showgrid = False , zeroline = False ), yaxis = dict ( showgrid = False , zeroline = False ), # Do not specify height for now as plotly is buggued and resets if switching pages # height=500, ) fig . update_xaxes ( showticklabels = False ) fig . update_yaxes ( showticklabels = False ) fig . update ( layout_coloraxis_showscale = False ) # Set how the image should be annotated if draw : fig . update_layout ( dragmode = \"drawclosedpath\" ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" logging . info ( \"Returning figure\" ) return fig def compute_heatmap_per_mz ( self , slice_index , lb_mz = None , hb_mz = None , draw = False , projected_image = True , return_base64_string = False , cache_flask = None , ): \"\"\"This function takes two boundaries and a slice index, and returns a heatmap of the lipid expressed in the slice whose m/z is between the two boundaries. Args: slice_index (int): The index of the requested slice. lb_mz (float, optional): The lower m/z boundary. Defaults to None. hb_mz (float, optional): The higher m/z boundary. Defaults to None. draw (bool, optional): If True, the user will have the possibility to draw on the resulting Plotly Figure. Defaults to False. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the value return_base64_string, may either return a base64 string, or a Plotly Figure. \"\"\" logging . info ( \"Starting figure computation, from mz boundaries\" ) # Upper bound lower than the lowest m/z value and higher that the highest m/z value if lb_mz is None : lb_mz = 200 if hb_mz is None : hb_mz = 1800 logging . info ( \"Getting image array\" ) # Compute image with given bounds image = self . compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , projected_image = projected_image , cache_flask = cache_flask , ) # Compute corresponding figure fig = self . build_lipid_heatmap_from_image ( image , return_base64_string = return_base64_string , draw = draw ) return fig def compute_heatmap_per_lipid_selection ( self , slice_index , ll_t_bounds , normalize = True , projected_image = True , apply_transform = False , ll_lipid_names = None , return_base64_string = False , cache_flask = None , ): \"\"\"This function is very similar to compute_heatmap_per_mz, but it takes a list of lipid boundaries, possibly along with lipid names, instead of just two boundaries. It returns a heatmap of the sum of expression of the requested lipids in the slice. Args: slice_index (int): The index of the requested slice. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels (although this is not used in the function). The second list is used to separate lipid. normalize (bool, optional): If True, and the lipid has been MAIA transformed (and is provided with the parameter lipid_name) and apply_transform is True, the resulting array is normalized according to a factor computed across all slice. If MAIA has not been applied to the current selection or apply_transform is False, it is normalized according to the 99th percentile. Else, it is not normalized. Defaults to True. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. ll_lipid_names (list(list(int)), optional): List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the value return_base64_string, may either return a base64 string, or a Plotly Figure. \"\"\" logging . info ( \"Compute heatmap per lipid selection\" + str ( ll_t_bounds )) # Start from empty image and add selected lipids # * Caution: array must be int, float gets badly converted afterwards image = np . zeros ( self . _atlas . image_shape , dtype = np . int32 ) # Build empty lipid names if not provided if ll_lipid_names is None : ll_lipid_names = [[ \"\" for y in l_t_bounds ] for l_t_bounds in ll_t_bounds ] # Loop over channels for l_t_bounds , l_lipid_names in zip ( ll_t_bounds , ll_lipid_names ): if l_t_bounds is not None : # Loop over lipids for boundaries , lipid_name in zip ( l_t_bounds , l_lipid_names ): if boundaries is not None : ( lb_mz , hb_mz ) = boundaries # Cmpute expression image per lipid image_temp = self . compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , normalize = normalize , projected_image = projected_image , apply_transform = apply_transform , lipid_name = lipid_name , cache_flask = cache_flask , ) image += image_temp # Compute corresponding figure fig = self . build_lipid_heatmap_from_image ( image , return_base64_string = return_base64_string ) return fig def compute_rgb_array_per_lipid_selection ( self , slice_index , ll_t_bounds , normalize_independently = True , projected_image = True , log = False , apply_transform = False , ll_lipid_names = None , cache_flask = None , ): \"\"\"This function computes a numpy RGB array (each pixel has 3 intensity values) of expression of the requested lipids (those whose m/z values are in ll_t_bounds) in the slice. Args: slice_index (int): The index of the requested slice. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. normalize_independently (bool, optional): If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. log (bool, optional): If True, the resulting array corresponds to log-transformed expression, for each lipid. Defaults to False. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. ll_lipid_names (list(list(int)), optional): List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (np.ndarray): A three-dimensional RGB numpy array (of uint8 dtype). The first two dimensions correspond to the acquisition image shape, and the third dimension corresponds to the channels. \"\"\" # Empty lipid names if no names provided if ll_lipid_names is None : ll_lipid_names = [ [ \"\" for y in l_t_bounds ] if l_t_bounds is not None else [ \"\" ] for l_t_bounds in ll_t_bounds ] # Build a list of empty images and add selected lipids for each channel l_images = [] # Loop over channels for l_boundaries , l_names in zip ( ll_t_bounds , ll_lipid_names ): image = np . zeros ( self . _atlas . image_shape if projected_image else self . _data . get_image_shape ( slice_index ) ) if l_boundaries is not None : # Loop over lipids for boundaries , lipid_name in zip ( l_boundaries , l_names ): if boundaries is not None : ( lb_mz , hb_mz ) = boundaries # Cmpute expression image per lipid image_temp = self . compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , normalize = normalize_independently , projected_image = projected_image , log = log , apply_transform = apply_transform , lipid_name = lipid_name , cache_flask = cache_flask , ) if image_temp is not None : image += image_temp l_images . append ( image ) # Reoder axis to match plotly go.image requirements array_image = np . moveaxis ( np . array ( l_images ), 0 , 2 ) return np . asarray ( array_image , dtype = np . uint8 ) def compute_rgb_image_per_lipid_selection ( self , slice_index , ll_t_bounds , normalize_independently = True , projected_image = True , log = False , return_image = False , apply_transform = False , ll_lipid_names = None , return_base64_string = False , cache_flask = None , ): \"\"\"This function is very similar to compute_heatmap_per_lipid_selection, but it returns a RGB image instead of a heatmap. Args: slice_index (int): The index of the requested slice. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. normalize_independently (bool, optional): If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. log (bool, optional): If True, the resulting array corresponds to log-transformed expression, for each lipid. Defaults to False. return_image (bool, optional): If True, a go.Image is returned directly, instead of a Plotly Figure. Defaults to False. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. ll_lipid_names (list(list(int)), optional): List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the inputted arguments, may either return a base64 string, a go.Image, or a Plotly Figure. \"\"\" logging . info ( \"Started RGB image computation for slice \" + str ( slice_index ) + logmem ()) # Empty lipid names if no names provided if ll_lipid_names is None : ll_lipid_names = [[ \"\" for y in l_t_bounds ] for l_t_bounds in ll_t_bounds ] logging . info ( \"Acquiring array_image for slice \" + str ( slice_index ) + logmem ()) # Get RGB array for the current lipid selection array_image = self . compute_rgb_array_per_lipid_selection ( slice_index , ll_t_bounds , normalize_independently = normalize_independently , projected_image = projected_image , log = log , apply_transform = apply_transform , ll_lipid_names = ll_lipid_names , cache_flask = cache_flask , ) logging . info ( \"Returning fig for slice \" + str ( slice_index ) + logmem ()) # Build the correspondig figure return self . build_lipid_heatmap_from_image ( array_image , return_base64_string = return_base64_string , draw = False , type_image = \"RGB\" , return_go_image = return_image , ) def compute_spectrum_low_res ( self , slice_index , annotations = None ): \"\"\"This function returns the full (low-resolution) spectrum of the requested slice. Args: slice_index (int): The slice index of the requested slice. annotations (list(tuple), optional): A list of m/z boundaries (one for each lipid to annotate), corresponding to the position of colored box superimposed on the spectra. Defaults to None. Returns: (go.Figure): A Plotly Figure representing the low-resolution spectrum. \"\"\" # Define figure data data = go . Scattergl ( x = self . _data . get_array_avg_spectrum_downsampled ( slice_index )[ 0 , :], y = self . _data . get_array_avg_spectrum_downsampled ( slice_index )[ 1 , :], visible = True , line_color = dic_colors [ \"blue\" ], fill = \"tozeroy\" , ) # Define figure layout layout = go . Layout ( margin = dict ( t = 50 , r = 0 , b = 10 , l = 0 ), showlegend = False , xaxis = dict ( rangeslider = { \"visible\" : False }, title = \"m/z\" ), yaxis = dict ( fixedrange = False , title = \"Intensity\" ), template = \"plotly_dark\" , autosize = True , title = { \"text\" : \"Low resolution spectrum (averaged across pixels)\" , \"y\" : 0.92 , \"x\" : 0.5 , \"xanchor\" : \"center\" , \"yanchor\" : \"top\" , \"font\" : dict ( size = 14 , ), }, paper_bgcolor = \"rgba(0,0,0,0.3)\" , plot_bgcolor = \"rgba(0,0,0,0.3)\" , ) # Build figure fig = go . Figure ( data = data , layout = layout ) # Annotate selected lipids with vertical bars if annotations is not None : for color , annot in zip ([ \"red\" , \"green\" , \"blue\" ], annotations ): if annot is not None : fig . add_vrect ( x0 = annot [ 0 ], x1 = annot [ 1 ], fillcolor = dic_colors [ color ], opacity = 0.4 , line_color = dic_colors [ color ], ) return fig def compute_spectrum_high_res ( self , slice_index , lb = None , hb = None , annotations = None , force_xlim = False , plot = True , standardization = False , cache_flask = None , ): \"\"\"This function returns the high-resolution spectrum of the requested slice between the two provided m/z boundaries lb and hb. If boundaries are not provided, it returns an empty spectrum. Args: slice_index (int): The slice index of the requested slice. lb (float, optional): The lower m/z boundary below which the spectrum to display must be cropped. Defaults to None. hb (float, optional): The higher m/z boundary below which the spectrum to display must be cropped. Defaults to None. annotations (list(tuple), optional): A list of m/z boundaries (one for each lipid to annotate), corresponding to the position of colored box superimposed on the spectra. Defaults to None. force_xlim (bool, optional): If Truen the zoom level will be set to enclose lb and hb, although that may not be the tightest region to enclose the data. Defaults to False. plot (bool, optional): If False, only the plotting data (m/z and intensities arrays) will be returned. Defaults to True. standardization (bool, optional): If True, the displayed spectrum is standardized with MAIA when possible. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the value of the boundaries, and the plot parameter, it may return a Plotly Figure containing an empty spectrum, or a spectrum between the two provided boundaries, or the corresponding data of such a spectrum. \"\"\" # Define default values for graph (empty) if lb is None and hb is None : x = ([],) y = ([],) # If boundaries are provided, get their index else : index_lb , index_hb = compute_thread_safe_function ( compute_index_boundaries , cache_flask , self . _data , slice_index , lb , hb , array_spectra_avg = self . _data . get_array_avg_spectrum ( slice_index , standardization = standardization ), lookup_table = self . _data . get_array_lookup_mz_avg ( slice_index ), ) def return_x_y ( array ): x = np . copy ( array [ 0 , index_lb : index_hb ]) y = np . copy ( array [ 1 , index_lb : index_hb ]) return x , y # Get x, y in a thread safe fashion # No need to clean memory as it's really small x , y = compute_thread_safe_function ( return_x_y , cache_flask , self . _data , slice_index , self . _data . get_array_avg_spectrum ( slice_index , standardization = standardization ), ) # In case download without plotting if not plot : return x , y # Define figure data data = go . Scattergl ( x = x , y = y , visible = True , line_color = dic_colors [ \"blue\" ], fill = \"tozeroy\" ) # Define figure layout layout = go . Layout ( margin = dict ( t = 50 , r = 0 , b = 10 , l = 0 ), showlegend = False , xaxis = dict ( rangeslider = { \"visible\" : False }, title = \"m/z\" ), yaxis = dict ( fixedrange = True , title = \"Intensity\" ), template = \"plotly_dark\" , title = { \"text\" : \"High resolution spectrum (averaged across pixels)\" , \"y\" : 0.92 , \"x\" : 0.5 , \"xanchor\" : \"center\" , \"yanchor\" : \"top\" , \"font\" : dict ( size = 14 , ), }, paper_bgcolor = \"rgba(0,0,0,0.3)\" , plot_bgcolor = \"rgba(0,0,0,0.3)\" , ) # Build figure layout fig = go . Figure ( data = data , layout = layout ) # Annotate selected lipids with vertical bars if annotations is not None : for color , x in zip ([ \"red\" , \"green\" , \"blue\" ], annotations ): if x is not None : if x [ 0 ] >= lb and x [ - 1 ] <= hb : fig . add_vrect ( x0 = x [ 0 ], x1 = x [ 1 ], line_width = 0 , fillcolor = dic_colors [ color ], opacity = 0.4 ) # In case we don't want to zoom in too much on the selected lipid if force_xlim : fig . update_xaxes ( range = [ lb , hb ]) return fig def return_empty_spectrum ( self ): \"\"\"This function returns an empty spectrum, used to display when no spectrum is available. Returns: (Plotly Figure): A Plotly Figure representing an empty spectrum.\"\"\" # Define empty figure data data = ( go . Scattergl ( x = [], y = [], visible = True ),) # Define figure layout layout = go . Layout ( margin = dict ( t = 5 , r = 0 , b = 10 , l = 0 ), showlegend = True , xaxis = dict ( title = \"m/z\" ), yaxis = dict ( title = \"Intensity\" ), template = \"plotly_dark\" , ) # Build figure fig = go . Figure ( data = data , layout = layout ) # Transparent background fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" return fig # ============================================================================================== # --- Methods used mainly in region_analysis # ============================================================================================== def return_heatmap_lipid ( self , fig = None ): \"\"\"This function is used to either generate a Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. Args: fig (Plotly Figure, optional): A Plotly Figure whose layout must be completed. If None, a new figure will be generated. Defaults to None. Returns: (Plotly Figure): A Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. \"\"\" # Build empty figure if not provided if fig is None : fig = go . Figure ( data = go . Heatmap ( z = [[]], x = [], y = [], visible = False )) # Improve figure layout fig . update_layout ( margin = dict ( t = 25 , r = 0 , b = 10 , l = 0 ), template = \"plotly_dark\" , font_size = 8 , ) # Transparent background fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" # Dark Template fig . layout . template = \"plotly_dark\" return fig # ============================================================================================== # --- Methods used mainly in threeD_exploration # ============================================================================================== def compute_treemaps_figure ( self , maxdepth = 5 ): \"\"\"This function is used to generate a Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. Args: maxdepth (int, optional): The depth of the treemap to generate. Defaults to 5. Returns: (Plotly.Figure): A Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. \"\"\" # Build treemaps from list of children and parents fig = px . treemap ( names = self . _atlas . l_nodes , parents = self . _atlas . l_parents , maxdepth = maxdepth ) # Improve layout fig . update_layout ( uniformtext = dict ( minsize = 15 ), margin = dict ( t = 30 , r = 0 , b = 10 , l = 0 ), ) fig . update_traces ( root_color = \"#1d3d5c\" ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" return fig def compute_3D_root_volume ( self , decrease_dimensionality_factor = 7 , differentiate_borders = False ): \"\"\"This function is used to generate a go.Isosurface of the Allen Brain root structure, which will be used to enclose the display of lipid expression of other structures in the brain. Args: decrease_dimensionality_factor (int, optional): Decrease the dimensionnality of the brain to display, to get a lighter output. Defaults to 7. Returns: (go.Isosurface): A semi-transparent go.Isosurface of the Allen Brain root structure. \"\"\" # Get array of annotations, which associate coordinate to id array_annotation_root = np . array ( self . _atlas . bg_atlas . annotation , dtype = np . int32 ) # Subsample array of annotation the same way array_atlas was subsampled array_annotation_root = array_annotation_root [ :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , ] # Bug correction for the last slice array_annotation_root = np . concatenate ( ( array_annotation_root , np . zeros (( 1 , array_annotation_root . shape [ 1 ], array_annotation_root . shape [ 2 ])), ) ) # Get the volume array array_atlas_borders_root = fill_array_borders ( array_annotation_root , differentiate_borders = differentiate_borders , color_near_borders = False , keep_structure_id = None , ) # Compute the 3D grid X_root , Y_root , Z_root = np . mgrid [ 0 : array_atlas_borders_root . shape [ 0 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders_root . shape [ 0 ] * 1 j , 0 : array_atlas_borders_root . shape [ 1 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders_root . shape [ 1 ] * 1 j , 0 : array_atlas_borders_root . shape [ 2 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders_root . shape [ 2 ] * 1 j , ] # Compute the plot brain_root_data = go . Isosurface ( x = X_root . flatten (), y = Y_root . flatten (), z = Z_root . flatten (), value = array_atlas_borders_root . flatten (), isomin =- 0.21 , isomax = 2.55 , opacity = 0.1 , # max opacity surface_count = 2 , colorscale = \"Blues\" , # colorscale, flatshading = True , showscale = False , ) return brain_root_data def get_array_of_annotations ( self , decrease_dimensionality_factor ): \"\"\"This function returns the array of annotations from the Allen Brain Atlas, subsampled to decrease the size of the output. Args: decrease_dimensionality_factor (int): An integer used for subsampling the array. The higher, the higher the subsampling. Returns: (np.ndarray): A 3D array of annotation, in which structures are annotated with specific identifiers. \"\"\" # Get subsampled array of annotations array_annotation = np . array ( self . _atlas . bg_atlas . annotation [ :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , ], dtype = np . int32 , ) # Bug correction for the last slice array_annotation = np . concatenate ( ( array_annotation , np . zeros (( 1 , array_annotation . shape [ 1 ], array_annotation . shape [ 2 ])), ) ) return array_annotation def compute_l_array_2D ( self , ll_t_bounds , normalize_independently = True , high_res = False , brain_1 = True , cache_flask = None , ): \"\"\"This function is used to get the list of expression per slice for all slices for the computation of the 3D brain volume. Args: ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. normalize_independently (bool, optional): If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. high_res (bool, optional): If True, the returned list of arrays correspond to the warped/upscaled data. Defaults to False as this is a very heavy plot. brain_1 (bool, optional): If True, the returned list of arrays correspond to the brain 1 data. Else, to the brain 2 data. Defaults to True. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (list(np.ndarray)): A list of numpy arrays representing the expression of the requested lipids (through ll_t_bounds) for each slice. \"\"\" l_array_data = [] # Correct the indices for the potentially unused slices from brain 1 if brain_1 : slice_index_offset = 0 else : slice_index_offset = len ( self . _data . get_slice_list ( indices = \"brain_1\" )) # Loop over slices and compute the expression of the requested lipids for slice_index in range ( len ( ll_t_bounds )): if ll_t_bounds [ slice_index ] != [ None , None , None ]: # Get the data as an expression image per lipid array_data = self . compute_rgb_array_per_lipid_selection ( slice_index + 1 + slice_index_offset , ll_t_bounds [ slice_index ], normalize_independently = normalize_independently , projected_image = high_res , log = False , apply_transform = True , cache_flask = cache_flask , ) # Sum array colors (i.e. lipids) array_data = np . sum ( array_data , axis =- 1 ) else : array_data = None # Append data to l_array_data l_array_data . append ( np . array ( array_data , dtype = np . float16 )) # float16 to gain space return l_array_data def compute_array_coordinates_3D ( self , l_array_data , high_res = False , brain_1 = True , ): \"\"\"This functions computes the list of coordinates and expression values for the voxels used in the 3D representation of the brain. Args: l_array_data (list(np.ndarray)): A list of numpy arrays representing lipid expression for each slice of the dataset. high_res (bool, optional): If True, the computations made correspond to the warped/upscaled data. Defaults to False as this is a very heavy plot. brain_1 (bool, optional): If True, the returned list of arrays correspond to the brain 1 data. Else, to the brain 2 data. Defaults to True. Returns: (np.ndarray, np.ndarray, np.ndarray, np.ndarray): 4 flat numpy arrays (3 for coordinates and 1 for expression). \"\"\" logging . info ( \"Starting computing 3D arrays\" + logmem ()) # Correct the indices for the potentially unused slices from brain 1 if brain_1 : slice_index_init = 0 slice_index_end = len ( self . _data . get_slice_list ( indices = \"brain_1\" )) else : slice_index_init = len ( self . _data . get_slice_list ( indices = \"brain_1\" )) slice_index_end = self . _data . get_slice_number () # get list of original coordinates for each slice if not high_res : l_coor = self . _atlas . l_original_coor [ slice_index_init : slice_index_end ] estimate = 400 * 400 else : estimate = 1311 * 918 l_coor = self . _atlas . array_coordinates_warped_data [ slice_index_init : slice_index_end ] # Initialize empty arrays with a large estimate for the orginal acquisition size max_size = estimate * ( slice_index_end - slice_index_init ) array_x = np . empty ( max_size , dtype = np . float32 ) array_y = np . empty ( max_size , dtype = np . float32 ) array_z = np . empty ( max_size , dtype = np . float32 ) array_c = np . empty ( max_size , dtype = np . int16 ) total_index = 0 logging . debug ( f \"Size array_x: { array_x . nbytes / 1024 / 1024 : .2f } \" ) logging . info ( \"Starting slice iteration\" + logmem ()) # get atlas shape and resolution reference_shape = self . _atlas . bg_atlas . reference . shape resolution = self . _atlas . resolution array_annotations = np . array ( self . _atlas . bg_atlas . annotation , dtype = np . int32 ) for slice_index in range ( 0 , len ( l_array_data ), 1 ): # Get the averaged expression data for the current slice array_data = l_array_data [ slice_index ] # If array_data is not an array but a 0 float, skip it if type ( array_data ) == float : continue # Remove pixels for which lipid expression is zero array_data_stripped = array_data . flatten () # array_data[array_data != 0].flatten() # Skip the current slice if expression is very sparse if len ( array_data_stripped ) < 10 or np . sum ( array_data_stripped ) < 1 : continue # Compute the percentile of expression to filter out lowly expressed pixels # Set to 0 for now, as no filtering is done percentile = 0 # np.percentile(array_data_stripped, 10) # Get the coordinates of the pixels in the ccfv3 coordinates = l_coor [ slice_index ] # coordinates_stripped = coordinates[array_data != 0] coordinates_stripped = coordinates . reshape ( - 1 , coordinates . shape [ - 1 ]) # Get the data as 4 arrays (3 for coordinates and 1 for expression) array_x , array_y , array_z , array_c , total_index = filter_voxels ( array_data_stripped . astype ( np . float32 ), coordinates_stripped , array_annotations , percentile , array_x , array_y , array_z , array_c , total_index , reference_shape , resolution , ) logging . info ( \"Slice \" + str ( slice_index ) + \" done\" + logmem ()) # Strip the arrays from the zeros array_x = array_x [: total_index ] array_y = array_y [: total_index ] array_z = array_z [: total_index ] # * Caution, array_c should be a list to work with Plotly array_c = array_c [: total_index ] . tolist () # Return the arrays for the 3D figure return array_x , array_y , array_z , array_c def compute_3D_volume_figure ( self , set_progress = None , ll_t_bounds = [[( None , None )]], name_lipid_1 = \"\" , name_lipid_2 = \"\" , name_lipid_3 = \"\" , set_id_regions = None , decrease_dimensionality_factor = 6 , cache_flask = None , structure_guided_interpolation = True , return_interpolated_array = False , return_individual_slice_data = False , divider_radius = 16 , brain_1 = False , ): \"\"\"This figure computes a Plotly Figure containing a go.Volume object representing the expression of the requested lipids in the selected regions, interpolated between the slices. Lipid names are used to retrieve the expression data from the Shelve database. Args: set_progress: Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. name_lipid_1 (str, optional): Name of the first selected lipid. Defaults to \"\". name_lipid_2 (str, optional): Name of the second selected lipid. Defaults to \"\". name_lipid_3 (str, optional): Name of the third selected lipid. Defaults to \"\". set_id_regions (set(int), optional): A set containing the identifiers of the brain regions (at the very bottom of the hierarchy) in which lipid expression is requested. Defaults to None, corresponding to the whole brain. decrease_dimensionality_factor (int): An integer used for subsampling the array of annotation, and therefore the resulting figure. The higher, the higher the subsampling. Needed as this is a very heavy plot. Defaults to 6. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. structure_guided_interpolation (bool, optional): If True, the interpolation is done using the annotated structures. If False, the interpolation is done blindly. return_interpolated_array (bool): If True, the interpolated array is returned. Else, the corresponding Plotly figure is returned. Defaults to False. return_individual_slice_data (bool): If True, the individual slice data (not interpolated) is returned. divider_radius (int): The inverse radius of the sphere used to do the interpolation. Defaults to 16. brain_1 (bool): If True, the brain 1 data is used. Else, the brain 2 data is used. Defaults to False. Returns: Depending on the value of return_interpolated_array and return_individual_slice_data, returns either the (not) interpolated array of expression of the requested lipids in the selected regions, or a Plotly Figure containing a go.Volume object representing the interpolated expression. \"\"\" if return_interpolated_array and return_individual_slice_data : logging . warning ( \"Cannot return both interpolated and not interpolated array... Returning the\" \" individual slice data.\" ) logging . info ( \"Starting 3D volume computation\" ) if set_progress is not None : set_progress (( 10 , \"Loading array of annotations\" )) # Get subsampled array of annotations array_annotation = self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_annotation\" , force_update = False , compute_function = self . get_array_of_annotations , decrease_dimensionality_factor = decrease_dimensionality_factor , ) # Get subsampled array of borders for each region array_atlas_borders = np . zeros ( array_annotation . shape , dtype = np . float32 ) if set_id_regions is not None : list_id_regions = np . array ( list ( set_id_regions ), dtype = np . int64 ) else : list_id_regions = None if set_progress is not None : set_progress (( 10 , \"Computing brain borders\" )) # Shelving this function is useless as it takes less than 0.1s to compute after # first compilation array_atlas_borders = fill_array_borders ( array_annotation , keep_structure_id = list_id_regions , decrease_dimensionality_factor = decrease_dimensionality_factor , ) logging . info ( \"Computed basic structure array\" ) if set_progress is not None : set_progress (( 20 , \"Computing expression for each lipid\" )) # Get array of expression for each lipid ll_array_data = [ self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_expression_\" + str ( brain_1 ) + \"_\" + str ( name_lipid ) + \"__\" , force_update = False , ignore_arguments_naming = True , compute_function = self . compute_l_array_2D , ll_t_bounds = [[ l_t_bounds [ i ], None , None ] for l_t_bounds in ll_t_bounds ], brain_1 = brain_1 , cache_flask = cache_flask , ) for i , name_lipid in enumerate ([ name_lipid_1 , name_lipid_2 , name_lipid_3 ]) ] if set_progress is not None : set_progress (( 50 , \"Averaging expression for each lipid\" )) # Average array of expression over lipid l_array_data_avg = [] for slice_index in range ( len ( self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" )) ): n = 0 avg = 0 for i in range ( 3 ): # * number of lipids is hardcoded s = ll_array_data [ i ][ slice_index ] if s is None : s = 0 elif s . size == 1 : if np . isnan ( s ): s = 0 else : n += 1 avg += s # In case there's no data for the current slice, set the average to 0 if n == 0 : n = 1 l_array_data_avg . append ( avg / n ) logging . info ( \"Averaged expression over all lipids\" ) if set_progress is not None : set_progress (( 60 , \"Getting slice coordinates\" )) # Get the 3D array of expression and coordinates array_x , array_y , array_z , array_c = self . compute_array_coordinates_3D ( l_array_data_avg , high_res = False , brain_1 = brain_1 ) if return_individual_slice_data : return array_x , array_y , array_z , array_c logging . info ( \"Computed array of expression in original space\" ) if set_progress is not None : set_progress (( 70 , \"Filling a new brain with expression\" )) # Compute the rescaled array of expression for each slice averaged over projected lipids array_slices = np . copy ( array_atlas_borders ) array_for_avg = np . full_like ( array_atlas_borders , 1 ) array_x_scaled = array_x * 1000000 / self . _atlas . resolution / decrease_dimensionality_factor array_y_scaled = array_y * 1000000 / self . _atlas . resolution / decrease_dimensionality_factor array_z_scaled = array_z * 1000000 / self . _atlas . resolution / decrease_dimensionality_factor array_slices = fill_array_slices ( array_x_scaled , array_y_scaled , array_z_scaled , np . array ( array_c ), array_slices , array_for_avg , limit_value_inside =- 1.99999 , ) logging . info ( \"Filled basic structure array with array of expression\" ) # Get the corresponding coordinates X , Y , Z = np . mgrid [ 0 : array_atlas_borders . shape [ 0 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders . shape [ 0 ] * 1 j , 0 : array_atlas_borders . shape [ 1 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders . shape [ 1 ] * 1 j , 0 : array_atlas_borders . shape [ 2 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders . shape [ 2 ] * 1 j , ] logging . info ( \"Built arrays of coordinates\" ) if set_id_regions is not None : x_min , x_max , y_min , y_max , z_min , z_max = crop_array ( array_annotation , list_id_regions ) array_annotation = array_annotation [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] array_slices = array_slices [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] X = X [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] Y = Y [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] Z = Z [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] logging . info ( \"Cropped the figure to only keep areas in which lipids are expressed\" ) if set_progress is not None : set_progress (( 70 , \"Interpolating expression\" )) # Compute an array containing the lipid expression interpolated for every voxel array_interpolated = fill_array_interpolation ( array_annotation , array_slices , divider_radius = 16 , limit_value_inside =- 1.99999 , structure_guided = structure_guided_interpolation , ) logging . info ( \"Finished interpolation between slices\" ) if return_interpolated_array : return array_interpolated if set_progress is not None : set_progress (( 80 , \"Building figure\" )) # Get root figure root_data = self . _storage . return_shelved_object ( \"figures/3D_page\" , \"volume_root\" , force_update = False , compute_function = self . compute_3D_root_volume , ) logging . info ( \"Building final figure\" ) # Build figure fig = go . Figure ( data = [ go . Volume ( x = X . flatten (), y = Y . flatten (), z = Z . flatten (), value = array_interpolated . flatten (), isomin = 0.01 , isomax = 1.5 , opacityscale = [ [ - 0.11 , 0.00 ], [ 0.01 , 0.0 ], [ 0.5 , 0.05 ], [ 2.5 , 0.7 ], ], surface_count = 10 , colorscale = \"viridis\" , ), root_data , ] ) # Hide grey background fig . update_layout ( margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" logging . info ( \"Done computing 3D volume figure\" ) if set_progress is not None : set_progress (( 90 , \"Returning figure\" )) return fig def compute_clustergram_figure ( self , set_progress , cache_flask , l_selected_regions , percentile = 90 , brain_1 = False , ): \"\"\"This function computes a Plotly Clustergram figure, allowing to cluster and compare the expression of all the MAIA-transformed lipids in the dataset in the selected regions. Args: set_progress: Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. l_selected_regions (list(int), optional): A list containing the identifiers of the brain regions (at the very bottom of the hierarchy) whose border must be annotated. percentile (int, optional): The percentile of average expression below which the lipids must be discarded (to get rid of low expression noise). Defaults to 90. brain_1 (bool): If True, the brain 1 data is used. Else, the brain 2 data is used. Defaults to False. Returns: (go.Figure): a Plotly Clustergram figure clustering and comparing the expression of all the MAIA-transformed lipids in the dataset in the selected regions. \"\"\" logging . info ( \"Starting computing clustergram figure\" ) # Memoize result as it's called everytime a filtering is done @cache_flask . memoize () def return_df_avg_lipids ( l_selected_regions ): dic_avg_lipids = {} l_slices = self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ) for slice_index in l_slices : # Display progress every 10 slices if slice_index % 10 == 0 : set_progress ( ( int ( slice_index / len ( l_slices ) * 100 ), \"Loading slice n\u00b0\" + str ( slice_index ), ) ) l_spectra = [] for region in l_selected_regions : long_region = self . _atlas . dic_acronym_name [ region ] if slice_index - 1 in self . _atlas . dic_existing_masks : if region in self . _atlas . dic_existing_masks [ slice_index - 1 ]: grah_scattergl_data = self . _atlas . get_projected_mask_and_spectrum ( slice_index - 1 , long_region , MAIA_correction = True )[ 1 ] l_spectra . append ( grah_scattergl_data ) else : l_spectra . append ( None ) else : raise Exception ( \"The masks have not been precomputed. Please precompute them before\" \" running this function.\" ) ll_idx_labels = global_lipid_index_store ( self . _data , slice_index - 1 , l_spectra ) logging . info ( \"Computing dictionnary for averaging slice \" + str ( slice_index )) # Compute average expression for each lipid and each selection set_lipids_idx = set () ll_lipids_idx = [] ll_avg_intensity = [] n_sel = len ( l_spectra ) for spectrum , l_idx_labels in zip ( l_spectra , ll_idx_labels ): if spectrum is not None : array_intensity_with_lipids = np . array ( spectrum , dtype = np . float32 )[ 1 , :] array_idx_labels = np . array ( l_idx_labels , dtype = np . int32 ) l_lipids_idx , l_avg_intensity = compute_avg_intensity_per_lipid ( array_intensity_with_lipids , array_idx_labels ) set_lipids_idx . update ( l_lipids_idx ) else : l_lipids_idx = None l_avg_intensity = None ll_lipids_idx . append ( l_lipids_idx ) ll_avg_intensity . append ( l_avg_intensity ) for i , ( l_lipids , l_avg_intensity ) in enumerate ( zip ( ll_lipids_idx , ll_avg_intensity ) ): if l_lipids is not None : for lipid , intensity in zip ( l_lipids , l_avg_intensity ): if lipid not in dic_avg_lipids : dic_avg_lipids [ lipid ] = [] for j in range ( n_sel ): dic_avg_lipids [ lipid ] . append ([]) dic_avg_lipids [ lipid ][ i ] . append ( intensity ) logging . info ( \"Averaging all lipid values across slices\" ) # Average intensity per slice for lipid in dic_avg_lipids : for i in range ( n_sel ): if len ( dic_avg_lipids [ lipid ][ i ]) > 0 : dic_avg_lipids [ lipid ][ i ] = np . mean ( dic_avg_lipids [ lipid ][ i ]) else : dic_avg_lipids [ lipid ][ i ] = 0 df_avg_intensity_lipids = pd . DataFrame . from_dict ( dic_avg_lipids , orient = \"index\" , columns = [ l_selected_regions [ i ] for i in range ( n_sel )], ) return df_avg_intensity_lipids df_avg_intensity_lipids = return_df_avg_lipids ( l_selected_regions ) logging . info ( \"Averaging done for all slices\" ) set_progress (( 90 , \"Loading data\" )) # Exclude very lowly expressed lipids df_min_expression = df_avg_intensity_lipids . min ( axis = 1 ) df_avg_intensity_lipids = df_avg_intensity_lipids [ df_min_expression > df_min_expression . quantile ( q = int ( percentile ) / 100 ) ] if len ( l_selected_regions ) > 1 : df_avg_intensity_lipids = df_avg_intensity_lipids . iloc [ ( df_avg_intensity_lipids . mean ( axis = 1 )) . argsort (), : ] else : df_avg_intensity_lipids . sort_values ( by = l_selected_regions [ 0 ], inplace = True ) logging . info ( \"Lowly expressed lipids excluded\" ) # Replace idx_lipids by actual name df_names = self . _data . get_annotations () df_avg_intensity_lipids . index = df_avg_intensity_lipids . index . map ( lambda idx : df_names . iloc [ idx ][ \"name\" ] + \"_\" + df_names . iloc [ idx ][ \"structure\" ] + \"_\" + df_names . iloc [ idx ][ \"cation\" ] ) logging . info ( \"Lipid indexes replaced by names\" ) logging . info ( \"Preparing plot\" ) # Plot fig_heatmap_lipids = Clustergram ( data = df_avg_intensity_lipids . to_numpy (), column_labels = df_avg_intensity_lipids . columns . to_list (), row_labels = df_avg_intensity_lipids . index . to_list (), hidden_labels = \"row\" if len ( df_avg_intensity_lipids . index . to_list ()) > 100 else None , color_map = \"Viridis\" , height = 800 , width = 1000 , display_ratio = [ 0.2 , 0.01 ], ) # Set background color to zero fig_heatmap_lipids . layout . template = \"plotly_dark\" fig_heatmap_lipids . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_heatmap_lipids . layout . paper_bgcolor = \"rgba(0,0,0,0)\" set_progress (( 100 , \"Returning figure\" )) logging . info ( \"Returning figure\" ) return fig_heatmap_lipids # ============================================================================================== # --- Methods used in scRNAseq page # ============================================================================================== def compute_scatter_3D ( self ): \"\"\"This functions computes a figure representing, in a 3D scatter plot, the spots acquired using spatial scRNAseq experiments. Returns: (Plotly.Figure): A Plotly Figure containing a go.Scatter3d object representing the acquired spots. \"\"\" logging . info ( \"Starting computing 3D scatter plot for scRNAseq experiments\" + logmem ()) # Get scatter figure for the scRNAseq spots scatter = go . Scatter3d ( x = self . _scRNAseq . xmol , y = self . _scRNAseq . zmol , z =- self . _scRNAseq . ymol , mode = \"markers\" , marker = dict ( size = 2.5 , opacity = 0.8 , color = dic_colors [ \"blue\" ]), ) # Get root figure root_data = self . _storage . return_shelved_object ( \"figures/3D_page\" , \"volume_root\" , force_update = False , compute_function = self . compute_3D_root_volume , differentiate_borders = True , ) # Remove inside of volume root_data [ \"value\" ] = np . where ( ( root_data [ \"value\" ] == - 0.01 ) | ( root_data [ \"value\" ] == - 2.0 ), - 2.0 , root_data [ \"value\" ] ) # Change orientation root_data_y = copy . deepcopy ( root_data [ \"y\" ]) root_data_z = copy . deepcopy ( root_data [ \"z\" ]) root_data [ \"y\" ] = root_data_z root_data [ \"z\" ] = - root_data_y # Remove parts of brain that prevent from clicking points root_data [ \"x\" ] = root_data [ \"x\" ][( root_data [ \"y\" ] < 6 ) & ( root_data [ \"z\" ] < - 3 )] root_data [ \"value\" ] = root_data [ \"value\" ][( root_data [ \"y\" ] < 6 ) & ( root_data [ \"z\" ] < - 3 )] root_data_y_copy = copy . deepcopy ( root_data [ \"y\" ]) root_data [ \"y\" ] = root_data [ \"y\" ][( root_data [ \"y\" ] < 6 ) & ( root_data [ \"z\" ] < - 3 )] root_data [ \"z\" ] = root_data [ \"z\" ][( root_data [ \"z\" ] < - 3 ) & ( root_data_y_copy < 6 )] # Block interaction for skull root_data [ \"hoverinfo\" ] = \"skip\" scatter [ \"hoverinfo\" ] = \"all\" # Build figure fig = go . Figure ( data = [ root_data , scatter ]) # Hide background fig . update_layout ( title_text = \"Click on a point to see the corresponding scRNAseq data\" , title_x = 0.5 , margin = dict ( r = 0 , b = 0 , l = 0 ), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" # Change orientation to have scatter dots face the reader x_eye = 0.01 * 2 y_eye = 1.0 * 2 z_eye = 0.5 * 2 camera = dict ( # up=dict(x=0, y=0, z=0), # center=dict(x=0, y=0, z=0), eye = dict ( x = x_eye , y = y_eye , z = z_eye ), ) fig . update_layout ( scene_camera = camera ) return fig def compute_barplots_enrichment ( self , brain_1 = False , idx_dot = None ): \"\"\"This functions computes two figures representing, in barplots, the lipid expression in the spots acquired using spatial scRNAseq experiments, as well as how it can be explained by an elastic net regression using gene expression as explaing factors. Args: brain_1 (bool, optional): If True, the barplot will be displayed with the regression coefficients computed from for the first brain. Returns: (Plotly.Figure, Plotly.Figure, list(str), list(str)): Two Plotly Figures containing each a go.Bar object representing the standardized lipid expression in the scRNAseq spots, and the elastic net regression coefficients for each lipid (bar). The two lists contain the corresponding names of the genes and lipids represented. \"\"\" logging . info ( \"Starting computing barplot for scRNAseq experiments\" + logmem ()) if brain_1 : x = self . _scRNAseq . l_name_lipids_brain_1 y = self . _scRNAseq . array_coef_brain_1 names = self . _scRNAseq . l_genes_brain_1 expression = self . _scRNAseq . array_exp_lipids_brain_1 l_score = self . _scRNAseq . l_score_brain_1 else : x = self . _scRNAseq . l_name_lipids_brain_2 y = self . _scRNAseq . array_coef_brain_2 names = self . _scRNAseq . l_genes_brain_2 expression = self . _scRNAseq . array_exp_lipids_brain_2 l_score = self . _scRNAseq . l_score_brain_2 # Turn expression into enrichment score expression = ( expression - np . mean ( expression , axis = 0 )) / np . std ( expression , axis = 0 ) # Take the average expression across all spots, or the expression in the selected spot if idx_dot is None : expression = np . mean ( expression , axis = 0 ) else : expression = expression [ idx_dot , :] # Sort lipids by enrichment index_sorted = np . argsort ( expression )[:: - 1 ] expression = expression [ index_sorted ] # Get arrays for plotting x = np . array ( x )[ index_sorted ] y = y [ index_sorted , :] l_score = np . array ( l_score )[ index_sorted ] # Limit to the 24 most expressed genes (in the most enriched lipid), # for only 24 colors are sharply distinguishable by naked eye index_sorted = np . argsort ( y [ 0 , :])[:: - 1 ] y = y [:, index_sorted [: 24 ]] names = np . array ( names )[ index_sorted [: 24 ]] # Normalize to 1 # y = (y.T / np.sum(abs(y), axis=1) * expression).T y = ( y . T / np . sum ( abs ( y ), axis = 1 )) . T # Incorporate score in the mix # y = np.vstack((y.T * l_score, (1 - l_score) * expression * np.ones((len(y),)))).T y = np . vstack (( y . T * l_score , ( 1 - l_score ) * 1.0 * np . ones (( len ( y ),)))) . T names = np . append ( names , \"Unexplained\" ) # Limit to 40 lipids for clarity x = x [: 40 ] y = y [: 40 , :] expression = expression [: 40 ] # Plot figure fig_lipids = go . Figure () fig_lipids . add_trace ( go . Bar ( x = x , y = expression , ) ) # Hide background fig_lipids . update_layout ( title_text = \"Lipid expression enrichment in selected spot (z-score)\" , title_x = 0.5 , barmode = \"relative\" , # margin=dict(t=0, r=0, b=0, l=0), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig_lipids . layout . template = \"plotly_dark\" fig_lipids . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_lipids . layout . paper_bgcolor = \"rgba(0,0,0,0)\" # Plot figure fig_genes = go . Figure () for idx , ( y_gene , name ) in enumerate ( zip ( y . T , names )): fig_genes . add_trace ( go . Bar ( x = x , y = abs ( y_gene ), name = name , marker_pattern_shape = [ \"+\" if t > 0 else \"-\" for t in y_gene ], # Doesn't work... marker_color = px . colors . qualitative . Dark24 [ idx ] if idx <= 23 else \"grey\" , hovertext = [ \" {:.2f} \" . format ( y [ idx_lipid , idx ] / np . sum ( abs ( y [ idx_lipid , :])) * 1.0 ) + \" (Fraction of (absolute) total elastic net coefficients)\" for idx_lipid in range ( len ( y )) ], ) ) # Hide background fig_genes . update_layout ( title_text = ( \"Elastic net coefficients, representing how lipid is explained by the corresponding\" \" gene\" ), title_x = 0.5 , barmode = \"relative\" , # margin=dict(t=0, r=0, b=0, l=0), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig_genes . layout . template = \"plotly_dark\" fig_genes . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_genes . layout . paper_bgcolor = \"rgba(0,0,0,0)\" return fig_lipids , fig_genes , names , x def compute_heatmap_lipid_genes ( self , lipid = None , l_genes = None , initial_frame = 5 , brain_1 = False , set_progress = None , ): \"\"\"This functions computes a heatmap representing, on the left side, the expression of a given lipid in the (low-resolution, interpolated) MALDI data, and the right side, the expressions of the selected genes (in l_genes) in the scRNAseq experiments from the molecular atlas data. Args: lipid (str): The name of the lipid to be displayed. If None, the most expressed lipid will be displayed. Defaults to None. l_genes (list): The list of gene names to be displayed. If None, the three most expressed genes will be displayed. Defaults to None. initial_frame (int, optional): The frame on which the slider is initialized. brain_1 (bool, optional): If True, the heatmap will be computed with the data coming from the first brain. Else, from the 2nd brain. Defaults to False. set_progress: Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. Returns: (Plotly.Figure): A Plotly Figure containing a go.Heatmap object representing the expression of the selected lipid and genes. \"\"\" logging . info ( \"Starting computing heatmap for scRNAseq experiments\" + logmem ()) if set_progress is not None : set_progress (( 5 , \"Loading data\" )) if brain_1 : x = self . _scRNAseq . l_name_lipids_brain_1 y = self . _scRNAseq . array_coef_brain_1 name_genes = self . _scRNAseq . l_genes_brain_1 name_lipids = self . _scRNAseq . l_name_lipids_brain_1 array_lipids = self . _scRNAseq . array_exp_lipids_brain_1 array_genes = self . _scRNAseq . array_exp_genes_brain_1 else : x = self . _scRNAseq . l_name_lipids_brain_2 y = self . _scRNAseq . array_coef_brain_2 name_genes = self . _scRNAseq . l_genes_brain_2 name_lipids = self . _scRNAseq . l_name_lipids_brain_2 array_lipids = self . _scRNAseq . array_exp_lipids_brain_2 array_genes = self . _scRNAseq . array_exp_genes_brain_2 # Get the most expressed lipid and genes if not provided if lipid is None and l_genes is None : expression = np . mean ( array_lipids , axis = 0 ) index_sorted = np . argsort ( expression )[:: - 1 ] expression = expression [ index_sorted ] lipids = np . array ( x )[ index_sorted ] y_sorted = y [ index_sorted , :] index_sorted = np . argsort ( y_sorted [ 0 , :])[:: - 1 ] y_sorted = y_sorted [:, index_sorted ] genes = np . array ( name_genes )[ index_sorted ] lipid = lipids [ 0 ] l_genes = genes [: 3 ] # Get coordinates x = self . _scRNAseq . xmol y = - self . _scRNAseq . ymol z = self . _scRNAseq . zmol # Get idx lipid and genes if lipid is not None : idx_lipid = list ( name_lipids ) . index ( lipid ) else : idx_lipid = None l_idx_genes_with_None = [ list ( name_genes ) . index ( gene ) if gene is not None else None for gene in l_genes ] l_idx_genes = [ idx_gene for idx_gene in l_idx_genes_with_None if idx_gene is not None ] # Build grids on which the data will be interpolated x_domain = np . arange ( np . min ( x ), np . max ( x ), 0.5 ) y_domain = np . arange ( np . min ( y ), np . max ( y ), 0.1 ) z_domain = np . arange ( np . min ( z ), np . max ( z ), 0.1 ) x_grid , y_grid , z_grid = np . meshgrid ( x_domain , y_domain , z_domain , indexing = \"ij\" ) if set_progress is not None : set_progress (( 15 , \"Preparing interpolation\" )) # Build data from interpolation since sampling is irregular if idx_lipid is not None : grid_lipid = griddata ( np . vstack (( x , y , z )) . T , array_lipids [:, idx_lipid ], ( x_grid , y_grid , z_grid ), method = \"linear\" , ) else : grid_lipid = None if len ( l_idx_genes ) == 1 : grid_genes = griddata ( np . vstack (( x , y , z )) . T , array_genes [:, l_idx_genes [ 0 ]], ( x_grid , y_grid , z_grid ), method = \"linear\" , ) elif len ( l_idx_genes ) > 1 : grid_genes = np . moveaxis ( np . stack ( [ griddata ( np . vstack (( x , y , z )) . T , array_genes [:, idx_genes ], ( x_grid , y_grid , z_grid ), method = \"linear\" , ) if idx_genes is not None else np . zeros_like ( x_grid ) for idx_genes in l_idx_genes_with_None ] ), 0 , - 1 , ) else : grid_genes = None if set_progress is not None : set_progress (( 75 , \"Finished interpolation... Building figure\" )) fig = make_subplots ( 1 , 2 ) # Build Figure, with several frames as it will be slidable if grid_lipid is not None : for i in range ( 0 , grid_lipid . shape [ 0 ], 1 ): fig . add_heatmap ( z = grid_lipid [ i , :, :], row = 1 , col = 1 , colorscale = \"Viridis\" , visible = True if i == initial_frame else False , showscale = False , ) if grid_genes is not None : if len ( grid_genes . shape ) == 3 : for i in range ( 0 , grid_genes . shape [ 0 ], 1 ): fig . add_heatmap ( z = grid_genes [ i , :, :], row = 1 , col = 2 , colorscale = \"Viridis\" , visible = True if i == initial_frame else False , showscale = False , ) elif len ( grid_genes . shape ) == 4 : for i in range ( 0 , grid_genes . shape [ 0 ], 1 ): fig . add_image ( z = grid_genes [ i , :, :, :], row = 1 , col = 2 , visible = True if i == initial_frame else False , ) if grid_genes is not None or grid_lipid is not None : steps = [] for i in range ( grid_lipid . shape [ 0 ]): step = dict ( method = \"restyle\" , args = [ \"visible\" , [ False ] * len ( fig . data )], label = str ( i ), ) if grid_lipid is not None and grid_genes is not None : step [ \"args\" ][ 1 ][ i ] = True step [ \"args\" ][ 1 ][ i + grid_lipid . shape [ 0 ]] = True elif grid_lipid is not None or grid_genes is not None : step [ \"args\" ][ 1 ][ i ] = True steps . append ( step ) sliders = [ dict ( active = initial_frame , steps = steps , pad = { \"b\" : 5 , \"t\" : 10 }, len = 0.9 , x = 0.05 , y = 0.0 , currentvalue = { \"visible\" : False , }, ) ] # Layout fig . update_layout ( title_text = \"Comparison between lipid and gene expression\" , title_x = 0.5 , title_y = 0.98 , margin = dict ( t = 20 , r = 20 , b = 20 , l = 20 ), template = \"plotly_dark\" , sliders = sliders , ) # No display of tick labels as they're wrong anyway fig . update_layout ( scene = dict ( xaxis = dict ( showticklabels = False ), yaxis = dict ( showticklabels = False ), ), paper_bgcolor = \"rgba(0,0,0,0.)\" , plot_bgcolor = \"rgba(0,0,0,0.)\" , yaxis_scaleanchor = \"x\" , ) # Reverse y axis if Image has been used if grid_genes is not None : if len ( grid_genes . shape ) == 4 : fig . update_yaxes ( autorange = True , row = 1 , col = 2 ) # Remove tick labels fig . update_xaxes ( showticklabels = False ) # Hide x axis ticks fig . update_yaxes ( showticklabels = False ) # Hide y axis ticks if set_progress is not None : set_progress (( 90 , \"Returning figure\" )) return fig # ============================================================================================== # --- Methods used for shelving results # ============================================================================================== def shelve_arrays_basic_figures ( self , force_update = False ): \"\"\"This function shelves in the database all the arrays of basic images computed in self.compute_figure_basic_image(), across all slices and all types of arrays. This forces the precomputations of these arrays, and allows to access them faster. Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Args: force_update (bool, optional): If True, the function will not overwrite existing files. Defaults to False. \"\"\" for idx_slice in range ( self . _data . get_slice_number ()): for type_figure in [ \"original_data\" , \"warped_data\" , \"projection_corrected\" , \"atlas\" ]: for display_annotations in [ True , False ]: # Force no annotation for the original data self . _storage . return_shelved_object ( \"figures/load_page\" , \"figure_basic_image\" , force_update = force_update , compute_function = self . compute_figure_basic_image , type_figure = type_figure , index_image = idx_slice , plot_atlas_contours = display_annotations if type_figure != \"original_data\" else False , ) self . _storage . dump_shelved_object ( \"figures/load_page\" , \"arrays_basic_figures_computed\" , True ) def shelve_all_l_array_2D ( self , force_update = False , sample = False , brain_1 = True ): \"\"\"This functions precomputes and shelves all the arrays of lipid expression used in a 3D representation of the brain (through self.compute_3D_volume_figure()). Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Args: force_update (bool, optional): If True, the function will not overwrite existing files. Defaults to False. sample (bool, optional): If True, only a fraction of the precomputations are made (for debug). Default to False. brain_1 (bool, optional): If True, the data is precomputed for the brain 1. Else for the brain 2. Defaults to True. \"\"\" # Count number of lipids processed for sampling n_processed = 0 if sample : logging . warning ( \"Only a sample of the lipid arrays will be computed!\" ) # Simulate a click on all lipid names df_annotations_MAIA = self . _data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 ) for name in sorted ( df_annotations_MAIA . name . unique ()): structures = df_annotations_MAIA [ df_annotations_MAIA [ \"name\" ] == name ] . structure . unique () for structure in sorted ( structures ): cations = df_annotations_MAIA [ ( df_annotations_MAIA [ \"name\" ] == name ) & ( df_annotations_MAIA [ \"structure\" ] == structure ) ] . cation . unique () for cation in sorted ( cations ): l_selected_lipids = [] for slice_index in self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ): # Find lipid location l_lipid_loc = ( self . _data . get_annotations () . index [ ( self . _data . get_annotations ()[ \"name\" ] == name ) & ( self . _data . get_annotations ()[ \"structure\" ] == structure ) & ( self . _data . get_annotations ()[ \"slice\" ] == slice_index ) & ( self . _data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) > 1 : logging . warning ( \"More than one lipid corresponds to the selection\" ) l_lipid_loc = [ l_lipid_loc [ - 1 ]] # If no lipid correspond to the selection, set to -1 if len ( l_lipid_loc ) == 0 : l_lipid_loc = [ - 1 ] # add lipid index for each slice l_selected_lipids . append ( l_lipid_loc [ 0 ]) # Get final lipid name lipid_string = name + \" \" + structure + \" \" + cation # If lipid is present in at least one slice if np . sum ( l_selected_lipids ) > - len ( self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ) ): # Build the list of mz boundaries for each peak and each index lll_lipid_bounds = [ [ [ ( float ( self . _data . get_annotations () . iloc [ index ][ \"min\" ]), float ( self . _data . get_annotations () . iloc [ index ][ \"max\" ]), ) ] if index != - 1 else None for index in [ lipid_1_index , - 1 , - 1 ] ] for lipid_1_index in l_selected_lipids ] # Compute 3D figures, selection is limited to one lipid name_lipid = lipid_string self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_expression_\" + str ( brain_1 ) + \"_\" + name_lipid + \"__\" , force_update = force_update , compute_function = self . compute_l_array_2D , ignore_arguments_naming = True , ll_t_bounds = lll_lipid_bounds , brain_1 = brain_1 , cache_flask = None , # No cache needed since launched at startup ) n_processed += 1 if n_processed >= 10 and sample : return None # Variable to signal everything has been computed self . _storage . dump_shelved_object ( \"figures/3D_page\" , \"arrays_expression_\" + str ( brain_1 ) + \"_computed\" , True ) def shelve_all_arrays_annotation ( self ): \"\"\"This functions precomputes and shelves the array of structure annotation used in a 3D representation of the brain (through self.compute_3D_volume_figure()), at different resolutions. Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. \"\"\" for decrease_dimensionality_factor in range ( 2 , 13 ): self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_annotation\" , force_update = False , compute_function = self . get_array_of_annotations , decrease_dimensionality_factor = decrease_dimensionality_factor , ) # Variable to signal everything has been computed self . _storage . dump_shelved_object ( \"figures/3D_page\" , \"arrays_annotation_computed\" , True ) __init__ ( maldi_data , storage , atlas , scRNAseq , sample = False ) Initialize the Figures class. Parameters: Name Type Description Default maldi_data MaldiData MaldiData object, used to manipulate the raw MALDI data. required storage Storage Used to access the shelve database. required atlas Atlas Used to manipulate the objects coming from the Allen Brain Atlas. required scRNAseq ScRNAseq Used to manipulate the objects coming from the scRNAseq dataset. required sample bool If True, only a fraction of the precomputations are made (for debug). Default to False. False Source code in modules/figures.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 def __init__ ( self , maldi_data , storage , atlas , scRNAseq , sample = False ): \"\"\"Initialize the Figures class. Args: maldi_data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. storage (Storage): Used to access the shelve database. atlas (Atlas): Used to manipulate the objects coming from the Allen Brain Atlas. scRNAseq (ScRNAseq): Used to manipulate the objects coming from the scRNAseq dataset. sample (bool, optional): If True, only a fraction of the precomputations are made (for debug). Default to False. \"\"\" logging . info ( \"Initializing Figures object\" + logmem ()) # Attribute to easily access the maldi and allen brain atlas data self . _data = maldi_data self . _atlas = atlas self . _scRNAseq = scRNAseq # attribute to access the shelve database self . _storage = storage # Dic of normalization factors across slices for MAIA normalized lipids self . dic_normalization_factors = self . _storage . return_shelved_object ( \"figures/lipid_selection\" , \"dic_normalization_factors\" , force_update = False , compute_function = self . compute_normalization_factor_across_slices , cache_flask = None , # No cache since launched at startup ) # Check that treemaps has been computed already. If not, compute it and store it. if not self . _storage . check_shelved_object ( \"figures/atlas_page/3D\" , \"treemaps\" ): self . _storage . return_shelved_object ( \"figures/atlas_page/3D\" , \"treemaps\" , force_update = False , compute_function = self . compute_treemaps_figure , ), # Check that 3D slice figures have been computed already. If not, compute it and store it. for brain in [ \"brain_1\" , \"brain_2\" ]: if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"slices_3D_\" + brain ): self . _storage . return_shelved_object ( \"figures/3D_page\" , \"slices_3D\" , force_update = False , compute_function = self . compute_figure_slices_3D , brain = brain , ) # Check that the 3D root volume figure has been computed already. If not, compute it and # store it. if self . _storage . check_shelved_object ( \"figures/scRNAseq_page\" , \"scatter3D\" ): self . _storage . return_shelved_object ( \"figures/scRNAseq_page\" , \"scatter3D\" , force_update = False , compute_function = self . compute_scatter_3D , ) # Check that the 3D scatter plot for scRNAseq data has been computed already. If not, # compute it and store it. if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"volume_root\" ): self . _storage . return_shelved_object ( \"figures/3D_page\" , \"volume_root\" , force_update = False , compute_function = self . compute_3D_root_volume , ) # Check that the base figures for lipid/genes heatmap have been computed already. If not, # compute them and store them. if not self . _storage . check_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid_True\" ) or not self . _storage . check_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid_False\" ): self . _storage . return_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid\" , force_update = False , compute_function = self . compute_heatmap_lipid_genes , brain_1 = False , ), self . _storage . return_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid\" , force_update = False , compute_function = self . compute_heatmap_lipid_genes , brain_1 = True , ), # Check that all basic figures in the load_slice page are present, if not, compute them if not self . _storage . check_shelved_object ( \"figures/load_page\" , \"arrays_basic_figures_computed\" ): self . shelve_arrays_basic_figures () # Check that the lipid distributions for all slices, and both brains, have been computed, if # not, compute them if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"arrays_expression_True_computed\" ): self . shelve_all_l_array_2D ( sample = sample , brain_1 = True ) if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"arrays_expression_False_computed\" ): self . shelve_all_l_array_2D ( sample = sample , brain_1 = False ) # Check that all arrays of annotations have been computed, if not, compute them if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"arrays_annotation_computed\" ): self . shelve_all_arrays_annotation () logging . info ( \"Figures object instantiated\" + logmem ()) build_lipid_heatmap_from_image ( image , return_base64_string = False , draw = False , type_image = None , return_go_image = False ) This function converts a numpy array into a base64 string, which can be returned directly, or itself be turned into a go.Image, which can be returned directly, or be turned into a Plotly Figure, which will be returned. Parameters: Name Type Description Default image np . ndarray A numpy array representing the image to be converted. Possibly with several channels. required return_base64_string bool If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. False draw bool If True, the user will have the possibility to draw on the resulting Plotly Figure. Defaults to False. False type_image string The type of the image to be converted to a base64 string. If image_array is in 3D, type must be RGB. If 4D, type must be RGBA. Else, no requirement (None). Defaults to None. None return_go_image bool If True, the go.Image is returned directly, before being integrated to a Plotly Figure. Defaults to False. False Returns: Type Description Depending on the inputted arguments, may either return a base64 string, a go.Image, or a Plotly Figure. Source code in modules/figures.py 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 def build_lipid_heatmap_from_image ( self , image , return_base64_string = False , draw = False , type_image = None , return_go_image = False , ): \"\"\"This function converts a numpy array into a base64 string, which can be returned directly, or itself be turned into a go.Image, which can be returned directly, or be turned into a Plotly Figure, which will be returned. Args: image (np.ndarray): A numpy array representing the image to be converted. Possibly with several channels. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. draw (bool, optional): If True, the user will have the possibility to draw on the resulting Plotly Figure. Defaults to False. type_image (string, optional): The type of the image to be converted to a base64 string. If image_array is in 3D, type must be RGB. If 4D, type must be RGBA. Else, no requirement (None). Defaults to None. return_go_image (bool, optional): If True, the go.Image is returned directly, before being integrated to a Plotly Figure. Defaults to False. Returns: Depending on the inputted arguments, may either return a base64 string, a go.Image, or a Plotly Figure. \"\"\" logging . info ( \"Converting image to string\" ) # Set optimize to False to gain computation time base64_string = convert_image_to_base64 ( image , type = type_image , overlay = None , transparent_zeros = True , optimize = False ) # Either return image directly if return_base64_string : return base64_string # Or compute heatmap as go image if needed logging . info ( \"Converting image to go image\" ) final_image = go . Image ( visible = True , source = base64_string , ) # Potentially return the go image directly if return_go_image : return final_image # Or build ploty graph fig = go . Figure ( final_image ) # Improve graph layout fig . update_layout ( margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), newshape = dict ( fillcolor = dic_colors [ \"blue\" ], opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ) ), xaxis = dict ( showgrid = False , zeroline = False ), yaxis = dict ( showgrid = False , zeroline = False ), # Do not specify height for now as plotly is buggued and resets if switching pages # height=500, ) fig . update_xaxes ( showticklabels = False ) fig . update_yaxes ( showticklabels = False ) fig . update ( layout_coloraxis_showscale = False ) # Set how the image should be annotated if draw : fig . update_layout ( dragmode = \"drawclosedpath\" ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" logging . info ( \"Returning figure\" ) return fig compute_3D_root_volume ( decrease_dimensionality_factor = 7 , differentiate_borders = False ) This function is used to generate a go.Isosurface of the Allen Brain root structure, which will be used to enclose the display of lipid expression of other structures in the brain. Parameters: Name Type Description Default decrease_dimensionality_factor int Decrease the dimensionnality of the brain to display, to get a lighter output. Defaults to 7. 7 Returns: Type Description go . Isosurface A semi-transparent go.Isosurface of the Allen Brain root structure. Source code in modules/figures.py 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 def compute_3D_root_volume ( self , decrease_dimensionality_factor = 7 , differentiate_borders = False ): \"\"\"This function is used to generate a go.Isosurface of the Allen Brain root structure, which will be used to enclose the display of lipid expression of other structures in the brain. Args: decrease_dimensionality_factor (int, optional): Decrease the dimensionnality of the brain to display, to get a lighter output. Defaults to 7. Returns: (go.Isosurface): A semi-transparent go.Isosurface of the Allen Brain root structure. \"\"\" # Get array of annotations, which associate coordinate to id array_annotation_root = np . array ( self . _atlas . bg_atlas . annotation , dtype = np . int32 ) # Subsample array of annotation the same way array_atlas was subsampled array_annotation_root = array_annotation_root [ :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , ] # Bug correction for the last slice array_annotation_root = np . concatenate ( ( array_annotation_root , np . zeros (( 1 , array_annotation_root . shape [ 1 ], array_annotation_root . shape [ 2 ])), ) ) # Get the volume array array_atlas_borders_root = fill_array_borders ( array_annotation_root , differentiate_borders = differentiate_borders , color_near_borders = False , keep_structure_id = None , ) # Compute the 3D grid X_root , Y_root , Z_root = np . mgrid [ 0 : array_atlas_borders_root . shape [ 0 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders_root . shape [ 0 ] * 1 j , 0 : array_atlas_borders_root . shape [ 1 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders_root . shape [ 1 ] * 1 j , 0 : array_atlas_borders_root . shape [ 2 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders_root . shape [ 2 ] * 1 j , ] # Compute the plot brain_root_data = go . Isosurface ( x = X_root . flatten (), y = Y_root . flatten (), z = Z_root . flatten (), value = array_atlas_borders_root . flatten (), isomin =- 0.21 , isomax = 2.55 , opacity = 0.1 , # max opacity surface_count = 2 , colorscale = \"Blues\" , # colorscale, flatshading = True , showscale = False , ) return brain_root_data compute_3D_volume_figure ( set_progress = None , ll_t_bounds = [[( None , None )]], name_lipid_1 = '' , name_lipid_2 = '' , name_lipid_3 = '' , set_id_regions = None , decrease_dimensionality_factor = 6 , cache_flask = None , structure_guided_interpolation = True , return_interpolated_array = False , return_individual_slice_data = False , divider_radius = 16 , brain_1 = False ) This figure computes a Plotly Figure containing a go.Volume object representing the expression of the requested lipids in the selected regions, interpolated between the slices. Lipid names are used to retrieve the expression data from the Shelve database. Parameters: Name Type Description Default set_progress Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. None ll_t_bounds list(list(tuple A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. [[(None, None)]] name_lipid_1 str Name of the first selected lipid. Defaults to \"\". '' name_lipid_2 str Name of the second selected lipid. Defaults to \"\". '' name_lipid_3 str Name of the third selected lipid. Defaults to \"\". '' set_id_regions set ( int ) A set containing the identifiers of the brain regions (at the very bottom of the hierarchy) in which lipid expression is requested. Defaults to None, corresponding to the whole brain. None decrease_dimensionality_factor int An integer used for subsampling the array of annotation, and therefore the resulting figure. The higher, the higher the subsampling. Needed as this is a very heavy plot. Defaults to 6. 6 cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None structure_guided_interpolation bool If True, the interpolation is done using the annotated structures. If False, the interpolation is done blindly. True return_interpolated_array bool If True, the interpolated array is returned. Else, the corresponding Plotly figure is returned. Defaults to False. False return_individual_slice_data bool If True, the individual slice data (not interpolated) is returned. False divider_radius int The inverse radius of the sphere used to do the interpolation. Defaults to 16. 16 brain_1 bool If True, the brain 1 data is used. Else, the brain 2 data is used. Defaults to False. False Returns: Type Description Depending on the value of return_interpolated_array and return_individual_slice_data, returns either the (not) interpolated array of expression of the requested lipids in the selected regions, or a Plotly Figure containing a go.Volume object representing the interpolated expression. Source code in modules/figures.py 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 def compute_3D_volume_figure ( self , set_progress = None , ll_t_bounds = [[( None , None )]], name_lipid_1 = \"\" , name_lipid_2 = \"\" , name_lipid_3 = \"\" , set_id_regions = None , decrease_dimensionality_factor = 6 , cache_flask = None , structure_guided_interpolation = True , return_interpolated_array = False , return_individual_slice_data = False , divider_radius = 16 , brain_1 = False , ): \"\"\"This figure computes a Plotly Figure containing a go.Volume object representing the expression of the requested lipids in the selected regions, interpolated between the slices. Lipid names are used to retrieve the expression data from the Shelve database. Args: set_progress: Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. name_lipid_1 (str, optional): Name of the first selected lipid. Defaults to \"\". name_lipid_2 (str, optional): Name of the second selected lipid. Defaults to \"\". name_lipid_3 (str, optional): Name of the third selected lipid. Defaults to \"\". set_id_regions (set(int), optional): A set containing the identifiers of the brain regions (at the very bottom of the hierarchy) in which lipid expression is requested. Defaults to None, corresponding to the whole brain. decrease_dimensionality_factor (int): An integer used for subsampling the array of annotation, and therefore the resulting figure. The higher, the higher the subsampling. Needed as this is a very heavy plot. Defaults to 6. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. structure_guided_interpolation (bool, optional): If True, the interpolation is done using the annotated structures. If False, the interpolation is done blindly. return_interpolated_array (bool): If True, the interpolated array is returned. Else, the corresponding Plotly figure is returned. Defaults to False. return_individual_slice_data (bool): If True, the individual slice data (not interpolated) is returned. divider_radius (int): The inverse radius of the sphere used to do the interpolation. Defaults to 16. brain_1 (bool): If True, the brain 1 data is used. Else, the brain 2 data is used. Defaults to False. Returns: Depending on the value of return_interpolated_array and return_individual_slice_data, returns either the (not) interpolated array of expression of the requested lipids in the selected regions, or a Plotly Figure containing a go.Volume object representing the interpolated expression. \"\"\" if return_interpolated_array and return_individual_slice_data : logging . warning ( \"Cannot return both interpolated and not interpolated array... Returning the\" \" individual slice data.\" ) logging . info ( \"Starting 3D volume computation\" ) if set_progress is not None : set_progress (( 10 , \"Loading array of annotations\" )) # Get subsampled array of annotations array_annotation = self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_annotation\" , force_update = False , compute_function = self . get_array_of_annotations , decrease_dimensionality_factor = decrease_dimensionality_factor , ) # Get subsampled array of borders for each region array_atlas_borders = np . zeros ( array_annotation . shape , dtype = np . float32 ) if set_id_regions is not None : list_id_regions = np . array ( list ( set_id_regions ), dtype = np . int64 ) else : list_id_regions = None if set_progress is not None : set_progress (( 10 , \"Computing brain borders\" )) # Shelving this function is useless as it takes less than 0.1s to compute after # first compilation array_atlas_borders = fill_array_borders ( array_annotation , keep_structure_id = list_id_regions , decrease_dimensionality_factor = decrease_dimensionality_factor , ) logging . info ( \"Computed basic structure array\" ) if set_progress is not None : set_progress (( 20 , \"Computing expression for each lipid\" )) # Get array of expression for each lipid ll_array_data = [ self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_expression_\" + str ( brain_1 ) + \"_\" + str ( name_lipid ) + \"__\" , force_update = False , ignore_arguments_naming = True , compute_function = self . compute_l_array_2D , ll_t_bounds = [[ l_t_bounds [ i ], None , None ] for l_t_bounds in ll_t_bounds ], brain_1 = brain_1 , cache_flask = cache_flask , ) for i , name_lipid in enumerate ([ name_lipid_1 , name_lipid_2 , name_lipid_3 ]) ] if set_progress is not None : set_progress (( 50 , \"Averaging expression for each lipid\" )) # Average array of expression over lipid l_array_data_avg = [] for slice_index in range ( len ( self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" )) ): n = 0 avg = 0 for i in range ( 3 ): # * number of lipids is hardcoded s = ll_array_data [ i ][ slice_index ] if s is None : s = 0 elif s . size == 1 : if np . isnan ( s ): s = 0 else : n += 1 avg += s # In case there's no data for the current slice, set the average to 0 if n == 0 : n = 1 l_array_data_avg . append ( avg / n ) logging . info ( \"Averaged expression over all lipids\" ) if set_progress is not None : set_progress (( 60 , \"Getting slice coordinates\" )) # Get the 3D array of expression and coordinates array_x , array_y , array_z , array_c = self . compute_array_coordinates_3D ( l_array_data_avg , high_res = False , brain_1 = brain_1 ) if return_individual_slice_data : return array_x , array_y , array_z , array_c logging . info ( \"Computed array of expression in original space\" ) if set_progress is not None : set_progress (( 70 , \"Filling a new brain with expression\" )) # Compute the rescaled array of expression for each slice averaged over projected lipids array_slices = np . copy ( array_atlas_borders ) array_for_avg = np . full_like ( array_atlas_borders , 1 ) array_x_scaled = array_x * 1000000 / self . _atlas . resolution / decrease_dimensionality_factor array_y_scaled = array_y * 1000000 / self . _atlas . resolution / decrease_dimensionality_factor array_z_scaled = array_z * 1000000 / self . _atlas . resolution / decrease_dimensionality_factor array_slices = fill_array_slices ( array_x_scaled , array_y_scaled , array_z_scaled , np . array ( array_c ), array_slices , array_for_avg , limit_value_inside =- 1.99999 , ) logging . info ( \"Filled basic structure array with array of expression\" ) # Get the corresponding coordinates X , Y , Z = np . mgrid [ 0 : array_atlas_borders . shape [ 0 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders . shape [ 0 ] * 1 j , 0 : array_atlas_borders . shape [ 1 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders . shape [ 1 ] * 1 j , 0 : array_atlas_borders . shape [ 2 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders . shape [ 2 ] * 1 j , ] logging . info ( \"Built arrays of coordinates\" ) if set_id_regions is not None : x_min , x_max , y_min , y_max , z_min , z_max = crop_array ( array_annotation , list_id_regions ) array_annotation = array_annotation [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] array_slices = array_slices [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] X = X [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] Y = Y [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] Z = Z [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] logging . info ( \"Cropped the figure to only keep areas in which lipids are expressed\" ) if set_progress is not None : set_progress (( 70 , \"Interpolating expression\" )) # Compute an array containing the lipid expression interpolated for every voxel array_interpolated = fill_array_interpolation ( array_annotation , array_slices , divider_radius = 16 , limit_value_inside =- 1.99999 , structure_guided = structure_guided_interpolation , ) logging . info ( \"Finished interpolation between slices\" ) if return_interpolated_array : return array_interpolated if set_progress is not None : set_progress (( 80 , \"Building figure\" )) # Get root figure root_data = self . _storage . return_shelved_object ( \"figures/3D_page\" , \"volume_root\" , force_update = False , compute_function = self . compute_3D_root_volume , ) logging . info ( \"Building final figure\" ) # Build figure fig = go . Figure ( data = [ go . Volume ( x = X . flatten (), y = Y . flatten (), z = Z . flatten (), value = array_interpolated . flatten (), isomin = 0.01 , isomax = 1.5 , opacityscale = [ [ - 0.11 , 0.00 ], [ 0.01 , 0.0 ], [ 0.5 , 0.05 ], [ 2.5 , 0.7 ], ], surface_count = 10 , colorscale = \"viridis\" , ), root_data , ] ) # Hide grey background fig . update_layout ( margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" logging . info ( \"Done computing 3D volume figure\" ) if set_progress is not None : set_progress (( 90 , \"Returning figure\" )) return fig compute_array_basic_images ( type_figure = 'warped_data' ) This function computes and returns a three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. No spectral data is read in the process, as the arrays corresponding to the images are directly stored as tiff files in the dataset. Parameters: Name Type Description Default type_figure str To be chosen among \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\". Depending on the chosen type, the final array will correspond to either the original images (\"original_data\"), the warped and upscaled images (\"warped_data\"), the warped and upscaled images, whose pixels outside of annotations regions have been zero-ed out (\"projection_corrected\"), or the images from the Allen Brain atlas projected onto the same plane as the corresponding slice from the MALDI data (\"atlas\"). Default to \"warped_data\". 'warped_data' Returns: Type Description np . ndarray A three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. The first dimension corresponds to the slices, the second and third to the images themselves. Source code in modules/figures.py 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 def compute_array_basic_images ( self , type_figure = \"warped_data\" ): \"\"\"This function computes and returns a three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. No spectral data is read in the process, as the arrays corresponding to the images are directly stored as tiff files in the dataset. Args: type_figure (str, optional): To be chosen among \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\". Depending on the chosen type, the final array will correspond to either the original images (\"original_data\"), the warped and upscaled images (\"warped_data\"), the warped and upscaled images, whose pixels outside of annotations regions have been zero-ed out (\"projection_corrected\"), or the images from the Allen Brain atlas projected onto the same plane as the corresponding slice from the MALDI data (\"atlas\"). Default to \"warped_data\". Returns: (np.ndarray): A three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. The first dimension corresponds to the slices, the second and third to the images themselves. \"\"\" # Check for all array types if type_figure == \"original_data\" : array_images = self . _data . compute_padded_original_images () elif type_figure == \"warped_data\" : if self . _data . _sample_data : with np . load ( \"data_sample/tiff_files/warped_data.npz\" ) as handle : array_images = handle [ \"array_warped_data\" ] else : array_images = io . imread ( \"data/tiff_files/warped_data.tif\" ) elif type_figure == \"projection_corrected\" : array_images = self . _atlas . array_projection_corrected elif type_figure == \"atlas\" : ( array_projected_images_atlas , array_projected_simplified_id , ) = self . _storage . return_shelved_object ( \"atlas/atlas_objects\" , \"array_images_atlas\" , force_update = False , compute_function = self . _atlas . prepare_and_compute_array_images_atlas , zero_out_of_annotation = True , ) array_images = array_projected_images_atlas else : logging . warning ( 'The type of requested array \" {} \" does not exist.' . format ( type_figure )) return None # If the array is not uint8, convert it to gain space if array_images . dtype != np . uint8 : array_images = np . array ( array_images , dtype = np . uint8 ) return array_images compute_array_coordinates_3D ( l_array_data , high_res = False , brain_1 = True ) This functions computes the list of coordinates and expression values for the voxels used in the 3D representation of the brain. Parameters: Name Type Description Default l_array_data list(np.ndarray A list of numpy arrays representing lipid expression for each slice of the dataset. required high_res bool If True, the computations made correspond to the warped/upscaled data. Defaults to False as this is a very heavy plot. False brain_1 bool If True, the returned list of arrays correspond to the brain 1 data. Else, to the brain 2 data. Defaults to True. True Returns: Type Description np . ndarray , np . ndarray , np . ndarray , np . ndarray 4 flat numpy arrays (3 for coordinates and 1 for expression). Source code in modules/figures.py 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 def compute_array_coordinates_3D ( self , l_array_data , high_res = False , brain_1 = True , ): \"\"\"This functions computes the list of coordinates and expression values for the voxels used in the 3D representation of the brain. Args: l_array_data (list(np.ndarray)): A list of numpy arrays representing lipid expression for each slice of the dataset. high_res (bool, optional): If True, the computations made correspond to the warped/upscaled data. Defaults to False as this is a very heavy plot. brain_1 (bool, optional): If True, the returned list of arrays correspond to the brain 1 data. Else, to the brain 2 data. Defaults to True. Returns: (np.ndarray, np.ndarray, np.ndarray, np.ndarray): 4 flat numpy arrays (3 for coordinates and 1 for expression). \"\"\" logging . info ( \"Starting computing 3D arrays\" + logmem ()) # Correct the indices for the potentially unused slices from brain 1 if brain_1 : slice_index_init = 0 slice_index_end = len ( self . _data . get_slice_list ( indices = \"brain_1\" )) else : slice_index_init = len ( self . _data . get_slice_list ( indices = \"brain_1\" )) slice_index_end = self . _data . get_slice_number () # get list of original coordinates for each slice if not high_res : l_coor = self . _atlas . l_original_coor [ slice_index_init : slice_index_end ] estimate = 400 * 400 else : estimate = 1311 * 918 l_coor = self . _atlas . array_coordinates_warped_data [ slice_index_init : slice_index_end ] # Initialize empty arrays with a large estimate for the orginal acquisition size max_size = estimate * ( slice_index_end - slice_index_init ) array_x = np . empty ( max_size , dtype = np . float32 ) array_y = np . empty ( max_size , dtype = np . float32 ) array_z = np . empty ( max_size , dtype = np . float32 ) array_c = np . empty ( max_size , dtype = np . int16 ) total_index = 0 logging . debug ( f \"Size array_x: { array_x . nbytes / 1024 / 1024 : .2f } \" ) logging . info ( \"Starting slice iteration\" + logmem ()) # get atlas shape and resolution reference_shape = self . _atlas . bg_atlas . reference . shape resolution = self . _atlas . resolution array_annotations = np . array ( self . _atlas . bg_atlas . annotation , dtype = np . int32 ) for slice_index in range ( 0 , len ( l_array_data ), 1 ): # Get the averaged expression data for the current slice array_data = l_array_data [ slice_index ] # If array_data is not an array but a 0 float, skip it if type ( array_data ) == float : continue # Remove pixels for which lipid expression is zero array_data_stripped = array_data . flatten () # array_data[array_data != 0].flatten() # Skip the current slice if expression is very sparse if len ( array_data_stripped ) < 10 or np . sum ( array_data_stripped ) < 1 : continue # Compute the percentile of expression to filter out lowly expressed pixels # Set to 0 for now, as no filtering is done percentile = 0 # np.percentile(array_data_stripped, 10) # Get the coordinates of the pixels in the ccfv3 coordinates = l_coor [ slice_index ] # coordinates_stripped = coordinates[array_data != 0] coordinates_stripped = coordinates . reshape ( - 1 , coordinates . shape [ - 1 ]) # Get the data as 4 arrays (3 for coordinates and 1 for expression) array_x , array_y , array_z , array_c , total_index = filter_voxels ( array_data_stripped . astype ( np . float32 ), coordinates_stripped , array_annotations , percentile , array_x , array_y , array_z , array_c , total_index , reference_shape , resolution , ) logging . info ( \"Slice \" + str ( slice_index ) + \" done\" + logmem ()) # Strip the arrays from the zeros array_x = array_x [: total_index ] array_y = array_y [: total_index ] array_z = array_z [: total_index ] # * Caution, array_c should be a list to work with Plotly array_c = array_c [: total_index ] . tolist () # Return the arrays for the 3D figure return array_x , array_y , array_z , array_c compute_barplots_enrichment ( brain_1 = False , idx_dot = None ) This functions computes two figures representing, in barplots, the lipid expression in the spots acquired using spatial scRNAseq experiments, as well as how it can be explained by an elastic net regression using gene expression as explaing factors. Parameters: Name Type Description Default brain_1 bool If True, the barplot will be displayed with the regression coefficients computed from for the first brain. False Returns: Type Description Plotly . Figure , Plotly . Figure , list ( str ), list ( str ) Two Plotly Figures containing each a go.Bar object representing the standardized lipid expression in the scRNAseq spots, and the elastic net regression coefficients for each lipid (bar). The two lists contain the corresponding names of the genes and lipids represented. Source code in modules/figures.py 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 def compute_barplots_enrichment ( self , brain_1 = False , idx_dot = None ): \"\"\"This functions computes two figures representing, in barplots, the lipid expression in the spots acquired using spatial scRNAseq experiments, as well as how it can be explained by an elastic net regression using gene expression as explaing factors. Args: brain_1 (bool, optional): If True, the barplot will be displayed with the regression coefficients computed from for the first brain. Returns: (Plotly.Figure, Plotly.Figure, list(str), list(str)): Two Plotly Figures containing each a go.Bar object representing the standardized lipid expression in the scRNAseq spots, and the elastic net regression coefficients for each lipid (bar). The two lists contain the corresponding names of the genes and lipids represented. \"\"\" logging . info ( \"Starting computing barplot for scRNAseq experiments\" + logmem ()) if brain_1 : x = self . _scRNAseq . l_name_lipids_brain_1 y = self . _scRNAseq . array_coef_brain_1 names = self . _scRNAseq . l_genes_brain_1 expression = self . _scRNAseq . array_exp_lipids_brain_1 l_score = self . _scRNAseq . l_score_brain_1 else : x = self . _scRNAseq . l_name_lipids_brain_2 y = self . _scRNAseq . array_coef_brain_2 names = self . _scRNAseq . l_genes_brain_2 expression = self . _scRNAseq . array_exp_lipids_brain_2 l_score = self . _scRNAseq . l_score_brain_2 # Turn expression into enrichment score expression = ( expression - np . mean ( expression , axis = 0 )) / np . std ( expression , axis = 0 ) # Take the average expression across all spots, or the expression in the selected spot if idx_dot is None : expression = np . mean ( expression , axis = 0 ) else : expression = expression [ idx_dot , :] # Sort lipids by enrichment index_sorted = np . argsort ( expression )[:: - 1 ] expression = expression [ index_sorted ] # Get arrays for plotting x = np . array ( x )[ index_sorted ] y = y [ index_sorted , :] l_score = np . array ( l_score )[ index_sorted ] # Limit to the 24 most expressed genes (in the most enriched lipid), # for only 24 colors are sharply distinguishable by naked eye index_sorted = np . argsort ( y [ 0 , :])[:: - 1 ] y = y [:, index_sorted [: 24 ]] names = np . array ( names )[ index_sorted [: 24 ]] # Normalize to 1 # y = (y.T / np.sum(abs(y), axis=1) * expression).T y = ( y . T / np . sum ( abs ( y ), axis = 1 )) . T # Incorporate score in the mix # y = np.vstack((y.T * l_score, (1 - l_score) * expression * np.ones((len(y),)))).T y = np . vstack (( y . T * l_score , ( 1 - l_score ) * 1.0 * np . ones (( len ( y ),)))) . T names = np . append ( names , \"Unexplained\" ) # Limit to 40 lipids for clarity x = x [: 40 ] y = y [: 40 , :] expression = expression [: 40 ] # Plot figure fig_lipids = go . Figure () fig_lipids . add_trace ( go . Bar ( x = x , y = expression , ) ) # Hide background fig_lipids . update_layout ( title_text = \"Lipid expression enrichment in selected spot (z-score)\" , title_x = 0.5 , barmode = \"relative\" , # margin=dict(t=0, r=0, b=0, l=0), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig_lipids . layout . template = \"plotly_dark\" fig_lipids . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_lipids . layout . paper_bgcolor = \"rgba(0,0,0,0)\" # Plot figure fig_genes = go . Figure () for idx , ( y_gene , name ) in enumerate ( zip ( y . T , names )): fig_genes . add_trace ( go . Bar ( x = x , y = abs ( y_gene ), name = name , marker_pattern_shape = [ \"+\" if t > 0 else \"-\" for t in y_gene ], # Doesn't work... marker_color = px . colors . qualitative . Dark24 [ idx ] if idx <= 23 else \"grey\" , hovertext = [ \" {:.2f} \" . format ( y [ idx_lipid , idx ] / np . sum ( abs ( y [ idx_lipid , :])) * 1.0 ) + \" (Fraction of (absolute) total elastic net coefficients)\" for idx_lipid in range ( len ( y )) ], ) ) # Hide background fig_genes . update_layout ( title_text = ( \"Elastic net coefficients, representing how lipid is explained by the corresponding\" \" gene\" ), title_x = 0.5 , barmode = \"relative\" , # margin=dict(t=0, r=0, b=0, l=0), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig_genes . layout . template = \"plotly_dark\" fig_genes . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_genes . layout . paper_bgcolor = \"rgba(0,0,0,0)\" return fig_lipids , fig_genes , names , x compute_clustergram_figure ( set_progress , cache_flask , l_selected_regions , percentile = 90 , brain_1 = False ) This function computes a Plotly Clustergram figure, allowing to cluster and compare the expression of all the MAIA-transformed lipids in the dataset in the selected regions. Parameters: Name Type Description Default set_progress Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. required cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. required l_selected_regions list ( int ) A list containing the identifiers of the brain regions (at the very bottom of the hierarchy) whose border must be annotated. required percentile int The percentile of average expression below which the lipids must be discarded (to get rid of low expression noise). Defaults to 90. 90 brain_1 bool If True, the brain 1 data is used. Else, the brain 2 data is used. Defaults to False. False Returns: Type Description go . Figure a Plotly Clustergram figure clustering and comparing the expression of all the MAIA-transformed lipids in the dataset in the selected regions. Source code in modules/figures.py 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 def compute_clustergram_figure ( self , set_progress , cache_flask , l_selected_regions , percentile = 90 , brain_1 = False , ): \"\"\"This function computes a Plotly Clustergram figure, allowing to cluster and compare the expression of all the MAIA-transformed lipids in the dataset in the selected regions. Args: set_progress: Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. l_selected_regions (list(int), optional): A list containing the identifiers of the brain regions (at the very bottom of the hierarchy) whose border must be annotated. percentile (int, optional): The percentile of average expression below which the lipids must be discarded (to get rid of low expression noise). Defaults to 90. brain_1 (bool): If True, the brain 1 data is used. Else, the brain 2 data is used. Defaults to False. Returns: (go.Figure): a Plotly Clustergram figure clustering and comparing the expression of all the MAIA-transformed lipids in the dataset in the selected regions. \"\"\" logging . info ( \"Starting computing clustergram figure\" ) # Memoize result as it's called everytime a filtering is done @cache_flask . memoize () def return_df_avg_lipids ( l_selected_regions ): dic_avg_lipids = {} l_slices = self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ) for slice_index in l_slices : # Display progress every 10 slices if slice_index % 10 == 0 : set_progress ( ( int ( slice_index / len ( l_slices ) * 100 ), \"Loading slice n\u00b0\" + str ( slice_index ), ) ) l_spectra = [] for region in l_selected_regions : long_region = self . _atlas . dic_acronym_name [ region ] if slice_index - 1 in self . _atlas . dic_existing_masks : if region in self . _atlas . dic_existing_masks [ slice_index - 1 ]: grah_scattergl_data = self . _atlas . get_projected_mask_and_spectrum ( slice_index - 1 , long_region , MAIA_correction = True )[ 1 ] l_spectra . append ( grah_scattergl_data ) else : l_spectra . append ( None ) else : raise Exception ( \"The masks have not been precomputed. Please precompute them before\" \" running this function.\" ) ll_idx_labels = global_lipid_index_store ( self . _data , slice_index - 1 , l_spectra ) logging . info ( \"Computing dictionnary for averaging slice \" + str ( slice_index )) # Compute average expression for each lipid and each selection set_lipids_idx = set () ll_lipids_idx = [] ll_avg_intensity = [] n_sel = len ( l_spectra ) for spectrum , l_idx_labels in zip ( l_spectra , ll_idx_labels ): if spectrum is not None : array_intensity_with_lipids = np . array ( spectrum , dtype = np . float32 )[ 1 , :] array_idx_labels = np . array ( l_idx_labels , dtype = np . int32 ) l_lipids_idx , l_avg_intensity = compute_avg_intensity_per_lipid ( array_intensity_with_lipids , array_idx_labels ) set_lipids_idx . update ( l_lipids_idx ) else : l_lipids_idx = None l_avg_intensity = None ll_lipids_idx . append ( l_lipids_idx ) ll_avg_intensity . append ( l_avg_intensity ) for i , ( l_lipids , l_avg_intensity ) in enumerate ( zip ( ll_lipids_idx , ll_avg_intensity ) ): if l_lipids is not None : for lipid , intensity in zip ( l_lipids , l_avg_intensity ): if lipid not in dic_avg_lipids : dic_avg_lipids [ lipid ] = [] for j in range ( n_sel ): dic_avg_lipids [ lipid ] . append ([]) dic_avg_lipids [ lipid ][ i ] . append ( intensity ) logging . info ( \"Averaging all lipid values across slices\" ) # Average intensity per slice for lipid in dic_avg_lipids : for i in range ( n_sel ): if len ( dic_avg_lipids [ lipid ][ i ]) > 0 : dic_avg_lipids [ lipid ][ i ] = np . mean ( dic_avg_lipids [ lipid ][ i ]) else : dic_avg_lipids [ lipid ][ i ] = 0 df_avg_intensity_lipids = pd . DataFrame . from_dict ( dic_avg_lipids , orient = \"index\" , columns = [ l_selected_regions [ i ] for i in range ( n_sel )], ) return df_avg_intensity_lipids df_avg_intensity_lipids = return_df_avg_lipids ( l_selected_regions ) logging . info ( \"Averaging done for all slices\" ) set_progress (( 90 , \"Loading data\" )) # Exclude very lowly expressed lipids df_min_expression = df_avg_intensity_lipids . min ( axis = 1 ) df_avg_intensity_lipids = df_avg_intensity_lipids [ df_min_expression > df_min_expression . quantile ( q = int ( percentile ) / 100 ) ] if len ( l_selected_regions ) > 1 : df_avg_intensity_lipids = df_avg_intensity_lipids . iloc [ ( df_avg_intensity_lipids . mean ( axis = 1 )) . argsort (), : ] else : df_avg_intensity_lipids . sort_values ( by = l_selected_regions [ 0 ], inplace = True ) logging . info ( \"Lowly expressed lipids excluded\" ) # Replace idx_lipids by actual name df_names = self . _data . get_annotations () df_avg_intensity_lipids . index = df_avg_intensity_lipids . index . map ( lambda idx : df_names . iloc [ idx ][ \"name\" ] + \"_\" + df_names . iloc [ idx ][ \"structure\" ] + \"_\" + df_names . iloc [ idx ][ \"cation\" ] ) logging . info ( \"Lipid indexes replaced by names\" ) logging . info ( \"Preparing plot\" ) # Plot fig_heatmap_lipids = Clustergram ( data = df_avg_intensity_lipids . to_numpy (), column_labels = df_avg_intensity_lipids . columns . to_list (), row_labels = df_avg_intensity_lipids . index . to_list (), hidden_labels = \"row\" if len ( df_avg_intensity_lipids . index . to_list ()) > 100 else None , color_map = \"Viridis\" , height = 800 , width = 1000 , display_ratio = [ 0.2 , 0.01 ], ) # Set background color to zero fig_heatmap_lipids . layout . template = \"plotly_dark\" fig_heatmap_lipids . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_heatmap_lipids . layout . paper_bgcolor = \"rgba(0,0,0,0)\" set_progress (( 100 , \"Returning figure\" )) logging . info ( \"Returning figure\" ) return fig_heatmap_lipids compute_figure_basic_image ( type_figure , index_image , plot_atlas_contours = True , only_contours = False , draw = False ) This function computes and returns a figure representing slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. The data is read directly from the array computed in self.compute_array_basic_images(). Parameters: Name Type Description Default type_figure str To be chosen among \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\". Depending on the chosen type, the final figure will correspond to either the original images (\"original_data\"), the warped and upscaled images (\"warped_data\"), the warped and upscaled images, whose pixels outside of annotations regions have been zero-ed out (\"projection_corrected\"), or the images from the Allen Brain atlas projected onto the same plane as the corresponding slice from the MALDI data (\"atlas\"). required index_image int Index of the requested slice image. required plot_atlas_contours bool If True, the atlas contours annotation is superimposed with the slice image. Defaults to True. True only_contours bool If True, only output the atlas contours annotation. All the other arugments but plot_atlas_contours (which must be True) get ignored. Defaults to False. False draw bool If True, the figure can be drawed on (used for region selection, in page region_analysis). Defaults to False. False Returns: Type Description go . Figure A Plotly figure representing the requested slice image of the requested type. Source code in modules/figures.py 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 def compute_figure_basic_image ( self , type_figure , index_image , plot_atlas_contours = True , only_contours = False , draw = False ): \"\"\"This function computes and returns a figure representing slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. The data is read directly from the array computed in self.compute_array_basic_images(). Args: type_figure (str): To be chosen among \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\". Depending on the chosen type, the final figure will correspond to either the original images (\"original_data\"), the warped and upscaled images (\"warped_data\"), the warped and upscaled images, whose pixels outside of annotations regions have been zero-ed out (\"projection_corrected\"), or the images from the Allen Brain atlas projected onto the same plane as the corresponding slice from the MALDI data (\"atlas\"). index_image (int): Index of the requested slice image. plot_atlas_contours (bool, optional): If True, the atlas contours annotation is superimposed with the slice image. Defaults to True. only_contours (bool, optional): If True, only output the atlas contours annotation. All the other arugments but plot_atlas_contours (which must be True) get ignored. Defaults to False. draw (bool, optional): If True, the figure can be drawed on (used for region selection, in page region_analysis). Defaults to False. Returns: (go.Figure): A Plotly figure representing the requested slice image of the requested type. \"\"\" # If only boundaries is requested, force the computation of atlas contours if only_contours : plot_atlas_contours = True else : # Get array of images array_images = self . _storage . return_shelved_object ( \"figures/load_page\" , \"array_basic_images\" , force_update = False , compute_function = self . compute_array_basic_images , type_figure = type_figure , ) # Get image at specified index array_image = array_images [ index_image ] # Add the contours if requested if plot_atlas_contours : array_image_atlas = self . _atlas . list_projected_atlas_borders_arrays [ index_image ] else : array_image_atlas = None # Create figure fig = go . Figure () # Compute image from our data if not only the atlas annotations are requested if not only_contours : fig . add_trace ( go . Image ( visible = True , source = convert_image_to_base64 ( array_image , overlay = array_image_atlas , transparent_zeros = True ), hoverinfo = \"none\" , ) ) # Add the labels only if it's not a simple annotation illustration # fig.update_xaxes( # title_text=self._atlas.bg_atlas.space.axis_labels[0][1], title_standoff=0 # ) else : fig . add_trace ( go . Image ( visible = True , source = convert_image_to_base64 ( array_image_atlas , optimize = True , binary = True , type = \"RGBA\" , decrease_resolution_factor = 8 , ), hoverinfo = \"none\" , ) ) # Improve layout fig . update_xaxes ( showticklabels = False ) fig . update_yaxes ( showticklabels = False ) fig . update_layout ( margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), xaxis = dict ( showgrid = False , zeroline = False ), yaxis = dict ( showgrid = False , zeroline = False ), template = \"plotly_dark\" , paper_bgcolor = \"rgba(0,0,0,0)\" , plot_bgcolor = \"rgba(0,0,0,0)\" , ) if draw : fig . update_layout ( dragmode = \"drawclosedpath\" , newshape = dict ( fillcolor = l_colors [ 0 ], opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ) ), autosize = True , ) return fig compute_figure_slices_3D ( reduce_resolution_factor = 20 , brain = 'brain_1' ) This function computes and returns a figure representing the slices from the maldi data in 3D. Parameters: Name Type Description Default reduce_resolution_factor int Divides (reduce) the initial resolution of the data. Needed as the resulting figure can be very heavy. Defaults to 20. 20 brain str Name of the brain to be used. Defaults to 'brain_1'. 'brain_1' Returns: Type Description go . Figure A Plotly figure representing the slices from the MALDI acquisitions in 3D. Source code in modules/figures.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 def compute_figure_slices_3D ( self , reduce_resolution_factor = 20 , brain = \"brain_1\" ): \"\"\"This function computes and returns a figure representing the slices from the maldi data in 3D. Args: reduce_resolution_factor (int, optional): Divides (reduce) the initial resolution of the data. Needed as the resulting figure can be very heavy. Defaults to 20. brain (str, optional): Name of the brain to be used. Defaults to 'brain_1'. Returns: (go.Figure): A Plotly figure representing the slices from the MALDI acquisitions in 3D. \"\"\" # Get transform parameters (a,u,v) for each slice l_transform_parameters = self . _storage . return_shelved_object ( \"atlas/atlas_objects\" , \"l_transform_parameters\" , force_update = False , compute_function = self . _atlas . compute_projection_parameters , ) # Reduce resolution of the slices new_dims = [] n_slices = self . _atlas . array_coordinates_warped_data . shape [ 0 ] d1 = self . _atlas . array_coordinates_warped_data . shape [ 1 ] d2 = self . _atlas . array_coordinates_warped_data . shape [ 2 ] for original_length , new_length in zip ( self . _atlas . array_projection_corrected . shape , ( n_slices , int ( round ( d1 / reduce_resolution_factor )), int ( round ( d2 / reduce_resolution_factor )), ), ): new_dims . append ( np . linspace ( 0 , original_length - 1 , new_length )) coords = np . meshgrid ( * new_dims , indexing = \"ij\" ) array_projection_small = map_coordinates ( self . _atlas . array_projection_corrected , coords ) # Build Figure, with several frames as it will be slidable fig = go . Figure ( frames = [ go . Frame ( data = self . get_surface ( slice_index - 1 , l_transform_parameters , array_projection_small , reduce_resolution_factor , ), name = str ( i + 1 ), ) for i , slice_index in enumerate ( self . _data . get_slice_list ( brain )) ] ) fig . add_trace ( self . get_surface ( self . _data . get_slice_list ( brain )[ 0 ] - 1 , l_transform_parameters , array_projection_small , reduce_resolution_factor , ) ) # Add a slider def frame_args ( duration ): return { \"frame\" : { \"duration\" : duration }, \"mode\" : \"immediate\" , \"fromcurrent\" : True , \"transition\" : { \"duration\" : duration , \"easing\" : \"linear\" }, } sliders = [ { \"pad\" : { \"b\" : 5 , \"t\" : 10 }, \"len\" : 0.9 , \"x\" : 0.05 , \"y\" : 0 , \"steps\" : [ { \"args\" : [[ f . name ], frame_args ( 0 )], \"label\" : str ( k ), \"method\" : \"animate\" , } for k , f in enumerate ( fig . frames ) ], \"currentvalue\" : { \"visible\" : False , }, } ] # Layout fig . update_layout ( scene = dict ( aspectratio = dict ( x = 1.5 , y = 1 , z = 1 ), yaxis = dict ( range = [ 0.0 , 0.35 ], autorange = False , backgroundcolor = \"rgba(0,0,0,0)\" , color = \"grey\" , gridcolor = \"grey\" , ), zaxis = dict ( range = [ 0.2 , - 0.02 ], autorange = False , backgroundcolor = \"rgba(0,0,0,0)\" , color = \"grey\" , gridcolor = \"grey\" , ), xaxis = dict ( range = [ 0.0 , 0.35 ], autorange = False , backgroundcolor = \"rgba(0,0,0,0)\" , color = \"grey\" , gridcolor = \"grey\" , ), ), margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), template = \"plotly_dark\" , sliders = sliders , ) # No display of tick labels as they're wrong anyway fig . update_layout ( scene = dict ( xaxis = dict ( showticklabels = False ), yaxis = dict ( showticklabels = False ), zaxis = dict ( showticklabels = False ), ), paper_bgcolor = \"rgba(0,0,0,0.)\" , plot_bgcolor = \"rgba(0,0,0,0.)\" , ) return fig compute_heatmap_lipid_genes ( lipid = None , l_genes = None , initial_frame = 5 , brain_1 = False , set_progress = None ) This functions computes a heatmap representing, on the left side, the expression of a given lipid in the (low-resolution, interpolated) MALDI data, and the right side, the expressions of the selected genes (in l_genes) in the scRNAseq experiments from the molecular atlas data. Parameters: Name Type Description Default lipid str The name of the lipid to be displayed. If None, the most expressed lipid will be displayed. Defaults to None. None l_genes list The list of gene names to be displayed. If None, the three most expressed genes will be displayed. Defaults to None. None initial_frame (int The frame on which the slider is initialized. 5 brain_1 bool If True, the heatmap will be computed with the data coming from the first brain. Else, from the 2nd brain. Defaults to False. False set_progress Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. None Returns: Type Description Plotly . Figure A Plotly Figure containing a go.Heatmap object representing the expression of the selected lipid and genes. Source code in modules/figures.py 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 2599 2600 2601 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 2645 2646 2647 2648 2649 2650 2651 2652 def compute_heatmap_lipid_genes ( self , lipid = None , l_genes = None , initial_frame = 5 , brain_1 = False , set_progress = None , ): \"\"\"This functions computes a heatmap representing, on the left side, the expression of a given lipid in the (low-resolution, interpolated) MALDI data, and the right side, the expressions of the selected genes (in l_genes) in the scRNAseq experiments from the molecular atlas data. Args: lipid (str): The name of the lipid to be displayed. If None, the most expressed lipid will be displayed. Defaults to None. l_genes (list): The list of gene names to be displayed. If None, the three most expressed genes will be displayed. Defaults to None. initial_frame (int, optional): The frame on which the slider is initialized. brain_1 (bool, optional): If True, the heatmap will be computed with the data coming from the first brain. Else, from the 2nd brain. Defaults to False. set_progress: Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. Returns: (Plotly.Figure): A Plotly Figure containing a go.Heatmap object representing the expression of the selected lipid and genes. \"\"\" logging . info ( \"Starting computing heatmap for scRNAseq experiments\" + logmem ()) if set_progress is not None : set_progress (( 5 , \"Loading data\" )) if brain_1 : x = self . _scRNAseq . l_name_lipids_brain_1 y = self . _scRNAseq . array_coef_brain_1 name_genes = self . _scRNAseq . l_genes_brain_1 name_lipids = self . _scRNAseq . l_name_lipids_brain_1 array_lipids = self . _scRNAseq . array_exp_lipids_brain_1 array_genes = self . _scRNAseq . array_exp_genes_brain_1 else : x = self . _scRNAseq . l_name_lipids_brain_2 y = self . _scRNAseq . array_coef_brain_2 name_genes = self . _scRNAseq . l_genes_brain_2 name_lipids = self . _scRNAseq . l_name_lipids_brain_2 array_lipids = self . _scRNAseq . array_exp_lipids_brain_2 array_genes = self . _scRNAseq . array_exp_genes_brain_2 # Get the most expressed lipid and genes if not provided if lipid is None and l_genes is None : expression = np . mean ( array_lipids , axis = 0 ) index_sorted = np . argsort ( expression )[:: - 1 ] expression = expression [ index_sorted ] lipids = np . array ( x )[ index_sorted ] y_sorted = y [ index_sorted , :] index_sorted = np . argsort ( y_sorted [ 0 , :])[:: - 1 ] y_sorted = y_sorted [:, index_sorted ] genes = np . array ( name_genes )[ index_sorted ] lipid = lipids [ 0 ] l_genes = genes [: 3 ] # Get coordinates x = self . _scRNAseq . xmol y = - self . _scRNAseq . ymol z = self . _scRNAseq . zmol # Get idx lipid and genes if lipid is not None : idx_lipid = list ( name_lipids ) . index ( lipid ) else : idx_lipid = None l_idx_genes_with_None = [ list ( name_genes ) . index ( gene ) if gene is not None else None for gene in l_genes ] l_idx_genes = [ idx_gene for idx_gene in l_idx_genes_with_None if idx_gene is not None ] # Build grids on which the data will be interpolated x_domain = np . arange ( np . min ( x ), np . max ( x ), 0.5 ) y_domain = np . arange ( np . min ( y ), np . max ( y ), 0.1 ) z_domain = np . arange ( np . min ( z ), np . max ( z ), 0.1 ) x_grid , y_grid , z_grid = np . meshgrid ( x_domain , y_domain , z_domain , indexing = \"ij\" ) if set_progress is not None : set_progress (( 15 , \"Preparing interpolation\" )) # Build data from interpolation since sampling is irregular if idx_lipid is not None : grid_lipid = griddata ( np . vstack (( x , y , z )) . T , array_lipids [:, idx_lipid ], ( x_grid , y_grid , z_grid ), method = \"linear\" , ) else : grid_lipid = None if len ( l_idx_genes ) == 1 : grid_genes = griddata ( np . vstack (( x , y , z )) . T , array_genes [:, l_idx_genes [ 0 ]], ( x_grid , y_grid , z_grid ), method = \"linear\" , ) elif len ( l_idx_genes ) > 1 : grid_genes = np . moveaxis ( np . stack ( [ griddata ( np . vstack (( x , y , z )) . T , array_genes [:, idx_genes ], ( x_grid , y_grid , z_grid ), method = \"linear\" , ) if idx_genes is not None else np . zeros_like ( x_grid ) for idx_genes in l_idx_genes_with_None ] ), 0 , - 1 , ) else : grid_genes = None if set_progress is not None : set_progress (( 75 , \"Finished interpolation... Building figure\" )) fig = make_subplots ( 1 , 2 ) # Build Figure, with several frames as it will be slidable if grid_lipid is not None : for i in range ( 0 , grid_lipid . shape [ 0 ], 1 ): fig . add_heatmap ( z = grid_lipid [ i , :, :], row = 1 , col = 1 , colorscale = \"Viridis\" , visible = True if i == initial_frame else False , showscale = False , ) if grid_genes is not None : if len ( grid_genes . shape ) == 3 : for i in range ( 0 , grid_genes . shape [ 0 ], 1 ): fig . add_heatmap ( z = grid_genes [ i , :, :], row = 1 , col = 2 , colorscale = \"Viridis\" , visible = True if i == initial_frame else False , showscale = False , ) elif len ( grid_genes . shape ) == 4 : for i in range ( 0 , grid_genes . shape [ 0 ], 1 ): fig . add_image ( z = grid_genes [ i , :, :, :], row = 1 , col = 2 , visible = True if i == initial_frame else False , ) if grid_genes is not None or grid_lipid is not None : steps = [] for i in range ( grid_lipid . shape [ 0 ]): step = dict ( method = \"restyle\" , args = [ \"visible\" , [ False ] * len ( fig . data )], label = str ( i ), ) if grid_lipid is not None and grid_genes is not None : step [ \"args\" ][ 1 ][ i ] = True step [ \"args\" ][ 1 ][ i + grid_lipid . shape [ 0 ]] = True elif grid_lipid is not None or grid_genes is not None : step [ \"args\" ][ 1 ][ i ] = True steps . append ( step ) sliders = [ dict ( active = initial_frame , steps = steps , pad = { \"b\" : 5 , \"t\" : 10 }, len = 0.9 , x = 0.05 , y = 0.0 , currentvalue = { \"visible\" : False , }, ) ] # Layout fig . update_layout ( title_text = \"Comparison between lipid and gene expression\" , title_x = 0.5 , title_y = 0.98 , margin = dict ( t = 20 , r = 20 , b = 20 , l = 20 ), template = \"plotly_dark\" , sliders = sliders , ) # No display of tick labels as they're wrong anyway fig . update_layout ( scene = dict ( xaxis = dict ( showticklabels = False ), yaxis = dict ( showticklabels = False ), ), paper_bgcolor = \"rgba(0,0,0,0.)\" , plot_bgcolor = \"rgba(0,0,0,0.)\" , yaxis_scaleanchor = \"x\" , ) # Reverse y axis if Image has been used if grid_genes is not None : if len ( grid_genes . shape ) == 4 : fig . update_yaxes ( autorange = True , row = 1 , col = 2 ) # Remove tick labels fig . update_xaxes ( showticklabels = False ) # Hide x axis ticks fig . update_yaxes ( showticklabels = False ) # Hide y axis ticks if set_progress is not None : set_progress (( 90 , \"Returning figure\" )) return fig compute_heatmap_per_lipid_selection ( slice_index , ll_t_bounds , normalize = True , projected_image = True , apply_transform = False , ll_lipid_names = None , return_base64_string = False , cache_flask = None ) This function is very similar to compute_heatmap_per_mz, but it takes a list of lipid boundaries, possibly along with lipid names, instead of just two boundaries. It returns a heatmap of the sum of expression of the requested lipids in the slice. Parameters: Name Type Description Default slice_index int The index of the requested slice. required ll_t_bounds list(list(tuple A list of lists of lipid boundaries (tuples). The first list is used to separate image channels (although this is not used in the function). The second list is used to separate lipid. required normalize bool If True, and the lipid has been MAIA transformed (and is provided with the parameter lipid_name) and apply_transform is True, the resulting array is normalized according to a factor computed across all slice. If MAIA has not been applied to the current selection or apply_transform is False, it is normalized according to the 99th percentile. Else, it is not normalized. Defaults to True. True projected_image bool If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. True apply_transform bool If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. False ll_lipid_names list ( list ( int )) List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. None return_base64_string bool If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. False cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description Depending on the value return_base64_string, may either return a base64 string, or a Plotly Figure. Source code in modules/figures.py 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 def compute_heatmap_per_lipid_selection ( self , slice_index , ll_t_bounds , normalize = True , projected_image = True , apply_transform = False , ll_lipid_names = None , return_base64_string = False , cache_flask = None , ): \"\"\"This function is very similar to compute_heatmap_per_mz, but it takes a list of lipid boundaries, possibly along with lipid names, instead of just two boundaries. It returns a heatmap of the sum of expression of the requested lipids in the slice. Args: slice_index (int): The index of the requested slice. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels (although this is not used in the function). The second list is used to separate lipid. normalize (bool, optional): If True, and the lipid has been MAIA transformed (and is provided with the parameter lipid_name) and apply_transform is True, the resulting array is normalized according to a factor computed across all slice. If MAIA has not been applied to the current selection or apply_transform is False, it is normalized according to the 99th percentile. Else, it is not normalized. Defaults to True. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. ll_lipid_names (list(list(int)), optional): List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the value return_base64_string, may either return a base64 string, or a Plotly Figure. \"\"\" logging . info ( \"Compute heatmap per lipid selection\" + str ( ll_t_bounds )) # Start from empty image and add selected lipids # * Caution: array must be int, float gets badly converted afterwards image = np . zeros ( self . _atlas . image_shape , dtype = np . int32 ) # Build empty lipid names if not provided if ll_lipid_names is None : ll_lipid_names = [[ \"\" for y in l_t_bounds ] for l_t_bounds in ll_t_bounds ] # Loop over channels for l_t_bounds , l_lipid_names in zip ( ll_t_bounds , ll_lipid_names ): if l_t_bounds is not None : # Loop over lipids for boundaries , lipid_name in zip ( l_t_bounds , l_lipid_names ): if boundaries is not None : ( lb_mz , hb_mz ) = boundaries # Cmpute expression image per lipid image_temp = self . compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , normalize = normalize , projected_image = projected_image , apply_transform = apply_transform , lipid_name = lipid_name , cache_flask = cache_flask , ) image += image_temp # Compute corresponding figure fig = self . build_lipid_heatmap_from_image ( image , return_base64_string = return_base64_string ) return fig compute_heatmap_per_mz ( slice_index , lb_mz = None , hb_mz = None , draw = False , projected_image = True , return_base64_string = False , cache_flask = None ) This function takes two boundaries and a slice index, and returns a heatmap of the lipid expressed in the slice whose m/z is between the two boundaries. Parameters: Name Type Description Default slice_index int The index of the requested slice. required lb_mz float The lower m/z boundary. Defaults to None. None hb_mz float The higher m/z boundary. Defaults to None. None draw bool If True, the user will have the possibility to draw on the resulting Plotly Figure. Defaults to False. False projected_image bool If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. True return_base64_string bool If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. False cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description Depending on the value return_base64_string, may either return a base64 string, or a Plotly Figure. Source code in modules/figures.py 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 def compute_heatmap_per_mz ( self , slice_index , lb_mz = None , hb_mz = None , draw = False , projected_image = True , return_base64_string = False , cache_flask = None , ): \"\"\"This function takes two boundaries and a slice index, and returns a heatmap of the lipid expressed in the slice whose m/z is between the two boundaries. Args: slice_index (int): The index of the requested slice. lb_mz (float, optional): The lower m/z boundary. Defaults to None. hb_mz (float, optional): The higher m/z boundary. Defaults to None. draw (bool, optional): If True, the user will have the possibility to draw on the resulting Plotly Figure. Defaults to False. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the value return_base64_string, may either return a base64 string, or a Plotly Figure. \"\"\" logging . info ( \"Starting figure computation, from mz boundaries\" ) # Upper bound lower than the lowest m/z value and higher that the highest m/z value if lb_mz is None : lb_mz = 200 if hb_mz is None : hb_mz = 1800 logging . info ( \"Getting image array\" ) # Compute image with given bounds image = self . compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , projected_image = projected_image , cache_flask = cache_flask , ) # Compute corresponding figure fig = self . build_lipid_heatmap_from_image ( image , return_base64_string = return_base64_string , draw = draw ) return fig compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , normalize = True , log = False , projected_image = True , apply_transform = False , lipid_name = '' , cache_flask = None ) This function allows to query the MALDI data to extract an image in the form of a Numpy array representing the intensity of the lipid peaking between the values lb_mz and hb_mz in the spectral data, for the slice slice_index. Parameters: Name Type Description Default slice_index int Index of the requested slice. required lb_mz float Lower boundary for the spectral data to query. required hb_mz float Higher boundary for the spectral data to query. required RGB_format bool If True, the values in the array are between 0 and 255, given that the data has been normalized beforehand. Else, between 0 and 1. This parameter only makes sense if the data has been normalized beforehand. Defaults to True. True normalize bool If True, and the lipid has been MAIA transformed (and is provided with the parameter lipid_name) and apply_transform is True, the resulting array is normalized according to a factor computed across all slice. If MAIA has not been applied to the current selection or apply_transform is False, it is normalized according to the 99th percentile. Else, it is not normalized. Defaults to True. True log bool If True, the resulting array is log-transformed. This is useful in case of low expression. Defaults to False. False projected_image bool If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. True apply_transform bool If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. False lipid_name str Name of the lipid that must be MAIA-transformed, if apply_transform and normalize are True. Defaults to \"\". '' cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description np . ndarray An image (in the form of a numpy array) representing the intensity of the lipid peaking between the values lb_mz and hb_mz in the spectral data, for the slice slice_index. Source code in modules/figures.py 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 def compute_image_per_lipid ( self , slice_index , lb_mz , hb_mz , RGB_format = True , normalize = True , log = False , projected_image = True , apply_transform = False , lipid_name = \"\" , cache_flask = None , ): \"\"\"This function allows to query the MALDI data to extract an image in the form of a Numpy array representing the intensity of the lipid peaking between the values lb_mz and hb_mz in the spectral data, for the slice slice_index. Args: slice_index (int): Index of the requested slice. lb_mz (float): Lower boundary for the spectral data to query. hb_mz (float): Higher boundary for the spectral data to query. RGB_format (bool, optional): If True, the values in the array are between 0 and 255, given that the data has been normalized beforehand. Else, between 0 and 1. This parameter only makes sense if the data has been normalized beforehand. Defaults to True. normalize (bool, optional): If True, and the lipid has been MAIA transformed (and is provided with the parameter lipid_name) and apply_transform is True, the resulting array is normalized according to a factor computed across all slice. If MAIA has not been applied to the current selection or apply_transform is False, it is normalized according to the 99th percentile. Else, it is not normalized. Defaults to True. log (bool, optional): If True, the resulting array is log-transformed. This is useful in case of low expression. Defaults to False. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. lipid_name (str, optional): Name of the lipid that must be MAIA-transformed, if apply_transform and normalize are True. Defaults to \"\". cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (np.ndarray): An image (in the form of a numpy array) representing the intensity of the lipid peaking between the values lb_mz and hb_mz in the spectral data, for the slice slice_index. \"\"\" logging . info ( \"Entering compute_image_per_lipid\" ) # Get image from raw mass spec data image = compute_thread_safe_function ( compute_image_using_index_and_image_lookup , cache_flask , self . _data , slice_index , lb_mz , hb_mz , self . _data . get_array_spectra ( slice_index ), self . _data . get_array_lookup_pixels ( slice_index ), self . _data . get_image_shape ( slice_index ), self . _data . get_array_lookup_mz ( slice_index ), self . _data . get_array_cumulated_lookup_mz_image ( slice_index ), self . _data . get_divider_lookup ( slice_index ), self . _data . get_array_peaks_transformed_lipids ( slice_index ), self . _data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), apply_transform = apply_transform , ) # Log-transform the image if requested if log : image = np . log ( image + 1 ) # In case of bug, return None if image is None : return None # Normalize the image if requested if normalize : # Normalize across slice if the lipid has been MAIA transformed if ( lipid_name , self . _data . is_brain_1 ( slice_index ), ) in self . dic_normalization_factors and apply_transform : perc = self . dic_normalization_factors [ ( lipid_name , self . _data . is_brain_1 ( slice_index )) ] logging . info ( \"Normalization made with respect to percentile computed across all slices.\" ) else : # Normalize by 99 percentile perc = np . percentile ( image , 99.0 ) if perc == 0 : perc = np . max ( image ) if perc == 0 : perc = 1 image = image / perc image = np . clip ( 0 , 1 , image ) # Turn to RGB format if requested if RGB_format : image *= 255 # Change dtype if normalized and RGB to save space if normalize and RGB_format : image = np . round ( image ) . astype ( np . uint8 ) # Project image into cleaned and higher resolution version if projected_image : image = project_image ( slice_index , image , self . _atlas . array_projection_correspondence_corrected ) return image compute_l_array_2D ( ll_t_bounds , normalize_independently = True , high_res = False , brain_1 = True , cache_flask = None ) This function is used to get the list of expression per slice for all slices for the computation of the 3D brain volume. Parameters: Name Type Description Default ll_t_bounds list(list(tuple A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. required normalize_independently bool If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. True high_res bool If True, the returned list of arrays correspond to the warped/upscaled data. Defaults to False as this is a very heavy plot. False brain_1 bool If True, the returned list of arrays correspond to the brain 1 data. Else, to the brain 2 data. Defaults to True. True cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description list ( np . ndarray ) A list of numpy arrays representing the expression of the requested lipids (through ll_t_bounds) for each slice. Source code in modules/figures.py 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 def compute_l_array_2D ( self , ll_t_bounds , normalize_independently = True , high_res = False , brain_1 = True , cache_flask = None , ): \"\"\"This function is used to get the list of expression per slice for all slices for the computation of the 3D brain volume. Args: ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. normalize_independently (bool, optional): If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. high_res (bool, optional): If True, the returned list of arrays correspond to the warped/upscaled data. Defaults to False as this is a very heavy plot. brain_1 (bool, optional): If True, the returned list of arrays correspond to the brain 1 data. Else, to the brain 2 data. Defaults to True. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (list(np.ndarray)): A list of numpy arrays representing the expression of the requested lipids (through ll_t_bounds) for each slice. \"\"\" l_array_data = [] # Correct the indices for the potentially unused slices from brain 1 if brain_1 : slice_index_offset = 0 else : slice_index_offset = len ( self . _data . get_slice_list ( indices = \"brain_1\" )) # Loop over slices and compute the expression of the requested lipids for slice_index in range ( len ( ll_t_bounds )): if ll_t_bounds [ slice_index ] != [ None , None , None ]: # Get the data as an expression image per lipid array_data = self . compute_rgb_array_per_lipid_selection ( slice_index + 1 + slice_index_offset , ll_t_bounds [ slice_index ], normalize_independently = normalize_independently , projected_image = high_res , log = False , apply_transform = True , cache_flask = cache_flask , ) # Sum array colors (i.e. lipids) array_data = np . sum ( array_data , axis =- 1 ) else : array_data = None # Append data to l_array_data l_array_data . append ( np . array ( array_data , dtype = np . float16 )) # float16 to gain space return l_array_data compute_normalization_factor_across_slices ( cache_flask = None ) This function computes a dictionnary of normalization factors (used for MAIA-transformed lipids) across all slices (99th percentile of expression). Parameters: Name Type Description Default cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description dict A dictionnary associating, for each MAIA-transformed lipid name, the 99th percentile of the intensity across all slices. Source code in modules/figures.py 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 def compute_normalization_factor_across_slices ( self , cache_flask = None ): \"\"\"This function computes a dictionnary of normalization factors (used for MAIA-transformed lipids) across all slices (99th percentile of expression). Args: cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (dict): A dictionnary associating, for each MAIA-transformed lipid name, the 99th percentile of the intensity across all slices. \"\"\" logging . info ( \"Compute normalization factor across slices for MAIA transformed lipids...\" + \" It may takes a while\" ) # Dictionnnary that will contain the percentile across all slices of a given brain dic_max_percentile = {} # Function to compute the percentile across all slices def _compute_percentile_across_slices ( name , structure , cation , brain_1 ): max_perc = 0 lipid_string = \"\" for slice_index in self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ): # Find lipid location l_lipid_loc = ( self . _data . get_annotations () . index [ ( self . _data . get_annotations ()[ \"name\" ] == name ) & ( self . _data . get_annotations ()[ \"structure\" ] == structure ) & ( self . _data . get_annotations ()[ \"slice\" ] == slice_index ) & ( self . _data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) >= 1 : index = l_lipid_loc [ - 1 ] # get final lipid name lipid_string = name + \"_\" + structure + \"_\" + cation # get lipid bounds lb_mz = float ( self . _data . get_annotations () . iloc [ index ][ \"min\" ]) hb_mz = float ( self . _data . get_annotations () . iloc [ index ][ \"max\" ]) # Get corresponding image image = compute_thread_safe_function ( compute_image_using_index_and_image_lookup , cache_flask , self . _data , slice_index , lb_mz , hb_mz , self . _data . get_array_spectra ( slice_index ), self . _data . get_array_lookup_pixels ( slice_index ), self . _data . get_image_shape ( slice_index ), self . _data . get_array_lookup_mz ( slice_index ), self . _data . get_array_cumulated_lookup_mz_image ( slice_index ), self . _data . get_divider_lookup ( slice_index ), self . _data . get_array_peaks_transformed_lipids ( slice_index ), self . _data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), apply_transform = False , ) # Check 99th percentile for normalization perc = np . percentile ( image , 99.0 ) # perc must be quite small in theory... otherwise it's a bug if perc > max_perc : # and perc<1: max_perc = perc return max_perc , lipid_string # Simulate a click on all MAIA transformed lipids for brain_1 in [ True , False ]: for ( index , ( name , structure , cation , mz ), ) in self . _data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 ) . iterrows (): max_perc , lipid_string = _compute_percentile_across_slices ( name , structure , cation , brain_1 ) # Store max percentile across slices dic_max_percentile [( lipid_string , brain_1 )] = max_perc return dic_max_percentile compute_rgb_array_per_lipid_selection ( slice_index , ll_t_bounds , normalize_independently = True , projected_image = True , log = False , apply_transform = False , ll_lipid_names = None , cache_flask = None ) This function computes a numpy RGB array (each pixel has 3 intensity values) of expression of the requested lipids (those whose m/z values are in ll_t_bounds) in the slice. Parameters: Name Type Description Default slice_index int The index of the requested slice. required ll_t_bounds list(list(tuple A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. required normalize_independently bool If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. True projected_image bool If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. True log bool If True, the resulting array corresponds to log-transformed expression, for each lipid. Defaults to False. False apply_transform bool If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. False ll_lipid_names list ( list ( int )) List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. None cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description np . ndarray A three-dimensional RGB numpy array (of uint8 dtype). The first two dimensions correspond to the acquisition image shape, and the third dimension corresponds to the channels. Source code in modules/figures.py 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 def compute_rgb_array_per_lipid_selection ( self , slice_index , ll_t_bounds , normalize_independently = True , projected_image = True , log = False , apply_transform = False , ll_lipid_names = None , cache_flask = None , ): \"\"\"This function computes a numpy RGB array (each pixel has 3 intensity values) of expression of the requested lipids (those whose m/z values are in ll_t_bounds) in the slice. Args: slice_index (int): The index of the requested slice. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. normalize_independently (bool, optional): If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. log (bool, optional): If True, the resulting array corresponds to log-transformed expression, for each lipid. Defaults to False. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. ll_lipid_names (list(list(int)), optional): List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (np.ndarray): A three-dimensional RGB numpy array (of uint8 dtype). The first two dimensions correspond to the acquisition image shape, and the third dimension corresponds to the channels. \"\"\" # Empty lipid names if no names provided if ll_lipid_names is None : ll_lipid_names = [ [ \"\" for y in l_t_bounds ] if l_t_bounds is not None else [ \"\" ] for l_t_bounds in ll_t_bounds ] # Build a list of empty images and add selected lipids for each channel l_images = [] # Loop over channels for l_boundaries , l_names in zip ( ll_t_bounds , ll_lipid_names ): image = np . zeros ( self . _atlas . image_shape if projected_image else self . _data . get_image_shape ( slice_index ) ) if l_boundaries is not None : # Loop over lipids for boundaries , lipid_name in zip ( l_boundaries , l_names ): if boundaries is not None : ( lb_mz , hb_mz ) = boundaries # Cmpute expression image per lipid image_temp = self . compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , normalize = normalize_independently , projected_image = projected_image , log = log , apply_transform = apply_transform , lipid_name = lipid_name , cache_flask = cache_flask , ) if image_temp is not None : image += image_temp l_images . append ( image ) # Reoder axis to match plotly go.image requirements array_image = np . moveaxis ( np . array ( l_images ), 0 , 2 ) return np . asarray ( array_image , dtype = np . uint8 ) compute_rgb_image_per_lipid_selection ( slice_index , ll_t_bounds , normalize_independently = True , projected_image = True , log = False , return_image = False , apply_transform = False , ll_lipid_names = None , return_base64_string = False , cache_flask = None ) This function is very similar to compute_heatmap_per_lipid_selection, but it returns a RGB image instead of a heatmap. Parameters: Name Type Description Default slice_index int The index of the requested slice. required ll_t_bounds list(list(tuple A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. required normalize_independently bool If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. True projected_image bool If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. True log bool If True, the resulting array corresponds to log-transformed expression, for each lipid. Defaults to False. False return_image bool If True, a go.Image is returned directly, instead of a Plotly Figure. Defaults to False. False apply_transform bool If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. False ll_lipid_names list ( list ( int )) List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. None return_base64_string bool If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. False cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description Depending on the inputted arguments, may either return a base64 string, a go.Image, or a Plotly Figure. Source code in modules/figures.py 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 def compute_rgb_image_per_lipid_selection ( self , slice_index , ll_t_bounds , normalize_independently = True , projected_image = True , log = False , return_image = False , apply_transform = False , ll_lipid_names = None , return_base64_string = False , cache_flask = None , ): \"\"\"This function is very similar to compute_heatmap_per_lipid_selection, but it returns a RGB image instead of a heatmap. Args: slice_index (int): The index of the requested slice. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. normalize_independently (bool, optional): If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. log (bool, optional): If True, the resulting array corresponds to log-transformed expression, for each lipid. Defaults to False. return_image (bool, optional): If True, a go.Image is returned directly, instead of a Plotly Figure. Defaults to False. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. ll_lipid_names (list(list(int)), optional): List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the inputted arguments, may either return a base64 string, a go.Image, or a Plotly Figure. \"\"\" logging . info ( \"Started RGB image computation for slice \" + str ( slice_index ) + logmem ()) # Empty lipid names if no names provided if ll_lipid_names is None : ll_lipid_names = [[ \"\" for y in l_t_bounds ] for l_t_bounds in ll_t_bounds ] logging . info ( \"Acquiring array_image for slice \" + str ( slice_index ) + logmem ()) # Get RGB array for the current lipid selection array_image = self . compute_rgb_array_per_lipid_selection ( slice_index , ll_t_bounds , normalize_independently = normalize_independently , projected_image = projected_image , log = log , apply_transform = apply_transform , ll_lipid_names = ll_lipid_names , cache_flask = cache_flask , ) logging . info ( \"Returning fig for slice \" + str ( slice_index ) + logmem ()) # Build the correspondig figure return self . build_lipid_heatmap_from_image ( array_image , return_base64_string = return_base64_string , draw = False , type_image = \"RGB\" , return_go_image = return_image , ) compute_scatter_3D () This functions computes a figure representing, in a 3D scatter plot, the spots acquired using spatial scRNAseq experiments. Returns: Type Description Plotly . Figure A Plotly Figure containing a go.Scatter3d object representing the acquired spots. Source code in modules/figures.py 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 def compute_scatter_3D ( self ): \"\"\"This functions computes a figure representing, in a 3D scatter plot, the spots acquired using spatial scRNAseq experiments. Returns: (Plotly.Figure): A Plotly Figure containing a go.Scatter3d object representing the acquired spots. \"\"\" logging . info ( \"Starting computing 3D scatter plot for scRNAseq experiments\" + logmem ()) # Get scatter figure for the scRNAseq spots scatter = go . Scatter3d ( x = self . _scRNAseq . xmol , y = self . _scRNAseq . zmol , z =- self . _scRNAseq . ymol , mode = \"markers\" , marker = dict ( size = 2.5 , opacity = 0.8 , color = dic_colors [ \"blue\" ]), ) # Get root figure root_data = self . _storage . return_shelved_object ( \"figures/3D_page\" , \"volume_root\" , force_update = False , compute_function = self . compute_3D_root_volume , differentiate_borders = True , ) # Remove inside of volume root_data [ \"value\" ] = np . where ( ( root_data [ \"value\" ] == - 0.01 ) | ( root_data [ \"value\" ] == - 2.0 ), - 2.0 , root_data [ \"value\" ] ) # Change orientation root_data_y = copy . deepcopy ( root_data [ \"y\" ]) root_data_z = copy . deepcopy ( root_data [ \"z\" ]) root_data [ \"y\" ] = root_data_z root_data [ \"z\" ] = - root_data_y # Remove parts of brain that prevent from clicking points root_data [ \"x\" ] = root_data [ \"x\" ][( root_data [ \"y\" ] < 6 ) & ( root_data [ \"z\" ] < - 3 )] root_data [ \"value\" ] = root_data [ \"value\" ][( root_data [ \"y\" ] < 6 ) & ( root_data [ \"z\" ] < - 3 )] root_data_y_copy = copy . deepcopy ( root_data [ \"y\" ]) root_data [ \"y\" ] = root_data [ \"y\" ][( root_data [ \"y\" ] < 6 ) & ( root_data [ \"z\" ] < - 3 )] root_data [ \"z\" ] = root_data [ \"z\" ][( root_data [ \"z\" ] < - 3 ) & ( root_data_y_copy < 6 )] # Block interaction for skull root_data [ \"hoverinfo\" ] = \"skip\" scatter [ \"hoverinfo\" ] = \"all\" # Build figure fig = go . Figure ( data = [ root_data , scatter ]) # Hide background fig . update_layout ( title_text = \"Click on a point to see the corresponding scRNAseq data\" , title_x = 0.5 , margin = dict ( r = 0 , b = 0 , l = 0 ), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" # Change orientation to have scatter dots face the reader x_eye = 0.01 * 2 y_eye = 1.0 * 2 z_eye = 0.5 * 2 camera = dict ( # up=dict(x=0, y=0, z=0), # center=dict(x=0, y=0, z=0), eye = dict ( x = x_eye , y = y_eye , z = z_eye ), ) fig . update_layout ( scene_camera = camera ) return fig compute_spectrum_high_res ( slice_index , lb = None , hb = None , annotations = None , force_xlim = False , plot = True , standardization = False , cache_flask = None ) This function returns the high-resolution spectrum of the requested slice between the two provided m/z boundaries lb and hb. If boundaries are not provided, it returns an empty spectrum. Parameters: Name Type Description Default slice_index int The slice index of the requested slice. required lb float The lower m/z boundary below which the spectrum to display must be cropped. Defaults to None. None hb float The higher m/z boundary below which the spectrum to display must be cropped. Defaults to None. None annotations list ( tuple ) A list of m/z boundaries (one for each lipid to annotate), corresponding to the position of colored box superimposed on the spectra. Defaults to None. None force_xlim bool If Truen the zoom level will be set to enclose lb and hb, although that may not be the tightest region to enclose the data. Defaults to False. False plot bool If False, only the plotting data (m/z and intensities arrays) will be returned. Defaults to True. True standardization bool If True, the displayed spectrum is standardized with MAIA when possible. False cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description Depending on the value of the boundaries, and the plot parameter, it may return a Plotly Figure containing an empty spectrum, or a spectrum between the two provided boundaries, or the corresponding data of such a spectrum. Source code in modules/figures.py 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 def compute_spectrum_high_res ( self , slice_index , lb = None , hb = None , annotations = None , force_xlim = False , plot = True , standardization = False , cache_flask = None , ): \"\"\"This function returns the high-resolution spectrum of the requested slice between the two provided m/z boundaries lb and hb. If boundaries are not provided, it returns an empty spectrum. Args: slice_index (int): The slice index of the requested slice. lb (float, optional): The lower m/z boundary below which the spectrum to display must be cropped. Defaults to None. hb (float, optional): The higher m/z boundary below which the spectrum to display must be cropped. Defaults to None. annotations (list(tuple), optional): A list of m/z boundaries (one for each lipid to annotate), corresponding to the position of colored box superimposed on the spectra. Defaults to None. force_xlim (bool, optional): If Truen the zoom level will be set to enclose lb and hb, although that may not be the tightest region to enclose the data. Defaults to False. plot (bool, optional): If False, only the plotting data (m/z and intensities arrays) will be returned. Defaults to True. standardization (bool, optional): If True, the displayed spectrum is standardized with MAIA when possible. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the value of the boundaries, and the plot parameter, it may return a Plotly Figure containing an empty spectrum, or a spectrum between the two provided boundaries, or the corresponding data of such a spectrum. \"\"\" # Define default values for graph (empty) if lb is None and hb is None : x = ([],) y = ([],) # If boundaries are provided, get their index else : index_lb , index_hb = compute_thread_safe_function ( compute_index_boundaries , cache_flask , self . _data , slice_index , lb , hb , array_spectra_avg = self . _data . get_array_avg_spectrum ( slice_index , standardization = standardization ), lookup_table = self . _data . get_array_lookup_mz_avg ( slice_index ), ) def return_x_y ( array ): x = np . copy ( array [ 0 , index_lb : index_hb ]) y = np . copy ( array [ 1 , index_lb : index_hb ]) return x , y # Get x, y in a thread safe fashion # No need to clean memory as it's really small x , y = compute_thread_safe_function ( return_x_y , cache_flask , self . _data , slice_index , self . _data . get_array_avg_spectrum ( slice_index , standardization = standardization ), ) # In case download without plotting if not plot : return x , y # Define figure data data = go . Scattergl ( x = x , y = y , visible = True , line_color = dic_colors [ \"blue\" ], fill = \"tozeroy\" ) # Define figure layout layout = go . Layout ( margin = dict ( t = 50 , r = 0 , b = 10 , l = 0 ), showlegend = False , xaxis = dict ( rangeslider = { \"visible\" : False }, title = \"m/z\" ), yaxis = dict ( fixedrange = True , title = \"Intensity\" ), template = \"plotly_dark\" , title = { \"text\" : \"High resolution spectrum (averaged across pixels)\" , \"y\" : 0.92 , \"x\" : 0.5 , \"xanchor\" : \"center\" , \"yanchor\" : \"top\" , \"font\" : dict ( size = 14 , ), }, paper_bgcolor = \"rgba(0,0,0,0.3)\" , plot_bgcolor = \"rgba(0,0,0,0.3)\" , ) # Build figure layout fig = go . Figure ( data = data , layout = layout ) # Annotate selected lipids with vertical bars if annotations is not None : for color , x in zip ([ \"red\" , \"green\" , \"blue\" ], annotations ): if x is not None : if x [ 0 ] >= lb and x [ - 1 ] <= hb : fig . add_vrect ( x0 = x [ 0 ], x1 = x [ 1 ], line_width = 0 , fillcolor = dic_colors [ color ], opacity = 0.4 ) # In case we don't want to zoom in too much on the selected lipid if force_xlim : fig . update_xaxes ( range = [ lb , hb ]) return fig compute_spectrum_low_res ( slice_index , annotations = None ) This function returns the full (low-resolution) spectrum of the requested slice. Parameters: Name Type Description Default slice_index int The slice index of the requested slice. required annotations list ( tuple ) A list of m/z boundaries (one for each lipid to annotate), corresponding to the position of colored box superimposed on the spectra. Defaults to None. None Returns: Type Description go . Figure A Plotly Figure representing the low-resolution spectrum. Source code in modules/figures.py 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 def compute_spectrum_low_res ( self , slice_index , annotations = None ): \"\"\"This function returns the full (low-resolution) spectrum of the requested slice. Args: slice_index (int): The slice index of the requested slice. annotations (list(tuple), optional): A list of m/z boundaries (one for each lipid to annotate), corresponding to the position of colored box superimposed on the spectra. Defaults to None. Returns: (go.Figure): A Plotly Figure representing the low-resolution spectrum. \"\"\" # Define figure data data = go . Scattergl ( x = self . _data . get_array_avg_spectrum_downsampled ( slice_index )[ 0 , :], y = self . _data . get_array_avg_spectrum_downsampled ( slice_index )[ 1 , :], visible = True , line_color = dic_colors [ \"blue\" ], fill = \"tozeroy\" , ) # Define figure layout layout = go . Layout ( margin = dict ( t = 50 , r = 0 , b = 10 , l = 0 ), showlegend = False , xaxis = dict ( rangeslider = { \"visible\" : False }, title = \"m/z\" ), yaxis = dict ( fixedrange = False , title = \"Intensity\" ), template = \"plotly_dark\" , autosize = True , title = { \"text\" : \"Low resolution spectrum (averaged across pixels)\" , \"y\" : 0.92 , \"x\" : 0.5 , \"xanchor\" : \"center\" , \"yanchor\" : \"top\" , \"font\" : dict ( size = 14 , ), }, paper_bgcolor = \"rgba(0,0,0,0.3)\" , plot_bgcolor = \"rgba(0,0,0,0.3)\" , ) # Build figure fig = go . Figure ( data = data , layout = layout ) # Annotate selected lipids with vertical bars if annotations is not None : for color , annot in zip ([ \"red\" , \"green\" , \"blue\" ], annotations ): if annot is not None : fig . add_vrect ( x0 = annot [ 0 ], x1 = annot [ 1 ], fillcolor = dic_colors [ color ], opacity = 0.4 , line_color = dic_colors [ color ], ) return fig compute_treemaps_figure ( maxdepth = 5 ) This function is used to generate a Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. Parameters: Name Type Description Default maxdepth int The depth of the treemap to generate. Defaults to 5. 5 Returns: Type Description Plotly . Figure A Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. Source code in modules/figures.py 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 def compute_treemaps_figure ( self , maxdepth = 5 ): \"\"\"This function is used to generate a Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. Args: maxdepth (int, optional): The depth of the treemap to generate. Defaults to 5. Returns: (Plotly.Figure): A Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. \"\"\" # Build treemaps from list of children and parents fig = px . treemap ( names = self . _atlas . l_nodes , parents = self . _atlas . l_parents , maxdepth = maxdepth ) # Improve layout fig . update_layout ( uniformtext = dict ( minsize = 15 ), margin = dict ( t = 30 , r = 0 , b = 10 , l = 0 ), ) fig . update_traces ( root_color = \"#1d3d5c\" ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" return fig get_array_of_annotations ( decrease_dimensionality_factor ) This function returns the array of annotations from the Allen Brain Atlas, subsampled to decrease the size of the output. Parameters: Name Type Description Default decrease_dimensionality_factor int An integer used for subsampling the array. The higher, the higher the subsampling. required Returns: Type Description np . ndarray A 3D array of annotation, in which structures are annotated with specific identifiers. Source code in modules/figures.py 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 def get_array_of_annotations ( self , decrease_dimensionality_factor ): \"\"\"This function returns the array of annotations from the Allen Brain Atlas, subsampled to decrease the size of the output. Args: decrease_dimensionality_factor (int): An integer used for subsampling the array. The higher, the higher the subsampling. Returns: (np.ndarray): A 3D array of annotation, in which structures are annotated with specific identifiers. \"\"\" # Get subsampled array of annotations array_annotation = np . array ( self . _atlas . bg_atlas . annotation [ :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , ], dtype = np . int32 , ) # Bug correction for the last slice array_annotation = np . concatenate ( ( array_annotation , np . zeros (( 1 , array_annotation . shape [ 1 ], array_annotation . shape [ 2 ])), ) ) return array_annotation get_surface ( slice_index , l_transform_parameters , array_projection , reduce_resolution_factor ) This function returns a Plotly Surface representing the requested slice in 3D. Parameters: Name Type Description Default slice_index int Index of the requested slice. required l_transform_parameters list(np.ndarray A list of tuples containing the parameters for the transformation of the slice coordinates from 2D to 3D and conversely. required array_projection np . ndarray The coordinates of the requested slice in 2D. required reduce_resolution_factor int Divides (reduce) the initial resolution of the data. Needed as the resulting figure can be very heavy. Defaults to 20. required Returns: Type Description go . Surface A Plotly Surface representing the requested slice in 3D. Source code in modules/figures.py 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 def get_surface ( self , slice_index , l_transform_parameters , array_projection , reduce_resolution_factor ): \"\"\"This function returns a Plotly Surface representing the requested slice in 3D. Args: slice_index (int): Index of the requested slice. l_transform_parameters (list(np.ndarray)): A list of tuples containing the parameters for the transformation of the slice coordinates from 2D to 3D and conversely. array_projection (np.ndarray): The coordinates of the requested slice in 2D. reduce_resolution_factor (int, optional): Divides (reduce) the initial resolution of the data. Needed as the resulting figure can be very heavy. Defaults to 20. Returns: (go.Surface): A Plotly Surface representing the requested slice in 3D. \"\"\" # Get the parameters for the transformation of the coordinats from 2D to 3D a , u , v = l_transform_parameters [ slice_index ] # Build 3 empty lists, which will contain the 3D coordinates of the requested slice ll_x = [] ll_y = [] ll_z = [] # Loop over the first 2D coordinate of the slice for i , lambd in enumerate ( range ( array_projection [ slice_index ] . shape [ 0 ])): l_x = [] l_y = [] l_z = [] # Loop over the second 2D coordinate of the slice for j , mu in enumerate ( range ( array_projection [ slice_index ] . shape [ 1 ])): # Get rescaled 3D coordinates x_atlas , y_atlas , z_atlas = ( np . array ( slice_to_atlas_transform ( a , u , v , lambd * reduce_resolution_factor , mu * reduce_resolution_factor ) ) * self . _atlas . resolution / 1000 ) l_x . append ( z_atlas ) l_y . append ( x_atlas ) l_z . append ( y_atlas ) # In case the 3D coordinate was not acquired, skip the current coordinate if l_x != []: ll_x . append ( l_x ) ll_y . append ( l_y ) ll_z . append ( l_z ) # Build a 3D surface from the 3D coordinates for the current slice surface = go . Surface ( z = np . array ( ll_z ), x = np . array ( ll_x ), y = np . array ( ll_y ), surfacecolor = array_projection [ slice_index ] . astype ( np . int32 ), cmin = 0 , cmax = 255 , colorscale = \"viridis\" , opacityscale = [[ 0 , 0 ], [ 0.1 , 1 ], [ 1 , 1 ]], showscale = False , ) return surface return_empty_spectrum () This function returns an empty spectrum, used to display when no spectrum is available. Returns: Type Description Plotly Figure A Plotly Figure representing an empty spectrum. Source code in modules/figures.py 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 def return_empty_spectrum ( self ): \"\"\"This function returns an empty spectrum, used to display when no spectrum is available. Returns: (Plotly Figure): A Plotly Figure representing an empty spectrum.\"\"\" # Define empty figure data data = ( go . Scattergl ( x = [], y = [], visible = True ),) # Define figure layout layout = go . Layout ( margin = dict ( t = 5 , r = 0 , b = 10 , l = 0 ), showlegend = True , xaxis = dict ( title = \"m/z\" ), yaxis = dict ( title = \"Intensity\" ), template = \"plotly_dark\" , ) # Build figure fig = go . Figure ( data = data , layout = layout ) # Transparent background fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" return fig return_heatmap_lipid ( fig = None ) This function is used to either generate a Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. Parameters: Name Type Description Default fig Plotly Figure A Plotly Figure whose layout must be completed. If None, a new figure will be generated. Defaults to None. None Returns: Type Description Plotly Figure A Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. Source code in modules/figures.py 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 def return_heatmap_lipid ( self , fig = None ): \"\"\"This function is used to either generate a Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. Args: fig (Plotly Figure, optional): A Plotly Figure whose layout must be completed. If None, a new figure will be generated. Defaults to None. Returns: (Plotly Figure): A Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. \"\"\" # Build empty figure if not provided if fig is None : fig = go . Figure ( data = go . Heatmap ( z = [[]], x = [], y = [], visible = False )) # Improve figure layout fig . update_layout ( margin = dict ( t = 25 , r = 0 , b = 10 , l = 0 ), template = \"plotly_dark\" , font_size = 8 , ) # Transparent background fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" # Dark Template fig . layout . template = \"plotly_dark\" return fig shelve_all_arrays_annotation () This functions precomputes and shelves the array of structure annotation used in a 3D representation of the brain (through self.compute_3D_volume_figure()), at different resolutions. Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Source code in modules/figures.py 2792 2793 2794 2795 2796 2797 2798 2799 2800 2801 2802 2803 2804 2805 2806 2807 2808 def shelve_all_arrays_annotation ( self ): \"\"\"This functions precomputes and shelves the array of structure annotation used in a 3D representation of the brain (through self.compute_3D_volume_figure()), at different resolutions. Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. \"\"\" for decrease_dimensionality_factor in range ( 2 , 13 ): self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_annotation\" , force_update = False , compute_function = self . get_array_of_annotations , decrease_dimensionality_factor = decrease_dimensionality_factor , ) # Variable to signal everything has been computed self . _storage . dump_shelved_object ( \"figures/3D_page\" , \"arrays_annotation_computed\" , True ) shelve_all_l_array_2D ( force_update = False , sample = False , brain_1 = True ) This functions precomputes and shelves all the arrays of lipid expression used in a 3D representation of the brain (through self.compute_3D_volume_figure()). Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Parameters: Name Type Description Default force_update bool If True, the function will not overwrite existing files. Defaults to False. False sample bool If True, only a fraction of the precomputations are made (for debug). Default to False. False brain_1 bool If True, the data is precomputed for the brain 1. Else for the brain 2. Defaults to True. True Source code in modules/figures.py 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713 2714 2715 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727 2728 2729 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741 2742 2743 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755 2756 2757 2758 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769 2770 2771 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783 2784 2785 2786 2787 2788 2789 2790 def shelve_all_l_array_2D ( self , force_update = False , sample = False , brain_1 = True ): \"\"\"This functions precomputes and shelves all the arrays of lipid expression used in a 3D representation of the brain (through self.compute_3D_volume_figure()). Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Args: force_update (bool, optional): If True, the function will not overwrite existing files. Defaults to False. sample (bool, optional): If True, only a fraction of the precomputations are made (for debug). Default to False. brain_1 (bool, optional): If True, the data is precomputed for the brain 1. Else for the brain 2. Defaults to True. \"\"\" # Count number of lipids processed for sampling n_processed = 0 if sample : logging . warning ( \"Only a sample of the lipid arrays will be computed!\" ) # Simulate a click on all lipid names df_annotations_MAIA = self . _data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 ) for name in sorted ( df_annotations_MAIA . name . unique ()): structures = df_annotations_MAIA [ df_annotations_MAIA [ \"name\" ] == name ] . structure . unique () for structure in sorted ( structures ): cations = df_annotations_MAIA [ ( df_annotations_MAIA [ \"name\" ] == name ) & ( df_annotations_MAIA [ \"structure\" ] == structure ) ] . cation . unique () for cation in sorted ( cations ): l_selected_lipids = [] for slice_index in self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ): # Find lipid location l_lipid_loc = ( self . _data . get_annotations () . index [ ( self . _data . get_annotations ()[ \"name\" ] == name ) & ( self . _data . get_annotations ()[ \"structure\" ] == structure ) & ( self . _data . get_annotations ()[ \"slice\" ] == slice_index ) & ( self . _data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) > 1 : logging . warning ( \"More than one lipid corresponds to the selection\" ) l_lipid_loc = [ l_lipid_loc [ - 1 ]] # If no lipid correspond to the selection, set to -1 if len ( l_lipid_loc ) == 0 : l_lipid_loc = [ - 1 ] # add lipid index for each slice l_selected_lipids . append ( l_lipid_loc [ 0 ]) # Get final lipid name lipid_string = name + \" \" + structure + \" \" + cation # If lipid is present in at least one slice if np . sum ( l_selected_lipids ) > - len ( self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ) ): # Build the list of mz boundaries for each peak and each index lll_lipid_bounds = [ [ [ ( float ( self . _data . get_annotations () . iloc [ index ][ \"min\" ]), float ( self . _data . get_annotations () . iloc [ index ][ \"max\" ]), ) ] if index != - 1 else None for index in [ lipid_1_index , - 1 , - 1 ] ] for lipid_1_index in l_selected_lipids ] # Compute 3D figures, selection is limited to one lipid name_lipid = lipid_string self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_expression_\" + str ( brain_1 ) + \"_\" + name_lipid + \"__\" , force_update = force_update , compute_function = self . compute_l_array_2D , ignore_arguments_naming = True , ll_t_bounds = lll_lipid_bounds , brain_1 = brain_1 , cache_flask = None , # No cache needed since launched at startup ) n_processed += 1 if n_processed >= 10 and sample : return None # Variable to signal everything has been computed self . _storage . dump_shelved_object ( \"figures/3D_page\" , \"arrays_expression_\" + str ( brain_1 ) + \"_computed\" , True ) shelve_arrays_basic_figures ( force_update = False ) This function shelves in the database all the arrays of basic images computed in self.compute_figure_basic_image(), across all slices and all types of arrays. This forces the precomputations of these arrays, and allows to access them faster. Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Parameters: Name Type Description Default force_update bool If True, the function will not overwrite existing files. Defaults to False. False Source code in modules/figures.py 2658 2659 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671 2672 2673 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685 2686 2687 def shelve_arrays_basic_figures ( self , force_update = False ): \"\"\"This function shelves in the database all the arrays of basic images computed in self.compute_figure_basic_image(), across all slices and all types of arrays. This forces the precomputations of these arrays, and allows to access them faster. Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Args: force_update (bool, optional): If True, the function will not overwrite existing files. Defaults to False. \"\"\" for idx_slice in range ( self . _data . get_slice_number ()): for type_figure in [ \"original_data\" , \"warped_data\" , \"projection_corrected\" , \"atlas\" ]: for display_annotations in [ True , False ]: # Force no annotation for the original data self . _storage . return_shelved_object ( \"figures/load_page\" , \"figure_basic_image\" , force_update = force_update , compute_function = self . compute_figure_basic_image , type_figure = type_figure , index_image = idx_slice , plot_atlas_contours = display_annotations if type_figure != \"original_data\" else False , ) self . _storage . dump_shelved_object ( \"figures/load_page\" , \"arrays_basic_figures_computed\" , True )","title":"figures"},{"location":"modules/figures/#modules.figures.Figures","text":"This class is used to produce the figures and widgets used in the app. It uses the special attribute slots for faster access to the attributes. Parameters are ignored in the docstring of the listed methods below to save space. Please consult the docstring of the actual methods in the source-code for more information: Attributes: Name Type Description _data MaldiData MaldiData object, used to manipulate the raw MALDI data. _storage Storage Used to access the shelve database. _atlas Atlas Used to manipulate the objects coming from the Allen Brain Atlas. _scRNAseq ScRNAseq Used to manipulate the objects coming from the scRNAseq dataset. dic_normalization_factors dict Dictionnary of normalization factors across slices for MAIA. Methods init (): Initialize the Figures class. compute_array_basic_images(): Computes a three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. compute_figure_basic_image(): Computes a figure representing slices from the TIC or the corresponding image from the atlas. compute_figure_slices_3D(): Computes a figure representing all slices from the maldi data in 3D. get_surface(): Computes a Plotly Surface representing the requested slice in 3D. compute_image_per_lipid(): Allows to query the MALDI data to extract an image representing the intensity of each lipid in the requested slice. compute_normalization_factor_across_slices(): Computes a dictionnary of normalization factors across all slices. build_lipid_heatmap_from_image(): Converts a numpy array into a base64 string, a go.Image, or a Plotly Figure. compute_heatmap_per_mz(): Computes a heatmap of the lipid expressed in the requested slice whose m/z is between the two provided boundaries. compute_heatmap_per_lipid_selection(): Computes a heatmap of the sum of expression of the requested lipids in the requested slice. compute_rgb_array_per_lipid_selection(): Computes a numpy RGB array of expression of the requested lipids in the requested slice. compute_rgb_image_per_lipid_selection(): Similar to compute_heatmap_per_lipid_selection, but computes an RGB image instead of a heatmap. compute_spectrum_low_res(): Returns the full (low-resolution) spectrum of the requested slice. compute_spectrum_high_res(): Returns the full (high-resolution) spectrum of the requested slice between the two provided m/z boundaries. return_empty_spectrum(): Returns an empty spectrum. return_heatmap_lipid(): Either generate a Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. compute_treemaps_figure(): Generates a Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. compute_3D_root_volume(): Generate a go.Isosurface of the Allen Brain root structure, which will be used to enclose the display of lipid expression of other structures in the brain. get_array_of_annotations(): Returns the array of annotations from the Allen Brain Atlas, subsampled to decrease the size of the output. compute_l_array_2D(): Gets the list of expression per slice for all slices for the computation of the 3D brain volume. compute_array_coordinates_3D(): Computes the list of coordinates and expression values for the voxels used in the 3D representation of the brain. compute_3D_volume_figure(): Computes a Plotly Figure containing a go.Volume object representing the expression of the requested lipids in the selected regions. compute_clustergram_figure(): Computes a Plotly Clustergram figure, allowing to cluster and compare the expression of all the MAIA-transformed lipids in the dataset in the selected regions. compute_scatter_3D(): cmputes a figure representing, in a 3D scatter plot, the spots acquired using spatial scRNAseq experiments. compute_barplots_enrichment(): Computes two figures representing, in barplots, the lipid expression in the spots acquired using spatial scRNAseq experiments, as well as how it can be explained by an elastic net regression using gene expression as explaing factors. compute_heatmap_lipid_genes(): Computes a heatmap representing the expression of a given lipid in the MALDI data and the expressions of the selected genes. shelve_arrays_basic_figures(): Shelves in the database all the arrays of basic images computed in compute_figure_basic_image(), across all slices and all types of arrays. shelve_all_l_array_2D(): Precomputes and shelves all the arrays of lipid expression used in a 3D representation of the brain. shelve_all_arrays_annotation(): Precomputes and shelves the array of structure annotation used in a 3D representation of the brain. Source code in modules/figures.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 2599 2600 2601 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 2645 2646 2647 2648 2649 2650 2651 2652 2653 2654 2655 2656 2657 2658 2659 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671 2672 2673 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685 2686 2687 2688 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713 2714 2715 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727 2728 2729 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741 2742 2743 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755 2756 2757 2758 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769 2770 2771 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783 2784 2785 2786 2787 2788 2789 2790 2791 2792 2793 2794 2795 2796 2797 2798 2799 2800 2801 2802 2803 2804 2805 2806 2807 2808 class Figures : \"\"\"This class is used to produce the figures and widgets used in the app. It uses the special attribute __slots__ for faster access to the attributes. Parameters are ignored in the docstring of the listed methods below to save space. Please consult the docstring of the actual methods in the source-code for more information: Attributes: _data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. _storage (Storage): Used to access the shelve database. _atlas (Atlas): Used to manipulate the objects coming from the Allen Brain Atlas. _scRNAseq (ScRNAseq): Used to manipulate the objects coming from the scRNAseq dataset. dic_normalization_factors (dict): Dictionnary of normalization factors across slices for MAIA. Methods: __init__(): Initialize the Figures class. compute_array_basic_images(): Computes a three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. compute_figure_basic_image(): Computes a figure representing slices from the TIC or the corresponding image from the atlas. compute_figure_slices_3D(): Computes a figure representing all slices from the maldi data in 3D. get_surface(): Computes a Plotly Surface representing the requested slice in 3D. compute_image_per_lipid(): Allows to query the MALDI data to extract an image representing the intensity of each lipid in the requested slice. compute_normalization_factor_across_slices(): Computes a dictionnary of normalization factors across all slices. build_lipid_heatmap_from_image(): Converts a numpy array into a base64 string, a go.Image, or a Plotly Figure. compute_heatmap_per_mz(): Computes a heatmap of the lipid expressed in the requested slice whose m/z is between the two provided boundaries. compute_heatmap_per_lipid_selection(): Computes a heatmap of the sum of expression of the requested lipids in the requested slice. compute_rgb_array_per_lipid_selection(): Computes a numpy RGB array of expression of the requested lipids in the requested slice. compute_rgb_image_per_lipid_selection(): Similar to compute_heatmap_per_lipid_selection, but computes an RGB image instead of a heatmap. compute_spectrum_low_res(): Returns the full (low-resolution) spectrum of the requested slice. compute_spectrum_high_res(): Returns the full (high-resolution) spectrum of the requested slice between the two provided m/z boundaries. return_empty_spectrum(): Returns an empty spectrum. return_heatmap_lipid(): Either generate a Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. compute_treemaps_figure(): Generates a Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. compute_3D_root_volume(): Generate a go.Isosurface of the Allen Brain root structure, which will be used to enclose the display of lipid expression of other structures in the brain. get_array_of_annotations(): Returns the array of annotations from the Allen Brain Atlas, subsampled to decrease the size of the output. compute_l_array_2D(): Gets the list of expression per slice for all slices for the computation of the 3D brain volume. compute_array_coordinates_3D(): Computes the list of coordinates and expression values for the voxels used in the 3D representation of the brain. compute_3D_volume_figure(): Computes a Plotly Figure containing a go.Volume object representing the expression of the requested lipids in the selected regions. compute_clustergram_figure(): Computes a Plotly Clustergram figure, allowing to cluster and compare the expression of all the MAIA-transformed lipids in the dataset in the selected regions. compute_scatter_3D(): cmputes a figure representing, in a 3D scatter plot, the spots acquired using spatial scRNAseq experiments. compute_barplots_enrichment(): Computes two figures representing, in barplots, the lipid expression in the spots acquired using spatial scRNAseq experiments, as well as how it can be explained by an elastic net regression using gene expression as explaing factors. compute_heatmap_lipid_genes(): Computes a heatmap representing the expression of a given lipid in the MALDI data and the expressions of the selected genes. shelve_arrays_basic_figures(): Shelves in the database all the arrays of basic images computed in compute_figure_basic_image(), across all slices and all types of arrays. shelve_all_l_array_2D(): Precomputes and shelves all the arrays of lipid expression used in a 3D representation of the brain. shelve_all_arrays_annotation(): Precomputes and shelves the array of structure annotation used in a 3D representation of the brain. \"\"\" __slots__ = [ \"_data\" , \"_atlas\" , \"_scRNAseq\" , \"_storage\" , \"dic_normalization_factors\" ] # ============================================================================================== # --- Constructor # ============================================================================================== def __init__ ( self , maldi_data , storage , atlas , scRNAseq , sample = False ): \"\"\"Initialize the Figures class. Args: maldi_data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. storage (Storage): Used to access the shelve database. atlas (Atlas): Used to manipulate the objects coming from the Allen Brain Atlas. scRNAseq (ScRNAseq): Used to manipulate the objects coming from the scRNAseq dataset. sample (bool, optional): If True, only a fraction of the precomputations are made (for debug). Default to False. \"\"\" logging . info ( \"Initializing Figures object\" + logmem ()) # Attribute to easily access the maldi and allen brain atlas data self . _data = maldi_data self . _atlas = atlas self . _scRNAseq = scRNAseq # attribute to access the shelve database self . _storage = storage # Dic of normalization factors across slices for MAIA normalized lipids self . dic_normalization_factors = self . _storage . return_shelved_object ( \"figures/lipid_selection\" , \"dic_normalization_factors\" , force_update = False , compute_function = self . compute_normalization_factor_across_slices , cache_flask = None , # No cache since launched at startup ) # Check that treemaps has been computed already. If not, compute it and store it. if not self . _storage . check_shelved_object ( \"figures/atlas_page/3D\" , \"treemaps\" ): self . _storage . return_shelved_object ( \"figures/atlas_page/3D\" , \"treemaps\" , force_update = False , compute_function = self . compute_treemaps_figure , ), # Check that 3D slice figures have been computed already. If not, compute it and store it. for brain in [ \"brain_1\" , \"brain_2\" ]: if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"slices_3D_\" + brain ): self . _storage . return_shelved_object ( \"figures/3D_page\" , \"slices_3D\" , force_update = False , compute_function = self . compute_figure_slices_3D , brain = brain , ) # Check that the 3D root volume figure has been computed already. If not, compute it and # store it. if self . _storage . check_shelved_object ( \"figures/scRNAseq_page\" , \"scatter3D\" ): self . _storage . return_shelved_object ( \"figures/scRNAseq_page\" , \"scatter3D\" , force_update = False , compute_function = self . compute_scatter_3D , ) # Check that the 3D scatter plot for scRNAseq data has been computed already. If not, # compute it and store it. if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"volume_root\" ): self . _storage . return_shelved_object ( \"figures/3D_page\" , \"volume_root\" , force_update = False , compute_function = self . compute_3D_root_volume , ) # Check that the base figures for lipid/genes heatmap have been computed already. If not, # compute them and store them. if not self . _storage . check_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid_True\" ) or not self . _storage . check_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid_False\" ): self . _storage . return_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid\" , force_update = False , compute_function = self . compute_heatmap_lipid_genes , brain_1 = False , ), self . _storage . return_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid\" , force_update = False , compute_function = self . compute_heatmap_lipid_genes , brain_1 = True , ), # Check that all basic figures in the load_slice page are present, if not, compute them if not self . _storage . check_shelved_object ( \"figures/load_page\" , \"arrays_basic_figures_computed\" ): self . shelve_arrays_basic_figures () # Check that the lipid distributions for all slices, and both brains, have been computed, if # not, compute them if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"arrays_expression_True_computed\" ): self . shelve_all_l_array_2D ( sample = sample , brain_1 = True ) if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"arrays_expression_False_computed\" ): self . shelve_all_l_array_2D ( sample = sample , brain_1 = False ) # Check that all arrays of annotations have been computed, if not, compute them if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"arrays_annotation_computed\" ): self . shelve_all_arrays_annotation () logging . info ( \"Figures object instantiated\" + logmem ()) # ============================================================================================== # --- Methods used mainly in load_slice # ============================================================================================== def compute_array_basic_images ( self , type_figure = \"warped_data\" ): \"\"\"This function computes and returns a three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. No spectral data is read in the process, as the arrays corresponding to the images are directly stored as tiff files in the dataset. Args: type_figure (str, optional): To be chosen among \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\". Depending on the chosen type, the final array will correspond to either the original images (\"original_data\"), the warped and upscaled images (\"warped_data\"), the warped and upscaled images, whose pixels outside of annotations regions have been zero-ed out (\"projection_corrected\"), or the images from the Allen Brain atlas projected onto the same plane as the corresponding slice from the MALDI data (\"atlas\"). Default to \"warped_data\". Returns: (np.ndarray): A three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. The first dimension corresponds to the slices, the second and third to the images themselves. \"\"\" # Check for all array types if type_figure == \"original_data\" : array_images = self . _data . compute_padded_original_images () elif type_figure == \"warped_data\" : if self . _data . _sample_data : with np . load ( \"data_sample/tiff_files/warped_data.npz\" ) as handle : array_images = handle [ \"array_warped_data\" ] else : array_images = io . imread ( \"data/tiff_files/warped_data.tif\" ) elif type_figure == \"projection_corrected\" : array_images = self . _atlas . array_projection_corrected elif type_figure == \"atlas\" : ( array_projected_images_atlas , array_projected_simplified_id , ) = self . _storage . return_shelved_object ( \"atlas/atlas_objects\" , \"array_images_atlas\" , force_update = False , compute_function = self . _atlas . prepare_and_compute_array_images_atlas , zero_out_of_annotation = True , ) array_images = array_projected_images_atlas else : logging . warning ( 'The type of requested array \" {} \" does not exist.' . format ( type_figure )) return None # If the array is not uint8, convert it to gain space if array_images . dtype != np . uint8 : array_images = np . array ( array_images , dtype = np . uint8 ) return array_images def compute_figure_basic_image ( self , type_figure , index_image , plot_atlas_contours = True , only_contours = False , draw = False ): \"\"\"This function computes and returns a figure representing slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. The data is read directly from the array computed in self.compute_array_basic_images(). Args: type_figure (str): To be chosen among \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\". Depending on the chosen type, the final figure will correspond to either the original images (\"original_data\"), the warped and upscaled images (\"warped_data\"), the warped and upscaled images, whose pixels outside of annotations regions have been zero-ed out (\"projection_corrected\"), or the images from the Allen Brain atlas projected onto the same plane as the corresponding slice from the MALDI data (\"atlas\"). index_image (int): Index of the requested slice image. plot_atlas_contours (bool, optional): If True, the atlas contours annotation is superimposed with the slice image. Defaults to True. only_contours (bool, optional): If True, only output the atlas contours annotation. All the other arugments but plot_atlas_contours (which must be True) get ignored. Defaults to False. draw (bool, optional): If True, the figure can be drawed on (used for region selection, in page region_analysis). Defaults to False. Returns: (go.Figure): A Plotly figure representing the requested slice image of the requested type. \"\"\" # If only boundaries is requested, force the computation of atlas contours if only_contours : plot_atlas_contours = True else : # Get array of images array_images = self . _storage . return_shelved_object ( \"figures/load_page\" , \"array_basic_images\" , force_update = False , compute_function = self . compute_array_basic_images , type_figure = type_figure , ) # Get image at specified index array_image = array_images [ index_image ] # Add the contours if requested if plot_atlas_contours : array_image_atlas = self . _atlas . list_projected_atlas_borders_arrays [ index_image ] else : array_image_atlas = None # Create figure fig = go . Figure () # Compute image from our data if not only the atlas annotations are requested if not only_contours : fig . add_trace ( go . Image ( visible = True , source = convert_image_to_base64 ( array_image , overlay = array_image_atlas , transparent_zeros = True ), hoverinfo = \"none\" , ) ) # Add the labels only if it's not a simple annotation illustration # fig.update_xaxes( # title_text=self._atlas.bg_atlas.space.axis_labels[0][1], title_standoff=0 # ) else : fig . add_trace ( go . Image ( visible = True , source = convert_image_to_base64 ( array_image_atlas , optimize = True , binary = True , type = \"RGBA\" , decrease_resolution_factor = 8 , ), hoverinfo = \"none\" , ) ) # Improve layout fig . update_xaxes ( showticklabels = False ) fig . update_yaxes ( showticklabels = False ) fig . update_layout ( margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), xaxis = dict ( showgrid = False , zeroline = False ), yaxis = dict ( showgrid = False , zeroline = False ), template = \"plotly_dark\" , paper_bgcolor = \"rgba(0,0,0,0)\" , plot_bgcolor = \"rgba(0,0,0,0)\" , ) if draw : fig . update_layout ( dragmode = \"drawclosedpath\" , newshape = dict ( fillcolor = l_colors [ 0 ], opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ) ), autosize = True , ) return fig def compute_figure_slices_3D ( self , reduce_resolution_factor = 20 , brain = \"brain_1\" ): \"\"\"This function computes and returns a figure representing the slices from the maldi data in 3D. Args: reduce_resolution_factor (int, optional): Divides (reduce) the initial resolution of the data. Needed as the resulting figure can be very heavy. Defaults to 20. brain (str, optional): Name of the brain to be used. Defaults to 'brain_1'. Returns: (go.Figure): A Plotly figure representing the slices from the MALDI acquisitions in 3D. \"\"\" # Get transform parameters (a,u,v) for each slice l_transform_parameters = self . _storage . return_shelved_object ( \"atlas/atlas_objects\" , \"l_transform_parameters\" , force_update = False , compute_function = self . _atlas . compute_projection_parameters , ) # Reduce resolution of the slices new_dims = [] n_slices = self . _atlas . array_coordinates_warped_data . shape [ 0 ] d1 = self . _atlas . array_coordinates_warped_data . shape [ 1 ] d2 = self . _atlas . array_coordinates_warped_data . shape [ 2 ] for original_length , new_length in zip ( self . _atlas . array_projection_corrected . shape , ( n_slices , int ( round ( d1 / reduce_resolution_factor )), int ( round ( d2 / reduce_resolution_factor )), ), ): new_dims . append ( np . linspace ( 0 , original_length - 1 , new_length )) coords = np . meshgrid ( * new_dims , indexing = \"ij\" ) array_projection_small = map_coordinates ( self . _atlas . array_projection_corrected , coords ) # Build Figure, with several frames as it will be slidable fig = go . Figure ( frames = [ go . Frame ( data = self . get_surface ( slice_index - 1 , l_transform_parameters , array_projection_small , reduce_resolution_factor , ), name = str ( i + 1 ), ) for i , slice_index in enumerate ( self . _data . get_slice_list ( brain )) ] ) fig . add_trace ( self . get_surface ( self . _data . get_slice_list ( brain )[ 0 ] - 1 , l_transform_parameters , array_projection_small , reduce_resolution_factor , ) ) # Add a slider def frame_args ( duration ): return { \"frame\" : { \"duration\" : duration }, \"mode\" : \"immediate\" , \"fromcurrent\" : True , \"transition\" : { \"duration\" : duration , \"easing\" : \"linear\" }, } sliders = [ { \"pad\" : { \"b\" : 5 , \"t\" : 10 }, \"len\" : 0.9 , \"x\" : 0.05 , \"y\" : 0 , \"steps\" : [ { \"args\" : [[ f . name ], frame_args ( 0 )], \"label\" : str ( k ), \"method\" : \"animate\" , } for k , f in enumerate ( fig . frames ) ], \"currentvalue\" : { \"visible\" : False , }, } ] # Layout fig . update_layout ( scene = dict ( aspectratio = dict ( x = 1.5 , y = 1 , z = 1 ), yaxis = dict ( range = [ 0.0 , 0.35 ], autorange = False , backgroundcolor = \"rgba(0,0,0,0)\" , color = \"grey\" , gridcolor = \"grey\" , ), zaxis = dict ( range = [ 0.2 , - 0.02 ], autorange = False , backgroundcolor = \"rgba(0,0,0,0)\" , color = \"grey\" , gridcolor = \"grey\" , ), xaxis = dict ( range = [ 0.0 , 0.35 ], autorange = False , backgroundcolor = \"rgba(0,0,0,0)\" , color = \"grey\" , gridcolor = \"grey\" , ), ), margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), template = \"plotly_dark\" , sliders = sliders , ) # No display of tick labels as they're wrong anyway fig . update_layout ( scene = dict ( xaxis = dict ( showticklabels = False ), yaxis = dict ( showticklabels = False ), zaxis = dict ( showticklabels = False ), ), paper_bgcolor = \"rgba(0,0,0,0.)\" , plot_bgcolor = \"rgba(0,0,0,0.)\" , ) return fig # Part of this function could probably be compiled with numba with some effort, but there's no # need as it's precomupted in a reasonable time anyway. def get_surface ( self , slice_index , l_transform_parameters , array_projection , reduce_resolution_factor ): \"\"\"This function returns a Plotly Surface representing the requested slice in 3D. Args: slice_index (int): Index of the requested slice. l_transform_parameters (list(np.ndarray)): A list of tuples containing the parameters for the transformation of the slice coordinates from 2D to 3D and conversely. array_projection (np.ndarray): The coordinates of the requested slice in 2D. reduce_resolution_factor (int, optional): Divides (reduce) the initial resolution of the data. Needed as the resulting figure can be very heavy. Defaults to 20. Returns: (go.Surface): A Plotly Surface representing the requested slice in 3D. \"\"\" # Get the parameters for the transformation of the coordinats from 2D to 3D a , u , v = l_transform_parameters [ slice_index ] # Build 3 empty lists, which will contain the 3D coordinates of the requested slice ll_x = [] ll_y = [] ll_z = [] # Loop over the first 2D coordinate of the slice for i , lambd in enumerate ( range ( array_projection [ slice_index ] . shape [ 0 ])): l_x = [] l_y = [] l_z = [] # Loop over the second 2D coordinate of the slice for j , mu in enumerate ( range ( array_projection [ slice_index ] . shape [ 1 ])): # Get rescaled 3D coordinates x_atlas , y_atlas , z_atlas = ( np . array ( slice_to_atlas_transform ( a , u , v , lambd * reduce_resolution_factor , mu * reduce_resolution_factor ) ) * self . _atlas . resolution / 1000 ) l_x . append ( z_atlas ) l_y . append ( x_atlas ) l_z . append ( y_atlas ) # In case the 3D coordinate was not acquired, skip the current coordinate if l_x != []: ll_x . append ( l_x ) ll_y . append ( l_y ) ll_z . append ( l_z ) # Build a 3D surface from the 3D coordinates for the current slice surface = go . Surface ( z = np . array ( ll_z ), x = np . array ( ll_x ), y = np . array ( ll_y ), surfacecolor = array_projection [ slice_index ] . astype ( np . int32 ), cmin = 0 , cmax = 255 , colorscale = \"viridis\" , opacityscale = [[ 0 , 0 ], [ 0.1 , 1 ], [ 1 , 1 ]], showscale = False , ) return surface # ============================================================================================== # --- Methods used mainly in lipid_selection # ============================================================================================== def compute_image_per_lipid ( self , slice_index , lb_mz , hb_mz , RGB_format = True , normalize = True , log = False , projected_image = True , apply_transform = False , lipid_name = \"\" , cache_flask = None , ): \"\"\"This function allows to query the MALDI data to extract an image in the form of a Numpy array representing the intensity of the lipid peaking between the values lb_mz and hb_mz in the spectral data, for the slice slice_index. Args: slice_index (int): Index of the requested slice. lb_mz (float): Lower boundary for the spectral data to query. hb_mz (float): Higher boundary for the spectral data to query. RGB_format (bool, optional): If True, the values in the array are between 0 and 255, given that the data has been normalized beforehand. Else, between 0 and 1. This parameter only makes sense if the data has been normalized beforehand. Defaults to True. normalize (bool, optional): If True, and the lipid has been MAIA transformed (and is provided with the parameter lipid_name) and apply_transform is True, the resulting array is normalized according to a factor computed across all slice. If MAIA has not been applied to the current selection or apply_transform is False, it is normalized according to the 99th percentile. Else, it is not normalized. Defaults to True. log (bool, optional): If True, the resulting array is log-transformed. This is useful in case of low expression. Defaults to False. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. lipid_name (str, optional): Name of the lipid that must be MAIA-transformed, if apply_transform and normalize are True. Defaults to \"\". cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (np.ndarray): An image (in the form of a numpy array) representing the intensity of the lipid peaking between the values lb_mz and hb_mz in the spectral data, for the slice slice_index. \"\"\" logging . info ( \"Entering compute_image_per_lipid\" ) # Get image from raw mass spec data image = compute_thread_safe_function ( compute_image_using_index_and_image_lookup , cache_flask , self . _data , slice_index , lb_mz , hb_mz , self . _data . get_array_spectra ( slice_index ), self . _data . get_array_lookup_pixels ( slice_index ), self . _data . get_image_shape ( slice_index ), self . _data . get_array_lookup_mz ( slice_index ), self . _data . get_array_cumulated_lookup_mz_image ( slice_index ), self . _data . get_divider_lookup ( slice_index ), self . _data . get_array_peaks_transformed_lipids ( slice_index ), self . _data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), apply_transform = apply_transform , ) # Log-transform the image if requested if log : image = np . log ( image + 1 ) # In case of bug, return None if image is None : return None # Normalize the image if requested if normalize : # Normalize across slice if the lipid has been MAIA transformed if ( lipid_name , self . _data . is_brain_1 ( slice_index ), ) in self . dic_normalization_factors and apply_transform : perc = self . dic_normalization_factors [ ( lipid_name , self . _data . is_brain_1 ( slice_index )) ] logging . info ( \"Normalization made with respect to percentile computed across all slices.\" ) else : # Normalize by 99 percentile perc = np . percentile ( image , 99.0 ) if perc == 0 : perc = np . max ( image ) if perc == 0 : perc = 1 image = image / perc image = np . clip ( 0 , 1 , image ) # Turn to RGB format if requested if RGB_format : image *= 255 # Change dtype if normalized and RGB to save space if normalize and RGB_format : image = np . round ( image ) . astype ( np . uint8 ) # Project image into cleaned and higher resolution version if projected_image : image = project_image ( slice_index , image , self . _atlas . array_projection_correspondence_corrected ) return image def compute_normalization_factor_across_slices ( self , cache_flask = None ): \"\"\"This function computes a dictionnary of normalization factors (used for MAIA-transformed lipids) across all slices (99th percentile of expression). Args: cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (dict): A dictionnary associating, for each MAIA-transformed lipid name, the 99th percentile of the intensity across all slices. \"\"\" logging . info ( \"Compute normalization factor across slices for MAIA transformed lipids...\" + \" It may takes a while\" ) # Dictionnnary that will contain the percentile across all slices of a given brain dic_max_percentile = {} # Function to compute the percentile across all slices def _compute_percentile_across_slices ( name , structure , cation , brain_1 ): max_perc = 0 lipid_string = \"\" for slice_index in self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ): # Find lipid location l_lipid_loc = ( self . _data . get_annotations () . index [ ( self . _data . get_annotations ()[ \"name\" ] == name ) & ( self . _data . get_annotations ()[ \"structure\" ] == structure ) & ( self . _data . get_annotations ()[ \"slice\" ] == slice_index ) & ( self . _data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) >= 1 : index = l_lipid_loc [ - 1 ] # get final lipid name lipid_string = name + \"_\" + structure + \"_\" + cation # get lipid bounds lb_mz = float ( self . _data . get_annotations () . iloc [ index ][ \"min\" ]) hb_mz = float ( self . _data . get_annotations () . iloc [ index ][ \"max\" ]) # Get corresponding image image = compute_thread_safe_function ( compute_image_using_index_and_image_lookup , cache_flask , self . _data , slice_index , lb_mz , hb_mz , self . _data . get_array_spectra ( slice_index ), self . _data . get_array_lookup_pixels ( slice_index ), self . _data . get_image_shape ( slice_index ), self . _data . get_array_lookup_mz ( slice_index ), self . _data . get_array_cumulated_lookup_mz_image ( slice_index ), self . _data . get_divider_lookup ( slice_index ), self . _data . get_array_peaks_transformed_lipids ( slice_index ), self . _data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), apply_transform = False , ) # Check 99th percentile for normalization perc = np . percentile ( image , 99.0 ) # perc must be quite small in theory... otherwise it's a bug if perc > max_perc : # and perc<1: max_perc = perc return max_perc , lipid_string # Simulate a click on all MAIA transformed lipids for brain_1 in [ True , False ]: for ( index , ( name , structure , cation , mz ), ) in self . _data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 ) . iterrows (): max_perc , lipid_string = _compute_percentile_across_slices ( name , structure , cation , brain_1 ) # Store max percentile across slices dic_max_percentile [( lipid_string , brain_1 )] = max_perc return dic_max_percentile def build_lipid_heatmap_from_image ( self , image , return_base64_string = False , draw = False , type_image = None , return_go_image = False , ): \"\"\"This function converts a numpy array into a base64 string, which can be returned directly, or itself be turned into a go.Image, which can be returned directly, or be turned into a Plotly Figure, which will be returned. Args: image (np.ndarray): A numpy array representing the image to be converted. Possibly with several channels. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. draw (bool, optional): If True, the user will have the possibility to draw on the resulting Plotly Figure. Defaults to False. type_image (string, optional): The type of the image to be converted to a base64 string. If image_array is in 3D, type must be RGB. If 4D, type must be RGBA. Else, no requirement (None). Defaults to None. return_go_image (bool, optional): If True, the go.Image is returned directly, before being integrated to a Plotly Figure. Defaults to False. Returns: Depending on the inputted arguments, may either return a base64 string, a go.Image, or a Plotly Figure. \"\"\" logging . info ( \"Converting image to string\" ) # Set optimize to False to gain computation time base64_string = convert_image_to_base64 ( image , type = type_image , overlay = None , transparent_zeros = True , optimize = False ) # Either return image directly if return_base64_string : return base64_string # Or compute heatmap as go image if needed logging . info ( \"Converting image to go image\" ) final_image = go . Image ( visible = True , source = base64_string , ) # Potentially return the go image directly if return_go_image : return final_image # Or build ploty graph fig = go . Figure ( final_image ) # Improve graph layout fig . update_layout ( margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), newshape = dict ( fillcolor = dic_colors [ \"blue\" ], opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ) ), xaxis = dict ( showgrid = False , zeroline = False ), yaxis = dict ( showgrid = False , zeroline = False ), # Do not specify height for now as plotly is buggued and resets if switching pages # height=500, ) fig . update_xaxes ( showticklabels = False ) fig . update_yaxes ( showticklabels = False ) fig . update ( layout_coloraxis_showscale = False ) # Set how the image should be annotated if draw : fig . update_layout ( dragmode = \"drawclosedpath\" ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" logging . info ( \"Returning figure\" ) return fig def compute_heatmap_per_mz ( self , slice_index , lb_mz = None , hb_mz = None , draw = False , projected_image = True , return_base64_string = False , cache_flask = None , ): \"\"\"This function takes two boundaries and a slice index, and returns a heatmap of the lipid expressed in the slice whose m/z is between the two boundaries. Args: slice_index (int): The index of the requested slice. lb_mz (float, optional): The lower m/z boundary. Defaults to None. hb_mz (float, optional): The higher m/z boundary. Defaults to None. draw (bool, optional): If True, the user will have the possibility to draw on the resulting Plotly Figure. Defaults to False. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the value return_base64_string, may either return a base64 string, or a Plotly Figure. \"\"\" logging . info ( \"Starting figure computation, from mz boundaries\" ) # Upper bound lower than the lowest m/z value and higher that the highest m/z value if lb_mz is None : lb_mz = 200 if hb_mz is None : hb_mz = 1800 logging . info ( \"Getting image array\" ) # Compute image with given bounds image = self . compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , projected_image = projected_image , cache_flask = cache_flask , ) # Compute corresponding figure fig = self . build_lipid_heatmap_from_image ( image , return_base64_string = return_base64_string , draw = draw ) return fig def compute_heatmap_per_lipid_selection ( self , slice_index , ll_t_bounds , normalize = True , projected_image = True , apply_transform = False , ll_lipid_names = None , return_base64_string = False , cache_flask = None , ): \"\"\"This function is very similar to compute_heatmap_per_mz, but it takes a list of lipid boundaries, possibly along with lipid names, instead of just two boundaries. It returns a heatmap of the sum of expression of the requested lipids in the slice. Args: slice_index (int): The index of the requested slice. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels (although this is not used in the function). The second list is used to separate lipid. normalize (bool, optional): If True, and the lipid has been MAIA transformed (and is provided with the parameter lipid_name) and apply_transform is True, the resulting array is normalized according to a factor computed across all slice. If MAIA has not been applied to the current selection or apply_transform is False, it is normalized according to the 99th percentile. Else, it is not normalized. Defaults to True. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. ll_lipid_names (list(list(int)), optional): List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the value return_base64_string, may either return a base64 string, or a Plotly Figure. \"\"\" logging . info ( \"Compute heatmap per lipid selection\" + str ( ll_t_bounds )) # Start from empty image and add selected lipids # * Caution: array must be int, float gets badly converted afterwards image = np . zeros ( self . _atlas . image_shape , dtype = np . int32 ) # Build empty lipid names if not provided if ll_lipid_names is None : ll_lipid_names = [[ \"\" for y in l_t_bounds ] for l_t_bounds in ll_t_bounds ] # Loop over channels for l_t_bounds , l_lipid_names in zip ( ll_t_bounds , ll_lipid_names ): if l_t_bounds is not None : # Loop over lipids for boundaries , lipid_name in zip ( l_t_bounds , l_lipid_names ): if boundaries is not None : ( lb_mz , hb_mz ) = boundaries # Cmpute expression image per lipid image_temp = self . compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , normalize = normalize , projected_image = projected_image , apply_transform = apply_transform , lipid_name = lipid_name , cache_flask = cache_flask , ) image += image_temp # Compute corresponding figure fig = self . build_lipid_heatmap_from_image ( image , return_base64_string = return_base64_string ) return fig def compute_rgb_array_per_lipid_selection ( self , slice_index , ll_t_bounds , normalize_independently = True , projected_image = True , log = False , apply_transform = False , ll_lipid_names = None , cache_flask = None , ): \"\"\"This function computes a numpy RGB array (each pixel has 3 intensity values) of expression of the requested lipids (those whose m/z values are in ll_t_bounds) in the slice. Args: slice_index (int): The index of the requested slice. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. normalize_independently (bool, optional): If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. log (bool, optional): If True, the resulting array corresponds to log-transformed expression, for each lipid. Defaults to False. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. ll_lipid_names (list(list(int)), optional): List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (np.ndarray): A three-dimensional RGB numpy array (of uint8 dtype). The first two dimensions correspond to the acquisition image shape, and the third dimension corresponds to the channels. \"\"\" # Empty lipid names if no names provided if ll_lipid_names is None : ll_lipid_names = [ [ \"\" for y in l_t_bounds ] if l_t_bounds is not None else [ \"\" ] for l_t_bounds in ll_t_bounds ] # Build a list of empty images and add selected lipids for each channel l_images = [] # Loop over channels for l_boundaries , l_names in zip ( ll_t_bounds , ll_lipid_names ): image = np . zeros ( self . _atlas . image_shape if projected_image else self . _data . get_image_shape ( slice_index ) ) if l_boundaries is not None : # Loop over lipids for boundaries , lipid_name in zip ( l_boundaries , l_names ): if boundaries is not None : ( lb_mz , hb_mz ) = boundaries # Cmpute expression image per lipid image_temp = self . compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , normalize = normalize_independently , projected_image = projected_image , log = log , apply_transform = apply_transform , lipid_name = lipid_name , cache_flask = cache_flask , ) if image_temp is not None : image += image_temp l_images . append ( image ) # Reoder axis to match plotly go.image requirements array_image = np . moveaxis ( np . array ( l_images ), 0 , 2 ) return np . asarray ( array_image , dtype = np . uint8 ) def compute_rgb_image_per_lipid_selection ( self , slice_index , ll_t_bounds , normalize_independently = True , projected_image = True , log = False , return_image = False , apply_transform = False , ll_lipid_names = None , return_base64_string = False , cache_flask = None , ): \"\"\"This function is very similar to compute_heatmap_per_lipid_selection, but it returns a RGB image instead of a heatmap. Args: slice_index (int): The index of the requested slice. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. normalize_independently (bool, optional): If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. log (bool, optional): If True, the resulting array corresponds to log-transformed expression, for each lipid. Defaults to False. return_image (bool, optional): If True, a go.Image is returned directly, instead of a Plotly Figure. Defaults to False. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. ll_lipid_names (list(list(int)), optional): List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the inputted arguments, may either return a base64 string, a go.Image, or a Plotly Figure. \"\"\" logging . info ( \"Started RGB image computation for slice \" + str ( slice_index ) + logmem ()) # Empty lipid names if no names provided if ll_lipid_names is None : ll_lipid_names = [[ \"\" for y in l_t_bounds ] for l_t_bounds in ll_t_bounds ] logging . info ( \"Acquiring array_image for slice \" + str ( slice_index ) + logmem ()) # Get RGB array for the current lipid selection array_image = self . compute_rgb_array_per_lipid_selection ( slice_index , ll_t_bounds , normalize_independently = normalize_independently , projected_image = projected_image , log = log , apply_transform = apply_transform , ll_lipid_names = ll_lipid_names , cache_flask = cache_flask , ) logging . info ( \"Returning fig for slice \" + str ( slice_index ) + logmem ()) # Build the correspondig figure return self . build_lipid_heatmap_from_image ( array_image , return_base64_string = return_base64_string , draw = False , type_image = \"RGB\" , return_go_image = return_image , ) def compute_spectrum_low_res ( self , slice_index , annotations = None ): \"\"\"This function returns the full (low-resolution) spectrum of the requested slice. Args: slice_index (int): The slice index of the requested slice. annotations (list(tuple), optional): A list of m/z boundaries (one for each lipid to annotate), corresponding to the position of colored box superimposed on the spectra. Defaults to None. Returns: (go.Figure): A Plotly Figure representing the low-resolution spectrum. \"\"\" # Define figure data data = go . Scattergl ( x = self . _data . get_array_avg_spectrum_downsampled ( slice_index )[ 0 , :], y = self . _data . get_array_avg_spectrum_downsampled ( slice_index )[ 1 , :], visible = True , line_color = dic_colors [ \"blue\" ], fill = \"tozeroy\" , ) # Define figure layout layout = go . Layout ( margin = dict ( t = 50 , r = 0 , b = 10 , l = 0 ), showlegend = False , xaxis = dict ( rangeslider = { \"visible\" : False }, title = \"m/z\" ), yaxis = dict ( fixedrange = False , title = \"Intensity\" ), template = \"plotly_dark\" , autosize = True , title = { \"text\" : \"Low resolution spectrum (averaged across pixels)\" , \"y\" : 0.92 , \"x\" : 0.5 , \"xanchor\" : \"center\" , \"yanchor\" : \"top\" , \"font\" : dict ( size = 14 , ), }, paper_bgcolor = \"rgba(0,0,0,0.3)\" , plot_bgcolor = \"rgba(0,0,0,0.3)\" , ) # Build figure fig = go . Figure ( data = data , layout = layout ) # Annotate selected lipids with vertical bars if annotations is not None : for color , annot in zip ([ \"red\" , \"green\" , \"blue\" ], annotations ): if annot is not None : fig . add_vrect ( x0 = annot [ 0 ], x1 = annot [ 1 ], fillcolor = dic_colors [ color ], opacity = 0.4 , line_color = dic_colors [ color ], ) return fig def compute_spectrum_high_res ( self , slice_index , lb = None , hb = None , annotations = None , force_xlim = False , plot = True , standardization = False , cache_flask = None , ): \"\"\"This function returns the high-resolution spectrum of the requested slice between the two provided m/z boundaries lb and hb. If boundaries are not provided, it returns an empty spectrum. Args: slice_index (int): The slice index of the requested slice. lb (float, optional): The lower m/z boundary below which the spectrum to display must be cropped. Defaults to None. hb (float, optional): The higher m/z boundary below which the spectrum to display must be cropped. Defaults to None. annotations (list(tuple), optional): A list of m/z boundaries (one for each lipid to annotate), corresponding to the position of colored box superimposed on the spectra. Defaults to None. force_xlim (bool, optional): If Truen the zoom level will be set to enclose lb and hb, although that may not be the tightest region to enclose the data. Defaults to False. plot (bool, optional): If False, only the plotting data (m/z and intensities arrays) will be returned. Defaults to True. standardization (bool, optional): If True, the displayed spectrum is standardized with MAIA when possible. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the value of the boundaries, and the plot parameter, it may return a Plotly Figure containing an empty spectrum, or a spectrum between the two provided boundaries, or the corresponding data of such a spectrum. \"\"\" # Define default values for graph (empty) if lb is None and hb is None : x = ([],) y = ([],) # If boundaries are provided, get their index else : index_lb , index_hb = compute_thread_safe_function ( compute_index_boundaries , cache_flask , self . _data , slice_index , lb , hb , array_spectra_avg = self . _data . get_array_avg_spectrum ( slice_index , standardization = standardization ), lookup_table = self . _data . get_array_lookup_mz_avg ( slice_index ), ) def return_x_y ( array ): x = np . copy ( array [ 0 , index_lb : index_hb ]) y = np . copy ( array [ 1 , index_lb : index_hb ]) return x , y # Get x, y in a thread safe fashion # No need to clean memory as it's really small x , y = compute_thread_safe_function ( return_x_y , cache_flask , self . _data , slice_index , self . _data . get_array_avg_spectrum ( slice_index , standardization = standardization ), ) # In case download without plotting if not plot : return x , y # Define figure data data = go . Scattergl ( x = x , y = y , visible = True , line_color = dic_colors [ \"blue\" ], fill = \"tozeroy\" ) # Define figure layout layout = go . Layout ( margin = dict ( t = 50 , r = 0 , b = 10 , l = 0 ), showlegend = False , xaxis = dict ( rangeslider = { \"visible\" : False }, title = \"m/z\" ), yaxis = dict ( fixedrange = True , title = \"Intensity\" ), template = \"plotly_dark\" , title = { \"text\" : \"High resolution spectrum (averaged across pixels)\" , \"y\" : 0.92 , \"x\" : 0.5 , \"xanchor\" : \"center\" , \"yanchor\" : \"top\" , \"font\" : dict ( size = 14 , ), }, paper_bgcolor = \"rgba(0,0,0,0.3)\" , plot_bgcolor = \"rgba(0,0,0,0.3)\" , ) # Build figure layout fig = go . Figure ( data = data , layout = layout ) # Annotate selected lipids with vertical bars if annotations is not None : for color , x in zip ([ \"red\" , \"green\" , \"blue\" ], annotations ): if x is not None : if x [ 0 ] >= lb and x [ - 1 ] <= hb : fig . add_vrect ( x0 = x [ 0 ], x1 = x [ 1 ], line_width = 0 , fillcolor = dic_colors [ color ], opacity = 0.4 ) # In case we don't want to zoom in too much on the selected lipid if force_xlim : fig . update_xaxes ( range = [ lb , hb ]) return fig def return_empty_spectrum ( self ): \"\"\"This function returns an empty spectrum, used to display when no spectrum is available. Returns: (Plotly Figure): A Plotly Figure representing an empty spectrum.\"\"\" # Define empty figure data data = ( go . Scattergl ( x = [], y = [], visible = True ),) # Define figure layout layout = go . Layout ( margin = dict ( t = 5 , r = 0 , b = 10 , l = 0 ), showlegend = True , xaxis = dict ( title = \"m/z\" ), yaxis = dict ( title = \"Intensity\" ), template = \"plotly_dark\" , ) # Build figure fig = go . Figure ( data = data , layout = layout ) # Transparent background fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" return fig # ============================================================================================== # --- Methods used mainly in region_analysis # ============================================================================================== def return_heatmap_lipid ( self , fig = None ): \"\"\"This function is used to either generate a Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. Args: fig (Plotly Figure, optional): A Plotly Figure whose layout must be completed. If None, a new figure will be generated. Defaults to None. Returns: (Plotly Figure): A Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. \"\"\" # Build empty figure if not provided if fig is None : fig = go . Figure ( data = go . Heatmap ( z = [[]], x = [], y = [], visible = False )) # Improve figure layout fig . update_layout ( margin = dict ( t = 25 , r = 0 , b = 10 , l = 0 ), template = \"plotly_dark\" , font_size = 8 , ) # Transparent background fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" # Dark Template fig . layout . template = \"plotly_dark\" return fig # ============================================================================================== # --- Methods used mainly in threeD_exploration # ============================================================================================== def compute_treemaps_figure ( self , maxdepth = 5 ): \"\"\"This function is used to generate a Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. Args: maxdepth (int, optional): The depth of the treemap to generate. Defaults to 5. Returns: (Plotly.Figure): A Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. \"\"\" # Build treemaps from list of children and parents fig = px . treemap ( names = self . _atlas . l_nodes , parents = self . _atlas . l_parents , maxdepth = maxdepth ) # Improve layout fig . update_layout ( uniformtext = dict ( minsize = 15 ), margin = dict ( t = 30 , r = 0 , b = 10 , l = 0 ), ) fig . update_traces ( root_color = \"#1d3d5c\" ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" return fig def compute_3D_root_volume ( self , decrease_dimensionality_factor = 7 , differentiate_borders = False ): \"\"\"This function is used to generate a go.Isosurface of the Allen Brain root structure, which will be used to enclose the display of lipid expression of other structures in the brain. Args: decrease_dimensionality_factor (int, optional): Decrease the dimensionnality of the brain to display, to get a lighter output. Defaults to 7. Returns: (go.Isosurface): A semi-transparent go.Isosurface of the Allen Brain root structure. \"\"\" # Get array of annotations, which associate coordinate to id array_annotation_root = np . array ( self . _atlas . bg_atlas . annotation , dtype = np . int32 ) # Subsample array of annotation the same way array_atlas was subsampled array_annotation_root = array_annotation_root [ :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , ] # Bug correction for the last slice array_annotation_root = np . concatenate ( ( array_annotation_root , np . zeros (( 1 , array_annotation_root . shape [ 1 ], array_annotation_root . shape [ 2 ])), ) ) # Get the volume array array_atlas_borders_root = fill_array_borders ( array_annotation_root , differentiate_borders = differentiate_borders , color_near_borders = False , keep_structure_id = None , ) # Compute the 3D grid X_root , Y_root , Z_root = np . mgrid [ 0 : array_atlas_borders_root . shape [ 0 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders_root . shape [ 0 ] * 1 j , 0 : array_atlas_borders_root . shape [ 1 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders_root . shape [ 1 ] * 1 j , 0 : array_atlas_borders_root . shape [ 2 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders_root . shape [ 2 ] * 1 j , ] # Compute the plot brain_root_data = go . Isosurface ( x = X_root . flatten (), y = Y_root . flatten (), z = Z_root . flatten (), value = array_atlas_borders_root . flatten (), isomin =- 0.21 , isomax = 2.55 , opacity = 0.1 , # max opacity surface_count = 2 , colorscale = \"Blues\" , # colorscale, flatshading = True , showscale = False , ) return brain_root_data def get_array_of_annotations ( self , decrease_dimensionality_factor ): \"\"\"This function returns the array of annotations from the Allen Brain Atlas, subsampled to decrease the size of the output. Args: decrease_dimensionality_factor (int): An integer used for subsampling the array. The higher, the higher the subsampling. Returns: (np.ndarray): A 3D array of annotation, in which structures are annotated with specific identifiers. \"\"\" # Get subsampled array of annotations array_annotation = np . array ( self . _atlas . bg_atlas . annotation [ :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , ], dtype = np . int32 , ) # Bug correction for the last slice array_annotation = np . concatenate ( ( array_annotation , np . zeros (( 1 , array_annotation . shape [ 1 ], array_annotation . shape [ 2 ])), ) ) return array_annotation def compute_l_array_2D ( self , ll_t_bounds , normalize_independently = True , high_res = False , brain_1 = True , cache_flask = None , ): \"\"\"This function is used to get the list of expression per slice for all slices for the computation of the 3D brain volume. Args: ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. normalize_independently (bool, optional): If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. high_res (bool, optional): If True, the returned list of arrays correspond to the warped/upscaled data. Defaults to False as this is a very heavy plot. brain_1 (bool, optional): If True, the returned list of arrays correspond to the brain 1 data. Else, to the brain 2 data. Defaults to True. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (list(np.ndarray)): A list of numpy arrays representing the expression of the requested lipids (through ll_t_bounds) for each slice. \"\"\" l_array_data = [] # Correct the indices for the potentially unused slices from brain 1 if brain_1 : slice_index_offset = 0 else : slice_index_offset = len ( self . _data . get_slice_list ( indices = \"brain_1\" )) # Loop over slices and compute the expression of the requested lipids for slice_index in range ( len ( ll_t_bounds )): if ll_t_bounds [ slice_index ] != [ None , None , None ]: # Get the data as an expression image per lipid array_data = self . compute_rgb_array_per_lipid_selection ( slice_index + 1 + slice_index_offset , ll_t_bounds [ slice_index ], normalize_independently = normalize_independently , projected_image = high_res , log = False , apply_transform = True , cache_flask = cache_flask , ) # Sum array colors (i.e. lipids) array_data = np . sum ( array_data , axis =- 1 ) else : array_data = None # Append data to l_array_data l_array_data . append ( np . array ( array_data , dtype = np . float16 )) # float16 to gain space return l_array_data def compute_array_coordinates_3D ( self , l_array_data , high_res = False , brain_1 = True , ): \"\"\"This functions computes the list of coordinates and expression values for the voxels used in the 3D representation of the brain. Args: l_array_data (list(np.ndarray)): A list of numpy arrays representing lipid expression for each slice of the dataset. high_res (bool, optional): If True, the computations made correspond to the warped/upscaled data. Defaults to False as this is a very heavy plot. brain_1 (bool, optional): If True, the returned list of arrays correspond to the brain 1 data. Else, to the brain 2 data. Defaults to True. Returns: (np.ndarray, np.ndarray, np.ndarray, np.ndarray): 4 flat numpy arrays (3 for coordinates and 1 for expression). \"\"\" logging . info ( \"Starting computing 3D arrays\" + logmem ()) # Correct the indices for the potentially unused slices from brain 1 if brain_1 : slice_index_init = 0 slice_index_end = len ( self . _data . get_slice_list ( indices = \"brain_1\" )) else : slice_index_init = len ( self . _data . get_slice_list ( indices = \"brain_1\" )) slice_index_end = self . _data . get_slice_number () # get list of original coordinates for each slice if not high_res : l_coor = self . _atlas . l_original_coor [ slice_index_init : slice_index_end ] estimate = 400 * 400 else : estimate = 1311 * 918 l_coor = self . _atlas . array_coordinates_warped_data [ slice_index_init : slice_index_end ] # Initialize empty arrays with a large estimate for the orginal acquisition size max_size = estimate * ( slice_index_end - slice_index_init ) array_x = np . empty ( max_size , dtype = np . float32 ) array_y = np . empty ( max_size , dtype = np . float32 ) array_z = np . empty ( max_size , dtype = np . float32 ) array_c = np . empty ( max_size , dtype = np . int16 ) total_index = 0 logging . debug ( f \"Size array_x: { array_x . nbytes / 1024 / 1024 : .2f } \" ) logging . info ( \"Starting slice iteration\" + logmem ()) # get atlas shape and resolution reference_shape = self . _atlas . bg_atlas . reference . shape resolution = self . _atlas . resolution array_annotations = np . array ( self . _atlas . bg_atlas . annotation , dtype = np . int32 ) for slice_index in range ( 0 , len ( l_array_data ), 1 ): # Get the averaged expression data for the current slice array_data = l_array_data [ slice_index ] # If array_data is not an array but a 0 float, skip it if type ( array_data ) == float : continue # Remove pixels for which lipid expression is zero array_data_stripped = array_data . flatten () # array_data[array_data != 0].flatten() # Skip the current slice if expression is very sparse if len ( array_data_stripped ) < 10 or np . sum ( array_data_stripped ) < 1 : continue # Compute the percentile of expression to filter out lowly expressed pixels # Set to 0 for now, as no filtering is done percentile = 0 # np.percentile(array_data_stripped, 10) # Get the coordinates of the pixels in the ccfv3 coordinates = l_coor [ slice_index ] # coordinates_stripped = coordinates[array_data != 0] coordinates_stripped = coordinates . reshape ( - 1 , coordinates . shape [ - 1 ]) # Get the data as 4 arrays (3 for coordinates and 1 for expression) array_x , array_y , array_z , array_c , total_index = filter_voxels ( array_data_stripped . astype ( np . float32 ), coordinates_stripped , array_annotations , percentile , array_x , array_y , array_z , array_c , total_index , reference_shape , resolution , ) logging . info ( \"Slice \" + str ( slice_index ) + \" done\" + logmem ()) # Strip the arrays from the zeros array_x = array_x [: total_index ] array_y = array_y [: total_index ] array_z = array_z [: total_index ] # * Caution, array_c should be a list to work with Plotly array_c = array_c [: total_index ] . tolist () # Return the arrays for the 3D figure return array_x , array_y , array_z , array_c def compute_3D_volume_figure ( self , set_progress = None , ll_t_bounds = [[( None , None )]], name_lipid_1 = \"\" , name_lipid_2 = \"\" , name_lipid_3 = \"\" , set_id_regions = None , decrease_dimensionality_factor = 6 , cache_flask = None , structure_guided_interpolation = True , return_interpolated_array = False , return_individual_slice_data = False , divider_radius = 16 , brain_1 = False , ): \"\"\"This figure computes a Plotly Figure containing a go.Volume object representing the expression of the requested lipids in the selected regions, interpolated between the slices. Lipid names are used to retrieve the expression data from the Shelve database. Args: set_progress: Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. name_lipid_1 (str, optional): Name of the first selected lipid. Defaults to \"\". name_lipid_2 (str, optional): Name of the second selected lipid. Defaults to \"\". name_lipid_3 (str, optional): Name of the third selected lipid. Defaults to \"\". set_id_regions (set(int), optional): A set containing the identifiers of the brain regions (at the very bottom of the hierarchy) in which lipid expression is requested. Defaults to None, corresponding to the whole brain. decrease_dimensionality_factor (int): An integer used for subsampling the array of annotation, and therefore the resulting figure. The higher, the higher the subsampling. Needed as this is a very heavy plot. Defaults to 6. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. structure_guided_interpolation (bool, optional): If True, the interpolation is done using the annotated structures. If False, the interpolation is done blindly. return_interpolated_array (bool): If True, the interpolated array is returned. Else, the corresponding Plotly figure is returned. Defaults to False. return_individual_slice_data (bool): If True, the individual slice data (not interpolated) is returned. divider_radius (int): The inverse radius of the sphere used to do the interpolation. Defaults to 16. brain_1 (bool): If True, the brain 1 data is used. Else, the brain 2 data is used. Defaults to False. Returns: Depending on the value of return_interpolated_array and return_individual_slice_data, returns either the (not) interpolated array of expression of the requested lipids in the selected regions, or a Plotly Figure containing a go.Volume object representing the interpolated expression. \"\"\" if return_interpolated_array and return_individual_slice_data : logging . warning ( \"Cannot return both interpolated and not interpolated array... Returning the\" \" individual slice data.\" ) logging . info ( \"Starting 3D volume computation\" ) if set_progress is not None : set_progress (( 10 , \"Loading array of annotations\" )) # Get subsampled array of annotations array_annotation = self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_annotation\" , force_update = False , compute_function = self . get_array_of_annotations , decrease_dimensionality_factor = decrease_dimensionality_factor , ) # Get subsampled array of borders for each region array_atlas_borders = np . zeros ( array_annotation . shape , dtype = np . float32 ) if set_id_regions is not None : list_id_regions = np . array ( list ( set_id_regions ), dtype = np . int64 ) else : list_id_regions = None if set_progress is not None : set_progress (( 10 , \"Computing brain borders\" )) # Shelving this function is useless as it takes less than 0.1s to compute after # first compilation array_atlas_borders = fill_array_borders ( array_annotation , keep_structure_id = list_id_regions , decrease_dimensionality_factor = decrease_dimensionality_factor , ) logging . info ( \"Computed basic structure array\" ) if set_progress is not None : set_progress (( 20 , \"Computing expression for each lipid\" )) # Get array of expression for each lipid ll_array_data = [ self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_expression_\" + str ( brain_1 ) + \"_\" + str ( name_lipid ) + \"__\" , force_update = False , ignore_arguments_naming = True , compute_function = self . compute_l_array_2D , ll_t_bounds = [[ l_t_bounds [ i ], None , None ] for l_t_bounds in ll_t_bounds ], brain_1 = brain_1 , cache_flask = cache_flask , ) for i , name_lipid in enumerate ([ name_lipid_1 , name_lipid_2 , name_lipid_3 ]) ] if set_progress is not None : set_progress (( 50 , \"Averaging expression for each lipid\" )) # Average array of expression over lipid l_array_data_avg = [] for slice_index in range ( len ( self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" )) ): n = 0 avg = 0 for i in range ( 3 ): # * number of lipids is hardcoded s = ll_array_data [ i ][ slice_index ] if s is None : s = 0 elif s . size == 1 : if np . isnan ( s ): s = 0 else : n += 1 avg += s # In case there's no data for the current slice, set the average to 0 if n == 0 : n = 1 l_array_data_avg . append ( avg / n ) logging . info ( \"Averaged expression over all lipids\" ) if set_progress is not None : set_progress (( 60 , \"Getting slice coordinates\" )) # Get the 3D array of expression and coordinates array_x , array_y , array_z , array_c = self . compute_array_coordinates_3D ( l_array_data_avg , high_res = False , brain_1 = brain_1 ) if return_individual_slice_data : return array_x , array_y , array_z , array_c logging . info ( \"Computed array of expression in original space\" ) if set_progress is not None : set_progress (( 70 , \"Filling a new brain with expression\" )) # Compute the rescaled array of expression for each slice averaged over projected lipids array_slices = np . copy ( array_atlas_borders ) array_for_avg = np . full_like ( array_atlas_borders , 1 ) array_x_scaled = array_x * 1000000 / self . _atlas . resolution / decrease_dimensionality_factor array_y_scaled = array_y * 1000000 / self . _atlas . resolution / decrease_dimensionality_factor array_z_scaled = array_z * 1000000 / self . _atlas . resolution / decrease_dimensionality_factor array_slices = fill_array_slices ( array_x_scaled , array_y_scaled , array_z_scaled , np . array ( array_c ), array_slices , array_for_avg , limit_value_inside =- 1.99999 , ) logging . info ( \"Filled basic structure array with array of expression\" ) # Get the corresponding coordinates X , Y , Z = np . mgrid [ 0 : array_atlas_borders . shape [ 0 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders . shape [ 0 ] * 1 j , 0 : array_atlas_borders . shape [ 1 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders . shape [ 1 ] * 1 j , 0 : array_atlas_borders . shape [ 2 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders . shape [ 2 ] * 1 j , ] logging . info ( \"Built arrays of coordinates\" ) if set_id_regions is not None : x_min , x_max , y_min , y_max , z_min , z_max = crop_array ( array_annotation , list_id_regions ) array_annotation = array_annotation [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] array_slices = array_slices [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] X = X [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] Y = Y [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] Z = Z [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] logging . info ( \"Cropped the figure to only keep areas in which lipids are expressed\" ) if set_progress is not None : set_progress (( 70 , \"Interpolating expression\" )) # Compute an array containing the lipid expression interpolated for every voxel array_interpolated = fill_array_interpolation ( array_annotation , array_slices , divider_radius = 16 , limit_value_inside =- 1.99999 , structure_guided = structure_guided_interpolation , ) logging . info ( \"Finished interpolation between slices\" ) if return_interpolated_array : return array_interpolated if set_progress is not None : set_progress (( 80 , \"Building figure\" )) # Get root figure root_data = self . _storage . return_shelved_object ( \"figures/3D_page\" , \"volume_root\" , force_update = False , compute_function = self . compute_3D_root_volume , ) logging . info ( \"Building final figure\" ) # Build figure fig = go . Figure ( data = [ go . Volume ( x = X . flatten (), y = Y . flatten (), z = Z . flatten (), value = array_interpolated . flatten (), isomin = 0.01 , isomax = 1.5 , opacityscale = [ [ - 0.11 , 0.00 ], [ 0.01 , 0.0 ], [ 0.5 , 0.05 ], [ 2.5 , 0.7 ], ], surface_count = 10 , colorscale = \"viridis\" , ), root_data , ] ) # Hide grey background fig . update_layout ( margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" logging . info ( \"Done computing 3D volume figure\" ) if set_progress is not None : set_progress (( 90 , \"Returning figure\" )) return fig def compute_clustergram_figure ( self , set_progress , cache_flask , l_selected_regions , percentile = 90 , brain_1 = False , ): \"\"\"This function computes a Plotly Clustergram figure, allowing to cluster and compare the expression of all the MAIA-transformed lipids in the dataset in the selected regions. Args: set_progress: Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. l_selected_regions (list(int), optional): A list containing the identifiers of the brain regions (at the very bottom of the hierarchy) whose border must be annotated. percentile (int, optional): The percentile of average expression below which the lipids must be discarded (to get rid of low expression noise). Defaults to 90. brain_1 (bool): If True, the brain 1 data is used. Else, the brain 2 data is used. Defaults to False. Returns: (go.Figure): a Plotly Clustergram figure clustering and comparing the expression of all the MAIA-transformed lipids in the dataset in the selected regions. \"\"\" logging . info ( \"Starting computing clustergram figure\" ) # Memoize result as it's called everytime a filtering is done @cache_flask . memoize () def return_df_avg_lipids ( l_selected_regions ): dic_avg_lipids = {} l_slices = self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ) for slice_index in l_slices : # Display progress every 10 slices if slice_index % 10 == 0 : set_progress ( ( int ( slice_index / len ( l_slices ) * 100 ), \"Loading slice n\u00b0\" + str ( slice_index ), ) ) l_spectra = [] for region in l_selected_regions : long_region = self . _atlas . dic_acronym_name [ region ] if slice_index - 1 in self . _atlas . dic_existing_masks : if region in self . _atlas . dic_existing_masks [ slice_index - 1 ]: grah_scattergl_data = self . _atlas . get_projected_mask_and_spectrum ( slice_index - 1 , long_region , MAIA_correction = True )[ 1 ] l_spectra . append ( grah_scattergl_data ) else : l_spectra . append ( None ) else : raise Exception ( \"The masks have not been precomputed. Please precompute them before\" \" running this function.\" ) ll_idx_labels = global_lipid_index_store ( self . _data , slice_index - 1 , l_spectra ) logging . info ( \"Computing dictionnary for averaging slice \" + str ( slice_index )) # Compute average expression for each lipid and each selection set_lipids_idx = set () ll_lipids_idx = [] ll_avg_intensity = [] n_sel = len ( l_spectra ) for spectrum , l_idx_labels in zip ( l_spectra , ll_idx_labels ): if spectrum is not None : array_intensity_with_lipids = np . array ( spectrum , dtype = np . float32 )[ 1 , :] array_idx_labels = np . array ( l_idx_labels , dtype = np . int32 ) l_lipids_idx , l_avg_intensity = compute_avg_intensity_per_lipid ( array_intensity_with_lipids , array_idx_labels ) set_lipids_idx . update ( l_lipids_idx ) else : l_lipids_idx = None l_avg_intensity = None ll_lipids_idx . append ( l_lipids_idx ) ll_avg_intensity . append ( l_avg_intensity ) for i , ( l_lipids , l_avg_intensity ) in enumerate ( zip ( ll_lipids_idx , ll_avg_intensity ) ): if l_lipids is not None : for lipid , intensity in zip ( l_lipids , l_avg_intensity ): if lipid not in dic_avg_lipids : dic_avg_lipids [ lipid ] = [] for j in range ( n_sel ): dic_avg_lipids [ lipid ] . append ([]) dic_avg_lipids [ lipid ][ i ] . append ( intensity ) logging . info ( \"Averaging all lipid values across slices\" ) # Average intensity per slice for lipid in dic_avg_lipids : for i in range ( n_sel ): if len ( dic_avg_lipids [ lipid ][ i ]) > 0 : dic_avg_lipids [ lipid ][ i ] = np . mean ( dic_avg_lipids [ lipid ][ i ]) else : dic_avg_lipids [ lipid ][ i ] = 0 df_avg_intensity_lipids = pd . DataFrame . from_dict ( dic_avg_lipids , orient = \"index\" , columns = [ l_selected_regions [ i ] for i in range ( n_sel )], ) return df_avg_intensity_lipids df_avg_intensity_lipids = return_df_avg_lipids ( l_selected_regions ) logging . info ( \"Averaging done for all slices\" ) set_progress (( 90 , \"Loading data\" )) # Exclude very lowly expressed lipids df_min_expression = df_avg_intensity_lipids . min ( axis = 1 ) df_avg_intensity_lipids = df_avg_intensity_lipids [ df_min_expression > df_min_expression . quantile ( q = int ( percentile ) / 100 ) ] if len ( l_selected_regions ) > 1 : df_avg_intensity_lipids = df_avg_intensity_lipids . iloc [ ( df_avg_intensity_lipids . mean ( axis = 1 )) . argsort (), : ] else : df_avg_intensity_lipids . sort_values ( by = l_selected_regions [ 0 ], inplace = True ) logging . info ( \"Lowly expressed lipids excluded\" ) # Replace idx_lipids by actual name df_names = self . _data . get_annotations () df_avg_intensity_lipids . index = df_avg_intensity_lipids . index . map ( lambda idx : df_names . iloc [ idx ][ \"name\" ] + \"_\" + df_names . iloc [ idx ][ \"structure\" ] + \"_\" + df_names . iloc [ idx ][ \"cation\" ] ) logging . info ( \"Lipid indexes replaced by names\" ) logging . info ( \"Preparing plot\" ) # Plot fig_heatmap_lipids = Clustergram ( data = df_avg_intensity_lipids . to_numpy (), column_labels = df_avg_intensity_lipids . columns . to_list (), row_labels = df_avg_intensity_lipids . index . to_list (), hidden_labels = \"row\" if len ( df_avg_intensity_lipids . index . to_list ()) > 100 else None , color_map = \"Viridis\" , height = 800 , width = 1000 , display_ratio = [ 0.2 , 0.01 ], ) # Set background color to zero fig_heatmap_lipids . layout . template = \"plotly_dark\" fig_heatmap_lipids . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_heatmap_lipids . layout . paper_bgcolor = \"rgba(0,0,0,0)\" set_progress (( 100 , \"Returning figure\" )) logging . info ( \"Returning figure\" ) return fig_heatmap_lipids # ============================================================================================== # --- Methods used in scRNAseq page # ============================================================================================== def compute_scatter_3D ( self ): \"\"\"This functions computes a figure representing, in a 3D scatter plot, the spots acquired using spatial scRNAseq experiments. Returns: (Plotly.Figure): A Plotly Figure containing a go.Scatter3d object representing the acquired spots. \"\"\" logging . info ( \"Starting computing 3D scatter plot for scRNAseq experiments\" + logmem ()) # Get scatter figure for the scRNAseq spots scatter = go . Scatter3d ( x = self . _scRNAseq . xmol , y = self . _scRNAseq . zmol , z =- self . _scRNAseq . ymol , mode = \"markers\" , marker = dict ( size = 2.5 , opacity = 0.8 , color = dic_colors [ \"blue\" ]), ) # Get root figure root_data = self . _storage . return_shelved_object ( \"figures/3D_page\" , \"volume_root\" , force_update = False , compute_function = self . compute_3D_root_volume , differentiate_borders = True , ) # Remove inside of volume root_data [ \"value\" ] = np . where ( ( root_data [ \"value\" ] == - 0.01 ) | ( root_data [ \"value\" ] == - 2.0 ), - 2.0 , root_data [ \"value\" ] ) # Change orientation root_data_y = copy . deepcopy ( root_data [ \"y\" ]) root_data_z = copy . deepcopy ( root_data [ \"z\" ]) root_data [ \"y\" ] = root_data_z root_data [ \"z\" ] = - root_data_y # Remove parts of brain that prevent from clicking points root_data [ \"x\" ] = root_data [ \"x\" ][( root_data [ \"y\" ] < 6 ) & ( root_data [ \"z\" ] < - 3 )] root_data [ \"value\" ] = root_data [ \"value\" ][( root_data [ \"y\" ] < 6 ) & ( root_data [ \"z\" ] < - 3 )] root_data_y_copy = copy . deepcopy ( root_data [ \"y\" ]) root_data [ \"y\" ] = root_data [ \"y\" ][( root_data [ \"y\" ] < 6 ) & ( root_data [ \"z\" ] < - 3 )] root_data [ \"z\" ] = root_data [ \"z\" ][( root_data [ \"z\" ] < - 3 ) & ( root_data_y_copy < 6 )] # Block interaction for skull root_data [ \"hoverinfo\" ] = \"skip\" scatter [ \"hoverinfo\" ] = \"all\" # Build figure fig = go . Figure ( data = [ root_data , scatter ]) # Hide background fig . update_layout ( title_text = \"Click on a point to see the corresponding scRNAseq data\" , title_x = 0.5 , margin = dict ( r = 0 , b = 0 , l = 0 ), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" # Change orientation to have scatter dots face the reader x_eye = 0.01 * 2 y_eye = 1.0 * 2 z_eye = 0.5 * 2 camera = dict ( # up=dict(x=0, y=0, z=0), # center=dict(x=0, y=0, z=0), eye = dict ( x = x_eye , y = y_eye , z = z_eye ), ) fig . update_layout ( scene_camera = camera ) return fig def compute_barplots_enrichment ( self , brain_1 = False , idx_dot = None ): \"\"\"This functions computes two figures representing, in barplots, the lipid expression in the spots acquired using spatial scRNAseq experiments, as well as how it can be explained by an elastic net regression using gene expression as explaing factors. Args: brain_1 (bool, optional): If True, the barplot will be displayed with the regression coefficients computed from for the first brain. Returns: (Plotly.Figure, Plotly.Figure, list(str), list(str)): Two Plotly Figures containing each a go.Bar object representing the standardized lipid expression in the scRNAseq spots, and the elastic net regression coefficients for each lipid (bar). The two lists contain the corresponding names of the genes and lipids represented. \"\"\" logging . info ( \"Starting computing barplot for scRNAseq experiments\" + logmem ()) if brain_1 : x = self . _scRNAseq . l_name_lipids_brain_1 y = self . _scRNAseq . array_coef_brain_1 names = self . _scRNAseq . l_genes_brain_1 expression = self . _scRNAseq . array_exp_lipids_brain_1 l_score = self . _scRNAseq . l_score_brain_1 else : x = self . _scRNAseq . l_name_lipids_brain_2 y = self . _scRNAseq . array_coef_brain_2 names = self . _scRNAseq . l_genes_brain_2 expression = self . _scRNAseq . array_exp_lipids_brain_2 l_score = self . _scRNAseq . l_score_brain_2 # Turn expression into enrichment score expression = ( expression - np . mean ( expression , axis = 0 )) / np . std ( expression , axis = 0 ) # Take the average expression across all spots, or the expression in the selected spot if idx_dot is None : expression = np . mean ( expression , axis = 0 ) else : expression = expression [ idx_dot , :] # Sort lipids by enrichment index_sorted = np . argsort ( expression )[:: - 1 ] expression = expression [ index_sorted ] # Get arrays for plotting x = np . array ( x )[ index_sorted ] y = y [ index_sorted , :] l_score = np . array ( l_score )[ index_sorted ] # Limit to the 24 most expressed genes (in the most enriched lipid), # for only 24 colors are sharply distinguishable by naked eye index_sorted = np . argsort ( y [ 0 , :])[:: - 1 ] y = y [:, index_sorted [: 24 ]] names = np . array ( names )[ index_sorted [: 24 ]] # Normalize to 1 # y = (y.T / np.sum(abs(y), axis=1) * expression).T y = ( y . T / np . sum ( abs ( y ), axis = 1 )) . T # Incorporate score in the mix # y = np.vstack((y.T * l_score, (1 - l_score) * expression * np.ones((len(y),)))).T y = np . vstack (( y . T * l_score , ( 1 - l_score ) * 1.0 * np . ones (( len ( y ),)))) . T names = np . append ( names , \"Unexplained\" ) # Limit to 40 lipids for clarity x = x [: 40 ] y = y [: 40 , :] expression = expression [: 40 ] # Plot figure fig_lipids = go . Figure () fig_lipids . add_trace ( go . Bar ( x = x , y = expression , ) ) # Hide background fig_lipids . update_layout ( title_text = \"Lipid expression enrichment in selected spot (z-score)\" , title_x = 0.5 , barmode = \"relative\" , # margin=dict(t=0, r=0, b=0, l=0), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig_lipids . layout . template = \"plotly_dark\" fig_lipids . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_lipids . layout . paper_bgcolor = \"rgba(0,0,0,0)\" # Plot figure fig_genes = go . Figure () for idx , ( y_gene , name ) in enumerate ( zip ( y . T , names )): fig_genes . add_trace ( go . Bar ( x = x , y = abs ( y_gene ), name = name , marker_pattern_shape = [ \"+\" if t > 0 else \"-\" for t in y_gene ], # Doesn't work... marker_color = px . colors . qualitative . Dark24 [ idx ] if idx <= 23 else \"grey\" , hovertext = [ \" {:.2f} \" . format ( y [ idx_lipid , idx ] / np . sum ( abs ( y [ idx_lipid , :])) * 1.0 ) + \" (Fraction of (absolute) total elastic net coefficients)\" for idx_lipid in range ( len ( y )) ], ) ) # Hide background fig_genes . update_layout ( title_text = ( \"Elastic net coefficients, representing how lipid is explained by the corresponding\" \" gene\" ), title_x = 0.5 , barmode = \"relative\" , # margin=dict(t=0, r=0, b=0, l=0), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig_genes . layout . template = \"plotly_dark\" fig_genes . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_genes . layout . paper_bgcolor = \"rgba(0,0,0,0)\" return fig_lipids , fig_genes , names , x def compute_heatmap_lipid_genes ( self , lipid = None , l_genes = None , initial_frame = 5 , brain_1 = False , set_progress = None , ): \"\"\"This functions computes a heatmap representing, on the left side, the expression of a given lipid in the (low-resolution, interpolated) MALDI data, and the right side, the expressions of the selected genes (in l_genes) in the scRNAseq experiments from the molecular atlas data. Args: lipid (str): The name of the lipid to be displayed. If None, the most expressed lipid will be displayed. Defaults to None. l_genes (list): The list of gene names to be displayed. If None, the three most expressed genes will be displayed. Defaults to None. initial_frame (int, optional): The frame on which the slider is initialized. brain_1 (bool, optional): If True, the heatmap will be computed with the data coming from the first brain. Else, from the 2nd brain. Defaults to False. set_progress: Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. Returns: (Plotly.Figure): A Plotly Figure containing a go.Heatmap object representing the expression of the selected lipid and genes. \"\"\" logging . info ( \"Starting computing heatmap for scRNAseq experiments\" + logmem ()) if set_progress is not None : set_progress (( 5 , \"Loading data\" )) if brain_1 : x = self . _scRNAseq . l_name_lipids_brain_1 y = self . _scRNAseq . array_coef_brain_1 name_genes = self . _scRNAseq . l_genes_brain_1 name_lipids = self . _scRNAseq . l_name_lipids_brain_1 array_lipids = self . _scRNAseq . array_exp_lipids_brain_1 array_genes = self . _scRNAseq . array_exp_genes_brain_1 else : x = self . _scRNAseq . l_name_lipids_brain_2 y = self . _scRNAseq . array_coef_brain_2 name_genes = self . _scRNAseq . l_genes_brain_2 name_lipids = self . _scRNAseq . l_name_lipids_brain_2 array_lipids = self . _scRNAseq . array_exp_lipids_brain_2 array_genes = self . _scRNAseq . array_exp_genes_brain_2 # Get the most expressed lipid and genes if not provided if lipid is None and l_genes is None : expression = np . mean ( array_lipids , axis = 0 ) index_sorted = np . argsort ( expression )[:: - 1 ] expression = expression [ index_sorted ] lipids = np . array ( x )[ index_sorted ] y_sorted = y [ index_sorted , :] index_sorted = np . argsort ( y_sorted [ 0 , :])[:: - 1 ] y_sorted = y_sorted [:, index_sorted ] genes = np . array ( name_genes )[ index_sorted ] lipid = lipids [ 0 ] l_genes = genes [: 3 ] # Get coordinates x = self . _scRNAseq . xmol y = - self . _scRNAseq . ymol z = self . _scRNAseq . zmol # Get idx lipid and genes if lipid is not None : idx_lipid = list ( name_lipids ) . index ( lipid ) else : idx_lipid = None l_idx_genes_with_None = [ list ( name_genes ) . index ( gene ) if gene is not None else None for gene in l_genes ] l_idx_genes = [ idx_gene for idx_gene in l_idx_genes_with_None if idx_gene is not None ] # Build grids on which the data will be interpolated x_domain = np . arange ( np . min ( x ), np . max ( x ), 0.5 ) y_domain = np . arange ( np . min ( y ), np . max ( y ), 0.1 ) z_domain = np . arange ( np . min ( z ), np . max ( z ), 0.1 ) x_grid , y_grid , z_grid = np . meshgrid ( x_domain , y_domain , z_domain , indexing = \"ij\" ) if set_progress is not None : set_progress (( 15 , \"Preparing interpolation\" )) # Build data from interpolation since sampling is irregular if idx_lipid is not None : grid_lipid = griddata ( np . vstack (( x , y , z )) . T , array_lipids [:, idx_lipid ], ( x_grid , y_grid , z_grid ), method = \"linear\" , ) else : grid_lipid = None if len ( l_idx_genes ) == 1 : grid_genes = griddata ( np . vstack (( x , y , z )) . T , array_genes [:, l_idx_genes [ 0 ]], ( x_grid , y_grid , z_grid ), method = \"linear\" , ) elif len ( l_idx_genes ) > 1 : grid_genes = np . moveaxis ( np . stack ( [ griddata ( np . vstack (( x , y , z )) . T , array_genes [:, idx_genes ], ( x_grid , y_grid , z_grid ), method = \"linear\" , ) if idx_genes is not None else np . zeros_like ( x_grid ) for idx_genes in l_idx_genes_with_None ] ), 0 , - 1 , ) else : grid_genes = None if set_progress is not None : set_progress (( 75 , \"Finished interpolation... Building figure\" )) fig = make_subplots ( 1 , 2 ) # Build Figure, with several frames as it will be slidable if grid_lipid is not None : for i in range ( 0 , grid_lipid . shape [ 0 ], 1 ): fig . add_heatmap ( z = grid_lipid [ i , :, :], row = 1 , col = 1 , colorscale = \"Viridis\" , visible = True if i == initial_frame else False , showscale = False , ) if grid_genes is not None : if len ( grid_genes . shape ) == 3 : for i in range ( 0 , grid_genes . shape [ 0 ], 1 ): fig . add_heatmap ( z = grid_genes [ i , :, :], row = 1 , col = 2 , colorscale = \"Viridis\" , visible = True if i == initial_frame else False , showscale = False , ) elif len ( grid_genes . shape ) == 4 : for i in range ( 0 , grid_genes . shape [ 0 ], 1 ): fig . add_image ( z = grid_genes [ i , :, :, :], row = 1 , col = 2 , visible = True if i == initial_frame else False , ) if grid_genes is not None or grid_lipid is not None : steps = [] for i in range ( grid_lipid . shape [ 0 ]): step = dict ( method = \"restyle\" , args = [ \"visible\" , [ False ] * len ( fig . data )], label = str ( i ), ) if grid_lipid is not None and grid_genes is not None : step [ \"args\" ][ 1 ][ i ] = True step [ \"args\" ][ 1 ][ i + grid_lipid . shape [ 0 ]] = True elif grid_lipid is not None or grid_genes is not None : step [ \"args\" ][ 1 ][ i ] = True steps . append ( step ) sliders = [ dict ( active = initial_frame , steps = steps , pad = { \"b\" : 5 , \"t\" : 10 }, len = 0.9 , x = 0.05 , y = 0.0 , currentvalue = { \"visible\" : False , }, ) ] # Layout fig . update_layout ( title_text = \"Comparison between lipid and gene expression\" , title_x = 0.5 , title_y = 0.98 , margin = dict ( t = 20 , r = 20 , b = 20 , l = 20 ), template = \"plotly_dark\" , sliders = sliders , ) # No display of tick labels as they're wrong anyway fig . update_layout ( scene = dict ( xaxis = dict ( showticklabels = False ), yaxis = dict ( showticklabels = False ), ), paper_bgcolor = \"rgba(0,0,0,0.)\" , plot_bgcolor = \"rgba(0,0,0,0.)\" , yaxis_scaleanchor = \"x\" , ) # Reverse y axis if Image has been used if grid_genes is not None : if len ( grid_genes . shape ) == 4 : fig . update_yaxes ( autorange = True , row = 1 , col = 2 ) # Remove tick labels fig . update_xaxes ( showticklabels = False ) # Hide x axis ticks fig . update_yaxes ( showticklabels = False ) # Hide y axis ticks if set_progress is not None : set_progress (( 90 , \"Returning figure\" )) return fig # ============================================================================================== # --- Methods used for shelving results # ============================================================================================== def shelve_arrays_basic_figures ( self , force_update = False ): \"\"\"This function shelves in the database all the arrays of basic images computed in self.compute_figure_basic_image(), across all slices and all types of arrays. This forces the precomputations of these arrays, and allows to access them faster. Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Args: force_update (bool, optional): If True, the function will not overwrite existing files. Defaults to False. \"\"\" for idx_slice in range ( self . _data . get_slice_number ()): for type_figure in [ \"original_data\" , \"warped_data\" , \"projection_corrected\" , \"atlas\" ]: for display_annotations in [ True , False ]: # Force no annotation for the original data self . _storage . return_shelved_object ( \"figures/load_page\" , \"figure_basic_image\" , force_update = force_update , compute_function = self . compute_figure_basic_image , type_figure = type_figure , index_image = idx_slice , plot_atlas_contours = display_annotations if type_figure != \"original_data\" else False , ) self . _storage . dump_shelved_object ( \"figures/load_page\" , \"arrays_basic_figures_computed\" , True ) def shelve_all_l_array_2D ( self , force_update = False , sample = False , brain_1 = True ): \"\"\"This functions precomputes and shelves all the arrays of lipid expression used in a 3D representation of the brain (through self.compute_3D_volume_figure()). Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Args: force_update (bool, optional): If True, the function will not overwrite existing files. Defaults to False. sample (bool, optional): If True, only a fraction of the precomputations are made (for debug). Default to False. brain_1 (bool, optional): If True, the data is precomputed for the brain 1. Else for the brain 2. Defaults to True. \"\"\" # Count number of lipids processed for sampling n_processed = 0 if sample : logging . warning ( \"Only a sample of the lipid arrays will be computed!\" ) # Simulate a click on all lipid names df_annotations_MAIA = self . _data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 ) for name in sorted ( df_annotations_MAIA . name . unique ()): structures = df_annotations_MAIA [ df_annotations_MAIA [ \"name\" ] == name ] . structure . unique () for structure in sorted ( structures ): cations = df_annotations_MAIA [ ( df_annotations_MAIA [ \"name\" ] == name ) & ( df_annotations_MAIA [ \"structure\" ] == structure ) ] . cation . unique () for cation in sorted ( cations ): l_selected_lipids = [] for slice_index in self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ): # Find lipid location l_lipid_loc = ( self . _data . get_annotations () . index [ ( self . _data . get_annotations ()[ \"name\" ] == name ) & ( self . _data . get_annotations ()[ \"structure\" ] == structure ) & ( self . _data . get_annotations ()[ \"slice\" ] == slice_index ) & ( self . _data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) > 1 : logging . warning ( \"More than one lipid corresponds to the selection\" ) l_lipid_loc = [ l_lipid_loc [ - 1 ]] # If no lipid correspond to the selection, set to -1 if len ( l_lipid_loc ) == 0 : l_lipid_loc = [ - 1 ] # add lipid index for each slice l_selected_lipids . append ( l_lipid_loc [ 0 ]) # Get final lipid name lipid_string = name + \" \" + structure + \" \" + cation # If lipid is present in at least one slice if np . sum ( l_selected_lipids ) > - len ( self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ) ): # Build the list of mz boundaries for each peak and each index lll_lipid_bounds = [ [ [ ( float ( self . _data . get_annotations () . iloc [ index ][ \"min\" ]), float ( self . _data . get_annotations () . iloc [ index ][ \"max\" ]), ) ] if index != - 1 else None for index in [ lipid_1_index , - 1 , - 1 ] ] for lipid_1_index in l_selected_lipids ] # Compute 3D figures, selection is limited to one lipid name_lipid = lipid_string self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_expression_\" + str ( brain_1 ) + \"_\" + name_lipid + \"__\" , force_update = force_update , compute_function = self . compute_l_array_2D , ignore_arguments_naming = True , ll_t_bounds = lll_lipid_bounds , brain_1 = brain_1 , cache_flask = None , # No cache needed since launched at startup ) n_processed += 1 if n_processed >= 10 and sample : return None # Variable to signal everything has been computed self . _storage . dump_shelved_object ( \"figures/3D_page\" , \"arrays_expression_\" + str ( brain_1 ) + \"_computed\" , True ) def shelve_all_arrays_annotation ( self ): \"\"\"This functions precomputes and shelves the array of structure annotation used in a 3D representation of the brain (through self.compute_3D_volume_figure()), at different resolutions. Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. \"\"\" for decrease_dimensionality_factor in range ( 2 , 13 ): self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_annotation\" , force_update = False , compute_function = self . get_array_of_annotations , decrease_dimensionality_factor = decrease_dimensionality_factor , ) # Variable to signal everything has been computed self . _storage . dump_shelved_object ( \"figures/3D_page\" , \"arrays_annotation_computed\" , True )","title":"Figures"},{"location":"modules/figures/#modules.figures.Figures.__init__","text":"Initialize the Figures class. Parameters: Name Type Description Default maldi_data MaldiData MaldiData object, used to manipulate the raw MALDI data. required storage Storage Used to access the shelve database. required atlas Atlas Used to manipulate the objects coming from the Allen Brain Atlas. required scRNAseq ScRNAseq Used to manipulate the objects coming from the scRNAseq dataset. required sample bool If True, only a fraction of the precomputations are made (for debug). Default to False. False Source code in modules/figures.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 def __init__ ( self , maldi_data , storage , atlas , scRNAseq , sample = False ): \"\"\"Initialize the Figures class. Args: maldi_data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. storage (Storage): Used to access the shelve database. atlas (Atlas): Used to manipulate the objects coming from the Allen Brain Atlas. scRNAseq (ScRNAseq): Used to manipulate the objects coming from the scRNAseq dataset. sample (bool, optional): If True, only a fraction of the precomputations are made (for debug). Default to False. \"\"\" logging . info ( \"Initializing Figures object\" + logmem ()) # Attribute to easily access the maldi and allen brain atlas data self . _data = maldi_data self . _atlas = atlas self . _scRNAseq = scRNAseq # attribute to access the shelve database self . _storage = storage # Dic of normalization factors across slices for MAIA normalized lipids self . dic_normalization_factors = self . _storage . return_shelved_object ( \"figures/lipid_selection\" , \"dic_normalization_factors\" , force_update = False , compute_function = self . compute_normalization_factor_across_slices , cache_flask = None , # No cache since launched at startup ) # Check that treemaps has been computed already. If not, compute it and store it. if not self . _storage . check_shelved_object ( \"figures/atlas_page/3D\" , \"treemaps\" ): self . _storage . return_shelved_object ( \"figures/atlas_page/3D\" , \"treemaps\" , force_update = False , compute_function = self . compute_treemaps_figure , ), # Check that 3D slice figures have been computed already. If not, compute it and store it. for brain in [ \"brain_1\" , \"brain_2\" ]: if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"slices_3D_\" + brain ): self . _storage . return_shelved_object ( \"figures/3D_page\" , \"slices_3D\" , force_update = False , compute_function = self . compute_figure_slices_3D , brain = brain , ) # Check that the 3D root volume figure has been computed already. If not, compute it and # store it. if self . _storage . check_shelved_object ( \"figures/scRNAseq_page\" , \"scatter3D\" ): self . _storage . return_shelved_object ( \"figures/scRNAseq_page\" , \"scatter3D\" , force_update = False , compute_function = self . compute_scatter_3D , ) # Check that the 3D scatter plot for scRNAseq data has been computed already. If not, # compute it and store it. if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"volume_root\" ): self . _storage . return_shelved_object ( \"figures/3D_page\" , \"volume_root\" , force_update = False , compute_function = self . compute_3D_root_volume , ) # Check that the base figures for lipid/genes heatmap have been computed already. If not, # compute them and store them. if not self . _storage . check_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid_True\" ) or not self . _storage . check_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid_False\" ): self . _storage . return_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid\" , force_update = False , compute_function = self . compute_heatmap_lipid_genes , brain_1 = False , ), self . _storage . return_shelved_object ( \"figures/scRNAseq_page\" , \"base_heatmap_lipid\" , force_update = False , compute_function = self . compute_heatmap_lipid_genes , brain_1 = True , ), # Check that all basic figures in the load_slice page are present, if not, compute them if not self . _storage . check_shelved_object ( \"figures/load_page\" , \"arrays_basic_figures_computed\" ): self . shelve_arrays_basic_figures () # Check that the lipid distributions for all slices, and both brains, have been computed, if # not, compute them if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"arrays_expression_True_computed\" ): self . shelve_all_l_array_2D ( sample = sample , brain_1 = True ) if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"arrays_expression_False_computed\" ): self . shelve_all_l_array_2D ( sample = sample , brain_1 = False ) # Check that all arrays of annotations have been computed, if not, compute them if not self . _storage . check_shelved_object ( \"figures/3D_page\" , \"arrays_annotation_computed\" ): self . shelve_all_arrays_annotation () logging . info ( \"Figures object instantiated\" + logmem ())","title":"__init__()"},{"location":"modules/figures/#modules.figures.Figures.build_lipid_heatmap_from_image","text":"This function converts a numpy array into a base64 string, which can be returned directly, or itself be turned into a go.Image, which can be returned directly, or be turned into a Plotly Figure, which will be returned. Parameters: Name Type Description Default image np . ndarray A numpy array representing the image to be converted. Possibly with several channels. required return_base64_string bool If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. False draw bool If True, the user will have the possibility to draw on the resulting Plotly Figure. Defaults to False. False type_image string The type of the image to be converted to a base64 string. If image_array is in 3D, type must be RGB. If 4D, type must be RGBA. Else, no requirement (None). Defaults to None. None return_go_image bool If True, the go.Image is returned directly, before being integrated to a Plotly Figure. Defaults to False. False Returns: Type Description Depending on the inputted arguments, may either return a base64 string, a go.Image, or a Plotly Figure. Source code in modules/figures.py 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 def build_lipid_heatmap_from_image ( self , image , return_base64_string = False , draw = False , type_image = None , return_go_image = False , ): \"\"\"This function converts a numpy array into a base64 string, which can be returned directly, or itself be turned into a go.Image, which can be returned directly, or be turned into a Plotly Figure, which will be returned. Args: image (np.ndarray): A numpy array representing the image to be converted. Possibly with several channels. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. draw (bool, optional): If True, the user will have the possibility to draw on the resulting Plotly Figure. Defaults to False. type_image (string, optional): The type of the image to be converted to a base64 string. If image_array is in 3D, type must be RGB. If 4D, type must be RGBA. Else, no requirement (None). Defaults to None. return_go_image (bool, optional): If True, the go.Image is returned directly, before being integrated to a Plotly Figure. Defaults to False. Returns: Depending on the inputted arguments, may either return a base64 string, a go.Image, or a Plotly Figure. \"\"\" logging . info ( \"Converting image to string\" ) # Set optimize to False to gain computation time base64_string = convert_image_to_base64 ( image , type = type_image , overlay = None , transparent_zeros = True , optimize = False ) # Either return image directly if return_base64_string : return base64_string # Or compute heatmap as go image if needed logging . info ( \"Converting image to go image\" ) final_image = go . Image ( visible = True , source = base64_string , ) # Potentially return the go image directly if return_go_image : return final_image # Or build ploty graph fig = go . Figure ( final_image ) # Improve graph layout fig . update_layout ( margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), newshape = dict ( fillcolor = dic_colors [ \"blue\" ], opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ) ), xaxis = dict ( showgrid = False , zeroline = False ), yaxis = dict ( showgrid = False , zeroline = False ), # Do not specify height for now as plotly is buggued and resets if switching pages # height=500, ) fig . update_xaxes ( showticklabels = False ) fig . update_yaxes ( showticklabels = False ) fig . update ( layout_coloraxis_showscale = False ) # Set how the image should be annotated if draw : fig . update_layout ( dragmode = \"drawclosedpath\" ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" logging . info ( \"Returning figure\" ) return fig","title":"build_lipid_heatmap_from_image()"},{"location":"modules/figures/#modules.figures.Figures.compute_3D_root_volume","text":"This function is used to generate a go.Isosurface of the Allen Brain root structure, which will be used to enclose the display of lipid expression of other structures in the brain. Parameters: Name Type Description Default decrease_dimensionality_factor int Decrease the dimensionnality of the brain to display, to get a lighter output. Defaults to 7. 7 Returns: Type Description go . Isosurface A semi-transparent go.Isosurface of the Allen Brain root structure. Source code in modules/figures.py 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 def compute_3D_root_volume ( self , decrease_dimensionality_factor = 7 , differentiate_borders = False ): \"\"\"This function is used to generate a go.Isosurface of the Allen Brain root structure, which will be used to enclose the display of lipid expression of other structures in the brain. Args: decrease_dimensionality_factor (int, optional): Decrease the dimensionnality of the brain to display, to get a lighter output. Defaults to 7. Returns: (go.Isosurface): A semi-transparent go.Isosurface of the Allen Brain root structure. \"\"\" # Get array of annotations, which associate coordinate to id array_annotation_root = np . array ( self . _atlas . bg_atlas . annotation , dtype = np . int32 ) # Subsample array of annotation the same way array_atlas was subsampled array_annotation_root = array_annotation_root [ :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , ] # Bug correction for the last slice array_annotation_root = np . concatenate ( ( array_annotation_root , np . zeros (( 1 , array_annotation_root . shape [ 1 ], array_annotation_root . shape [ 2 ])), ) ) # Get the volume array array_atlas_borders_root = fill_array_borders ( array_annotation_root , differentiate_borders = differentiate_borders , color_near_borders = False , keep_structure_id = None , ) # Compute the 3D grid X_root , Y_root , Z_root = np . mgrid [ 0 : array_atlas_borders_root . shape [ 0 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders_root . shape [ 0 ] * 1 j , 0 : array_atlas_borders_root . shape [ 1 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders_root . shape [ 1 ] * 1 j , 0 : array_atlas_borders_root . shape [ 2 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders_root . shape [ 2 ] * 1 j , ] # Compute the plot brain_root_data = go . Isosurface ( x = X_root . flatten (), y = Y_root . flatten (), z = Z_root . flatten (), value = array_atlas_borders_root . flatten (), isomin =- 0.21 , isomax = 2.55 , opacity = 0.1 , # max opacity surface_count = 2 , colorscale = \"Blues\" , # colorscale, flatshading = True , showscale = False , ) return brain_root_data","title":"compute_3D_root_volume()"},{"location":"modules/figures/#modules.figures.Figures.compute_3D_volume_figure","text":"This figure computes a Plotly Figure containing a go.Volume object representing the expression of the requested lipids in the selected regions, interpolated between the slices. Lipid names are used to retrieve the expression data from the Shelve database. Parameters: Name Type Description Default set_progress Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. None ll_t_bounds list(list(tuple A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. [[(None, None)]] name_lipid_1 str Name of the first selected lipid. Defaults to \"\". '' name_lipid_2 str Name of the second selected lipid. Defaults to \"\". '' name_lipid_3 str Name of the third selected lipid. Defaults to \"\". '' set_id_regions set ( int ) A set containing the identifiers of the brain regions (at the very bottom of the hierarchy) in which lipid expression is requested. Defaults to None, corresponding to the whole brain. None decrease_dimensionality_factor int An integer used for subsampling the array of annotation, and therefore the resulting figure. The higher, the higher the subsampling. Needed as this is a very heavy plot. Defaults to 6. 6 cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None structure_guided_interpolation bool If True, the interpolation is done using the annotated structures. If False, the interpolation is done blindly. True return_interpolated_array bool If True, the interpolated array is returned. Else, the corresponding Plotly figure is returned. Defaults to False. False return_individual_slice_data bool If True, the individual slice data (not interpolated) is returned. False divider_radius int The inverse radius of the sphere used to do the interpolation. Defaults to 16. 16 brain_1 bool If True, the brain 1 data is used. Else, the brain 2 data is used. Defaults to False. False Returns: Type Description Depending on the value of return_interpolated_array and return_individual_slice_data, returns either the (not) interpolated array of expression of the requested lipids in the selected regions, or a Plotly Figure containing a go.Volume object representing the interpolated expression. Source code in modules/figures.py 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 def compute_3D_volume_figure ( self , set_progress = None , ll_t_bounds = [[( None , None )]], name_lipid_1 = \"\" , name_lipid_2 = \"\" , name_lipid_3 = \"\" , set_id_regions = None , decrease_dimensionality_factor = 6 , cache_flask = None , structure_guided_interpolation = True , return_interpolated_array = False , return_individual_slice_data = False , divider_radius = 16 , brain_1 = False , ): \"\"\"This figure computes a Plotly Figure containing a go.Volume object representing the expression of the requested lipids in the selected regions, interpolated between the slices. Lipid names are used to retrieve the expression data from the Shelve database. Args: set_progress: Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. name_lipid_1 (str, optional): Name of the first selected lipid. Defaults to \"\". name_lipid_2 (str, optional): Name of the second selected lipid. Defaults to \"\". name_lipid_3 (str, optional): Name of the third selected lipid. Defaults to \"\". set_id_regions (set(int), optional): A set containing the identifiers of the brain regions (at the very bottom of the hierarchy) in which lipid expression is requested. Defaults to None, corresponding to the whole brain. decrease_dimensionality_factor (int): An integer used for subsampling the array of annotation, and therefore the resulting figure. The higher, the higher the subsampling. Needed as this is a very heavy plot. Defaults to 6. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. structure_guided_interpolation (bool, optional): If True, the interpolation is done using the annotated structures. If False, the interpolation is done blindly. return_interpolated_array (bool): If True, the interpolated array is returned. Else, the corresponding Plotly figure is returned. Defaults to False. return_individual_slice_data (bool): If True, the individual slice data (not interpolated) is returned. divider_radius (int): The inverse radius of the sphere used to do the interpolation. Defaults to 16. brain_1 (bool): If True, the brain 1 data is used. Else, the brain 2 data is used. Defaults to False. Returns: Depending on the value of return_interpolated_array and return_individual_slice_data, returns either the (not) interpolated array of expression of the requested lipids in the selected regions, or a Plotly Figure containing a go.Volume object representing the interpolated expression. \"\"\" if return_interpolated_array and return_individual_slice_data : logging . warning ( \"Cannot return both interpolated and not interpolated array... Returning the\" \" individual slice data.\" ) logging . info ( \"Starting 3D volume computation\" ) if set_progress is not None : set_progress (( 10 , \"Loading array of annotations\" )) # Get subsampled array of annotations array_annotation = self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_annotation\" , force_update = False , compute_function = self . get_array_of_annotations , decrease_dimensionality_factor = decrease_dimensionality_factor , ) # Get subsampled array of borders for each region array_atlas_borders = np . zeros ( array_annotation . shape , dtype = np . float32 ) if set_id_regions is not None : list_id_regions = np . array ( list ( set_id_regions ), dtype = np . int64 ) else : list_id_regions = None if set_progress is not None : set_progress (( 10 , \"Computing brain borders\" )) # Shelving this function is useless as it takes less than 0.1s to compute after # first compilation array_atlas_borders = fill_array_borders ( array_annotation , keep_structure_id = list_id_regions , decrease_dimensionality_factor = decrease_dimensionality_factor , ) logging . info ( \"Computed basic structure array\" ) if set_progress is not None : set_progress (( 20 , \"Computing expression for each lipid\" )) # Get array of expression for each lipid ll_array_data = [ self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_expression_\" + str ( brain_1 ) + \"_\" + str ( name_lipid ) + \"__\" , force_update = False , ignore_arguments_naming = True , compute_function = self . compute_l_array_2D , ll_t_bounds = [[ l_t_bounds [ i ], None , None ] for l_t_bounds in ll_t_bounds ], brain_1 = brain_1 , cache_flask = cache_flask , ) for i , name_lipid in enumerate ([ name_lipid_1 , name_lipid_2 , name_lipid_3 ]) ] if set_progress is not None : set_progress (( 50 , \"Averaging expression for each lipid\" )) # Average array of expression over lipid l_array_data_avg = [] for slice_index in range ( len ( self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" )) ): n = 0 avg = 0 for i in range ( 3 ): # * number of lipids is hardcoded s = ll_array_data [ i ][ slice_index ] if s is None : s = 0 elif s . size == 1 : if np . isnan ( s ): s = 0 else : n += 1 avg += s # In case there's no data for the current slice, set the average to 0 if n == 0 : n = 1 l_array_data_avg . append ( avg / n ) logging . info ( \"Averaged expression over all lipids\" ) if set_progress is not None : set_progress (( 60 , \"Getting slice coordinates\" )) # Get the 3D array of expression and coordinates array_x , array_y , array_z , array_c = self . compute_array_coordinates_3D ( l_array_data_avg , high_res = False , brain_1 = brain_1 ) if return_individual_slice_data : return array_x , array_y , array_z , array_c logging . info ( \"Computed array of expression in original space\" ) if set_progress is not None : set_progress (( 70 , \"Filling a new brain with expression\" )) # Compute the rescaled array of expression for each slice averaged over projected lipids array_slices = np . copy ( array_atlas_borders ) array_for_avg = np . full_like ( array_atlas_borders , 1 ) array_x_scaled = array_x * 1000000 / self . _atlas . resolution / decrease_dimensionality_factor array_y_scaled = array_y * 1000000 / self . _atlas . resolution / decrease_dimensionality_factor array_z_scaled = array_z * 1000000 / self . _atlas . resolution / decrease_dimensionality_factor array_slices = fill_array_slices ( array_x_scaled , array_y_scaled , array_z_scaled , np . array ( array_c ), array_slices , array_for_avg , limit_value_inside =- 1.99999 , ) logging . info ( \"Filled basic structure array with array of expression\" ) # Get the corresponding coordinates X , Y , Z = np . mgrid [ 0 : array_atlas_borders . shape [ 0 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders . shape [ 0 ] * 1 j , 0 : array_atlas_borders . shape [ 1 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders . shape [ 1 ] * 1 j , 0 : array_atlas_borders . shape [ 2 ] / 1000 * 25 * decrease_dimensionality_factor : array_atlas_borders . shape [ 2 ] * 1 j , ] logging . info ( \"Built arrays of coordinates\" ) if set_id_regions is not None : x_min , x_max , y_min , y_max , z_min , z_max = crop_array ( array_annotation , list_id_regions ) array_annotation = array_annotation [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] array_slices = array_slices [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] X = X [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] Y = Y [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] Z = Z [ x_min : x_max + 1 , y_min : y_max + 1 , z_min : z_max + 1 ] logging . info ( \"Cropped the figure to only keep areas in which lipids are expressed\" ) if set_progress is not None : set_progress (( 70 , \"Interpolating expression\" )) # Compute an array containing the lipid expression interpolated for every voxel array_interpolated = fill_array_interpolation ( array_annotation , array_slices , divider_radius = 16 , limit_value_inside =- 1.99999 , structure_guided = structure_guided_interpolation , ) logging . info ( \"Finished interpolation between slices\" ) if return_interpolated_array : return array_interpolated if set_progress is not None : set_progress (( 80 , \"Building figure\" )) # Get root figure root_data = self . _storage . return_shelved_object ( \"figures/3D_page\" , \"volume_root\" , force_update = False , compute_function = self . compute_3D_root_volume , ) logging . info ( \"Building final figure\" ) # Build figure fig = go . Figure ( data = [ go . Volume ( x = X . flatten (), y = Y . flatten (), z = Z . flatten (), value = array_interpolated . flatten (), isomin = 0.01 , isomax = 1.5 , opacityscale = [ [ - 0.11 , 0.00 ], [ 0.01 , 0.0 ], [ 0.5 , 0.05 ], [ 2.5 , 0.7 ], ], surface_count = 10 , colorscale = \"viridis\" , ), root_data , ] ) # Hide grey background fig . update_layout ( margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" logging . info ( \"Done computing 3D volume figure\" ) if set_progress is not None : set_progress (( 90 , \"Returning figure\" )) return fig","title":"compute_3D_volume_figure()"},{"location":"modules/figures/#modules.figures.Figures.compute_array_basic_images","text":"This function computes and returns a three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. No spectral data is read in the process, as the arrays corresponding to the images are directly stored as tiff files in the dataset. Parameters: Name Type Description Default type_figure str To be chosen among \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\". Depending on the chosen type, the final array will correspond to either the original images (\"original_data\"), the warped and upscaled images (\"warped_data\"), the warped and upscaled images, whose pixels outside of annotations regions have been zero-ed out (\"projection_corrected\"), or the images from the Allen Brain atlas projected onto the same plane as the corresponding slice from the MALDI data (\"atlas\"). Default to \"warped_data\". 'warped_data' Returns: Type Description np . ndarray A three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. The first dimension corresponds to the slices, the second and third to the images themselves. Source code in modules/figures.py 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 def compute_array_basic_images ( self , type_figure = \"warped_data\" ): \"\"\"This function computes and returns a three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. No spectral data is read in the process, as the arrays corresponding to the images are directly stored as tiff files in the dataset. Args: type_figure (str, optional): To be chosen among \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\". Depending on the chosen type, the final array will correspond to either the original images (\"original_data\"), the warped and upscaled images (\"warped_data\"), the warped and upscaled images, whose pixels outside of annotations regions have been zero-ed out (\"projection_corrected\"), or the images from the Allen Brain atlas projected onto the same plane as the corresponding slice from the MALDI data (\"atlas\"). Default to \"warped_data\". Returns: (np.ndarray): A three-dimensional array representing all slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. The first dimension corresponds to the slices, the second and third to the images themselves. \"\"\" # Check for all array types if type_figure == \"original_data\" : array_images = self . _data . compute_padded_original_images () elif type_figure == \"warped_data\" : if self . _data . _sample_data : with np . load ( \"data_sample/tiff_files/warped_data.npz\" ) as handle : array_images = handle [ \"array_warped_data\" ] else : array_images = io . imread ( \"data/tiff_files/warped_data.tif\" ) elif type_figure == \"projection_corrected\" : array_images = self . _atlas . array_projection_corrected elif type_figure == \"atlas\" : ( array_projected_images_atlas , array_projected_simplified_id , ) = self . _storage . return_shelved_object ( \"atlas/atlas_objects\" , \"array_images_atlas\" , force_update = False , compute_function = self . _atlas . prepare_and_compute_array_images_atlas , zero_out_of_annotation = True , ) array_images = array_projected_images_atlas else : logging . warning ( 'The type of requested array \" {} \" does not exist.' . format ( type_figure )) return None # If the array is not uint8, convert it to gain space if array_images . dtype != np . uint8 : array_images = np . array ( array_images , dtype = np . uint8 ) return array_images","title":"compute_array_basic_images()"},{"location":"modules/figures/#modules.figures.Figures.compute_array_coordinates_3D","text":"This functions computes the list of coordinates and expression values for the voxels used in the 3D representation of the brain. Parameters: Name Type Description Default l_array_data list(np.ndarray A list of numpy arrays representing lipid expression for each slice of the dataset. required high_res bool If True, the computations made correspond to the warped/upscaled data. Defaults to False as this is a very heavy plot. False brain_1 bool If True, the returned list of arrays correspond to the brain 1 data. Else, to the brain 2 data. Defaults to True. True Returns: Type Description np . ndarray , np . ndarray , np . ndarray , np . ndarray 4 flat numpy arrays (3 for coordinates and 1 for expression). Source code in modules/figures.py 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 def compute_array_coordinates_3D ( self , l_array_data , high_res = False , brain_1 = True , ): \"\"\"This functions computes the list of coordinates and expression values for the voxels used in the 3D representation of the brain. Args: l_array_data (list(np.ndarray)): A list of numpy arrays representing lipid expression for each slice of the dataset. high_res (bool, optional): If True, the computations made correspond to the warped/upscaled data. Defaults to False as this is a very heavy plot. brain_1 (bool, optional): If True, the returned list of arrays correspond to the brain 1 data. Else, to the brain 2 data. Defaults to True. Returns: (np.ndarray, np.ndarray, np.ndarray, np.ndarray): 4 flat numpy arrays (3 for coordinates and 1 for expression). \"\"\" logging . info ( \"Starting computing 3D arrays\" + logmem ()) # Correct the indices for the potentially unused slices from brain 1 if brain_1 : slice_index_init = 0 slice_index_end = len ( self . _data . get_slice_list ( indices = \"brain_1\" )) else : slice_index_init = len ( self . _data . get_slice_list ( indices = \"brain_1\" )) slice_index_end = self . _data . get_slice_number () # get list of original coordinates for each slice if not high_res : l_coor = self . _atlas . l_original_coor [ slice_index_init : slice_index_end ] estimate = 400 * 400 else : estimate = 1311 * 918 l_coor = self . _atlas . array_coordinates_warped_data [ slice_index_init : slice_index_end ] # Initialize empty arrays with a large estimate for the orginal acquisition size max_size = estimate * ( slice_index_end - slice_index_init ) array_x = np . empty ( max_size , dtype = np . float32 ) array_y = np . empty ( max_size , dtype = np . float32 ) array_z = np . empty ( max_size , dtype = np . float32 ) array_c = np . empty ( max_size , dtype = np . int16 ) total_index = 0 logging . debug ( f \"Size array_x: { array_x . nbytes / 1024 / 1024 : .2f } \" ) logging . info ( \"Starting slice iteration\" + logmem ()) # get atlas shape and resolution reference_shape = self . _atlas . bg_atlas . reference . shape resolution = self . _atlas . resolution array_annotations = np . array ( self . _atlas . bg_atlas . annotation , dtype = np . int32 ) for slice_index in range ( 0 , len ( l_array_data ), 1 ): # Get the averaged expression data for the current slice array_data = l_array_data [ slice_index ] # If array_data is not an array but a 0 float, skip it if type ( array_data ) == float : continue # Remove pixels for which lipid expression is zero array_data_stripped = array_data . flatten () # array_data[array_data != 0].flatten() # Skip the current slice if expression is very sparse if len ( array_data_stripped ) < 10 or np . sum ( array_data_stripped ) < 1 : continue # Compute the percentile of expression to filter out lowly expressed pixels # Set to 0 for now, as no filtering is done percentile = 0 # np.percentile(array_data_stripped, 10) # Get the coordinates of the pixels in the ccfv3 coordinates = l_coor [ slice_index ] # coordinates_stripped = coordinates[array_data != 0] coordinates_stripped = coordinates . reshape ( - 1 , coordinates . shape [ - 1 ]) # Get the data as 4 arrays (3 for coordinates and 1 for expression) array_x , array_y , array_z , array_c , total_index = filter_voxels ( array_data_stripped . astype ( np . float32 ), coordinates_stripped , array_annotations , percentile , array_x , array_y , array_z , array_c , total_index , reference_shape , resolution , ) logging . info ( \"Slice \" + str ( slice_index ) + \" done\" + logmem ()) # Strip the arrays from the zeros array_x = array_x [: total_index ] array_y = array_y [: total_index ] array_z = array_z [: total_index ] # * Caution, array_c should be a list to work with Plotly array_c = array_c [: total_index ] . tolist () # Return the arrays for the 3D figure return array_x , array_y , array_z , array_c","title":"compute_array_coordinates_3D()"},{"location":"modules/figures/#modules.figures.Figures.compute_barplots_enrichment","text":"This functions computes two figures representing, in barplots, the lipid expression in the spots acquired using spatial scRNAseq experiments, as well as how it can be explained by an elastic net regression using gene expression as explaing factors. Parameters: Name Type Description Default brain_1 bool If True, the barplot will be displayed with the regression coefficients computed from for the first brain. False Returns: Type Description Plotly . Figure , Plotly . Figure , list ( str ), list ( str ) Two Plotly Figures containing each a go.Bar object representing the standardized lipid expression in the scRNAseq spots, and the elastic net regression coefficients for each lipid (bar). The two lists contain the corresponding names of the genes and lipids represented. Source code in modules/figures.py 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 def compute_barplots_enrichment ( self , brain_1 = False , idx_dot = None ): \"\"\"This functions computes two figures representing, in barplots, the lipid expression in the spots acquired using spatial scRNAseq experiments, as well as how it can be explained by an elastic net regression using gene expression as explaing factors. Args: brain_1 (bool, optional): If True, the barplot will be displayed with the regression coefficients computed from for the first brain. Returns: (Plotly.Figure, Plotly.Figure, list(str), list(str)): Two Plotly Figures containing each a go.Bar object representing the standardized lipid expression in the scRNAseq spots, and the elastic net regression coefficients for each lipid (bar). The two lists contain the corresponding names of the genes and lipids represented. \"\"\" logging . info ( \"Starting computing barplot for scRNAseq experiments\" + logmem ()) if brain_1 : x = self . _scRNAseq . l_name_lipids_brain_1 y = self . _scRNAseq . array_coef_brain_1 names = self . _scRNAseq . l_genes_brain_1 expression = self . _scRNAseq . array_exp_lipids_brain_1 l_score = self . _scRNAseq . l_score_brain_1 else : x = self . _scRNAseq . l_name_lipids_brain_2 y = self . _scRNAseq . array_coef_brain_2 names = self . _scRNAseq . l_genes_brain_2 expression = self . _scRNAseq . array_exp_lipids_brain_2 l_score = self . _scRNAseq . l_score_brain_2 # Turn expression into enrichment score expression = ( expression - np . mean ( expression , axis = 0 )) / np . std ( expression , axis = 0 ) # Take the average expression across all spots, or the expression in the selected spot if idx_dot is None : expression = np . mean ( expression , axis = 0 ) else : expression = expression [ idx_dot , :] # Sort lipids by enrichment index_sorted = np . argsort ( expression )[:: - 1 ] expression = expression [ index_sorted ] # Get arrays for plotting x = np . array ( x )[ index_sorted ] y = y [ index_sorted , :] l_score = np . array ( l_score )[ index_sorted ] # Limit to the 24 most expressed genes (in the most enriched lipid), # for only 24 colors are sharply distinguishable by naked eye index_sorted = np . argsort ( y [ 0 , :])[:: - 1 ] y = y [:, index_sorted [: 24 ]] names = np . array ( names )[ index_sorted [: 24 ]] # Normalize to 1 # y = (y.T / np.sum(abs(y), axis=1) * expression).T y = ( y . T / np . sum ( abs ( y ), axis = 1 )) . T # Incorporate score in the mix # y = np.vstack((y.T * l_score, (1 - l_score) * expression * np.ones((len(y),)))).T y = np . vstack (( y . T * l_score , ( 1 - l_score ) * 1.0 * np . ones (( len ( y ),)))) . T names = np . append ( names , \"Unexplained\" ) # Limit to 40 lipids for clarity x = x [: 40 ] y = y [: 40 , :] expression = expression [: 40 ] # Plot figure fig_lipids = go . Figure () fig_lipids . add_trace ( go . Bar ( x = x , y = expression , ) ) # Hide background fig_lipids . update_layout ( title_text = \"Lipid expression enrichment in selected spot (z-score)\" , title_x = 0.5 , barmode = \"relative\" , # margin=dict(t=0, r=0, b=0, l=0), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig_lipids . layout . template = \"plotly_dark\" fig_lipids . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_lipids . layout . paper_bgcolor = \"rgba(0,0,0,0)\" # Plot figure fig_genes = go . Figure () for idx , ( y_gene , name ) in enumerate ( zip ( y . T , names )): fig_genes . add_trace ( go . Bar ( x = x , y = abs ( y_gene ), name = name , marker_pattern_shape = [ \"+\" if t > 0 else \"-\" for t in y_gene ], # Doesn't work... marker_color = px . colors . qualitative . Dark24 [ idx ] if idx <= 23 else \"grey\" , hovertext = [ \" {:.2f} \" . format ( y [ idx_lipid , idx ] / np . sum ( abs ( y [ idx_lipid , :])) * 1.0 ) + \" (Fraction of (absolute) total elastic net coefficients)\" for idx_lipid in range ( len ( y )) ], ) ) # Hide background fig_genes . update_layout ( title_text = ( \"Elastic net coefficients, representing how lipid is explained by the corresponding\" \" gene\" ), title_x = 0.5 , barmode = \"relative\" , # margin=dict(t=0, r=0, b=0, l=0), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig_genes . layout . template = \"plotly_dark\" fig_genes . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_genes . layout . paper_bgcolor = \"rgba(0,0,0,0)\" return fig_lipids , fig_genes , names , x","title":"compute_barplots_enrichment()"},{"location":"modules/figures/#modules.figures.Figures.compute_clustergram_figure","text":"This function computes a Plotly Clustergram figure, allowing to cluster and compare the expression of all the MAIA-transformed lipids in the dataset in the selected regions. Parameters: Name Type Description Default set_progress Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. required cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. required l_selected_regions list ( int ) A list containing the identifiers of the brain regions (at the very bottom of the hierarchy) whose border must be annotated. required percentile int The percentile of average expression below which the lipids must be discarded (to get rid of low expression noise). Defaults to 90. 90 brain_1 bool If True, the brain 1 data is used. Else, the brain 2 data is used. Defaults to False. False Returns: Type Description go . Figure a Plotly Clustergram figure clustering and comparing the expression of all the MAIA-transformed lipids in the dataset in the selected regions. Source code in modules/figures.py 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 def compute_clustergram_figure ( self , set_progress , cache_flask , l_selected_regions , percentile = 90 , brain_1 = False , ): \"\"\"This function computes a Plotly Clustergram figure, allowing to cluster and compare the expression of all the MAIA-transformed lipids in the dataset in the selected regions. Args: set_progress: Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. l_selected_regions (list(int), optional): A list containing the identifiers of the brain regions (at the very bottom of the hierarchy) whose border must be annotated. percentile (int, optional): The percentile of average expression below which the lipids must be discarded (to get rid of low expression noise). Defaults to 90. brain_1 (bool): If True, the brain 1 data is used. Else, the brain 2 data is used. Defaults to False. Returns: (go.Figure): a Plotly Clustergram figure clustering and comparing the expression of all the MAIA-transformed lipids in the dataset in the selected regions. \"\"\" logging . info ( \"Starting computing clustergram figure\" ) # Memoize result as it's called everytime a filtering is done @cache_flask . memoize () def return_df_avg_lipids ( l_selected_regions ): dic_avg_lipids = {} l_slices = self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ) for slice_index in l_slices : # Display progress every 10 slices if slice_index % 10 == 0 : set_progress ( ( int ( slice_index / len ( l_slices ) * 100 ), \"Loading slice n\u00b0\" + str ( slice_index ), ) ) l_spectra = [] for region in l_selected_regions : long_region = self . _atlas . dic_acronym_name [ region ] if slice_index - 1 in self . _atlas . dic_existing_masks : if region in self . _atlas . dic_existing_masks [ slice_index - 1 ]: grah_scattergl_data = self . _atlas . get_projected_mask_and_spectrum ( slice_index - 1 , long_region , MAIA_correction = True )[ 1 ] l_spectra . append ( grah_scattergl_data ) else : l_spectra . append ( None ) else : raise Exception ( \"The masks have not been precomputed. Please precompute them before\" \" running this function.\" ) ll_idx_labels = global_lipid_index_store ( self . _data , slice_index - 1 , l_spectra ) logging . info ( \"Computing dictionnary for averaging slice \" + str ( slice_index )) # Compute average expression for each lipid and each selection set_lipids_idx = set () ll_lipids_idx = [] ll_avg_intensity = [] n_sel = len ( l_spectra ) for spectrum , l_idx_labels in zip ( l_spectra , ll_idx_labels ): if spectrum is not None : array_intensity_with_lipids = np . array ( spectrum , dtype = np . float32 )[ 1 , :] array_idx_labels = np . array ( l_idx_labels , dtype = np . int32 ) l_lipids_idx , l_avg_intensity = compute_avg_intensity_per_lipid ( array_intensity_with_lipids , array_idx_labels ) set_lipids_idx . update ( l_lipids_idx ) else : l_lipids_idx = None l_avg_intensity = None ll_lipids_idx . append ( l_lipids_idx ) ll_avg_intensity . append ( l_avg_intensity ) for i , ( l_lipids , l_avg_intensity ) in enumerate ( zip ( ll_lipids_idx , ll_avg_intensity ) ): if l_lipids is not None : for lipid , intensity in zip ( l_lipids , l_avg_intensity ): if lipid not in dic_avg_lipids : dic_avg_lipids [ lipid ] = [] for j in range ( n_sel ): dic_avg_lipids [ lipid ] . append ([]) dic_avg_lipids [ lipid ][ i ] . append ( intensity ) logging . info ( \"Averaging all lipid values across slices\" ) # Average intensity per slice for lipid in dic_avg_lipids : for i in range ( n_sel ): if len ( dic_avg_lipids [ lipid ][ i ]) > 0 : dic_avg_lipids [ lipid ][ i ] = np . mean ( dic_avg_lipids [ lipid ][ i ]) else : dic_avg_lipids [ lipid ][ i ] = 0 df_avg_intensity_lipids = pd . DataFrame . from_dict ( dic_avg_lipids , orient = \"index\" , columns = [ l_selected_regions [ i ] for i in range ( n_sel )], ) return df_avg_intensity_lipids df_avg_intensity_lipids = return_df_avg_lipids ( l_selected_regions ) logging . info ( \"Averaging done for all slices\" ) set_progress (( 90 , \"Loading data\" )) # Exclude very lowly expressed lipids df_min_expression = df_avg_intensity_lipids . min ( axis = 1 ) df_avg_intensity_lipids = df_avg_intensity_lipids [ df_min_expression > df_min_expression . quantile ( q = int ( percentile ) / 100 ) ] if len ( l_selected_regions ) > 1 : df_avg_intensity_lipids = df_avg_intensity_lipids . iloc [ ( df_avg_intensity_lipids . mean ( axis = 1 )) . argsort (), : ] else : df_avg_intensity_lipids . sort_values ( by = l_selected_regions [ 0 ], inplace = True ) logging . info ( \"Lowly expressed lipids excluded\" ) # Replace idx_lipids by actual name df_names = self . _data . get_annotations () df_avg_intensity_lipids . index = df_avg_intensity_lipids . index . map ( lambda idx : df_names . iloc [ idx ][ \"name\" ] + \"_\" + df_names . iloc [ idx ][ \"structure\" ] + \"_\" + df_names . iloc [ idx ][ \"cation\" ] ) logging . info ( \"Lipid indexes replaced by names\" ) logging . info ( \"Preparing plot\" ) # Plot fig_heatmap_lipids = Clustergram ( data = df_avg_intensity_lipids . to_numpy (), column_labels = df_avg_intensity_lipids . columns . to_list (), row_labels = df_avg_intensity_lipids . index . to_list (), hidden_labels = \"row\" if len ( df_avg_intensity_lipids . index . to_list ()) > 100 else None , color_map = \"Viridis\" , height = 800 , width = 1000 , display_ratio = [ 0.2 , 0.01 ], ) # Set background color to zero fig_heatmap_lipids . layout . template = \"plotly_dark\" fig_heatmap_lipids . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_heatmap_lipids . layout . paper_bgcolor = \"rgba(0,0,0,0)\" set_progress (( 100 , \"Returning figure\" )) logging . info ( \"Returning figure\" ) return fig_heatmap_lipids","title":"compute_clustergram_figure()"},{"location":"modules/figures/#modules.figures.Figures.compute_figure_basic_image","text":"This function computes and returns a figure representing slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. The data is read directly from the array computed in self.compute_array_basic_images(). Parameters: Name Type Description Default type_figure str To be chosen among \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\". Depending on the chosen type, the final figure will correspond to either the original images (\"original_data\"), the warped and upscaled images (\"warped_data\"), the warped and upscaled images, whose pixels outside of annotations regions have been zero-ed out (\"projection_corrected\"), or the images from the Allen Brain atlas projected onto the same plane as the corresponding slice from the MALDI data (\"atlas\"). required index_image int Index of the requested slice image. required plot_atlas_contours bool If True, the atlas contours annotation is superimposed with the slice image. Defaults to True. True only_contours bool If True, only output the atlas contours annotation. All the other arugments but plot_atlas_contours (which must be True) get ignored. Defaults to False. False draw bool If True, the figure can be drawed on (used for region selection, in page region_analysis). Defaults to False. False Returns: Type Description go . Figure A Plotly figure representing the requested slice image of the requested type. Source code in modules/figures.py 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 def compute_figure_basic_image ( self , type_figure , index_image , plot_atlas_contours = True , only_contours = False , draw = False ): \"\"\"This function computes and returns a figure representing slices from the maldi_data acquisition (TIC) or the corresponding image from the atlas. The data is read directly from the array computed in self.compute_array_basic_images(). Args: type_figure (str): To be chosen among \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\". Depending on the chosen type, the final figure will correspond to either the original images (\"original_data\"), the warped and upscaled images (\"warped_data\"), the warped and upscaled images, whose pixels outside of annotations regions have been zero-ed out (\"projection_corrected\"), or the images from the Allen Brain atlas projected onto the same plane as the corresponding slice from the MALDI data (\"atlas\"). index_image (int): Index of the requested slice image. plot_atlas_contours (bool, optional): If True, the atlas contours annotation is superimposed with the slice image. Defaults to True. only_contours (bool, optional): If True, only output the atlas contours annotation. All the other arugments but plot_atlas_contours (which must be True) get ignored. Defaults to False. draw (bool, optional): If True, the figure can be drawed on (used for region selection, in page region_analysis). Defaults to False. Returns: (go.Figure): A Plotly figure representing the requested slice image of the requested type. \"\"\" # If only boundaries is requested, force the computation of atlas contours if only_contours : plot_atlas_contours = True else : # Get array of images array_images = self . _storage . return_shelved_object ( \"figures/load_page\" , \"array_basic_images\" , force_update = False , compute_function = self . compute_array_basic_images , type_figure = type_figure , ) # Get image at specified index array_image = array_images [ index_image ] # Add the contours if requested if plot_atlas_contours : array_image_atlas = self . _atlas . list_projected_atlas_borders_arrays [ index_image ] else : array_image_atlas = None # Create figure fig = go . Figure () # Compute image from our data if not only the atlas annotations are requested if not only_contours : fig . add_trace ( go . Image ( visible = True , source = convert_image_to_base64 ( array_image , overlay = array_image_atlas , transparent_zeros = True ), hoverinfo = \"none\" , ) ) # Add the labels only if it's not a simple annotation illustration # fig.update_xaxes( # title_text=self._atlas.bg_atlas.space.axis_labels[0][1], title_standoff=0 # ) else : fig . add_trace ( go . Image ( visible = True , source = convert_image_to_base64 ( array_image_atlas , optimize = True , binary = True , type = \"RGBA\" , decrease_resolution_factor = 8 , ), hoverinfo = \"none\" , ) ) # Improve layout fig . update_xaxes ( showticklabels = False ) fig . update_yaxes ( showticklabels = False ) fig . update_layout ( margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), xaxis = dict ( showgrid = False , zeroline = False ), yaxis = dict ( showgrid = False , zeroline = False ), template = \"plotly_dark\" , paper_bgcolor = \"rgba(0,0,0,0)\" , plot_bgcolor = \"rgba(0,0,0,0)\" , ) if draw : fig . update_layout ( dragmode = \"drawclosedpath\" , newshape = dict ( fillcolor = l_colors [ 0 ], opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ) ), autosize = True , ) return fig","title":"compute_figure_basic_image()"},{"location":"modules/figures/#modules.figures.Figures.compute_figure_slices_3D","text":"This function computes and returns a figure representing the slices from the maldi data in 3D. Parameters: Name Type Description Default reduce_resolution_factor int Divides (reduce) the initial resolution of the data. Needed as the resulting figure can be very heavy. Defaults to 20. 20 brain str Name of the brain to be used. Defaults to 'brain_1'. 'brain_1' Returns: Type Description go . Figure A Plotly figure representing the slices from the MALDI acquisitions in 3D. Source code in modules/figures.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 def compute_figure_slices_3D ( self , reduce_resolution_factor = 20 , brain = \"brain_1\" ): \"\"\"This function computes and returns a figure representing the slices from the maldi data in 3D. Args: reduce_resolution_factor (int, optional): Divides (reduce) the initial resolution of the data. Needed as the resulting figure can be very heavy. Defaults to 20. brain (str, optional): Name of the brain to be used. Defaults to 'brain_1'. Returns: (go.Figure): A Plotly figure representing the slices from the MALDI acquisitions in 3D. \"\"\" # Get transform parameters (a,u,v) for each slice l_transform_parameters = self . _storage . return_shelved_object ( \"atlas/atlas_objects\" , \"l_transform_parameters\" , force_update = False , compute_function = self . _atlas . compute_projection_parameters , ) # Reduce resolution of the slices new_dims = [] n_slices = self . _atlas . array_coordinates_warped_data . shape [ 0 ] d1 = self . _atlas . array_coordinates_warped_data . shape [ 1 ] d2 = self . _atlas . array_coordinates_warped_data . shape [ 2 ] for original_length , new_length in zip ( self . _atlas . array_projection_corrected . shape , ( n_slices , int ( round ( d1 / reduce_resolution_factor )), int ( round ( d2 / reduce_resolution_factor )), ), ): new_dims . append ( np . linspace ( 0 , original_length - 1 , new_length )) coords = np . meshgrid ( * new_dims , indexing = \"ij\" ) array_projection_small = map_coordinates ( self . _atlas . array_projection_corrected , coords ) # Build Figure, with several frames as it will be slidable fig = go . Figure ( frames = [ go . Frame ( data = self . get_surface ( slice_index - 1 , l_transform_parameters , array_projection_small , reduce_resolution_factor , ), name = str ( i + 1 ), ) for i , slice_index in enumerate ( self . _data . get_slice_list ( brain )) ] ) fig . add_trace ( self . get_surface ( self . _data . get_slice_list ( brain )[ 0 ] - 1 , l_transform_parameters , array_projection_small , reduce_resolution_factor , ) ) # Add a slider def frame_args ( duration ): return { \"frame\" : { \"duration\" : duration }, \"mode\" : \"immediate\" , \"fromcurrent\" : True , \"transition\" : { \"duration\" : duration , \"easing\" : \"linear\" }, } sliders = [ { \"pad\" : { \"b\" : 5 , \"t\" : 10 }, \"len\" : 0.9 , \"x\" : 0.05 , \"y\" : 0 , \"steps\" : [ { \"args\" : [[ f . name ], frame_args ( 0 )], \"label\" : str ( k ), \"method\" : \"animate\" , } for k , f in enumerate ( fig . frames ) ], \"currentvalue\" : { \"visible\" : False , }, } ] # Layout fig . update_layout ( scene = dict ( aspectratio = dict ( x = 1.5 , y = 1 , z = 1 ), yaxis = dict ( range = [ 0.0 , 0.35 ], autorange = False , backgroundcolor = \"rgba(0,0,0,0)\" , color = \"grey\" , gridcolor = \"grey\" , ), zaxis = dict ( range = [ 0.2 , - 0.02 ], autorange = False , backgroundcolor = \"rgba(0,0,0,0)\" , color = \"grey\" , gridcolor = \"grey\" , ), xaxis = dict ( range = [ 0.0 , 0.35 ], autorange = False , backgroundcolor = \"rgba(0,0,0,0)\" , color = \"grey\" , gridcolor = \"grey\" , ), ), margin = dict ( t = 0 , r = 0 , b = 0 , l = 0 ), template = \"plotly_dark\" , sliders = sliders , ) # No display of tick labels as they're wrong anyway fig . update_layout ( scene = dict ( xaxis = dict ( showticklabels = False ), yaxis = dict ( showticklabels = False ), zaxis = dict ( showticklabels = False ), ), paper_bgcolor = \"rgba(0,0,0,0.)\" , plot_bgcolor = \"rgba(0,0,0,0.)\" , ) return fig","title":"compute_figure_slices_3D()"},{"location":"modules/figures/#modules.figures.Figures.compute_heatmap_lipid_genes","text":"This functions computes a heatmap representing, on the left side, the expression of a given lipid in the (low-resolution, interpolated) MALDI data, and the right side, the expressions of the selected genes (in l_genes) in the scRNAseq experiments from the molecular atlas data. Parameters: Name Type Description Default lipid str The name of the lipid to be displayed. If None, the most expressed lipid will be displayed. Defaults to None. None l_genes list The list of gene names to be displayed. If None, the three most expressed genes will be displayed. Defaults to None. None initial_frame (int The frame on which the slider is initialized. 5 brain_1 bool If True, the heatmap will be computed with the data coming from the first brain. Else, from the 2nd brain. Defaults to False. False set_progress Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. None Returns: Type Description Plotly . Figure A Plotly Figure containing a go.Heatmap object representing the expression of the selected lipid and genes. Source code in modules/figures.py 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 2599 2600 2601 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 2645 2646 2647 2648 2649 2650 2651 2652 def compute_heatmap_lipid_genes ( self , lipid = None , l_genes = None , initial_frame = 5 , brain_1 = False , set_progress = None , ): \"\"\"This functions computes a heatmap representing, on the left side, the expression of a given lipid in the (low-resolution, interpolated) MALDI data, and the right side, the expressions of the selected genes (in l_genes) in the scRNAseq experiments from the molecular atlas data. Args: lipid (str): The name of the lipid to be displayed. If None, the most expressed lipid will be displayed. Defaults to None. l_genes (list): The list of gene names to be displayed. If None, the three most expressed genes will be displayed. Defaults to None. initial_frame (int, optional): The frame on which the slider is initialized. brain_1 (bool, optional): If True, the heatmap will be computed with the data coming from the first brain. Else, from the 2nd brain. Defaults to False. set_progress: Used as part of the Plotly long callbacks, to indicate the progress of the computation in the corresponding progress bar. Returns: (Plotly.Figure): A Plotly Figure containing a go.Heatmap object representing the expression of the selected lipid and genes. \"\"\" logging . info ( \"Starting computing heatmap for scRNAseq experiments\" + logmem ()) if set_progress is not None : set_progress (( 5 , \"Loading data\" )) if brain_1 : x = self . _scRNAseq . l_name_lipids_brain_1 y = self . _scRNAseq . array_coef_brain_1 name_genes = self . _scRNAseq . l_genes_brain_1 name_lipids = self . _scRNAseq . l_name_lipids_brain_1 array_lipids = self . _scRNAseq . array_exp_lipids_brain_1 array_genes = self . _scRNAseq . array_exp_genes_brain_1 else : x = self . _scRNAseq . l_name_lipids_brain_2 y = self . _scRNAseq . array_coef_brain_2 name_genes = self . _scRNAseq . l_genes_brain_2 name_lipids = self . _scRNAseq . l_name_lipids_brain_2 array_lipids = self . _scRNAseq . array_exp_lipids_brain_2 array_genes = self . _scRNAseq . array_exp_genes_brain_2 # Get the most expressed lipid and genes if not provided if lipid is None and l_genes is None : expression = np . mean ( array_lipids , axis = 0 ) index_sorted = np . argsort ( expression )[:: - 1 ] expression = expression [ index_sorted ] lipids = np . array ( x )[ index_sorted ] y_sorted = y [ index_sorted , :] index_sorted = np . argsort ( y_sorted [ 0 , :])[:: - 1 ] y_sorted = y_sorted [:, index_sorted ] genes = np . array ( name_genes )[ index_sorted ] lipid = lipids [ 0 ] l_genes = genes [: 3 ] # Get coordinates x = self . _scRNAseq . xmol y = - self . _scRNAseq . ymol z = self . _scRNAseq . zmol # Get idx lipid and genes if lipid is not None : idx_lipid = list ( name_lipids ) . index ( lipid ) else : idx_lipid = None l_idx_genes_with_None = [ list ( name_genes ) . index ( gene ) if gene is not None else None for gene in l_genes ] l_idx_genes = [ idx_gene for idx_gene in l_idx_genes_with_None if idx_gene is not None ] # Build grids on which the data will be interpolated x_domain = np . arange ( np . min ( x ), np . max ( x ), 0.5 ) y_domain = np . arange ( np . min ( y ), np . max ( y ), 0.1 ) z_domain = np . arange ( np . min ( z ), np . max ( z ), 0.1 ) x_grid , y_grid , z_grid = np . meshgrid ( x_domain , y_domain , z_domain , indexing = \"ij\" ) if set_progress is not None : set_progress (( 15 , \"Preparing interpolation\" )) # Build data from interpolation since sampling is irregular if idx_lipid is not None : grid_lipid = griddata ( np . vstack (( x , y , z )) . T , array_lipids [:, idx_lipid ], ( x_grid , y_grid , z_grid ), method = \"linear\" , ) else : grid_lipid = None if len ( l_idx_genes ) == 1 : grid_genes = griddata ( np . vstack (( x , y , z )) . T , array_genes [:, l_idx_genes [ 0 ]], ( x_grid , y_grid , z_grid ), method = \"linear\" , ) elif len ( l_idx_genes ) > 1 : grid_genes = np . moveaxis ( np . stack ( [ griddata ( np . vstack (( x , y , z )) . T , array_genes [:, idx_genes ], ( x_grid , y_grid , z_grid ), method = \"linear\" , ) if idx_genes is not None else np . zeros_like ( x_grid ) for idx_genes in l_idx_genes_with_None ] ), 0 , - 1 , ) else : grid_genes = None if set_progress is not None : set_progress (( 75 , \"Finished interpolation... Building figure\" )) fig = make_subplots ( 1 , 2 ) # Build Figure, with several frames as it will be slidable if grid_lipid is not None : for i in range ( 0 , grid_lipid . shape [ 0 ], 1 ): fig . add_heatmap ( z = grid_lipid [ i , :, :], row = 1 , col = 1 , colorscale = \"Viridis\" , visible = True if i == initial_frame else False , showscale = False , ) if grid_genes is not None : if len ( grid_genes . shape ) == 3 : for i in range ( 0 , grid_genes . shape [ 0 ], 1 ): fig . add_heatmap ( z = grid_genes [ i , :, :], row = 1 , col = 2 , colorscale = \"Viridis\" , visible = True if i == initial_frame else False , showscale = False , ) elif len ( grid_genes . shape ) == 4 : for i in range ( 0 , grid_genes . shape [ 0 ], 1 ): fig . add_image ( z = grid_genes [ i , :, :, :], row = 1 , col = 2 , visible = True if i == initial_frame else False , ) if grid_genes is not None or grid_lipid is not None : steps = [] for i in range ( grid_lipid . shape [ 0 ]): step = dict ( method = \"restyle\" , args = [ \"visible\" , [ False ] * len ( fig . data )], label = str ( i ), ) if grid_lipid is not None and grid_genes is not None : step [ \"args\" ][ 1 ][ i ] = True step [ \"args\" ][ 1 ][ i + grid_lipid . shape [ 0 ]] = True elif grid_lipid is not None or grid_genes is not None : step [ \"args\" ][ 1 ][ i ] = True steps . append ( step ) sliders = [ dict ( active = initial_frame , steps = steps , pad = { \"b\" : 5 , \"t\" : 10 }, len = 0.9 , x = 0.05 , y = 0.0 , currentvalue = { \"visible\" : False , }, ) ] # Layout fig . update_layout ( title_text = \"Comparison between lipid and gene expression\" , title_x = 0.5 , title_y = 0.98 , margin = dict ( t = 20 , r = 20 , b = 20 , l = 20 ), template = \"plotly_dark\" , sliders = sliders , ) # No display of tick labels as they're wrong anyway fig . update_layout ( scene = dict ( xaxis = dict ( showticklabels = False ), yaxis = dict ( showticklabels = False ), ), paper_bgcolor = \"rgba(0,0,0,0.)\" , plot_bgcolor = \"rgba(0,0,0,0.)\" , yaxis_scaleanchor = \"x\" , ) # Reverse y axis if Image has been used if grid_genes is not None : if len ( grid_genes . shape ) == 4 : fig . update_yaxes ( autorange = True , row = 1 , col = 2 ) # Remove tick labels fig . update_xaxes ( showticklabels = False ) # Hide x axis ticks fig . update_yaxes ( showticklabels = False ) # Hide y axis ticks if set_progress is not None : set_progress (( 90 , \"Returning figure\" )) return fig","title":"compute_heatmap_lipid_genes()"},{"location":"modules/figures/#modules.figures.Figures.compute_heatmap_per_lipid_selection","text":"This function is very similar to compute_heatmap_per_mz, but it takes a list of lipid boundaries, possibly along with lipid names, instead of just two boundaries. It returns a heatmap of the sum of expression of the requested lipids in the slice. Parameters: Name Type Description Default slice_index int The index of the requested slice. required ll_t_bounds list(list(tuple A list of lists of lipid boundaries (tuples). The first list is used to separate image channels (although this is not used in the function). The second list is used to separate lipid. required normalize bool If True, and the lipid has been MAIA transformed (and is provided with the parameter lipid_name) and apply_transform is True, the resulting array is normalized according to a factor computed across all slice. If MAIA has not been applied to the current selection or apply_transform is False, it is normalized according to the 99th percentile. Else, it is not normalized. Defaults to True. True projected_image bool If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. True apply_transform bool If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. False ll_lipid_names list ( list ( int )) List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. None return_base64_string bool If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. False cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description Depending on the value return_base64_string, may either return a base64 string, or a Plotly Figure. Source code in modules/figures.py 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 def compute_heatmap_per_lipid_selection ( self , slice_index , ll_t_bounds , normalize = True , projected_image = True , apply_transform = False , ll_lipid_names = None , return_base64_string = False , cache_flask = None , ): \"\"\"This function is very similar to compute_heatmap_per_mz, but it takes a list of lipid boundaries, possibly along with lipid names, instead of just two boundaries. It returns a heatmap of the sum of expression of the requested lipids in the slice. Args: slice_index (int): The index of the requested slice. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels (although this is not used in the function). The second list is used to separate lipid. normalize (bool, optional): If True, and the lipid has been MAIA transformed (and is provided with the parameter lipid_name) and apply_transform is True, the resulting array is normalized according to a factor computed across all slice. If MAIA has not been applied to the current selection or apply_transform is False, it is normalized according to the 99th percentile. Else, it is not normalized. Defaults to True. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. ll_lipid_names (list(list(int)), optional): List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the value return_base64_string, may either return a base64 string, or a Plotly Figure. \"\"\" logging . info ( \"Compute heatmap per lipid selection\" + str ( ll_t_bounds )) # Start from empty image and add selected lipids # * Caution: array must be int, float gets badly converted afterwards image = np . zeros ( self . _atlas . image_shape , dtype = np . int32 ) # Build empty lipid names if not provided if ll_lipid_names is None : ll_lipid_names = [[ \"\" for y in l_t_bounds ] for l_t_bounds in ll_t_bounds ] # Loop over channels for l_t_bounds , l_lipid_names in zip ( ll_t_bounds , ll_lipid_names ): if l_t_bounds is not None : # Loop over lipids for boundaries , lipid_name in zip ( l_t_bounds , l_lipid_names ): if boundaries is not None : ( lb_mz , hb_mz ) = boundaries # Cmpute expression image per lipid image_temp = self . compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , normalize = normalize , projected_image = projected_image , apply_transform = apply_transform , lipid_name = lipid_name , cache_flask = cache_flask , ) image += image_temp # Compute corresponding figure fig = self . build_lipid_heatmap_from_image ( image , return_base64_string = return_base64_string ) return fig","title":"compute_heatmap_per_lipid_selection()"},{"location":"modules/figures/#modules.figures.Figures.compute_heatmap_per_mz","text":"This function takes two boundaries and a slice index, and returns a heatmap of the lipid expressed in the slice whose m/z is between the two boundaries. Parameters: Name Type Description Default slice_index int The index of the requested slice. required lb_mz float The lower m/z boundary. Defaults to None. None hb_mz float The higher m/z boundary. Defaults to None. None draw bool If True, the user will have the possibility to draw on the resulting Plotly Figure. Defaults to False. False projected_image bool If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. True return_base64_string bool If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. False cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description Depending on the value return_base64_string, may either return a base64 string, or a Plotly Figure. Source code in modules/figures.py 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 def compute_heatmap_per_mz ( self , slice_index , lb_mz = None , hb_mz = None , draw = False , projected_image = True , return_base64_string = False , cache_flask = None , ): \"\"\"This function takes two boundaries and a slice index, and returns a heatmap of the lipid expressed in the slice whose m/z is between the two boundaries. Args: slice_index (int): The index of the requested slice. lb_mz (float, optional): The lower m/z boundary. Defaults to None. hb_mz (float, optional): The higher m/z boundary. Defaults to None. draw (bool, optional): If True, the user will have the possibility to draw on the resulting Plotly Figure. Defaults to False. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the value return_base64_string, may either return a base64 string, or a Plotly Figure. \"\"\" logging . info ( \"Starting figure computation, from mz boundaries\" ) # Upper bound lower than the lowest m/z value and higher that the highest m/z value if lb_mz is None : lb_mz = 200 if hb_mz is None : hb_mz = 1800 logging . info ( \"Getting image array\" ) # Compute image with given bounds image = self . compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , projected_image = projected_image , cache_flask = cache_flask , ) # Compute corresponding figure fig = self . build_lipid_heatmap_from_image ( image , return_base64_string = return_base64_string , draw = draw ) return fig","title":"compute_heatmap_per_mz()"},{"location":"modules/figures/#modules.figures.Figures.compute_image_per_lipid","text":"This function allows to query the MALDI data to extract an image in the form of a Numpy array representing the intensity of the lipid peaking between the values lb_mz and hb_mz in the spectral data, for the slice slice_index. Parameters: Name Type Description Default slice_index int Index of the requested slice. required lb_mz float Lower boundary for the spectral data to query. required hb_mz float Higher boundary for the spectral data to query. required RGB_format bool If True, the values in the array are between 0 and 255, given that the data has been normalized beforehand. Else, between 0 and 1. This parameter only makes sense if the data has been normalized beforehand. Defaults to True. True normalize bool If True, and the lipid has been MAIA transformed (and is provided with the parameter lipid_name) and apply_transform is True, the resulting array is normalized according to a factor computed across all slice. If MAIA has not been applied to the current selection or apply_transform is False, it is normalized according to the 99th percentile. Else, it is not normalized. Defaults to True. True log bool If True, the resulting array is log-transformed. This is useful in case of low expression. Defaults to False. False projected_image bool If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. True apply_transform bool If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. False lipid_name str Name of the lipid that must be MAIA-transformed, if apply_transform and normalize are True. Defaults to \"\". '' cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description np . ndarray An image (in the form of a numpy array) representing the intensity of the lipid peaking between the values lb_mz and hb_mz in the spectral data, for the slice slice_index. Source code in modules/figures.py 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 def compute_image_per_lipid ( self , slice_index , lb_mz , hb_mz , RGB_format = True , normalize = True , log = False , projected_image = True , apply_transform = False , lipid_name = \"\" , cache_flask = None , ): \"\"\"This function allows to query the MALDI data to extract an image in the form of a Numpy array representing the intensity of the lipid peaking between the values lb_mz and hb_mz in the spectral data, for the slice slice_index. Args: slice_index (int): Index of the requested slice. lb_mz (float): Lower boundary for the spectral data to query. hb_mz (float): Higher boundary for the spectral data to query. RGB_format (bool, optional): If True, the values in the array are between 0 and 255, given that the data has been normalized beforehand. Else, between 0 and 1. This parameter only makes sense if the data has been normalized beforehand. Defaults to True. normalize (bool, optional): If True, and the lipid has been MAIA transformed (and is provided with the parameter lipid_name) and apply_transform is True, the resulting array is normalized according to a factor computed across all slice. If MAIA has not been applied to the current selection or apply_transform is False, it is normalized according to the 99th percentile. Else, it is not normalized. Defaults to True. log (bool, optional): If True, the resulting array is log-transformed. This is useful in case of low expression. Defaults to False. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. lipid_name (str, optional): Name of the lipid that must be MAIA-transformed, if apply_transform and normalize are True. Defaults to \"\". cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (np.ndarray): An image (in the form of a numpy array) representing the intensity of the lipid peaking between the values lb_mz and hb_mz in the spectral data, for the slice slice_index. \"\"\" logging . info ( \"Entering compute_image_per_lipid\" ) # Get image from raw mass spec data image = compute_thread_safe_function ( compute_image_using_index_and_image_lookup , cache_flask , self . _data , slice_index , lb_mz , hb_mz , self . _data . get_array_spectra ( slice_index ), self . _data . get_array_lookup_pixels ( slice_index ), self . _data . get_image_shape ( slice_index ), self . _data . get_array_lookup_mz ( slice_index ), self . _data . get_array_cumulated_lookup_mz_image ( slice_index ), self . _data . get_divider_lookup ( slice_index ), self . _data . get_array_peaks_transformed_lipids ( slice_index ), self . _data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), apply_transform = apply_transform , ) # Log-transform the image if requested if log : image = np . log ( image + 1 ) # In case of bug, return None if image is None : return None # Normalize the image if requested if normalize : # Normalize across slice if the lipid has been MAIA transformed if ( lipid_name , self . _data . is_brain_1 ( slice_index ), ) in self . dic_normalization_factors and apply_transform : perc = self . dic_normalization_factors [ ( lipid_name , self . _data . is_brain_1 ( slice_index )) ] logging . info ( \"Normalization made with respect to percentile computed across all slices.\" ) else : # Normalize by 99 percentile perc = np . percentile ( image , 99.0 ) if perc == 0 : perc = np . max ( image ) if perc == 0 : perc = 1 image = image / perc image = np . clip ( 0 , 1 , image ) # Turn to RGB format if requested if RGB_format : image *= 255 # Change dtype if normalized and RGB to save space if normalize and RGB_format : image = np . round ( image ) . astype ( np . uint8 ) # Project image into cleaned and higher resolution version if projected_image : image = project_image ( slice_index , image , self . _atlas . array_projection_correspondence_corrected ) return image","title":"compute_image_per_lipid()"},{"location":"modules/figures/#modules.figures.Figures.compute_l_array_2D","text":"This function is used to get the list of expression per slice for all slices for the computation of the 3D brain volume. Parameters: Name Type Description Default ll_t_bounds list(list(tuple A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. required normalize_independently bool If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. True high_res bool If True, the returned list of arrays correspond to the warped/upscaled data. Defaults to False as this is a very heavy plot. False brain_1 bool If True, the returned list of arrays correspond to the brain 1 data. Else, to the brain 2 data. Defaults to True. True cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description list ( np . ndarray ) A list of numpy arrays representing the expression of the requested lipids (through ll_t_bounds) for each slice. Source code in modules/figures.py 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 def compute_l_array_2D ( self , ll_t_bounds , normalize_independently = True , high_res = False , brain_1 = True , cache_flask = None , ): \"\"\"This function is used to get the list of expression per slice for all slices for the computation of the 3D brain volume. Args: ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. normalize_independently (bool, optional): If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. high_res (bool, optional): If True, the returned list of arrays correspond to the warped/upscaled data. Defaults to False as this is a very heavy plot. brain_1 (bool, optional): If True, the returned list of arrays correspond to the brain 1 data. Else, to the brain 2 data. Defaults to True. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (list(np.ndarray)): A list of numpy arrays representing the expression of the requested lipids (through ll_t_bounds) for each slice. \"\"\" l_array_data = [] # Correct the indices for the potentially unused slices from brain 1 if brain_1 : slice_index_offset = 0 else : slice_index_offset = len ( self . _data . get_slice_list ( indices = \"brain_1\" )) # Loop over slices and compute the expression of the requested lipids for slice_index in range ( len ( ll_t_bounds )): if ll_t_bounds [ slice_index ] != [ None , None , None ]: # Get the data as an expression image per lipid array_data = self . compute_rgb_array_per_lipid_selection ( slice_index + 1 + slice_index_offset , ll_t_bounds [ slice_index ], normalize_independently = normalize_independently , projected_image = high_res , log = False , apply_transform = True , cache_flask = cache_flask , ) # Sum array colors (i.e. lipids) array_data = np . sum ( array_data , axis =- 1 ) else : array_data = None # Append data to l_array_data l_array_data . append ( np . array ( array_data , dtype = np . float16 )) # float16 to gain space return l_array_data","title":"compute_l_array_2D()"},{"location":"modules/figures/#modules.figures.Figures.compute_normalization_factor_across_slices","text":"This function computes a dictionnary of normalization factors (used for MAIA-transformed lipids) across all slices (99th percentile of expression). Parameters: Name Type Description Default cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description dict A dictionnary associating, for each MAIA-transformed lipid name, the 99th percentile of the intensity across all slices. Source code in modules/figures.py 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 def compute_normalization_factor_across_slices ( self , cache_flask = None ): \"\"\"This function computes a dictionnary of normalization factors (used for MAIA-transformed lipids) across all slices (99th percentile of expression). Args: cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (dict): A dictionnary associating, for each MAIA-transformed lipid name, the 99th percentile of the intensity across all slices. \"\"\" logging . info ( \"Compute normalization factor across slices for MAIA transformed lipids...\" + \" It may takes a while\" ) # Dictionnnary that will contain the percentile across all slices of a given brain dic_max_percentile = {} # Function to compute the percentile across all slices def _compute_percentile_across_slices ( name , structure , cation , brain_1 ): max_perc = 0 lipid_string = \"\" for slice_index in self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ): # Find lipid location l_lipid_loc = ( self . _data . get_annotations () . index [ ( self . _data . get_annotations ()[ \"name\" ] == name ) & ( self . _data . get_annotations ()[ \"structure\" ] == structure ) & ( self . _data . get_annotations ()[ \"slice\" ] == slice_index ) & ( self . _data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) >= 1 : index = l_lipid_loc [ - 1 ] # get final lipid name lipid_string = name + \"_\" + structure + \"_\" + cation # get lipid bounds lb_mz = float ( self . _data . get_annotations () . iloc [ index ][ \"min\" ]) hb_mz = float ( self . _data . get_annotations () . iloc [ index ][ \"max\" ]) # Get corresponding image image = compute_thread_safe_function ( compute_image_using_index_and_image_lookup , cache_flask , self . _data , slice_index , lb_mz , hb_mz , self . _data . get_array_spectra ( slice_index ), self . _data . get_array_lookup_pixels ( slice_index ), self . _data . get_image_shape ( slice_index ), self . _data . get_array_lookup_mz ( slice_index ), self . _data . get_array_cumulated_lookup_mz_image ( slice_index ), self . _data . get_divider_lookup ( slice_index ), self . _data . get_array_peaks_transformed_lipids ( slice_index ), self . _data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), apply_transform = False , ) # Check 99th percentile for normalization perc = np . percentile ( image , 99.0 ) # perc must be quite small in theory... otherwise it's a bug if perc > max_perc : # and perc<1: max_perc = perc return max_perc , lipid_string # Simulate a click on all MAIA transformed lipids for brain_1 in [ True , False ]: for ( index , ( name , structure , cation , mz ), ) in self . _data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 ) . iterrows (): max_perc , lipid_string = _compute_percentile_across_slices ( name , structure , cation , brain_1 ) # Store max percentile across slices dic_max_percentile [( lipid_string , brain_1 )] = max_perc return dic_max_percentile","title":"compute_normalization_factor_across_slices()"},{"location":"modules/figures/#modules.figures.Figures.compute_rgb_array_per_lipid_selection","text":"This function computes a numpy RGB array (each pixel has 3 intensity values) of expression of the requested lipids (those whose m/z values are in ll_t_bounds) in the slice. Parameters: Name Type Description Default slice_index int The index of the requested slice. required ll_t_bounds list(list(tuple A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. required normalize_independently bool If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. True projected_image bool If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. True log bool If True, the resulting array corresponds to log-transformed expression, for each lipid. Defaults to False. False apply_transform bool If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. False ll_lipid_names list ( list ( int )) List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. None cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description np . ndarray A three-dimensional RGB numpy array (of uint8 dtype). The first two dimensions correspond to the acquisition image shape, and the third dimension corresponds to the channels. Source code in modules/figures.py 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 def compute_rgb_array_per_lipid_selection ( self , slice_index , ll_t_bounds , normalize_independently = True , projected_image = True , log = False , apply_transform = False , ll_lipid_names = None , cache_flask = None , ): \"\"\"This function computes a numpy RGB array (each pixel has 3 intensity values) of expression of the requested lipids (those whose m/z values are in ll_t_bounds) in the slice. Args: slice_index (int): The index of the requested slice. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. normalize_independently (bool, optional): If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. log (bool, optional): If True, the resulting array corresponds to log-transformed expression, for each lipid. Defaults to False. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. ll_lipid_names (list(list(int)), optional): List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: (np.ndarray): A three-dimensional RGB numpy array (of uint8 dtype). The first two dimensions correspond to the acquisition image shape, and the third dimension corresponds to the channels. \"\"\" # Empty lipid names if no names provided if ll_lipid_names is None : ll_lipid_names = [ [ \"\" for y in l_t_bounds ] if l_t_bounds is not None else [ \"\" ] for l_t_bounds in ll_t_bounds ] # Build a list of empty images and add selected lipids for each channel l_images = [] # Loop over channels for l_boundaries , l_names in zip ( ll_t_bounds , ll_lipid_names ): image = np . zeros ( self . _atlas . image_shape if projected_image else self . _data . get_image_shape ( slice_index ) ) if l_boundaries is not None : # Loop over lipids for boundaries , lipid_name in zip ( l_boundaries , l_names ): if boundaries is not None : ( lb_mz , hb_mz ) = boundaries # Cmpute expression image per lipid image_temp = self . compute_image_per_lipid ( slice_index , lb_mz , hb_mz , RGB_format = True , normalize = normalize_independently , projected_image = projected_image , log = log , apply_transform = apply_transform , lipid_name = lipid_name , cache_flask = cache_flask , ) if image_temp is not None : image += image_temp l_images . append ( image ) # Reoder axis to match plotly go.image requirements array_image = np . moveaxis ( np . array ( l_images ), 0 , 2 ) return np . asarray ( array_image , dtype = np . uint8 )","title":"compute_rgb_array_per_lipid_selection()"},{"location":"modules/figures/#modules.figures.Figures.compute_rgb_image_per_lipid_selection","text":"This function is very similar to compute_heatmap_per_lipid_selection, but it returns a RGB image instead of a heatmap. Parameters: Name Type Description Default slice_index int The index of the requested slice. required ll_t_bounds list(list(tuple A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. required normalize_independently bool If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. True projected_image bool If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. True log bool If True, the resulting array corresponds to log-transformed expression, for each lipid. Defaults to False. False return_image bool If True, a go.Image is returned directly, instead of a Plotly Figure. Defaults to False. False apply_transform bool If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. False ll_lipid_names list ( list ( int )) List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. None return_base64_string bool If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. False cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description Depending on the inputted arguments, may either return a base64 string, a go.Image, or a Plotly Figure. Source code in modules/figures.py 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 def compute_rgb_image_per_lipid_selection ( self , slice_index , ll_t_bounds , normalize_independently = True , projected_image = True , log = False , return_image = False , apply_transform = False , ll_lipid_names = None , return_base64_string = False , cache_flask = None , ): \"\"\"This function is very similar to compute_heatmap_per_lipid_selection, but it returns a RGB image instead of a heatmap. Args: slice_index (int): The index of the requested slice. ll_t_bounds (list(list(tuple))): A list of lists of lipid boundaries (tuples). The first list is used to separate image channels. The second list is used to separate lipid. normalize_independently (bool, optional): If True, each lipid intensity array is normalized independently, regardless of other lipids or channel used. Defaults to True. projected_image (bool, optional): If True, the pixels of the original acquisition get matched to a higher-resolution, warped space. The gaps are filled by duplicating the most appropriate pixels (see dosctring of Atlas.project_image() for more information). Defaults to True. log (bool, optional): If True, the resulting array corresponds to log-transformed expression, for each lipid. Defaults to False. return_image (bool, optional): If True, a go.Image is returned directly, instead of a Plotly Figure. Defaults to False. apply_transform (bool, optional): If True, applies the MAIA transform (if possible) to the current selection, given that the parameter normalize is also True, and that lipid_name corresponds to an existing lipid. Defaults to False. ll_lipid_names (list(list(int)), optional): List of list of lipid names that must be MAIA-transformed, if apply_transform and normalize are True. The first list is used to separate channels, when applicable. Defaults to None. return_base64_string (bool, optional): If True, the base64 string of the image is returned directly, before any figure building. Defaults to False. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the inputted arguments, may either return a base64 string, a go.Image, or a Plotly Figure. \"\"\" logging . info ( \"Started RGB image computation for slice \" + str ( slice_index ) + logmem ()) # Empty lipid names if no names provided if ll_lipid_names is None : ll_lipid_names = [[ \"\" for y in l_t_bounds ] for l_t_bounds in ll_t_bounds ] logging . info ( \"Acquiring array_image for slice \" + str ( slice_index ) + logmem ()) # Get RGB array for the current lipid selection array_image = self . compute_rgb_array_per_lipid_selection ( slice_index , ll_t_bounds , normalize_independently = normalize_independently , projected_image = projected_image , log = log , apply_transform = apply_transform , ll_lipid_names = ll_lipid_names , cache_flask = cache_flask , ) logging . info ( \"Returning fig for slice \" + str ( slice_index ) + logmem ()) # Build the correspondig figure return self . build_lipid_heatmap_from_image ( array_image , return_base64_string = return_base64_string , draw = False , type_image = \"RGB\" , return_go_image = return_image , )","title":"compute_rgb_image_per_lipid_selection()"},{"location":"modules/figures/#modules.figures.Figures.compute_scatter_3D","text":"This functions computes a figure representing, in a 3D scatter plot, the spots acquired using spatial scRNAseq experiments. Returns: Type Description Plotly . Figure A Plotly Figure containing a go.Scatter3d object representing the acquired spots. Source code in modules/figures.py 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 def compute_scatter_3D ( self ): \"\"\"This functions computes a figure representing, in a 3D scatter plot, the spots acquired using spatial scRNAseq experiments. Returns: (Plotly.Figure): A Plotly Figure containing a go.Scatter3d object representing the acquired spots. \"\"\" logging . info ( \"Starting computing 3D scatter plot for scRNAseq experiments\" + logmem ()) # Get scatter figure for the scRNAseq spots scatter = go . Scatter3d ( x = self . _scRNAseq . xmol , y = self . _scRNAseq . zmol , z =- self . _scRNAseq . ymol , mode = \"markers\" , marker = dict ( size = 2.5 , opacity = 0.8 , color = dic_colors [ \"blue\" ]), ) # Get root figure root_data = self . _storage . return_shelved_object ( \"figures/3D_page\" , \"volume_root\" , force_update = False , compute_function = self . compute_3D_root_volume , differentiate_borders = True , ) # Remove inside of volume root_data [ \"value\" ] = np . where ( ( root_data [ \"value\" ] == - 0.01 ) | ( root_data [ \"value\" ] == - 2.0 ), - 2.0 , root_data [ \"value\" ] ) # Change orientation root_data_y = copy . deepcopy ( root_data [ \"y\" ]) root_data_z = copy . deepcopy ( root_data [ \"z\" ]) root_data [ \"y\" ] = root_data_z root_data [ \"z\" ] = - root_data_y # Remove parts of brain that prevent from clicking points root_data [ \"x\" ] = root_data [ \"x\" ][( root_data [ \"y\" ] < 6 ) & ( root_data [ \"z\" ] < - 3 )] root_data [ \"value\" ] = root_data [ \"value\" ][( root_data [ \"y\" ] < 6 ) & ( root_data [ \"z\" ] < - 3 )] root_data_y_copy = copy . deepcopy ( root_data [ \"y\" ]) root_data [ \"y\" ] = root_data [ \"y\" ][( root_data [ \"y\" ] < 6 ) & ( root_data [ \"z\" ] < - 3 )] root_data [ \"z\" ] = root_data [ \"z\" ][( root_data [ \"z\" ] < - 3 ) & ( root_data_y_copy < 6 )] # Block interaction for skull root_data [ \"hoverinfo\" ] = \"skip\" scatter [ \"hoverinfo\" ] = \"all\" # Build figure fig = go . Figure ( data = [ root_data , scatter ]) # Hide background fig . update_layout ( title_text = \"Click on a point to see the corresponding scRNAseq data\" , title_x = 0.5 , margin = dict ( r = 0 , b = 0 , l = 0 ), scene = dict ( xaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), yaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), zaxis = dict ( backgroundcolor = \"rgba(0,0,0,0)\" ), ), ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" # Change orientation to have scatter dots face the reader x_eye = 0.01 * 2 y_eye = 1.0 * 2 z_eye = 0.5 * 2 camera = dict ( # up=dict(x=0, y=0, z=0), # center=dict(x=0, y=0, z=0), eye = dict ( x = x_eye , y = y_eye , z = z_eye ), ) fig . update_layout ( scene_camera = camera ) return fig","title":"compute_scatter_3D()"},{"location":"modules/figures/#modules.figures.Figures.compute_spectrum_high_res","text":"This function returns the high-resolution spectrum of the requested slice between the two provided m/z boundaries lb and hb. If boundaries are not provided, it returns an empty spectrum. Parameters: Name Type Description Default slice_index int The slice index of the requested slice. required lb float The lower m/z boundary below which the spectrum to display must be cropped. Defaults to None. None hb float The higher m/z boundary below which the spectrum to display must be cropped. Defaults to None. None annotations list ( tuple ) A list of m/z boundaries (one for each lipid to annotate), corresponding to the position of colored box superimposed on the spectra. Defaults to None. None force_xlim bool If Truen the zoom level will be set to enclose lb and hb, although that may not be the tightest region to enclose the data. Defaults to False. False plot bool If False, only the plotting data (m/z and intensities arrays) will be returned. Defaults to True. True standardization bool If True, the displayed spectrum is standardized with MAIA when possible. False cache_flask flask_caching . Cache Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. None Returns: Type Description Depending on the value of the boundaries, and the plot parameter, it may return a Plotly Figure containing an empty spectrum, or a spectrum between the two provided boundaries, or the corresponding data of such a spectrum. Source code in modules/figures.py 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 def compute_spectrum_high_res ( self , slice_index , lb = None , hb = None , annotations = None , force_xlim = False , plot = True , standardization = False , cache_flask = None , ): \"\"\"This function returns the high-resolution spectrum of the requested slice between the two provided m/z boundaries lb and hb. If boundaries are not provided, it returns an empty spectrum. Args: slice_index (int): The slice index of the requested slice. lb (float, optional): The lower m/z boundary below which the spectrum to display must be cropped. Defaults to None. hb (float, optional): The higher m/z boundary below which the spectrum to display must be cropped. Defaults to None. annotations (list(tuple), optional): A list of m/z boundaries (one for each lipid to annotate), corresponding to the position of colored box superimposed on the spectra. Defaults to None. force_xlim (bool, optional): If Truen the zoom level will be set to enclose lb and hb, although that may not be the tightest region to enclose the data. Defaults to False. plot (bool, optional): If False, only the plotting data (m/z and intensities arrays) will be returned. Defaults to True. standardization (bool, optional): If True, the displayed spectrum is standardized with MAIA when possible. cache_flask (flask_caching.Cache, optional): Cache of the Flask database. If set to None, the reading of memory-mapped data will not be multithreads-safe. Defaults to None. Returns: Depending on the value of the boundaries, and the plot parameter, it may return a Plotly Figure containing an empty spectrum, or a spectrum between the two provided boundaries, or the corresponding data of such a spectrum. \"\"\" # Define default values for graph (empty) if lb is None and hb is None : x = ([],) y = ([],) # If boundaries are provided, get their index else : index_lb , index_hb = compute_thread_safe_function ( compute_index_boundaries , cache_flask , self . _data , slice_index , lb , hb , array_spectra_avg = self . _data . get_array_avg_spectrum ( slice_index , standardization = standardization ), lookup_table = self . _data . get_array_lookup_mz_avg ( slice_index ), ) def return_x_y ( array ): x = np . copy ( array [ 0 , index_lb : index_hb ]) y = np . copy ( array [ 1 , index_lb : index_hb ]) return x , y # Get x, y in a thread safe fashion # No need to clean memory as it's really small x , y = compute_thread_safe_function ( return_x_y , cache_flask , self . _data , slice_index , self . _data . get_array_avg_spectrum ( slice_index , standardization = standardization ), ) # In case download without plotting if not plot : return x , y # Define figure data data = go . Scattergl ( x = x , y = y , visible = True , line_color = dic_colors [ \"blue\" ], fill = \"tozeroy\" ) # Define figure layout layout = go . Layout ( margin = dict ( t = 50 , r = 0 , b = 10 , l = 0 ), showlegend = False , xaxis = dict ( rangeslider = { \"visible\" : False }, title = \"m/z\" ), yaxis = dict ( fixedrange = True , title = \"Intensity\" ), template = \"plotly_dark\" , title = { \"text\" : \"High resolution spectrum (averaged across pixels)\" , \"y\" : 0.92 , \"x\" : 0.5 , \"xanchor\" : \"center\" , \"yanchor\" : \"top\" , \"font\" : dict ( size = 14 , ), }, paper_bgcolor = \"rgba(0,0,0,0.3)\" , plot_bgcolor = \"rgba(0,0,0,0.3)\" , ) # Build figure layout fig = go . Figure ( data = data , layout = layout ) # Annotate selected lipids with vertical bars if annotations is not None : for color , x in zip ([ \"red\" , \"green\" , \"blue\" ], annotations ): if x is not None : if x [ 0 ] >= lb and x [ - 1 ] <= hb : fig . add_vrect ( x0 = x [ 0 ], x1 = x [ 1 ], line_width = 0 , fillcolor = dic_colors [ color ], opacity = 0.4 ) # In case we don't want to zoom in too much on the selected lipid if force_xlim : fig . update_xaxes ( range = [ lb , hb ]) return fig","title":"compute_spectrum_high_res()"},{"location":"modules/figures/#modules.figures.Figures.compute_spectrum_low_res","text":"This function returns the full (low-resolution) spectrum of the requested slice. Parameters: Name Type Description Default slice_index int The slice index of the requested slice. required annotations list ( tuple ) A list of m/z boundaries (one for each lipid to annotate), corresponding to the position of colored box superimposed on the spectra. Defaults to None. None Returns: Type Description go . Figure A Plotly Figure representing the low-resolution spectrum. Source code in modules/figures.py 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 def compute_spectrum_low_res ( self , slice_index , annotations = None ): \"\"\"This function returns the full (low-resolution) spectrum of the requested slice. Args: slice_index (int): The slice index of the requested slice. annotations (list(tuple), optional): A list of m/z boundaries (one for each lipid to annotate), corresponding to the position of colored box superimposed on the spectra. Defaults to None. Returns: (go.Figure): A Plotly Figure representing the low-resolution spectrum. \"\"\" # Define figure data data = go . Scattergl ( x = self . _data . get_array_avg_spectrum_downsampled ( slice_index )[ 0 , :], y = self . _data . get_array_avg_spectrum_downsampled ( slice_index )[ 1 , :], visible = True , line_color = dic_colors [ \"blue\" ], fill = \"tozeroy\" , ) # Define figure layout layout = go . Layout ( margin = dict ( t = 50 , r = 0 , b = 10 , l = 0 ), showlegend = False , xaxis = dict ( rangeslider = { \"visible\" : False }, title = \"m/z\" ), yaxis = dict ( fixedrange = False , title = \"Intensity\" ), template = \"plotly_dark\" , autosize = True , title = { \"text\" : \"Low resolution spectrum (averaged across pixels)\" , \"y\" : 0.92 , \"x\" : 0.5 , \"xanchor\" : \"center\" , \"yanchor\" : \"top\" , \"font\" : dict ( size = 14 , ), }, paper_bgcolor = \"rgba(0,0,0,0.3)\" , plot_bgcolor = \"rgba(0,0,0,0.3)\" , ) # Build figure fig = go . Figure ( data = data , layout = layout ) # Annotate selected lipids with vertical bars if annotations is not None : for color , annot in zip ([ \"red\" , \"green\" , \"blue\" ], annotations ): if annot is not None : fig . add_vrect ( x0 = annot [ 0 ], x1 = annot [ 1 ], fillcolor = dic_colors [ color ], opacity = 0.4 , line_color = dic_colors [ color ], ) return fig","title":"compute_spectrum_low_res()"},{"location":"modules/figures/#modules.figures.Figures.compute_treemaps_figure","text":"This function is used to generate a Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. Parameters: Name Type Description Default maxdepth int The depth of the treemap to generate. Defaults to 5. 5 Returns: Type Description Plotly . Figure A Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. Source code in modules/figures.py 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 def compute_treemaps_figure ( self , maxdepth = 5 ): \"\"\"This function is used to generate a Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. Args: maxdepth (int, optional): The depth of the treemap to generate. Defaults to 5. Returns: (Plotly.Figure): A Plotly Figure containing a treemap of the Allen Brain Atlas hierarchy. \"\"\" # Build treemaps from list of children and parents fig = px . treemap ( names = self . _atlas . l_nodes , parents = self . _atlas . l_parents , maxdepth = maxdepth ) # Improve layout fig . update_layout ( uniformtext = dict ( minsize = 15 ), margin = dict ( t = 30 , r = 0 , b = 10 , l = 0 ), ) fig . update_traces ( root_color = \"#1d3d5c\" ) # Set background color to zero fig . layout . template = \"plotly_dark\" fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" return fig","title":"compute_treemaps_figure()"},{"location":"modules/figures/#modules.figures.Figures.get_array_of_annotations","text":"This function returns the array of annotations from the Allen Brain Atlas, subsampled to decrease the size of the output. Parameters: Name Type Description Default decrease_dimensionality_factor int An integer used for subsampling the array. The higher, the higher the subsampling. required Returns: Type Description np . ndarray A 3D array of annotation, in which structures are annotated with specific identifiers. Source code in modules/figures.py 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 def get_array_of_annotations ( self , decrease_dimensionality_factor ): \"\"\"This function returns the array of annotations from the Allen Brain Atlas, subsampled to decrease the size of the output. Args: decrease_dimensionality_factor (int): An integer used for subsampling the array. The higher, the higher the subsampling. Returns: (np.ndarray): A 3D array of annotation, in which structures are annotated with specific identifiers. \"\"\" # Get subsampled array of annotations array_annotation = np . array ( self . _atlas . bg_atlas . annotation [ :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , :: decrease_dimensionality_factor , ], dtype = np . int32 , ) # Bug correction for the last slice array_annotation = np . concatenate ( ( array_annotation , np . zeros (( 1 , array_annotation . shape [ 1 ], array_annotation . shape [ 2 ])), ) ) return array_annotation","title":"get_array_of_annotations()"},{"location":"modules/figures/#modules.figures.Figures.get_surface","text":"This function returns a Plotly Surface representing the requested slice in 3D. Parameters: Name Type Description Default slice_index int Index of the requested slice. required l_transform_parameters list(np.ndarray A list of tuples containing the parameters for the transformation of the slice coordinates from 2D to 3D and conversely. required array_projection np . ndarray The coordinates of the requested slice in 2D. required reduce_resolution_factor int Divides (reduce) the initial resolution of the data. Needed as the resulting figure can be very heavy. Defaults to 20. required Returns: Type Description go . Surface A Plotly Surface representing the requested slice in 3D. Source code in modules/figures.py 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 def get_surface ( self , slice_index , l_transform_parameters , array_projection , reduce_resolution_factor ): \"\"\"This function returns a Plotly Surface representing the requested slice in 3D. Args: slice_index (int): Index of the requested slice. l_transform_parameters (list(np.ndarray)): A list of tuples containing the parameters for the transformation of the slice coordinates from 2D to 3D and conversely. array_projection (np.ndarray): The coordinates of the requested slice in 2D. reduce_resolution_factor (int, optional): Divides (reduce) the initial resolution of the data. Needed as the resulting figure can be very heavy. Defaults to 20. Returns: (go.Surface): A Plotly Surface representing the requested slice in 3D. \"\"\" # Get the parameters for the transformation of the coordinats from 2D to 3D a , u , v = l_transform_parameters [ slice_index ] # Build 3 empty lists, which will contain the 3D coordinates of the requested slice ll_x = [] ll_y = [] ll_z = [] # Loop over the first 2D coordinate of the slice for i , lambd in enumerate ( range ( array_projection [ slice_index ] . shape [ 0 ])): l_x = [] l_y = [] l_z = [] # Loop over the second 2D coordinate of the slice for j , mu in enumerate ( range ( array_projection [ slice_index ] . shape [ 1 ])): # Get rescaled 3D coordinates x_atlas , y_atlas , z_atlas = ( np . array ( slice_to_atlas_transform ( a , u , v , lambd * reduce_resolution_factor , mu * reduce_resolution_factor ) ) * self . _atlas . resolution / 1000 ) l_x . append ( z_atlas ) l_y . append ( x_atlas ) l_z . append ( y_atlas ) # In case the 3D coordinate was not acquired, skip the current coordinate if l_x != []: ll_x . append ( l_x ) ll_y . append ( l_y ) ll_z . append ( l_z ) # Build a 3D surface from the 3D coordinates for the current slice surface = go . Surface ( z = np . array ( ll_z ), x = np . array ( ll_x ), y = np . array ( ll_y ), surfacecolor = array_projection [ slice_index ] . astype ( np . int32 ), cmin = 0 , cmax = 255 , colorscale = \"viridis\" , opacityscale = [[ 0 , 0 ], [ 0.1 , 1 ], [ 1 , 1 ]], showscale = False , ) return surface","title":"get_surface()"},{"location":"modules/figures/#modules.figures.Figures.return_empty_spectrum","text":"This function returns an empty spectrum, used to display when no spectrum is available. Returns: Type Description Plotly Figure A Plotly Figure representing an empty spectrum. Source code in modules/figures.py 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 def return_empty_spectrum ( self ): \"\"\"This function returns an empty spectrum, used to display when no spectrum is available. Returns: (Plotly Figure): A Plotly Figure representing an empty spectrum.\"\"\" # Define empty figure data data = ( go . Scattergl ( x = [], y = [], visible = True ),) # Define figure layout layout = go . Layout ( margin = dict ( t = 5 , r = 0 , b = 10 , l = 0 ), showlegend = True , xaxis = dict ( title = \"m/z\" ), yaxis = dict ( title = \"Intensity\" ), template = \"plotly_dark\" , ) # Build figure fig = go . Figure ( data = data , layout = layout ) # Transparent background fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" return fig","title":"return_empty_spectrum()"},{"location":"modules/figures/#modules.figures.Figures.return_heatmap_lipid","text":"This function is used to either generate a Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. Parameters: Name Type Description Default fig Plotly Figure A Plotly Figure whose layout must be completed. If None, a new figure will be generated. Defaults to None. None Returns: Type Description Plotly Figure A Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. Source code in modules/figures.py 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 def return_heatmap_lipid ( self , fig = None ): \"\"\"This function is used to either generate a Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. Args: fig (Plotly Figure, optional): A Plotly Figure whose layout must be completed. If None, a new figure will be generated. Defaults to None. Returns: (Plotly Figure): A Plotly Figure containing an empty go.Heatmap, or complete the figure passed as argument with a proper layout that matches the theme of the app. \"\"\" # Build empty figure if not provided if fig is None : fig = go . Figure ( data = go . Heatmap ( z = [[]], x = [], y = [], visible = False )) # Improve figure layout fig . update_layout ( margin = dict ( t = 25 , r = 0 , b = 10 , l = 0 ), template = \"plotly_dark\" , font_size = 8 , ) # Transparent background fig . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig . layout . paper_bgcolor = \"rgba(0,0,0,0)\" # Dark Template fig . layout . template = \"plotly_dark\" return fig","title":"return_heatmap_lipid()"},{"location":"modules/figures/#modules.figures.Figures.shelve_all_arrays_annotation","text":"This functions precomputes and shelves the array of structure annotation used in a 3D representation of the brain (through self.compute_3D_volume_figure()), at different resolutions. Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Source code in modules/figures.py 2792 2793 2794 2795 2796 2797 2798 2799 2800 2801 2802 2803 2804 2805 2806 2807 2808 def shelve_all_arrays_annotation ( self ): \"\"\"This functions precomputes and shelves the array of structure annotation used in a 3D representation of the brain (through self.compute_3D_volume_figure()), at different resolutions. Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. \"\"\" for decrease_dimensionality_factor in range ( 2 , 13 ): self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_annotation\" , force_update = False , compute_function = self . get_array_of_annotations , decrease_dimensionality_factor = decrease_dimensionality_factor , ) # Variable to signal everything has been computed self . _storage . dump_shelved_object ( \"figures/3D_page\" , \"arrays_annotation_computed\" , True )","title":"shelve_all_arrays_annotation()"},{"location":"modules/figures/#modules.figures.Figures.shelve_all_l_array_2D","text":"This functions precomputes and shelves all the arrays of lipid expression used in a 3D representation of the brain (through self.compute_3D_volume_figure()). Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Parameters: Name Type Description Default force_update bool If True, the function will not overwrite existing files. Defaults to False. False sample bool If True, only a fraction of the precomputations are made (for debug). Default to False. False brain_1 bool If True, the data is precomputed for the brain 1. Else for the brain 2. Defaults to True. True Source code in modules/figures.py 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713 2714 2715 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727 2728 2729 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741 2742 2743 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755 2756 2757 2758 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769 2770 2771 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783 2784 2785 2786 2787 2788 2789 2790 def shelve_all_l_array_2D ( self , force_update = False , sample = False , brain_1 = True ): \"\"\"This functions precomputes and shelves all the arrays of lipid expression used in a 3D representation of the brain (through self.compute_3D_volume_figure()). Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Args: force_update (bool, optional): If True, the function will not overwrite existing files. Defaults to False. sample (bool, optional): If True, only a fraction of the precomputations are made (for debug). Default to False. brain_1 (bool, optional): If True, the data is precomputed for the brain 1. Else for the brain 2. Defaults to True. \"\"\" # Count number of lipids processed for sampling n_processed = 0 if sample : logging . warning ( \"Only a sample of the lipid arrays will be computed!\" ) # Simulate a click on all lipid names df_annotations_MAIA = self . _data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 ) for name in sorted ( df_annotations_MAIA . name . unique ()): structures = df_annotations_MAIA [ df_annotations_MAIA [ \"name\" ] == name ] . structure . unique () for structure in sorted ( structures ): cations = df_annotations_MAIA [ ( df_annotations_MAIA [ \"name\" ] == name ) & ( df_annotations_MAIA [ \"structure\" ] == structure ) ] . cation . unique () for cation in sorted ( cations ): l_selected_lipids = [] for slice_index in self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ): # Find lipid location l_lipid_loc = ( self . _data . get_annotations () . index [ ( self . _data . get_annotations ()[ \"name\" ] == name ) & ( self . _data . get_annotations ()[ \"structure\" ] == structure ) & ( self . _data . get_annotations ()[ \"slice\" ] == slice_index ) & ( self . _data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) > 1 : logging . warning ( \"More than one lipid corresponds to the selection\" ) l_lipid_loc = [ l_lipid_loc [ - 1 ]] # If no lipid correspond to the selection, set to -1 if len ( l_lipid_loc ) == 0 : l_lipid_loc = [ - 1 ] # add lipid index for each slice l_selected_lipids . append ( l_lipid_loc [ 0 ]) # Get final lipid name lipid_string = name + \" \" + structure + \" \" + cation # If lipid is present in at least one slice if np . sum ( l_selected_lipids ) > - len ( self . _data . get_slice_list ( indices = \"brain_1\" if brain_1 else \"brain_2\" ) ): # Build the list of mz boundaries for each peak and each index lll_lipid_bounds = [ [ [ ( float ( self . _data . get_annotations () . iloc [ index ][ \"min\" ]), float ( self . _data . get_annotations () . iloc [ index ][ \"max\" ]), ) ] if index != - 1 else None for index in [ lipid_1_index , - 1 , - 1 ] ] for lipid_1_index in l_selected_lipids ] # Compute 3D figures, selection is limited to one lipid name_lipid = lipid_string self . _storage . return_shelved_object ( \"figures/3D_page\" , \"arrays_expression_\" + str ( brain_1 ) + \"_\" + name_lipid + \"__\" , force_update = force_update , compute_function = self . compute_l_array_2D , ignore_arguments_naming = True , ll_t_bounds = lll_lipid_bounds , brain_1 = brain_1 , cache_flask = None , # No cache needed since launched at startup ) n_processed += 1 if n_processed >= 10 and sample : return None # Variable to signal everything has been computed self . _storage . dump_shelved_object ( \"figures/3D_page\" , \"arrays_expression_\" + str ( brain_1 ) + \"_computed\" , True )","title":"shelve_all_l_array_2D()"},{"location":"modules/figures/#modules.figures.Figures.shelve_arrays_basic_figures","text":"This function shelves in the database all the arrays of basic images computed in self.compute_figure_basic_image(), across all slices and all types of arrays. This forces the precomputations of these arrays, and allows to access them faster. Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Parameters: Name Type Description Default force_update bool If True, the function will not overwrite existing files. Defaults to False. False Source code in modules/figures.py 2658 2659 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671 2672 2673 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685 2686 2687 def shelve_arrays_basic_figures ( self , force_update = False ): \"\"\"This function shelves in the database all the arrays of basic images computed in self.compute_figure_basic_image(), across all slices and all types of arrays. This forces the precomputations of these arrays, and allows to access them faster. Once everything has been shelved, a boolean value is stored in the shelve database, to indicate that the arrays do not need to be recomputed at next app startup. Args: force_update (bool, optional): If True, the function will not overwrite existing files. Defaults to False. \"\"\" for idx_slice in range ( self . _data . get_slice_number ()): for type_figure in [ \"original_data\" , \"warped_data\" , \"projection_corrected\" , \"atlas\" ]: for display_annotations in [ True , False ]: # Force no annotation for the original data self . _storage . return_shelved_object ( \"figures/load_page\" , \"figure_basic_image\" , force_update = force_update , compute_function = self . compute_figure_basic_image , type_figure = type_figure , index_image = idx_slice , plot_atlas_contours = display_annotations if type_figure != \"original_data\" else False , ) self . _storage . dump_shelved_object ( \"figures/load_page\" , \"arrays_basic_figures_computed\" , True )","title":"shelve_arrays_basic_figures()"},{"location":"modules/launch/","text":"This class contains functions used to do check and run all precomputation at first app launch. Launch Class used to precompute and shelve objects at app launch. Attributes: Name Type Description data MaldiData Used to manipulate the raw MALDI data. atlas Atlas Used to manipulate the objects coming from the Allen Brain Atlas. figures Figures Used to build the figures of the app. storage Storage Used to access the shelve database. l_atlas_objects_at_init list List of atlas objects normally computed at app startup if not already in shelve database. l_figures_objects_at_init list List of figures objects normally computed at app startup if not already in shelve database. l_other_objects_to_compute list List of other objects which must be computed to prevent slowing down the app during normal use. l_db_entries list List of all entries in the shelve database (i.e. concatenation of the 3 previous lists). l_entries_to_ignore list List of entries to ignore when checking if they are in the shelve database. Methods init (data, atlas, figures, storage): Initialize the Launch class. check_missing_db_entries(): Check if all the entries in l_db_entries are in the shelve db. compute_and_fill_entries(l_missing_entries): Precompute all the entries in l_missing_entries and fill them in the shelve database. launch(force_exit_if_first_launch=True): Launch the checks and precomputations at app startup. Source code in modules/launch.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 class Launch : \"\"\"Class used to precompute and shelve objects at app launch. Attributes: data (MaldiData): Used to manipulate the raw MALDI data. atlas (Atlas): Used to manipulate the objects coming from the Allen Brain Atlas. figures (Figures): Used to build the figures of the app. storage (Storage): Used to access the shelve database. l_atlas_objects_at_init (list): List of atlas objects normally computed at app startup if not already in shelve database. l_figures_objects_at_init (list): List of figures objects normally computed at app startup if not already in shelve database. l_other_objects_to_compute (list): List of other objects which must be computed to prevent slowing down the app during normal use. l_db_entries (list): List of all entries in the shelve database (i.e. concatenation of the 3 previous lists). l_entries_to_ignore (list): List of entries to ignore when checking if they are in the shelve database. Methods: __init__(data, atlas, figures, storage): Initialize the Launch class. check_missing_db_entries(): Check if all the entries in l_db_entries are in the shelve db. compute_and_fill_entries(l_missing_entries): Precompute all the entries in l_missing_entries and fill them in the shelve database. launch(force_exit_if_first_launch=True): Launch the checks and precomputations at app startup. \"\"\" # ============================================================================================== # --- Constructor # ============================================================================================== def __init__ ( self , data , atlas , figures , storage ): \"\"\"Initialize the class Launch. Args: data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. atlas (Atlas): Atlas object, used to manipulate the objects coming from the Allen Brain Atlas. figures (Figures): Figures object, used to build the figures of the app. storage (Storage): Storage object, used to access the shelve database. \"\"\" # App main objects self . data = data self . atlas = atlas self . figures = figures # Database path self . storage = storage # Objects to shelve in the Atlas class. Everything in this list is shelved at # initialization of Atlas and Figures objects. The computations described are the ones done # at startup. self . l_atlas_objects_at_init = [ # Computed in Atlas.__init__() as an argument of Atlas. Corresponds to the object # returned by Atlas.compute_dic_acronym_children_id() \"atlas/atlas_objects/dic_acronym_children_id\" , # # Computed in Atlas.__init__() as an argument of Atlas. Corresponds to the object # returned by Atlas.compute_hierarchy_list() \"atlas/atlas_objects/hierarchy\" , # # Computed in Atlas.__init__() as an argument of Atlas. Corresponds to the object # returned by Atlas.compute_array_projection(True, True) \"atlas/atlas_objects/arrays_projection_corrected_True_True\" , # # Computed in Atlas.__init__(), calling Atlas.compute_array_projection() when # computing arrays_projection_corrected_True_True. Corresponds to the object returned by # Atlas.compute_projection_parameters() # * This computation takes ~20s \"atlas/atlas_objects/l_transform_parameters\" , # # Computed in Atlas.__init__(), calling Atlas.save_all_projected_masks_and_spectra(), # but it doesn't correpond to an object returned by a specific function. # All the masks and spectra are also computed and saved in the shelve database with the # following ids: # \"atlas/atlas_objects/mask_and_spectrum_$slice_index$_$id_mask$\", # \"atlas/atlas_objects/mask_and_spectrum_MAIA_corrected_$slice_index$_$id_mask$\" # (not explicitely in this list as there are too many, and they are necessarily computed # along with dic_existing_masks). # * This a very long computation, the longest in the app. * \"atlas/atlas_objects/dic_existing_masks\" , # # Computed when needed, as a property of Atlas. Corresponds to the object returned by # Atlas.compute_list_projected_atlas_borders_figures(). In practice, this function is # called at startup, when calling Figures.compute_dic_fig_contours() in # Figures.__init()__, through the computation of compute_figure_basic_image (with # plot_atlas_contours set to True). \"atlas/atlas_objects/list_projected_atlas_borders_arrays\" , # # Computed at startup through calling # Atlas.compute_list_projected_atlas_borders_figures() (see comment just above). # Corresponds to the object returned by atlas.prepare_and_compute_array_images_atlas(). \"atlas/atlas_objects/array_images_atlas_True\" , # ] # Objects to shelve in the Figures class. Everything in this list is shelved at # initialization of the Figure object. The computations described are the ones done at # startup. self . l_figures_objects_at_init = [ # Computed in Figures.__init__() as an argument of Figures. Corresponds to the # object returned by # Figures.compute_normalization_factor_across_slices(cache_flask=None) \"figures/lipid_selection/dic_normalization_factors_None\" , # # Computed in Figures.__init__(). Corresponds to the object returned # by Figures.compute_treemaps_figure(). \"figures/atlas_page/3D/treemaps\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_figure_slices_3D(brain), with brain equal to 'brain_1' or 'brain_2'. \"figures/3D_page/slices_3D_brain_1\" , \"figures/3D_page/slices_3D_brain_2\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_3D_root_volume(). \"figures/3D_page/volume_root\" , # # Computed in Figures.__init__() through Figures.compute_scatter_3D(). Corresponds to # the object returned by Figures.compute_3D_root_volume(differentiate_borders=True). \"figures/3D_page/volume_root_True\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_scatter_3D(). \"figures/scRNAseq_page/scatter3D\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_heatmap_lipid_genes() with brain_1 parameter True or False. \"figures/scRNAseq_page/base_heatmap_lipid_True\" , \"figures/scRNAseq_page/base_heatmap_lipid_False\" , # # Computed in Figures.__init(), calling Figures.shelve_arrays_basic_figures(), but # it doesn't correpond to an object returned by a specific function. # All figures are computed and saved in the shelve database with the following ids: # \"figures/load_page/figure_basic_image_$type_figure$_$idx_slice$_$display_annotations\", # (not explicitely in this list as there are too many). # * This a long computation. \"figures/load_page/arrays_basic_figures_computed\" , # # Computed in compute_figure_basic_image() only, which is called in # Figures.shelve_arrays_basic_figures(), itself called in Figures.__init__(). # Corresponds to the object returned by # figures.compute_array_basic_images(type_figure), with type_figure having the # following values: \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\" \"figures/load_page/array_basic_images_original_data\" , \"figures/load_page/array_basic_images_warped_data\" , \"figures/load_page/array_basic_images_projection_corrected\" , \"figures/load_page/array_basic_images_atlas\" , # # Computed in Figures.__init(), calling Figures.shelve_all_l_array_2D(), but it # doesn't correspond to an object returned by a specific function. # All the list of 2D slices of expression objects are computed and saved in the # shelve database with the following ids (True is for brain 1 data, False is for brain 2 # data): # \"figures/3D_page/arrays_expression_True_$name_lipid$__\", # \"figures/3D_page/arrays_expression_False_$name_lipid$__\", # (not explicitely in this list as there are too many). # * This a very long computation. \"figures/3D_page/arrays_expression_True_computed\" , \"figures/3D_page/arrays_expression_False_computed\" , # # Computed in in Figures.__init(), calling Figures.shelve_all_arrays_annotation(), # but it doesn't correspond to an object returned by a specific function. The # corresponding objects saved in Figures.shelve_all_arrays_annotation() are in the # comment below. \"figures/3D_page/arrays_annotation_computed\" , ] + [ # Computed in in Figures.__init(), calling Figures.shelve_all_arrays_annotation(). # Corresponds to the object returned by # Figures.get_array_of_annotations(decrease_dimensionality_factor), with # decrease_dimensionality_factor ranging from 2 to 11. \"figures/3D_page/arrays_annotation_\" + str ( decrease_dimensionality_factor ) for decrease_dimensionality_factor in range ( 2 , 13 ) ] # Objects to shelve in the ScRNAseq class. Everything in this list is shelved at # initialization of the ScRNAseq objects. The computations described are the ones done # at startup. self . l_scRNAseq_objects_at_init = [] # Objects to shelve not belonging to a specific class. Objects in the list are not # automatically shelved at startup. self . l_other_objects_to_compute = [ # Computed when loading the lipid_selection page. Corresponds to the object returned by # return_lipid_options(). \"annotations/lipid_options\" , ] # List of all db entries self . l_db_entries = ( self . l_atlas_objects_at_init + self . l_figures_objects_at_init + self . l_scRNAseq_objects_at_init + self . l_other_objects_to_compute ) # Db entries to ignore as they are either computed through other entries, or not relevant self . l_entries_to_ignore = [ \"figures/3D_page/arrays_expression_\" , \"figures/load_page/figure_basic_image_\" , \"atlas/atlas_objects/mask_and_spectrum_\" , \"atlas/atlas_objects/dic_processed_temp\" , \"launch/first_launch\" , ] # ============================================================================================== # --- Methods # ============================================================================================== def check_missing_db_entries ( self ): \"\"\"This function checks if all the entries in self.l_db_entries are in the shelve database. It then returns a list containing the missing entries. \"\"\" # Get database db = shelve . open ( self . storage . path_db ) # Build a set of missing entries l_missing_entries = list ( set ( self . l_db_entries ) - set ( db . keys ())) if len ( l_missing_entries ) > 0 : logging . info ( \"Missing entries found in the shelve database:\" + str ( l_missing_entries )) # Find out if there are entries in the databse and not in the list of entries to check l_unexpected_entries = list ( set ( db . keys ()) - set ( self . l_db_entries )) # Remove entries that are not in the initial list but are in the database, i.e all 2D lipid # slices, all brain regions, all figures in the load_slice page, and all atlas masks. l_unexpected_entries = [ x for x in l_unexpected_entries if [ entry not in x for entry in self . l_entries_to_ignore ] . count ( True ) == 0 ] if len ( l_unexpected_entries ) > 0 : logging . warning ( \"WARNING: unexpected entries found in the shelve database: \" + str ( l_unexpected_entries ) ) # Close database db . close () return l_missing_entries def compute_and_fill_entries ( self , l_missing_entries ): \"\"\"This function precompute all the entries in l_missing_entries and fill them in the shelve database. Args: l_missing_entries (list): list of entries to compute and insert in the shelve database. \"\"\" # Get database db = shelve . open ( self . storage . path_db ) # Compute missing entries if possible for entry in l_missing_entries : if entry in self . l_atlas_objects_at_init : logging . warning ( \"This entry should not be missing,\" + \" as it is computed during Atlas initialization: \" + entry + \" . Please rebuild the atlas variable\" ) elif entry in self . l_figures_objects_at_init : logging . warning ( \"This entry should not be missing,\" + \" as it is computed during Figures initialization: \" + entry + \" . Please rebuild the figures variable\" ) elif entry in self . l_other_objects_to_compute : logging . info ( \"Entry: \" + entry + \" is missing. Computing now.\" ) if entry == \"annotations/lipid_options\" : db [ entry ] = self . data . return_lipid_options () else : logging . warning ( \"Entry \" + entry + \" not found in the list of entries to compute.\" ) # Close database db . close () def run_compiled_functions ( self ): \"\"\"This function runs once the slowest numba functions, whose compilation can take a little bit of time, so that the app is as fast as it can be after startup. Basically, it simulates the user doing various actions in the app. \"\"\" # Simulate the user drawing one region (here on slice 1), and compute the corresponding # spectral data def draw_region_and_compute_spectral_data (): # Define function parameters slice_index = 1 path = np . array ( [( 53 , 108 ), ( 54 , 102 ), ( 59 , 101 ), ( 58 , 103 ), ( 56 , 105 ), ( 53 , 108 )], dtype = np . int32 ) # Force compile numba functions executing them list_index_bound_rows , list_index_bound_column_per_row = sample_rows_from_path ( path ) grah_scattergl_data = compute_spectrum_per_row_selection ( list_index_bound_rows , list_index_bound_column_per_row , self . data . get_array_spectra ( slice_index ), self . data . get_array_lookup_pixels ( slice_index ), self . data . get_image_shape ( slice_index ), self . data . get_array_peaks_transformed_lipids ( slice_index ), self . data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), zeros_extend = False , apply_correction = False , ) grah_scattergl_data = convert_array_to_fine_grained ( grah_scattergl_data , 10 **- 3 , lb = 350 , hb = 1250 , ) grah_scattergl_data = strip_zeros ( grah_scattergl_data ) l_idx_labels = np . array ([ - 1 , 2 , - 1 ], dtype = np . int32 ) return_idx_sup ( l_idx_labels ) return_idx_inf ( l_idx_labels ) add_zeros_to_spectrum ( grah_scattergl_data , pad_individual_peaks = True , padding = 10 **- 4 , ) array_intensity_with_lipids = np . array ( [ 1.21864345e-04 , 9.33317497e-05 , 6.23099259e-05 ], dtype = np . float32 ) array_idx_labels = np . array ([ - 1 - 1 - 1 ], dtype = np . int32 ) compute_avg_intensity_per_lipid ( array_intensity_with_lipids , array_idx_labels ) compute_image_using_index_and_image_lookup ( 500.1 , 500.2 , self . data . get_array_spectra ( slice_index ), self . data . get_array_lookup_pixels ( slice_index ), self . data . get_image_shape ( slice_index ), self . data . get_array_lookup_mz ( slice_index ), self . data . get_array_cumulated_lookup_mz_image ( slice_index ), self . data . get_divider_lookup ( slice_index ), self . data . get_array_peaks_transformed_lipids ( slice_index ), self . data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), apply_transform = False , ) def select_lipid_and_region_and_plot_volume (): ll_t_bounds = [[ None , None , None ] for i in self . data . get_slice_list ( indices = \"brain_1\" )] ll_t_bounds [ 0 ] = [[( 622.61 , 622.62 )], None , None ] set_id_regions = { 1006 } self . figures . compute_3D_volume_figure ( None , ll_t_bounds , set_id_regions = set_id_regions ) logging . info ( \"Please wait while compiled functions are executed...\" ) draw_region_and_compute_spectral_data () select_lipid_and_region_and_plot_volume () # Clean memory as it has not been done since compute_thread_safe function wasn't used self . data . clean_memory ( slice_index = 1 ) logging . info ( \"Compiled functions executed.\" ) def launch ( self , force_exit_if_first_launch = True ): \"\"\"This function is used at the execution of the app. It will take care of checking/cleaning the database entries, run compiled functions once, and precompute all the objects that can be precomputed. At the very first launch, the app can be greedy in memory, reason for which the user can choose to force the exit of the app, to start with a lighter process. Args: force_exit_if_first_launch (bool): if True, the app will force exit if it is the first launch. \"\"\" # Check for missing entries l_missing_entries = self . check_missing_db_entries () # Compute missing entries self . compute_and_fill_entries ( l_missing_entries ) # Run compiled functions self . run_compiled_functions () # Check if the app has been run before, and potentially force exit if not if not self . storage . check_shelved_object ( \"launch\" , \"first_launch\" ): self . storage . dump_shelved_object ( \"launch\" , \"first_launch\" , True ) if force_exit_if_first_launch : sys . exit ( \"The app has been exited now that everything has been precomputed.\" + \"Please launch the app again.\" ) __init__ ( data , atlas , figures , storage ) Initialize the class Launch. Parameters: Name Type Description Default data MaldiData MaldiData object, used to manipulate the raw MALDI data. required atlas Atlas Atlas object, used to manipulate the objects coming from the Allen Brain Atlas. required figures Figures Figures object, used to build the figures of the app. required storage Storage Storage object, used to access the shelve database. required Source code in modules/launch.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 def __init__ ( self , data , atlas , figures , storage ): \"\"\"Initialize the class Launch. Args: data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. atlas (Atlas): Atlas object, used to manipulate the objects coming from the Allen Brain Atlas. figures (Figures): Figures object, used to build the figures of the app. storage (Storage): Storage object, used to access the shelve database. \"\"\" # App main objects self . data = data self . atlas = atlas self . figures = figures # Database path self . storage = storage # Objects to shelve in the Atlas class. Everything in this list is shelved at # initialization of Atlas and Figures objects. The computations described are the ones done # at startup. self . l_atlas_objects_at_init = [ # Computed in Atlas.__init__() as an argument of Atlas. Corresponds to the object # returned by Atlas.compute_dic_acronym_children_id() \"atlas/atlas_objects/dic_acronym_children_id\" , # # Computed in Atlas.__init__() as an argument of Atlas. Corresponds to the object # returned by Atlas.compute_hierarchy_list() \"atlas/atlas_objects/hierarchy\" , # # Computed in Atlas.__init__() as an argument of Atlas. Corresponds to the object # returned by Atlas.compute_array_projection(True, True) \"atlas/atlas_objects/arrays_projection_corrected_True_True\" , # # Computed in Atlas.__init__(), calling Atlas.compute_array_projection() when # computing arrays_projection_corrected_True_True. Corresponds to the object returned by # Atlas.compute_projection_parameters() # * This computation takes ~20s \"atlas/atlas_objects/l_transform_parameters\" , # # Computed in Atlas.__init__(), calling Atlas.save_all_projected_masks_and_spectra(), # but it doesn't correpond to an object returned by a specific function. # All the masks and spectra are also computed and saved in the shelve database with the # following ids: # \"atlas/atlas_objects/mask_and_spectrum_$slice_index$_$id_mask$\", # \"atlas/atlas_objects/mask_and_spectrum_MAIA_corrected_$slice_index$_$id_mask$\" # (not explicitely in this list as there are too many, and they are necessarily computed # along with dic_existing_masks). # * This a very long computation, the longest in the app. * \"atlas/atlas_objects/dic_existing_masks\" , # # Computed when needed, as a property of Atlas. Corresponds to the object returned by # Atlas.compute_list_projected_atlas_borders_figures(). In practice, this function is # called at startup, when calling Figures.compute_dic_fig_contours() in # Figures.__init()__, through the computation of compute_figure_basic_image (with # plot_atlas_contours set to True). \"atlas/atlas_objects/list_projected_atlas_borders_arrays\" , # # Computed at startup through calling # Atlas.compute_list_projected_atlas_borders_figures() (see comment just above). # Corresponds to the object returned by atlas.prepare_and_compute_array_images_atlas(). \"atlas/atlas_objects/array_images_atlas_True\" , # ] # Objects to shelve in the Figures class. Everything in this list is shelved at # initialization of the Figure object. The computations described are the ones done at # startup. self . l_figures_objects_at_init = [ # Computed in Figures.__init__() as an argument of Figures. Corresponds to the # object returned by # Figures.compute_normalization_factor_across_slices(cache_flask=None) \"figures/lipid_selection/dic_normalization_factors_None\" , # # Computed in Figures.__init__(). Corresponds to the object returned # by Figures.compute_treemaps_figure(). \"figures/atlas_page/3D/treemaps\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_figure_slices_3D(brain), with brain equal to 'brain_1' or 'brain_2'. \"figures/3D_page/slices_3D_brain_1\" , \"figures/3D_page/slices_3D_brain_2\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_3D_root_volume(). \"figures/3D_page/volume_root\" , # # Computed in Figures.__init__() through Figures.compute_scatter_3D(). Corresponds to # the object returned by Figures.compute_3D_root_volume(differentiate_borders=True). \"figures/3D_page/volume_root_True\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_scatter_3D(). \"figures/scRNAseq_page/scatter3D\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_heatmap_lipid_genes() with brain_1 parameter True or False. \"figures/scRNAseq_page/base_heatmap_lipid_True\" , \"figures/scRNAseq_page/base_heatmap_lipid_False\" , # # Computed in Figures.__init(), calling Figures.shelve_arrays_basic_figures(), but # it doesn't correpond to an object returned by a specific function. # All figures are computed and saved in the shelve database with the following ids: # \"figures/load_page/figure_basic_image_$type_figure$_$idx_slice$_$display_annotations\", # (not explicitely in this list as there are too many). # * This a long computation. \"figures/load_page/arrays_basic_figures_computed\" , # # Computed in compute_figure_basic_image() only, which is called in # Figures.shelve_arrays_basic_figures(), itself called in Figures.__init__(). # Corresponds to the object returned by # figures.compute_array_basic_images(type_figure), with type_figure having the # following values: \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\" \"figures/load_page/array_basic_images_original_data\" , \"figures/load_page/array_basic_images_warped_data\" , \"figures/load_page/array_basic_images_projection_corrected\" , \"figures/load_page/array_basic_images_atlas\" , # # Computed in Figures.__init(), calling Figures.shelve_all_l_array_2D(), but it # doesn't correspond to an object returned by a specific function. # All the list of 2D slices of expression objects are computed and saved in the # shelve database with the following ids (True is for brain 1 data, False is for brain 2 # data): # \"figures/3D_page/arrays_expression_True_$name_lipid$__\", # \"figures/3D_page/arrays_expression_False_$name_lipid$__\", # (not explicitely in this list as there are too many). # * This a very long computation. \"figures/3D_page/arrays_expression_True_computed\" , \"figures/3D_page/arrays_expression_False_computed\" , # # Computed in in Figures.__init(), calling Figures.shelve_all_arrays_annotation(), # but it doesn't correspond to an object returned by a specific function. The # corresponding objects saved in Figures.shelve_all_arrays_annotation() are in the # comment below. \"figures/3D_page/arrays_annotation_computed\" , ] + [ # Computed in in Figures.__init(), calling Figures.shelve_all_arrays_annotation(). # Corresponds to the object returned by # Figures.get_array_of_annotations(decrease_dimensionality_factor), with # decrease_dimensionality_factor ranging from 2 to 11. \"figures/3D_page/arrays_annotation_\" + str ( decrease_dimensionality_factor ) for decrease_dimensionality_factor in range ( 2 , 13 ) ] # Objects to shelve in the ScRNAseq class. Everything in this list is shelved at # initialization of the ScRNAseq objects. The computations described are the ones done # at startup. self . l_scRNAseq_objects_at_init = [] # Objects to shelve not belonging to a specific class. Objects in the list are not # automatically shelved at startup. self . l_other_objects_to_compute = [ # Computed when loading the lipid_selection page. Corresponds to the object returned by # return_lipid_options(). \"annotations/lipid_options\" , ] # List of all db entries self . l_db_entries = ( self . l_atlas_objects_at_init + self . l_figures_objects_at_init + self . l_scRNAseq_objects_at_init + self . l_other_objects_to_compute ) # Db entries to ignore as they are either computed through other entries, or not relevant self . l_entries_to_ignore = [ \"figures/3D_page/arrays_expression_\" , \"figures/load_page/figure_basic_image_\" , \"atlas/atlas_objects/mask_and_spectrum_\" , \"atlas/atlas_objects/dic_processed_temp\" , \"launch/first_launch\" , ] check_missing_db_entries () This function checks if all the entries in self.l_db_entries are in the shelve database. It then returns a list containing the missing entries. Source code in modules/launch.py 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 def check_missing_db_entries ( self ): \"\"\"This function checks if all the entries in self.l_db_entries are in the shelve database. It then returns a list containing the missing entries. \"\"\" # Get database db = shelve . open ( self . storage . path_db ) # Build a set of missing entries l_missing_entries = list ( set ( self . l_db_entries ) - set ( db . keys ())) if len ( l_missing_entries ) > 0 : logging . info ( \"Missing entries found in the shelve database:\" + str ( l_missing_entries )) # Find out if there are entries in the databse and not in the list of entries to check l_unexpected_entries = list ( set ( db . keys ()) - set ( self . l_db_entries )) # Remove entries that are not in the initial list but are in the database, i.e all 2D lipid # slices, all brain regions, all figures in the load_slice page, and all atlas masks. l_unexpected_entries = [ x for x in l_unexpected_entries if [ entry not in x for entry in self . l_entries_to_ignore ] . count ( True ) == 0 ] if len ( l_unexpected_entries ) > 0 : logging . warning ( \"WARNING: unexpected entries found in the shelve database: \" + str ( l_unexpected_entries ) ) # Close database db . close () return l_missing_entries compute_and_fill_entries ( l_missing_entries ) This function precompute all the entries in l_missing_entries and fill them in the shelve database. Parameters: Name Type Description Default l_missing_entries list list of entries to compute and insert in the shelve database. required Source code in modules/launch.py 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 def compute_and_fill_entries ( self , l_missing_entries ): \"\"\"This function precompute all the entries in l_missing_entries and fill them in the shelve database. Args: l_missing_entries (list): list of entries to compute and insert in the shelve database. \"\"\" # Get database db = shelve . open ( self . storage . path_db ) # Compute missing entries if possible for entry in l_missing_entries : if entry in self . l_atlas_objects_at_init : logging . warning ( \"This entry should not be missing,\" + \" as it is computed during Atlas initialization: \" + entry + \" . Please rebuild the atlas variable\" ) elif entry in self . l_figures_objects_at_init : logging . warning ( \"This entry should not be missing,\" + \" as it is computed during Figures initialization: \" + entry + \" . Please rebuild the figures variable\" ) elif entry in self . l_other_objects_to_compute : logging . info ( \"Entry: \" + entry + \" is missing. Computing now.\" ) if entry == \"annotations/lipid_options\" : db [ entry ] = self . data . return_lipid_options () else : logging . warning ( \"Entry \" + entry + \" not found in the list of entries to compute.\" ) # Close database db . close () launch ( force_exit_if_first_launch = True ) This function is used at the execution of the app. It will take care of checking/cleaning the database entries, run compiled functions once, and precompute all the objects that can be precomputed. At the very first launch, the app can be greedy in memory, reason for which the user can choose to force the exit of the app, to start with a lighter process. Parameters: Name Type Description Default force_exit_if_first_launch bool if True, the app will force exit if it is the first launch. True Source code in modules/launch.py 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 def launch ( self , force_exit_if_first_launch = True ): \"\"\"This function is used at the execution of the app. It will take care of checking/cleaning the database entries, run compiled functions once, and precompute all the objects that can be precomputed. At the very first launch, the app can be greedy in memory, reason for which the user can choose to force the exit of the app, to start with a lighter process. Args: force_exit_if_first_launch (bool): if True, the app will force exit if it is the first launch. \"\"\" # Check for missing entries l_missing_entries = self . check_missing_db_entries () # Compute missing entries self . compute_and_fill_entries ( l_missing_entries ) # Run compiled functions self . run_compiled_functions () # Check if the app has been run before, and potentially force exit if not if not self . storage . check_shelved_object ( \"launch\" , \"first_launch\" ): self . storage . dump_shelved_object ( \"launch\" , \"first_launch\" , True ) if force_exit_if_first_launch : sys . exit ( \"The app has been exited now that everything has been precomputed.\" + \"Please launch the app again.\" ) run_compiled_functions () This function runs once the slowest numba functions, whose compilation can take a little bit of time, so that the app is as fast as it can be after startup. Basically, it simulates the user doing various actions in the app. Source code in modules/launch.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 def run_compiled_functions ( self ): \"\"\"This function runs once the slowest numba functions, whose compilation can take a little bit of time, so that the app is as fast as it can be after startup. Basically, it simulates the user doing various actions in the app. \"\"\" # Simulate the user drawing one region (here on slice 1), and compute the corresponding # spectral data def draw_region_and_compute_spectral_data (): # Define function parameters slice_index = 1 path = np . array ( [( 53 , 108 ), ( 54 , 102 ), ( 59 , 101 ), ( 58 , 103 ), ( 56 , 105 ), ( 53 , 108 )], dtype = np . int32 ) # Force compile numba functions executing them list_index_bound_rows , list_index_bound_column_per_row = sample_rows_from_path ( path ) grah_scattergl_data = compute_spectrum_per_row_selection ( list_index_bound_rows , list_index_bound_column_per_row , self . data . get_array_spectra ( slice_index ), self . data . get_array_lookup_pixels ( slice_index ), self . data . get_image_shape ( slice_index ), self . data . get_array_peaks_transformed_lipids ( slice_index ), self . data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), zeros_extend = False , apply_correction = False , ) grah_scattergl_data = convert_array_to_fine_grained ( grah_scattergl_data , 10 **- 3 , lb = 350 , hb = 1250 , ) grah_scattergl_data = strip_zeros ( grah_scattergl_data ) l_idx_labels = np . array ([ - 1 , 2 , - 1 ], dtype = np . int32 ) return_idx_sup ( l_idx_labels ) return_idx_inf ( l_idx_labels ) add_zeros_to_spectrum ( grah_scattergl_data , pad_individual_peaks = True , padding = 10 **- 4 , ) array_intensity_with_lipids = np . array ( [ 1.21864345e-04 , 9.33317497e-05 , 6.23099259e-05 ], dtype = np . float32 ) array_idx_labels = np . array ([ - 1 - 1 - 1 ], dtype = np . int32 ) compute_avg_intensity_per_lipid ( array_intensity_with_lipids , array_idx_labels ) compute_image_using_index_and_image_lookup ( 500.1 , 500.2 , self . data . get_array_spectra ( slice_index ), self . data . get_array_lookup_pixels ( slice_index ), self . data . get_image_shape ( slice_index ), self . data . get_array_lookup_mz ( slice_index ), self . data . get_array_cumulated_lookup_mz_image ( slice_index ), self . data . get_divider_lookup ( slice_index ), self . data . get_array_peaks_transformed_lipids ( slice_index ), self . data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), apply_transform = False , ) def select_lipid_and_region_and_plot_volume (): ll_t_bounds = [[ None , None , None ] for i in self . data . get_slice_list ( indices = \"brain_1\" )] ll_t_bounds [ 0 ] = [[( 622.61 , 622.62 )], None , None ] set_id_regions = { 1006 } self . figures . compute_3D_volume_figure ( None , ll_t_bounds , set_id_regions = set_id_regions ) logging . info ( \"Please wait while compiled functions are executed...\" ) draw_region_and_compute_spectral_data () select_lipid_and_region_and_plot_volume () # Clean memory as it has not been done since compute_thread_safe function wasn't used self . data . clean_memory ( slice_index = 1 ) logging . info ( \"Compiled functions executed.\" )","title":"launch"},{"location":"modules/launch/#modules.launch.Launch","text":"Class used to precompute and shelve objects at app launch. Attributes: Name Type Description data MaldiData Used to manipulate the raw MALDI data. atlas Atlas Used to manipulate the objects coming from the Allen Brain Atlas. figures Figures Used to build the figures of the app. storage Storage Used to access the shelve database. l_atlas_objects_at_init list List of atlas objects normally computed at app startup if not already in shelve database. l_figures_objects_at_init list List of figures objects normally computed at app startup if not already in shelve database. l_other_objects_to_compute list List of other objects which must be computed to prevent slowing down the app during normal use. l_db_entries list List of all entries in the shelve database (i.e. concatenation of the 3 previous lists). l_entries_to_ignore list List of entries to ignore when checking if they are in the shelve database. Methods init (data, atlas, figures, storage): Initialize the Launch class. check_missing_db_entries(): Check if all the entries in l_db_entries are in the shelve db. compute_and_fill_entries(l_missing_entries): Precompute all the entries in l_missing_entries and fill them in the shelve database. launch(force_exit_if_first_launch=True): Launch the checks and precomputations at app startup. Source code in modules/launch.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 class Launch : \"\"\"Class used to precompute and shelve objects at app launch. Attributes: data (MaldiData): Used to manipulate the raw MALDI data. atlas (Atlas): Used to manipulate the objects coming from the Allen Brain Atlas. figures (Figures): Used to build the figures of the app. storage (Storage): Used to access the shelve database. l_atlas_objects_at_init (list): List of atlas objects normally computed at app startup if not already in shelve database. l_figures_objects_at_init (list): List of figures objects normally computed at app startup if not already in shelve database. l_other_objects_to_compute (list): List of other objects which must be computed to prevent slowing down the app during normal use. l_db_entries (list): List of all entries in the shelve database (i.e. concatenation of the 3 previous lists). l_entries_to_ignore (list): List of entries to ignore when checking if they are in the shelve database. Methods: __init__(data, atlas, figures, storage): Initialize the Launch class. check_missing_db_entries(): Check if all the entries in l_db_entries are in the shelve db. compute_and_fill_entries(l_missing_entries): Precompute all the entries in l_missing_entries and fill them in the shelve database. launch(force_exit_if_first_launch=True): Launch the checks and precomputations at app startup. \"\"\" # ============================================================================================== # --- Constructor # ============================================================================================== def __init__ ( self , data , atlas , figures , storage ): \"\"\"Initialize the class Launch. Args: data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. atlas (Atlas): Atlas object, used to manipulate the objects coming from the Allen Brain Atlas. figures (Figures): Figures object, used to build the figures of the app. storage (Storage): Storage object, used to access the shelve database. \"\"\" # App main objects self . data = data self . atlas = atlas self . figures = figures # Database path self . storage = storage # Objects to shelve in the Atlas class. Everything in this list is shelved at # initialization of Atlas and Figures objects. The computations described are the ones done # at startup. self . l_atlas_objects_at_init = [ # Computed in Atlas.__init__() as an argument of Atlas. Corresponds to the object # returned by Atlas.compute_dic_acronym_children_id() \"atlas/atlas_objects/dic_acronym_children_id\" , # # Computed in Atlas.__init__() as an argument of Atlas. Corresponds to the object # returned by Atlas.compute_hierarchy_list() \"atlas/atlas_objects/hierarchy\" , # # Computed in Atlas.__init__() as an argument of Atlas. Corresponds to the object # returned by Atlas.compute_array_projection(True, True) \"atlas/atlas_objects/arrays_projection_corrected_True_True\" , # # Computed in Atlas.__init__(), calling Atlas.compute_array_projection() when # computing arrays_projection_corrected_True_True. Corresponds to the object returned by # Atlas.compute_projection_parameters() # * This computation takes ~20s \"atlas/atlas_objects/l_transform_parameters\" , # # Computed in Atlas.__init__(), calling Atlas.save_all_projected_masks_and_spectra(), # but it doesn't correpond to an object returned by a specific function. # All the masks and spectra are also computed and saved in the shelve database with the # following ids: # \"atlas/atlas_objects/mask_and_spectrum_$slice_index$_$id_mask$\", # \"atlas/atlas_objects/mask_and_spectrum_MAIA_corrected_$slice_index$_$id_mask$\" # (not explicitely in this list as there are too many, and they are necessarily computed # along with dic_existing_masks). # * This a very long computation, the longest in the app. * \"atlas/atlas_objects/dic_existing_masks\" , # # Computed when needed, as a property of Atlas. Corresponds to the object returned by # Atlas.compute_list_projected_atlas_borders_figures(). In practice, this function is # called at startup, when calling Figures.compute_dic_fig_contours() in # Figures.__init()__, through the computation of compute_figure_basic_image (with # plot_atlas_contours set to True). \"atlas/atlas_objects/list_projected_atlas_borders_arrays\" , # # Computed at startup through calling # Atlas.compute_list_projected_atlas_borders_figures() (see comment just above). # Corresponds to the object returned by atlas.prepare_and_compute_array_images_atlas(). \"atlas/atlas_objects/array_images_atlas_True\" , # ] # Objects to shelve in the Figures class. Everything in this list is shelved at # initialization of the Figure object. The computations described are the ones done at # startup. self . l_figures_objects_at_init = [ # Computed in Figures.__init__() as an argument of Figures. Corresponds to the # object returned by # Figures.compute_normalization_factor_across_slices(cache_flask=None) \"figures/lipid_selection/dic_normalization_factors_None\" , # # Computed in Figures.__init__(). Corresponds to the object returned # by Figures.compute_treemaps_figure(). \"figures/atlas_page/3D/treemaps\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_figure_slices_3D(brain), with brain equal to 'brain_1' or 'brain_2'. \"figures/3D_page/slices_3D_brain_1\" , \"figures/3D_page/slices_3D_brain_2\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_3D_root_volume(). \"figures/3D_page/volume_root\" , # # Computed in Figures.__init__() through Figures.compute_scatter_3D(). Corresponds to # the object returned by Figures.compute_3D_root_volume(differentiate_borders=True). \"figures/3D_page/volume_root_True\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_scatter_3D(). \"figures/scRNAseq_page/scatter3D\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_heatmap_lipid_genes() with brain_1 parameter True or False. \"figures/scRNAseq_page/base_heatmap_lipid_True\" , \"figures/scRNAseq_page/base_heatmap_lipid_False\" , # # Computed in Figures.__init(), calling Figures.shelve_arrays_basic_figures(), but # it doesn't correpond to an object returned by a specific function. # All figures are computed and saved in the shelve database with the following ids: # \"figures/load_page/figure_basic_image_$type_figure$_$idx_slice$_$display_annotations\", # (not explicitely in this list as there are too many). # * This a long computation. \"figures/load_page/arrays_basic_figures_computed\" , # # Computed in compute_figure_basic_image() only, which is called in # Figures.shelve_arrays_basic_figures(), itself called in Figures.__init__(). # Corresponds to the object returned by # figures.compute_array_basic_images(type_figure), with type_figure having the # following values: \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\" \"figures/load_page/array_basic_images_original_data\" , \"figures/load_page/array_basic_images_warped_data\" , \"figures/load_page/array_basic_images_projection_corrected\" , \"figures/load_page/array_basic_images_atlas\" , # # Computed in Figures.__init(), calling Figures.shelve_all_l_array_2D(), but it # doesn't correspond to an object returned by a specific function. # All the list of 2D slices of expression objects are computed and saved in the # shelve database with the following ids (True is for brain 1 data, False is for brain 2 # data): # \"figures/3D_page/arrays_expression_True_$name_lipid$__\", # \"figures/3D_page/arrays_expression_False_$name_lipid$__\", # (not explicitely in this list as there are too many). # * This a very long computation. \"figures/3D_page/arrays_expression_True_computed\" , \"figures/3D_page/arrays_expression_False_computed\" , # # Computed in in Figures.__init(), calling Figures.shelve_all_arrays_annotation(), # but it doesn't correspond to an object returned by a specific function. The # corresponding objects saved in Figures.shelve_all_arrays_annotation() are in the # comment below. \"figures/3D_page/arrays_annotation_computed\" , ] + [ # Computed in in Figures.__init(), calling Figures.shelve_all_arrays_annotation(). # Corresponds to the object returned by # Figures.get_array_of_annotations(decrease_dimensionality_factor), with # decrease_dimensionality_factor ranging from 2 to 11. \"figures/3D_page/arrays_annotation_\" + str ( decrease_dimensionality_factor ) for decrease_dimensionality_factor in range ( 2 , 13 ) ] # Objects to shelve in the ScRNAseq class. Everything in this list is shelved at # initialization of the ScRNAseq objects. The computations described are the ones done # at startup. self . l_scRNAseq_objects_at_init = [] # Objects to shelve not belonging to a specific class. Objects in the list are not # automatically shelved at startup. self . l_other_objects_to_compute = [ # Computed when loading the lipid_selection page. Corresponds to the object returned by # return_lipid_options(). \"annotations/lipid_options\" , ] # List of all db entries self . l_db_entries = ( self . l_atlas_objects_at_init + self . l_figures_objects_at_init + self . l_scRNAseq_objects_at_init + self . l_other_objects_to_compute ) # Db entries to ignore as they are either computed through other entries, or not relevant self . l_entries_to_ignore = [ \"figures/3D_page/arrays_expression_\" , \"figures/load_page/figure_basic_image_\" , \"atlas/atlas_objects/mask_and_spectrum_\" , \"atlas/atlas_objects/dic_processed_temp\" , \"launch/first_launch\" , ] # ============================================================================================== # --- Methods # ============================================================================================== def check_missing_db_entries ( self ): \"\"\"This function checks if all the entries in self.l_db_entries are in the shelve database. It then returns a list containing the missing entries. \"\"\" # Get database db = shelve . open ( self . storage . path_db ) # Build a set of missing entries l_missing_entries = list ( set ( self . l_db_entries ) - set ( db . keys ())) if len ( l_missing_entries ) > 0 : logging . info ( \"Missing entries found in the shelve database:\" + str ( l_missing_entries )) # Find out if there are entries in the databse and not in the list of entries to check l_unexpected_entries = list ( set ( db . keys ()) - set ( self . l_db_entries )) # Remove entries that are not in the initial list but are in the database, i.e all 2D lipid # slices, all brain regions, all figures in the load_slice page, and all atlas masks. l_unexpected_entries = [ x for x in l_unexpected_entries if [ entry not in x for entry in self . l_entries_to_ignore ] . count ( True ) == 0 ] if len ( l_unexpected_entries ) > 0 : logging . warning ( \"WARNING: unexpected entries found in the shelve database: \" + str ( l_unexpected_entries ) ) # Close database db . close () return l_missing_entries def compute_and_fill_entries ( self , l_missing_entries ): \"\"\"This function precompute all the entries in l_missing_entries and fill them in the shelve database. Args: l_missing_entries (list): list of entries to compute and insert in the shelve database. \"\"\" # Get database db = shelve . open ( self . storage . path_db ) # Compute missing entries if possible for entry in l_missing_entries : if entry in self . l_atlas_objects_at_init : logging . warning ( \"This entry should not be missing,\" + \" as it is computed during Atlas initialization: \" + entry + \" . Please rebuild the atlas variable\" ) elif entry in self . l_figures_objects_at_init : logging . warning ( \"This entry should not be missing,\" + \" as it is computed during Figures initialization: \" + entry + \" . Please rebuild the figures variable\" ) elif entry in self . l_other_objects_to_compute : logging . info ( \"Entry: \" + entry + \" is missing. Computing now.\" ) if entry == \"annotations/lipid_options\" : db [ entry ] = self . data . return_lipid_options () else : logging . warning ( \"Entry \" + entry + \" not found in the list of entries to compute.\" ) # Close database db . close () def run_compiled_functions ( self ): \"\"\"This function runs once the slowest numba functions, whose compilation can take a little bit of time, so that the app is as fast as it can be after startup. Basically, it simulates the user doing various actions in the app. \"\"\" # Simulate the user drawing one region (here on slice 1), and compute the corresponding # spectral data def draw_region_and_compute_spectral_data (): # Define function parameters slice_index = 1 path = np . array ( [( 53 , 108 ), ( 54 , 102 ), ( 59 , 101 ), ( 58 , 103 ), ( 56 , 105 ), ( 53 , 108 )], dtype = np . int32 ) # Force compile numba functions executing them list_index_bound_rows , list_index_bound_column_per_row = sample_rows_from_path ( path ) grah_scattergl_data = compute_spectrum_per_row_selection ( list_index_bound_rows , list_index_bound_column_per_row , self . data . get_array_spectra ( slice_index ), self . data . get_array_lookup_pixels ( slice_index ), self . data . get_image_shape ( slice_index ), self . data . get_array_peaks_transformed_lipids ( slice_index ), self . data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), zeros_extend = False , apply_correction = False , ) grah_scattergl_data = convert_array_to_fine_grained ( grah_scattergl_data , 10 **- 3 , lb = 350 , hb = 1250 , ) grah_scattergl_data = strip_zeros ( grah_scattergl_data ) l_idx_labels = np . array ([ - 1 , 2 , - 1 ], dtype = np . int32 ) return_idx_sup ( l_idx_labels ) return_idx_inf ( l_idx_labels ) add_zeros_to_spectrum ( grah_scattergl_data , pad_individual_peaks = True , padding = 10 **- 4 , ) array_intensity_with_lipids = np . array ( [ 1.21864345e-04 , 9.33317497e-05 , 6.23099259e-05 ], dtype = np . float32 ) array_idx_labels = np . array ([ - 1 - 1 - 1 ], dtype = np . int32 ) compute_avg_intensity_per_lipid ( array_intensity_with_lipids , array_idx_labels ) compute_image_using_index_and_image_lookup ( 500.1 , 500.2 , self . data . get_array_spectra ( slice_index ), self . data . get_array_lookup_pixels ( slice_index ), self . data . get_image_shape ( slice_index ), self . data . get_array_lookup_mz ( slice_index ), self . data . get_array_cumulated_lookup_mz_image ( slice_index ), self . data . get_divider_lookup ( slice_index ), self . data . get_array_peaks_transformed_lipids ( slice_index ), self . data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), apply_transform = False , ) def select_lipid_and_region_and_plot_volume (): ll_t_bounds = [[ None , None , None ] for i in self . data . get_slice_list ( indices = \"brain_1\" )] ll_t_bounds [ 0 ] = [[( 622.61 , 622.62 )], None , None ] set_id_regions = { 1006 } self . figures . compute_3D_volume_figure ( None , ll_t_bounds , set_id_regions = set_id_regions ) logging . info ( \"Please wait while compiled functions are executed...\" ) draw_region_and_compute_spectral_data () select_lipid_and_region_and_plot_volume () # Clean memory as it has not been done since compute_thread_safe function wasn't used self . data . clean_memory ( slice_index = 1 ) logging . info ( \"Compiled functions executed.\" ) def launch ( self , force_exit_if_first_launch = True ): \"\"\"This function is used at the execution of the app. It will take care of checking/cleaning the database entries, run compiled functions once, and precompute all the objects that can be precomputed. At the very first launch, the app can be greedy in memory, reason for which the user can choose to force the exit of the app, to start with a lighter process. Args: force_exit_if_first_launch (bool): if True, the app will force exit if it is the first launch. \"\"\" # Check for missing entries l_missing_entries = self . check_missing_db_entries () # Compute missing entries self . compute_and_fill_entries ( l_missing_entries ) # Run compiled functions self . run_compiled_functions () # Check if the app has been run before, and potentially force exit if not if not self . storage . check_shelved_object ( \"launch\" , \"first_launch\" ): self . storage . dump_shelved_object ( \"launch\" , \"first_launch\" , True ) if force_exit_if_first_launch : sys . exit ( \"The app has been exited now that everything has been precomputed.\" + \"Please launch the app again.\" )","title":"Launch"},{"location":"modules/launch/#modules.launch.Launch.__init__","text":"Initialize the class Launch. Parameters: Name Type Description Default data MaldiData MaldiData object, used to manipulate the raw MALDI data. required atlas Atlas Atlas object, used to manipulate the objects coming from the Allen Brain Atlas. required figures Figures Figures object, used to build the figures of the app. required storage Storage Storage object, used to access the shelve database. required Source code in modules/launch.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 def __init__ ( self , data , atlas , figures , storage ): \"\"\"Initialize the class Launch. Args: data (MaldiData): MaldiData object, used to manipulate the raw MALDI data. atlas (Atlas): Atlas object, used to manipulate the objects coming from the Allen Brain Atlas. figures (Figures): Figures object, used to build the figures of the app. storage (Storage): Storage object, used to access the shelve database. \"\"\" # App main objects self . data = data self . atlas = atlas self . figures = figures # Database path self . storage = storage # Objects to shelve in the Atlas class. Everything in this list is shelved at # initialization of Atlas and Figures objects. The computations described are the ones done # at startup. self . l_atlas_objects_at_init = [ # Computed in Atlas.__init__() as an argument of Atlas. Corresponds to the object # returned by Atlas.compute_dic_acronym_children_id() \"atlas/atlas_objects/dic_acronym_children_id\" , # # Computed in Atlas.__init__() as an argument of Atlas. Corresponds to the object # returned by Atlas.compute_hierarchy_list() \"atlas/atlas_objects/hierarchy\" , # # Computed in Atlas.__init__() as an argument of Atlas. Corresponds to the object # returned by Atlas.compute_array_projection(True, True) \"atlas/atlas_objects/arrays_projection_corrected_True_True\" , # # Computed in Atlas.__init__(), calling Atlas.compute_array_projection() when # computing arrays_projection_corrected_True_True. Corresponds to the object returned by # Atlas.compute_projection_parameters() # * This computation takes ~20s \"atlas/atlas_objects/l_transform_parameters\" , # # Computed in Atlas.__init__(), calling Atlas.save_all_projected_masks_and_spectra(), # but it doesn't correpond to an object returned by a specific function. # All the masks and spectra are also computed and saved in the shelve database with the # following ids: # \"atlas/atlas_objects/mask_and_spectrum_$slice_index$_$id_mask$\", # \"atlas/atlas_objects/mask_and_spectrum_MAIA_corrected_$slice_index$_$id_mask$\" # (not explicitely in this list as there are too many, and they are necessarily computed # along with dic_existing_masks). # * This a very long computation, the longest in the app. * \"atlas/atlas_objects/dic_existing_masks\" , # # Computed when needed, as a property of Atlas. Corresponds to the object returned by # Atlas.compute_list_projected_atlas_borders_figures(). In practice, this function is # called at startup, when calling Figures.compute_dic_fig_contours() in # Figures.__init()__, through the computation of compute_figure_basic_image (with # plot_atlas_contours set to True). \"atlas/atlas_objects/list_projected_atlas_borders_arrays\" , # # Computed at startup through calling # Atlas.compute_list_projected_atlas_borders_figures() (see comment just above). # Corresponds to the object returned by atlas.prepare_and_compute_array_images_atlas(). \"atlas/atlas_objects/array_images_atlas_True\" , # ] # Objects to shelve in the Figures class. Everything in this list is shelved at # initialization of the Figure object. The computations described are the ones done at # startup. self . l_figures_objects_at_init = [ # Computed in Figures.__init__() as an argument of Figures. Corresponds to the # object returned by # Figures.compute_normalization_factor_across_slices(cache_flask=None) \"figures/lipid_selection/dic_normalization_factors_None\" , # # Computed in Figures.__init__(). Corresponds to the object returned # by Figures.compute_treemaps_figure(). \"figures/atlas_page/3D/treemaps\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_figure_slices_3D(brain), with brain equal to 'brain_1' or 'brain_2'. \"figures/3D_page/slices_3D_brain_1\" , \"figures/3D_page/slices_3D_brain_2\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_3D_root_volume(). \"figures/3D_page/volume_root\" , # # Computed in Figures.__init__() through Figures.compute_scatter_3D(). Corresponds to # the object returned by Figures.compute_3D_root_volume(differentiate_borders=True). \"figures/3D_page/volume_root_True\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_scatter_3D(). \"figures/scRNAseq_page/scatter3D\" , # # Computed in Figures.__init__(). Corresponds to the object returned by # Figures.compute_heatmap_lipid_genes() with brain_1 parameter True or False. \"figures/scRNAseq_page/base_heatmap_lipid_True\" , \"figures/scRNAseq_page/base_heatmap_lipid_False\" , # # Computed in Figures.__init(), calling Figures.shelve_arrays_basic_figures(), but # it doesn't correpond to an object returned by a specific function. # All figures are computed and saved in the shelve database with the following ids: # \"figures/load_page/figure_basic_image_$type_figure$_$idx_slice$_$display_annotations\", # (not explicitely in this list as there are too many). # * This a long computation. \"figures/load_page/arrays_basic_figures_computed\" , # # Computed in compute_figure_basic_image() only, which is called in # Figures.shelve_arrays_basic_figures(), itself called in Figures.__init__(). # Corresponds to the object returned by # figures.compute_array_basic_images(type_figure), with type_figure having the # following values: \"original_data\", \"warped_data\", \"projection_corrected\", \"atlas\" \"figures/load_page/array_basic_images_original_data\" , \"figures/load_page/array_basic_images_warped_data\" , \"figures/load_page/array_basic_images_projection_corrected\" , \"figures/load_page/array_basic_images_atlas\" , # # Computed in Figures.__init(), calling Figures.shelve_all_l_array_2D(), but it # doesn't correspond to an object returned by a specific function. # All the list of 2D slices of expression objects are computed and saved in the # shelve database with the following ids (True is for brain 1 data, False is for brain 2 # data): # \"figures/3D_page/arrays_expression_True_$name_lipid$__\", # \"figures/3D_page/arrays_expression_False_$name_lipid$__\", # (not explicitely in this list as there are too many). # * This a very long computation. \"figures/3D_page/arrays_expression_True_computed\" , \"figures/3D_page/arrays_expression_False_computed\" , # # Computed in in Figures.__init(), calling Figures.shelve_all_arrays_annotation(), # but it doesn't correspond to an object returned by a specific function. The # corresponding objects saved in Figures.shelve_all_arrays_annotation() are in the # comment below. \"figures/3D_page/arrays_annotation_computed\" , ] + [ # Computed in in Figures.__init(), calling Figures.shelve_all_arrays_annotation(). # Corresponds to the object returned by # Figures.get_array_of_annotations(decrease_dimensionality_factor), with # decrease_dimensionality_factor ranging from 2 to 11. \"figures/3D_page/arrays_annotation_\" + str ( decrease_dimensionality_factor ) for decrease_dimensionality_factor in range ( 2 , 13 ) ] # Objects to shelve in the ScRNAseq class. Everything in this list is shelved at # initialization of the ScRNAseq objects. The computations described are the ones done # at startup. self . l_scRNAseq_objects_at_init = [] # Objects to shelve not belonging to a specific class. Objects in the list are not # automatically shelved at startup. self . l_other_objects_to_compute = [ # Computed when loading the lipid_selection page. Corresponds to the object returned by # return_lipid_options(). \"annotations/lipid_options\" , ] # List of all db entries self . l_db_entries = ( self . l_atlas_objects_at_init + self . l_figures_objects_at_init + self . l_scRNAseq_objects_at_init + self . l_other_objects_to_compute ) # Db entries to ignore as they are either computed through other entries, or not relevant self . l_entries_to_ignore = [ \"figures/3D_page/arrays_expression_\" , \"figures/load_page/figure_basic_image_\" , \"atlas/atlas_objects/mask_and_spectrum_\" , \"atlas/atlas_objects/dic_processed_temp\" , \"launch/first_launch\" , ]","title":"__init__()"},{"location":"modules/launch/#modules.launch.Launch.check_missing_db_entries","text":"This function checks if all the entries in self.l_db_entries are in the shelve database. It then returns a list containing the missing entries. Source code in modules/launch.py 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 def check_missing_db_entries ( self ): \"\"\"This function checks if all the entries in self.l_db_entries are in the shelve database. It then returns a list containing the missing entries. \"\"\" # Get database db = shelve . open ( self . storage . path_db ) # Build a set of missing entries l_missing_entries = list ( set ( self . l_db_entries ) - set ( db . keys ())) if len ( l_missing_entries ) > 0 : logging . info ( \"Missing entries found in the shelve database:\" + str ( l_missing_entries )) # Find out if there are entries in the databse and not in the list of entries to check l_unexpected_entries = list ( set ( db . keys ()) - set ( self . l_db_entries )) # Remove entries that are not in the initial list but are in the database, i.e all 2D lipid # slices, all brain regions, all figures in the load_slice page, and all atlas masks. l_unexpected_entries = [ x for x in l_unexpected_entries if [ entry not in x for entry in self . l_entries_to_ignore ] . count ( True ) == 0 ] if len ( l_unexpected_entries ) > 0 : logging . warning ( \"WARNING: unexpected entries found in the shelve database: \" + str ( l_unexpected_entries ) ) # Close database db . close () return l_missing_entries","title":"check_missing_db_entries()"},{"location":"modules/launch/#modules.launch.Launch.compute_and_fill_entries","text":"This function precompute all the entries in l_missing_entries and fill them in the shelve database. Parameters: Name Type Description Default l_missing_entries list list of entries to compute and insert in the shelve database. required Source code in modules/launch.py 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 def compute_and_fill_entries ( self , l_missing_entries ): \"\"\"This function precompute all the entries in l_missing_entries and fill them in the shelve database. Args: l_missing_entries (list): list of entries to compute and insert in the shelve database. \"\"\" # Get database db = shelve . open ( self . storage . path_db ) # Compute missing entries if possible for entry in l_missing_entries : if entry in self . l_atlas_objects_at_init : logging . warning ( \"This entry should not be missing,\" + \" as it is computed during Atlas initialization: \" + entry + \" . Please rebuild the atlas variable\" ) elif entry in self . l_figures_objects_at_init : logging . warning ( \"This entry should not be missing,\" + \" as it is computed during Figures initialization: \" + entry + \" . Please rebuild the figures variable\" ) elif entry in self . l_other_objects_to_compute : logging . info ( \"Entry: \" + entry + \" is missing. Computing now.\" ) if entry == \"annotations/lipid_options\" : db [ entry ] = self . data . return_lipid_options () else : logging . warning ( \"Entry \" + entry + \" not found in the list of entries to compute.\" ) # Close database db . close ()","title":"compute_and_fill_entries()"},{"location":"modules/launch/#modules.launch.Launch.launch","text":"This function is used at the execution of the app. It will take care of checking/cleaning the database entries, run compiled functions once, and precompute all the objects that can be precomputed. At the very first launch, the app can be greedy in memory, reason for which the user can choose to force the exit of the app, to start with a lighter process. Parameters: Name Type Description Default force_exit_if_first_launch bool if True, the app will force exit if it is the first launch. True Source code in modules/launch.py 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 def launch ( self , force_exit_if_first_launch = True ): \"\"\"This function is used at the execution of the app. It will take care of checking/cleaning the database entries, run compiled functions once, and precompute all the objects that can be precomputed. At the very first launch, the app can be greedy in memory, reason for which the user can choose to force the exit of the app, to start with a lighter process. Args: force_exit_if_first_launch (bool): if True, the app will force exit if it is the first launch. \"\"\" # Check for missing entries l_missing_entries = self . check_missing_db_entries () # Compute missing entries self . compute_and_fill_entries ( l_missing_entries ) # Run compiled functions self . run_compiled_functions () # Check if the app has been run before, and potentially force exit if not if not self . storage . check_shelved_object ( \"launch\" , \"first_launch\" ): self . storage . dump_shelved_object ( \"launch\" , \"first_launch\" , True ) if force_exit_if_first_launch : sys . exit ( \"The app has been exited now that everything has been precomputed.\" + \"Please launch the app again.\" )","title":"launch()"},{"location":"modules/launch/#modules.launch.Launch.run_compiled_functions","text":"This function runs once the slowest numba functions, whose compilation can take a little bit of time, so that the app is as fast as it can be after startup. Basically, it simulates the user doing various actions in the app. Source code in modules/launch.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 def run_compiled_functions ( self ): \"\"\"This function runs once the slowest numba functions, whose compilation can take a little bit of time, so that the app is as fast as it can be after startup. Basically, it simulates the user doing various actions in the app. \"\"\" # Simulate the user drawing one region (here on slice 1), and compute the corresponding # spectral data def draw_region_and_compute_spectral_data (): # Define function parameters slice_index = 1 path = np . array ( [( 53 , 108 ), ( 54 , 102 ), ( 59 , 101 ), ( 58 , 103 ), ( 56 , 105 ), ( 53 , 108 )], dtype = np . int32 ) # Force compile numba functions executing them list_index_bound_rows , list_index_bound_column_per_row = sample_rows_from_path ( path ) grah_scattergl_data = compute_spectrum_per_row_selection ( list_index_bound_rows , list_index_bound_column_per_row , self . data . get_array_spectra ( slice_index ), self . data . get_array_lookup_pixels ( slice_index ), self . data . get_image_shape ( slice_index ), self . data . get_array_peaks_transformed_lipids ( slice_index ), self . data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), zeros_extend = False , apply_correction = False , ) grah_scattergl_data = convert_array_to_fine_grained ( grah_scattergl_data , 10 **- 3 , lb = 350 , hb = 1250 , ) grah_scattergl_data = strip_zeros ( grah_scattergl_data ) l_idx_labels = np . array ([ - 1 , 2 , - 1 ], dtype = np . int32 ) return_idx_sup ( l_idx_labels ) return_idx_inf ( l_idx_labels ) add_zeros_to_spectrum ( grah_scattergl_data , pad_individual_peaks = True , padding = 10 **- 4 , ) array_intensity_with_lipids = np . array ( [ 1.21864345e-04 , 9.33317497e-05 , 6.23099259e-05 ], dtype = np . float32 ) array_idx_labels = np . array ([ - 1 - 1 - 1 ], dtype = np . int32 ) compute_avg_intensity_per_lipid ( array_intensity_with_lipids , array_idx_labels ) compute_image_using_index_and_image_lookup ( 500.1 , 500.2 , self . data . get_array_spectra ( slice_index ), self . data . get_array_lookup_pixels ( slice_index ), self . data . get_image_shape ( slice_index ), self . data . get_array_lookup_mz ( slice_index ), self . data . get_array_cumulated_lookup_mz_image ( slice_index ), self . data . get_divider_lookup ( slice_index ), self . data . get_array_peaks_transformed_lipids ( slice_index ), self . data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), apply_transform = False , ) def select_lipid_and_region_and_plot_volume (): ll_t_bounds = [[ None , None , None ] for i in self . data . get_slice_list ( indices = \"brain_1\" )] ll_t_bounds [ 0 ] = [[( 622.61 , 622.62 )], None , None ] set_id_regions = { 1006 } self . figures . compute_3D_volume_figure ( None , ll_t_bounds , set_id_regions = set_id_regions ) logging . info ( \"Please wait while compiled functions are executed...\" ) draw_region_and_compute_spectral_data () select_lipid_and_region_and_plot_volume () # Clean memory as it has not been done since compute_thread_safe function wasn't used self . data . clean_memory ( slice_index = 1 ) logging . info ( \"Compiled functions executed.\" )","title":"run_compiled_functions()"},{"location":"modules/maldi_data/","text":"This class is used to access the data coming from acquisitions (MALDI), essentially in the form of memory maps, and annotations. MaldiData A class to access the various arrays in the dataset from two dictionnaries, lightweight (always kept in ram), and memmap (remains on disk). It uses the special attribute slots for faster access to the attributes. If _sample_data is True, all the dataset is stored in the lightweight dictionnary, and the memmap dictionnary is empty. Attributes: Name Type Description _sample_data bool if True, use the sampled dataset. Else use the whole dataset. _dic_lightweight dictionnary a dictionnary containing the following lightweights arrays, which remain in memory as long as the app is running, as well as the shape of thoses stored in memory maps: - image_shape: a tuple of integers, indicating the vertical and horizontal sizes of the corresponding slice. - divider_lookup: integer that sets the resolution of the lookup tables. - array_avg_spectrum_downsampled: bidimensional, it contains the low-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_lookup_pixels: bidimensional, it maps each pixel to two array_spectra_high_res indices, delimiting the corresponding spectrum. - array_lookup_mz_avg: unidimensional, it maps m/z values to indexes in the averaged array_spectra for each pixel. - array_peaks_transformed_lipids: bidimensional, it contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. In addition, it contains the shape of all the arrays stored in the numpy memory maps. Dictionnary indices start at 1. _n_slices int number of slices present in the dataset. _l_slices list list of slices indices in the dataset. Indices start at 1. _l_slices_brain_1 list list of slices indices belonging to brain 1. _l_slices_brain_2 list list of slices indices belonging to brain 2. _dic_memmap dictionnary a dictionnary containing numpy memory maps allowing to access the heavyweights arrays of the datasets, without saturating the disk (ONLY IF _sample_data IS FALSE. ELSE ALL THE DATASET IS STORED IN _dic_lightweight). The arrays in the dictionnary are: - array_spectra: bidimensional, it contains the concatenated spectra of each pixel. First row contains the m/z values, while second row contains the corresponding intensities. - array_avg_spectrum: bidimensional, it contains the high-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_avg_spectrum_after_standardization: Same as array_avg_spectrum, but after MAIA standardization. - array_lookup_mz: bidimensional, it maps m/z values to indexes in array_spectra for each pixel. - array_cumulated_lookup_mz_image: bidimensional, it maps m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. - array_corrective_factors: three-dimensional, it contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). _path_data str path were the data files are stored. _df_annotations pd . dataframe a dataframe containing for each slice and each annotated peak the name of the lipid in between the two annotated peak boundaries. Columns are 'slice', 'name', 'structure', 'cation', 'theoretical m/z', 'min', 'max', 'num_pixels', and 'mz_estimated'. _df_annotations_MAIA_transformed_lipids_brain_1 pd . dataframe a dataframe containing the average m/z value of each MAIA transformed lipid. Columns are 'name', 'structure', 'cation', 'estimated_mz', for brain 1. _df_annotations_MAIA_transformed_lipids_brain_2 pd . dataframe Same as _df_annotations_MAIA_transformed_lipids_brain_1 for brain 2. Methods init (path_data=\"data/whole_dataset/\", path_annotations=\"data/annotations/\"): Initialize the class MaldiData. get_annotations(): Getter for the lipid annotation of each slice, contained in a pandas dataframe. get_annotations_MAIA_transformed_lipids(brain_1=True): Getter for the MAIA transformed lipid annotation, contained in a pandas dataframe. get_slice_number(): Getter for the number of slice present in the dataset. get_slice_list(indices=\"all\"): Getter for the list of slice indices in the dataset. get_image_shape(slice_index): Getter for image_shape, which indicates the shape of the image corresponding to the acquisition indexed by slice_index. get_divider_lookup(slice_index): Getter for divider_lookup, which sets the resolution of the lookup of the acquisition indexed by slice_index. get_array_avg_spectrum_downsampled(slice_index): Getter for array_avg_spectrum_downsampled, which is a low resolution version of average spectrum of the acquisition indexed by slice_index. get_array_lookup_pixels(slice_index): Getter for array_lookup_pixels, which is a lookup table that maps pixel value to the corresponding spectrum indices in the corresponding spectrum data. get_array_lookup_mz_avg(slice_index): Getter for array_lookup_mz_avg, which is a lookup table that maps m/z values to the corresponding indices in the averaged sectral data. get_array_peaks_transformed_lipids(slice_index): Getter for array_peaks_transformed_lipids, which is a lookup table for the indices of the peaks of the transformed lipids in the spectral data. get_array_corrective_factors(slice_index): Getter for array_corrective_factors, which is a numpy array containing the MAIA corrective factors for each pixel of the requested acquired slice. get_array_spectra(slice_index): Getter for array_spectra, which is a (memmaped) numpy array containing the spectral data of slice indexed by slice_index. get_array_mz(slice_index): Getter for array_mz, which corresponds to the first row of array_spectra, i.e. the m/z values of the spectral data. get_array_intensity(slice_index): Getter for array_intensity, which corresponds to the second row of array_spectra, i.e. the intensity values of the spectral data. get_array_avg_spectrum(slice_index, standardization=True): Getter for array_avg_spectrum, which is a (memmaped) numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index. get_array_lookup_mz(slice_index): Getter for array_lookup_mz, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. get_array_cumulated_lookup_mz_image(slice_index): Getter for array_cumulated_lookup_mz_image, which is a lookup table that maps m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. get_partial_array_spectra(slice_index, lb=None, hb=None, index=None): Getter for partial_array_spectra, which is a (memmaped) numpy array containing the spectral data of slice indexed by slice_index, between lb and hb m/z values. get_partial_array_mz(slice_index, lb=None, hb=None, index=None): Getter for partial_array_mz, which corresponds to the first row of partial_array_spectra, i.e. the m/z values of the spectral data, between lb and hb. get_partial_array_intensity(slice_index, lb=None, hb=None, index=None): Getter for partial_array_intensity, which corresponds to the second row of partial_array_spectra, i.e. the intensity values of the spectral data, between lb and hb. get_partial_array_avg_spectrum(slice_index, lb=None, hb=None, standardization=True): Getter for partial_array_avg_spectrum, which is a (memmaped) numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index, between lb and hb m/z values. get_lookup_mz(slice_index, index): Returns the m/z value corresponding to the index in the spectral data of slice indexed by slice_index. get_cumulated_lookup_mz_image(slice_index, index): Returns the cumulated spectrum until the corresponding m/z value for the pixel corresponding to the index in the spectral data of slice indexed by slice_index. is_brain_1(self, slice_index): Returns True if the slice indexed by slice_index is from brain 1, False otherwise. clean_memory(slice_index=None, array=None, cache=None): Cleans the memory (reset the memory-mapped arrays) of the app. compute_l_labels(): Computes and returns the labels of the lipids in the dataset. return_lipid_options(): Computes and returns the list of lipid names, structures and cation. compute_padded_original_images(): Pads the original slice images of the dataset so that they all have the same size. Source code in modules/maldi_data.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 class MaldiData : \"\"\"A class to access the various arrays in the dataset from two dictionnaries, lightweight (always kept in ram), and memmap (remains on disk). It uses the special attribute __slots__ for faster access to the attributes. If _sample_data is True, all the dataset is stored in the lightweight dictionnary, and the memmap dictionnary is empty. Attributes: _sample_data (bool): if True, use the sampled dataset. Else use the whole dataset. _dic_lightweight (dictionnary): a dictionnary containing the following lightweights arrays, which remain in memory as long as the app is running, as well as the shape of thoses stored in memory maps: - image_shape: a tuple of integers, indicating the vertical and horizontal sizes of the corresponding slice. - divider_lookup: integer that sets the resolution of the lookup tables. - array_avg_spectrum_downsampled: bidimensional, it contains the low-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_lookup_pixels: bidimensional, it maps each pixel to two array_spectra_high_res indices, delimiting the corresponding spectrum. - array_lookup_mz_avg: unidimensional, it maps m/z values to indexes in the averaged array_spectra for each pixel. - array_peaks_transformed_lipids: bidimensional, it contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. In addition, it contains the shape of all the arrays stored in the numpy memory maps. Dictionnary indices start at 1. _n_slices (int): number of slices present in the dataset. _l_slices (list): list of slices indices in the dataset. Indices start at 1. _l_slices_brain_1 (list): list of slices indices belonging to brain 1. _l_slices_brain_2 (list): list of slices indices belonging to brain 2. _dic_memmap (dictionnary): a dictionnary containing numpy memory maps allowing to access the heavyweights arrays of the datasets, without saturating the disk (ONLY IF _sample_data IS FALSE. ELSE ALL THE DATASET IS STORED IN _dic_lightweight). The arrays in the dictionnary are: - array_spectra: bidimensional, it contains the concatenated spectra of each pixel. First row contains the m/z values, while second row contains the corresponding intensities. - array_avg_spectrum: bidimensional, it contains the high-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_avg_spectrum_after_standardization: Same as array_avg_spectrum, but after MAIA standardization. - array_lookup_mz: bidimensional, it maps m/z values to indexes in array_spectra for each pixel. - array_cumulated_lookup_mz_image: bidimensional, it maps m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. - array_corrective_factors: three-dimensional, it contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). _path_data (str): path were the data files are stored. _df_annotations (pd.dataframe): a dataframe containing for each slice and each annotated peak the name of the lipid in between the two annotated peak boundaries. Columns are 'slice', 'name', 'structure', 'cation', 'theoretical m/z', 'min', 'max', 'num_pixels', and 'mz_estimated'. _df_annotations_MAIA_transformed_lipids_brain_1 (pd.dataframe): a dataframe containing the average m/z value of each MAIA transformed lipid. Columns are 'name', 'structure', 'cation', 'estimated_mz', for brain 1. _df_annotations_MAIA_transformed_lipids_brain_2 (pd.dataframe): Same as _df_annotations_MAIA_transformed_lipids_brain_1 for brain 2. Methods: __init__(path_data=\"data/whole_dataset/\", path_annotations=\"data/annotations/\"): Initialize the class MaldiData. get_annotations(): Getter for the lipid annotation of each slice, contained in a pandas dataframe. get_annotations_MAIA_transformed_lipids(brain_1=True): Getter for the MAIA transformed lipid annotation, contained in a pandas dataframe. get_slice_number(): Getter for the number of slice present in the dataset. get_slice_list(indices=\"all\"): Getter for the list of slice indices in the dataset. get_image_shape(slice_index): Getter for image_shape, which indicates the shape of the image corresponding to the acquisition indexed by slice_index. get_divider_lookup(slice_index): Getter for divider_lookup, which sets the resolution of the lookup of the acquisition indexed by slice_index. get_array_avg_spectrum_downsampled(slice_index): Getter for array_avg_spectrum_downsampled, which is a low resolution version of average spectrum of the acquisition indexed by slice_index. get_array_lookup_pixels(slice_index): Getter for array_lookup_pixels, which is a lookup table that maps pixel value to the corresponding spectrum indices in the corresponding spectrum data. get_array_lookup_mz_avg(slice_index): Getter for array_lookup_mz_avg, which is a lookup table that maps m/z values to the corresponding indices in the averaged sectral data. get_array_peaks_transformed_lipids(slice_index): Getter for array_peaks_transformed_lipids, which is a lookup table for the indices of the peaks of the transformed lipids in the spectral data. get_array_corrective_factors(slice_index): Getter for array_corrective_factors, which is a numpy array containing the MAIA corrective factors for each pixel of the requested acquired slice. get_array_spectra(slice_index): Getter for array_spectra, which is a (memmaped) numpy array containing the spectral data of slice indexed by slice_index. get_array_mz(slice_index): Getter for array_mz, which corresponds to the first row of array_spectra, i.e. the m/z values of the spectral data. get_array_intensity(slice_index): Getter for array_intensity, which corresponds to the second row of array_spectra, i.e. the intensity values of the spectral data. get_array_avg_spectrum(slice_index, standardization=True): Getter for array_avg_spectrum, which is a (memmaped) numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index. get_array_lookup_mz(slice_index): Getter for array_lookup_mz, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. get_array_cumulated_lookup_mz_image(slice_index): Getter for array_cumulated_lookup_mz_image, which is a lookup table that maps m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. get_partial_array_spectra(slice_index, lb=None, hb=None, index=None): Getter for partial_array_spectra, which is a (memmaped) numpy array containing the spectral data of slice indexed by slice_index, between lb and hb m/z values. get_partial_array_mz(slice_index, lb=None, hb=None, index=None): Getter for partial_array_mz, which corresponds to the first row of partial_array_spectra, i.e. the m/z values of the spectral data, between lb and hb. get_partial_array_intensity(slice_index, lb=None, hb=None, index=None): Getter for partial_array_intensity, which corresponds to the second row of partial_array_spectra, i.e. the intensity values of the spectral data, between lb and hb. get_partial_array_avg_spectrum(slice_index, lb=None, hb=None, standardization=True): Getter for partial_array_avg_spectrum, which is a (memmaped) numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index, between lb and hb m/z values. get_lookup_mz(slice_index, index): Returns the m/z value corresponding to the index in the spectral data of slice indexed by slice_index. get_cumulated_lookup_mz_image(slice_index, index): Returns the cumulated spectrum until the corresponding m/z value for the pixel corresponding to the index in the spectral data of slice indexed by slice_index. is_brain_1(self, slice_index): Returns True if the slice indexed by slice_index is from brain 1, False otherwise. clean_memory(slice_index=None, array=None, cache=None): Cleans the memory (reset the memory-mapped arrays) of the app. compute_l_labels(): Computes and returns the labels of the lipids in the dataset. return_lipid_options(): Computes and returns the list of lipid names, structures and cation. compute_padded_original_images(): Pads the original slice images of the dataset so that they all have the same size. \"\"\" __slots__ = [ \"_dic_lightweight\" , \"_dic_memmap\" , \"_l_slices\" , \"_n_slices\" , \"_l_slices_brain_1\" , \"_l_slices_brain_2\" , \"_sample_data\" , \"_df_annotations\" , \"_df_annotations_MAIA_transformed_lipids_brain_1\" , \"_df_annotations_MAIA_transformed_lipids_brain_2\" , \"_path_data\" , ] # ============================================================================================== # --- Constructor # ============================================================================================== def __init__ ( self , path_data = \"data/whole_dataset/\" , path_annotations = \"data/annotations/\" , sample_data = False , ): \"\"\"Initialize the class MaldiData. Args: path_data (str): Path used to load the files containing the MALDI data. path_annotations (str): Path used to load the files containing the annotations. \"\"\" logging . info ( \"Initializing MaldiData object\" + logmem ()) # Set if use the sampled dataset or not self . _sample_data = sample_data # Load the dictionnary containing small-size data for all slices if self . _sample_data : with lzma . open ( path_data + \"light_arrays.pickle\" , \"rb\" ) as handle : self . _dic_lightweight = pickle . load ( handle ) else : with open ( path_data + \"light_arrays.pickle\" , \"rb\" ) as handle : self . _dic_lightweight = pickle . load ( handle ) # Simple variable to get the number of slices self . _n_slices = len ( self . _dic_lightweight ) self . _l_slices = sorted ( list ( self . _dic_lightweight . keys ())) self . _l_slices_brain_1 = sorted ( [ slice_idx for slice_idx , val in self . _dic_lightweight . items () if val [ \"is_brain_1\" ]] ) self . _l_slices_brain_2 = sorted ( [ slice_idx for slice_idx , val in self . _dic_lightweight . items () if not val [ \"is_brain_1\" ]] ) # Set the accesser to the mmap files self . _dic_memmap = {} if not self . _sample_data : for slice_index in self . _l_slices : self . _dic_memmap [ slice_index ] = {} for array_name in [ \"array_spectra\" , \"array_avg_spectrum\" , \"array_avg_spectrum_after_standardization\" , \"array_lookup_mz\" , \"array_cumulated_lookup_mz_image\" , \"array_corrective_factors\" , ]: self . _dic_memmap [ slice_index ][ array_name ] = np . memmap ( path_data + array_name + \"_\" + str ( slice_index ) + \".mmap\" , dtype = \"float32\" if array_name != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ slice_index ][ array_name + \"_shape\" ], ) # Save path_data for cleaning memmap in case self . _path_data = path_data # Load lipid annotation (not user-session specific) self . _df_annotations = pd . read_csv ( path_annotations + \"lipid_annotation.csv\" ) # Load lipid annotations of MAIA-transformed lipids for brain 1 self . _df_annotations_MAIA_transformed_lipids_brain_1 = pd . read_csv ( path_annotations + \"transformed_lipids_brain_1.csv\" ) # Brain 2 is not contained in the sampled dataset if not self . _sample_data : # Load lipid annotations of MAIA-transformed lipids for brain 2 self . _df_annotations_MAIA_transformed_lipids_brain_2 = pd . read_csv ( path_annotations + \"transformed_lipids_brain_2.csv\" ) else : self . _df_annotations_MAIA_transformed_lipids_brain_2 = None logging . info ( \"MaldiData object instantiated\" + logmem ()) # ============================================================================================== # --- Methods # ============================================================================================== def get_annotations ( self ): \"\"\"Getter for the lipid annotation of each slice, contained in a pandas dataframe. Returns: (pd.DataFrame): A dataframe of annotations. \"\"\" return self . _df_annotations def get_annotations_MAIA_transformed_lipids ( self , brain_1 = True ): \"\"\"Getter for the MAIA transformed lipid annotation, contained in a pandas dataframe. Args: brain_1 (bool, optional): If True, return the lipid annotions for brain 1. Else for brain 2. Defaults to True. Returns: (pd.DataFrame): A dataframe of lipid annotations for the MAIA transformed lipids. \"\"\" if brain_1 : return self . _df_annotations_MAIA_transformed_lipids_brain_1 else : return self . _df_annotations_MAIA_transformed_lipids_brain_2 def get_slice_number ( self ): \"\"\"Getter for the number of slice present in the dataset. Returns: (int): The number of slices in the dataset. \"\"\" return self . _n_slices def get_slice_list ( self , indices = \"all\" ): \"\"\"Getter for the list of slice indices. Args: indices (str, optional): If \"all\", return the list of all slice indices. If \"brain_1\", return the list of slice indices for brain 1. If \"brain_2\", return the list of slice indices for brain 2. Defaults to \"all\". Indices start at 1. Returns: (list): The list of requested slice indices. \"\"\" if indices == \"all\" : return self . _l_slices elif indices == \"brain_1\" : return self . _l_slices_brain_1 elif indices == \"brain_2\" : return self . _l_slices_brain_2 else : raise ValueError ( \"Invalid string for indices\" ) def get_image_shape ( self , slice_index ): \"\"\"Getter for image_shape, which indicates the shape of the image corresponding to the acquisition indexed by slice_index. Args: slice_index (int): Index of the slice whose shape is requested. Returns: (np.ndarray): The shape of the requested slice image. \"\"\" return self . _dic_lightweight [ slice_index ][ \"image_shape\" ] def get_divider_lookup ( self , slice_index ): \"\"\"Getter for divider_lookup, which sets the resolution of the lookup of the acquisition indexed by slice_index. Args: slice_index (int): Index of the slice whose divider lookup value is requested. Returns: (int): The divider lookup value for the requested slice. \"\"\" return self . _dic_lightweight [ slice_index ][ \"divider_lookup\" ] def get_array_avg_spectrum_downsampled ( self , slice_index ): \"\"\"Getter for array_avg_spectrum_downsampled, which is a low-resolution version of the average spectrum of the acquisition indexed by slice_index. Args: slice_index (int): Index of the slice whose spectrum data is requested. Returns: (np.ndarray): A low-resolution version of the average spectrum of the acquisition indexed by slice_index. \"\"\" # Previously called array_averaged_mz_intensity_low_res return self . _dic_lightweight [ slice_index ][ \"array_avg_spectrum_downsampled\" ] def get_array_lookup_pixels ( self , slice_index ): \"\"\"Getter for array_lookup_pixels, which is a lookup table that maps pixel value to the corresponding spectrum indices in the corresponding spectrum data. Args: slice_index (int): Index of the slice whose pixel lookup table is requested. Returns: (np.ndarray): The requested lookup table. \"\"\" # Previously called array_pixel_indexes_high_res return self . _dic_lightweight [ slice_index ][ \"array_lookup_pixels\" ] def get_array_lookup_mz_avg ( self , slice_index ): \"\"\"Getter for array_lookup_mz_avg, which is a lookup table that maps m/z values to the corresponding indices in the averaged sectral data. Args: slice_index (int): Index of the slice for which the lookup table is requested. Returns: (np.ndarray): The requested lookup table. \"\"\" # Previously called lookup_table_averaged_spectrum_high_res return self . _dic_lightweight [ slice_index ][ \"array_lookup_mz_avg\" ] def get_array_peaks_transformed_lipids ( self , slice_index ): \"\"\"Getter for array_peaks_transformed_lipids, which is a lookup table for the indices of the peaks of the transformed lipids in the spectral data. Args: slice_index (int): Index of the slice for which the peaks lookup table is requested. Returns: (np.ndarray): Bidimensional array of peak annotations for the requested slice. \"\"\" return self . _dic_lightweight [ slice_index ][ \"array_peaks_transformed_lipids\" ] def get_array_corrective_factors ( self , slice_index ): \"\"\"Getter for array_corrective_factors, which is a numpy array containing the MAIA corrective factors for each pixel of the requested acquired slice. Args: slice_index (int): Index of the slice for which the corrective factors are requested. Returns: (np.ndarray (mmaped if not sampled dataset)): Three-dimensional array containing the MAIA corrective factor used for lipids and each pixel. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_corrective_factors\" ] else : return self . _dic_memmap [ slice_index ][ \"array_corrective_factors\" ] def get_array_spectra ( self , slice_index ): \"\"\"Getter for array_spectra, which is a numpy array containing the spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the spectral data is requested. Returns: (np.ndarray (mmaped if not sampled dataset)): Spectral data of the requested slice. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_spectra\" ] else : return self . _dic_memmap [ slice_index ][ \"array_spectra\" ] def get_array_mz ( self , slice_index ): \"\"\"Getter for array_mz, which corresponds to the first row of array_spectra, i.e. the m/z values of the spectral data. Args: slice_index (int): Index of the slice for which the m/z values are requested. Returns: (np.ndarray (mmaped if not sampled dataset)): m/z values of the spectral data of the requested slice. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_spectra\" ][ 0 , :] else : return self . _dic_memmap [ slice_index ][ \"array_spectra\" ][ 0 , :] def get_array_intensity ( self , slice_index ): \"\"\"Getter for array_intensity, which corresponds to the second row of array_spectra, i.e. the intensity values of the spectral data. Args: slice_index (int): Index of the slice for which the intensity values are requested. Returns: (np.ndarray (mmaped if not sampled dataset)): Intensity values of the spectral data of the requested slice. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_spectra\" ][ 1 , :] else : return self . _dic_memmap [ slice_index ][ \"array_spectra\" ][ 1 , :] def get_array_avg_spectrum ( self , slice_index , standardization = True ): \"\"\"Getter for array_avg_spectrum, which is a numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the average spectrum is requested. standardization (bool): If True, the average spectrum is standardized with MAIA. Returns: (np.ndarray (mmaped if not sampled dataset)): The requested average spectrum. \"\"\" if not standardization : if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_avg_spectrum\" ] else : return self . _dic_memmap [ slice_index ][ \"array_avg_spectrum\" ] else : if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_avg_spectrum_after_standardization\" ] else : return self . _dic_memmap [ slice_index ][ \"array_avg_spectrum_after_standardization\" ] def get_array_lookup_mz ( self , slice_index ): \"\"\"Getter for array_lookup_mz, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. Args: slice_index (int): Index of the slice for which the lookup table is requested. Returns: (np.ndarray (mmaped if not sampled dataset)): The requested lookup table. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_lookup_mz\" ] else : return self . _dic_memmap [ slice_index ][ \"array_lookup_mz\" ] def get_array_cumulated_lookup_mz_image ( self , slice_index ): \"\"\"Getter for array_cumulated_lookup_mz_image, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. Args: slice_index (int): Index of the slice for which the lookup table is requested. Returns: (np.ndarray (mmaped if not sampled dataset)): The requested lookup table. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_cumulated_lookup_mz_image\" ] else : return self . _dic_memmap [ slice_index ][ \"array_cumulated_lookup_mz_image\" ] def get_partial_array_spectra ( self , slice_index , lb = None , hb = None , index = None ): \"\"\"Getter for partial_array_spectra, which is a numpy array containing the spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the spectral data is requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. index (int): Index of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): Spectral data of the requested slice. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] if lb is None and hb is None and index is None : # Previously called array_spectra_high_res. return dic [ \"array_spectra\" ] elif lb is not None and hb is not None : return dic [ \"array_spectra\" ][:, lb : hb ] elif index is not None : return dic [ \"array_spectra\" ][:, index ] # If not specific index has been provided, it returns a range if index is None : # Start with most likely case if hb is not None and lb is not None : return dic [ \"array_spectra\" ][:, lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_intensity ( slice_index ) # Most likely the remaining cases won't be used elif lb is None : return dic [ \"array_spectra\" ][:, : hb ] else : return dic [ \"array_spectra\" ][:, lb :] # Else, it returns the required index else : if lb is not None or hb is not None : logging . warning ( \"Both one or several boundaries and one index have been specified\" + \" when calling array_spectra. \" + \"Only the index request will be satisfied.\" ) return dic [ \"array_spectra\" ][:, index ] def get_partial_array_mz ( self , slice_index , lb = None , hb = None , index = None ): \"\"\"Getter for partial_array_mz, which corresponds to the first row of partial_array_spectra, i.e. the m/z values of the spectral data, between lb and hb. Args: slice_index (int): Index of the slice for which the m/z values are requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): m/z values of the spectral data of the requested slice between lb and hb. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] if lb is None and hb is None and index is None : # Previously called array_spectra_high_res return dic [ \"array_spectra\" ][ 0 , :] elif lb is not None and hb is not None : return dic [ \"array_spectra\" ][ 0 , lb : hb ] elif index is not None : return dic [ \"array_spectra\" ][ 0 , index ] # If not specific index has been provided, it returns a range if index is None : # Start with most likely case if hb is not None and lb is not None : return dic [ \"array_spectra\" ][ 0 , lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_mz ( slice_index ) # Most likely the remaining cases won't be used elif lb is None : return dic [ \"array_spectra\" ][ 0 , : hb ] else : return dic [ \"array_spectra\" ][ 0 , lb :] # Else, it returns the required index else : if lb is not None or hb is not None : logging . warning ( \"Both one or several boundaries and one index have been specified\" + \" when calling array_spectra. \" + \"Only the index request will be satisfied.\" ) return dic [ \"array_spectra\" ][ 0 , index ] def get_partial_array_intensity ( self , slice_index , lb = None , hb = None , index = None ): \"\"\"Getter for partial_array_intensity, which corresponds to the second row of partial_array_spectra, i.e. the intensity values of the spectral data, between lb and hb. Args: slice_index (int): Index of the slice for which the intensity values are requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray, mmaped if not sampled dataset): Intensity values of the spectral data of the requested slice between lb and hb. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] if lb is None and hb is None and index is None : # Previously called array_spectra_high_res return dic [ \"array_spectra\" ][ 1 , :] elif lb is not None and hb is not None : return dic [ \"array_spectra\" ][ 1 , lb : hb ] elif index is not None : return dic [ \"array_spectra\" ][ 1 , index ] # If not specific index has been provided, it returns a range if index is None : # Start with most likely case if hb is not None and lb is not None : return dic [ \"array_spectra\" ][ 1 , lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_intensity ( slice_index ) # Most likely the remaining cases won't be used elif lb is None : return dic [ \"array_spectra\" ][ 1 , : hb ] else : return dic [ \"array_spectra\" ][ 1 , lb :] # Else, it returns the required index else : if lb is not None or hb is not None : logging . warning ( \"Both one or several boundaries and one index have been specified\" + \" when calling array_spectra. \" + \"Only the index request will be satisfied.\" ) return dic [ \"array_spectra\" ][ 1 , index ] def get_partial_array_avg_spectrum ( self , slice_index , lb = None , hb = None , standardization = True ): \"\"\"Getter for partial_array_avg_spectrum, which corresponds to the average spectrum of the spectral data, between lb and hb. Args: slice_index (int): Index of the slice for which the average spectrum is requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. standardization (bool): If True, the average spectrum is normalized. Returns: (np.ndarray, mmaped if not sampled dataset)): Average spectrum of the spectral data of the requested slice between lb and hb. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] # Start with most likely case if hb is not None and lb is not None : if standardization : return dic [ slice_index ][ \"array_avg_spectrum\" ][:, lb : hb ] else : return dic [ slice_index ][ \"array_avg_spectrum_before_standardization\" ][:, lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_avg_spectrum ( slice_index , standardization ) # Most likely the remaining cases won't be used elif lb is None : if standardization : return dic [ slice_index ][ \"array_avg_spectrum\" ][:, : hb ] else : return dic [ slice_index ][ \"array_avg_spectrum_before_standardization\" ][:, : hb ] else : if standardization : return dic [ slice_index ][ \"array_avg_spectrum\" ][:, lb :] else : return dic [ slice_index ][ \"array_avg_spectrum_before_standardization\" ][:, lb :] def get_lookup_mz ( self , slice_index , index ): \"\"\"Returns the m/z value corresponding to the index in the spectral data of the slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the m/z value is requested. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): m/z value of the spectral data of the requested slice and requested lookup. \"\"\" # Just return the (one) required lookup to go faster if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_lookup_mz\" ][ index ] else : return self . _dic_memmap [ slice_index ][ \"array_lookup_mz\" ][ index ] def get_cumulated_lookup_mz_image ( self , slice_index , index ): \"\"\"Returns the cumulated spectrum until the corresponding m/z value for the pixel corresponding to the index in the spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the m/z value is requested. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): Cumulated m/z value of the spectral data of the requested slice and requested lookup. \"\"\" # Just return the (one) required lookup to go faster if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_cumulated_lookup_mz_image\" ][ index ] else : return self . _dic_memmap [ slice_index ][ \"array_cumulated_lookup_mz_image\" ][ index ] def is_brain_1 ( self , slice_index ): \"\"\"Returns True if the slice indexed by slice_index is a brain 1. Else, returns False. Args: slice_index (int): Index of the slice for which the status is requested. Returns: (bool): True if the slice indexed by slice_index is a brain 1. Else, returns False. \"\"\" return self . _dic_lightweight [ slice_index ][ \"is_brain_1\" ] def clean_memory ( self , slice_index = None , array = None , cache = None ): \"\"\"Cleans the memory (reset the memory-mapped arrays) of the app. slice_index and array allow for a more fine-grained cleaning. If \"cache\" is provided, it will be used to lock the dataset while cleaning. Overall, this function takes about 5ms to run on all memmaps, and 1ms on a given slice. Args: slice_index (int, optional): Index of the slice whose corresponding mmap must be cleaned. Defaults to None. array (str, optional): Name of the array whose corresponding mmap must be cleaned. Defaults to None. cache (flask_caching.Cache, optional): Cache of the database. Defaults to None. \"\"\" if self . _sample_data : logging . warning ( \"Cleaning memory-mapped dictionnary has been requested, but the sample dataset if\" \" currently being used.\" ) return None # Wait for memory to be released before taking action if cache is not None : while cache . get ( \"locked-reading\" ) or cache . get ( \"locked-cleaning\" ): time . sleep ( 0.05 ) # Lock memory to prevent other processes from accessing it cache . set ( \"locked-cleaning\" , True ) # Case no array name has been provided if array is None : l_array_names = [ \"array_spectra\" , \"array_avg_spectrum\" , \"array_avg_spectrum_after_standardization\" , \"array_lookup_mz\" , \"array_cumulated_lookup_mz_image\" , \"array_corrective_factors\" , ] # Clean all memmaps if no slice index have been given if slice_index is None : for index in self . _l_slices : for array_name in l_array_names : self . _dic_memmap [ index ][ array_name ] = np . memmap ( self . _path_data + array_name + \"_\" + str ( index ) + \".mmap\" , dtype = \"float32\" if array_name != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ index ][ array_name + \"_shape\" ], ) # Else clean all memmaps of a given slice index else : for array_name in l_array_names : self . _dic_memmap [ slice_index ][ array_name ] = np . memmap ( self . _path_data + array_name + \"_\" + str ( slice_index ) + \".mmap\" , dtype = \"float32\" if array_name != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ slice_index ][ array_name + \"_shape\" ], ) # Case an array name has been provided else : # Clean all memmaps corresponding to the current array if no slice_index have been given if slice_index is None : for index in self . _l_slices : self . _dic_memmap [ index ][ array ] = np . memmap ( self . _path_data + array + \"_\" + str ( index ) + \".mmap\" , dtype = \"float32\" if array != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ index ][ array + \"_shape\" ], ) # Else clean the memap of the given slice index else : self . _dic_memmap [ slice_index ][ array ] = np . memmap ( self . _path_data + array + \"_\" + str ( slice_index ) + \".mmap\" , dtype = \"float32\" if array != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ slice_index ][ array + \"_shape\" ], ) # Release memory if cache is not None : cache . set ( \"locked-cleaning\" , False ) logging . info ( \"Memory cleaned\" ) def compute_l_labels ( self ): \"\"\"Computes the list of labels of the dataset. Returns: (list): List of labels of the dataset. \"\"\" l_labels = ( self . _df_annotations [ \"name\" ] + \"_\" + self . _df_annotations [ \"structure\" ] + \"_\" + self . _df_annotations [ \"cation\" ] ) . to_list () return l_labels def return_lipid_options ( self ): \"\"\"Computes and returns the list of lipid names, structures and cation. Returns: (list): List of lipid names, structures and cations. \"\"\" return [ { \"label\" : name + \" \" + structure + \" \" + cation , \"value\" : name + \" \" + structure + \" \" + cation , \"group\" : name , } for name in sorted ( self . get_annotations () . name . unique ()) for structure in sorted ( self . get_annotations ()[( self . get_annotations ()[ \"name\" ] == name )] . structure . unique () ) for cation in sorted ( self . get_annotations ()[ ( self . get_annotations ()[ \"name\" ] == name ) & ( self . get_annotations ()[ \"structure\" ] == structure ) ] . cation . unique () ) ] def compute_padded_original_images ( self ): \"\"\"Pads the original images of the dataset so that they are all the same size. Returns: (np.ndarray): A 3D numpy array, where the first dimension corresponds to the slice index, and the second and third dimensions correspond to the padded images. \"\"\" # Compute number of slices from the original acquisition are present in the folder if self . _sample_data : path = \"data_sample/tiff_files/original_data/\" else : path = \"data/tiff_files/original_data/\" n_slices = len ([ x for x in os . listdir ( path ) if \"slice_\" in x ]) if n_slices != self . get_slice_number (): logging . warning ( \"The number of slices computed from the original tiff files is different from\" + \" the number of slice \" + \"recorded in the MaldiData object.\" ) # Store them as arrays in a list l_array_slices = [] for i in range ( n_slices ): filename = path + \"slice_\" + str ( i + 1 ) + \".tiff\" if self . _sample_data : l_array_slices . append ( np . array ( io . imread ( filename ), dtype = np . int16 )) else : l_array_slices . append ( np . array ( io . imread ( filename ), dtype = np . int16 )[:, :, 2 ]) # Find the size of the biggest image max_size = ( np . max ([ array_slice . shape [ 0 ] for array_slice in l_array_slices ]), np . max ([ array_slice . shape [ 1 ] for array_slice in l_array_slices ]), ) # Pad the images with zeros (we add +-0.1 in case we need to round above or below 0.5 # if odd dimension) l_array_slices = [ np . pad ( array_slice , ( ( int ( round ( max_size [ 0 ] - array_slice . shape [ 0 ] / 2 - 0.1 )), int ( round ( max_size [ 0 ] - array_slice . shape [ 0 ] / 2 + 0.1 )), ), ( int ( round ( max_size [ 1 ] - array_slice . shape [ 1 ] / 2 - 0.1 )), int ( round ( max_size [ 1 ] - array_slice . shape [ 1 ] / 2 + 0.1 )), ), ), ) for array_slice in l_array_slices ] return np . array ( l_array_slices ) __init__ ( path_data = 'data/whole_dataset/' , path_annotations = 'data/annotations/' , sample_data = False ) Initialize the class MaldiData. Parameters: Name Type Description Default path_data str Path used to load the files containing the MALDI data. 'data/whole_dataset/' path_annotations str Path used to load the files containing the annotations. 'data/annotations/' Source code in modules/maldi_data.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 def __init__ ( self , path_data = \"data/whole_dataset/\" , path_annotations = \"data/annotations/\" , sample_data = False , ): \"\"\"Initialize the class MaldiData. Args: path_data (str): Path used to load the files containing the MALDI data. path_annotations (str): Path used to load the files containing the annotations. \"\"\" logging . info ( \"Initializing MaldiData object\" + logmem ()) # Set if use the sampled dataset or not self . _sample_data = sample_data # Load the dictionnary containing small-size data for all slices if self . _sample_data : with lzma . open ( path_data + \"light_arrays.pickle\" , \"rb\" ) as handle : self . _dic_lightweight = pickle . load ( handle ) else : with open ( path_data + \"light_arrays.pickle\" , \"rb\" ) as handle : self . _dic_lightweight = pickle . load ( handle ) # Simple variable to get the number of slices self . _n_slices = len ( self . _dic_lightweight ) self . _l_slices = sorted ( list ( self . _dic_lightweight . keys ())) self . _l_slices_brain_1 = sorted ( [ slice_idx for slice_idx , val in self . _dic_lightweight . items () if val [ \"is_brain_1\" ]] ) self . _l_slices_brain_2 = sorted ( [ slice_idx for slice_idx , val in self . _dic_lightweight . items () if not val [ \"is_brain_1\" ]] ) # Set the accesser to the mmap files self . _dic_memmap = {} if not self . _sample_data : for slice_index in self . _l_slices : self . _dic_memmap [ slice_index ] = {} for array_name in [ \"array_spectra\" , \"array_avg_spectrum\" , \"array_avg_spectrum_after_standardization\" , \"array_lookup_mz\" , \"array_cumulated_lookup_mz_image\" , \"array_corrective_factors\" , ]: self . _dic_memmap [ slice_index ][ array_name ] = np . memmap ( path_data + array_name + \"_\" + str ( slice_index ) + \".mmap\" , dtype = \"float32\" if array_name != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ slice_index ][ array_name + \"_shape\" ], ) # Save path_data for cleaning memmap in case self . _path_data = path_data # Load lipid annotation (not user-session specific) self . _df_annotations = pd . read_csv ( path_annotations + \"lipid_annotation.csv\" ) # Load lipid annotations of MAIA-transformed lipids for brain 1 self . _df_annotations_MAIA_transformed_lipids_brain_1 = pd . read_csv ( path_annotations + \"transformed_lipids_brain_1.csv\" ) # Brain 2 is not contained in the sampled dataset if not self . _sample_data : # Load lipid annotations of MAIA-transformed lipids for brain 2 self . _df_annotations_MAIA_transformed_lipids_brain_2 = pd . read_csv ( path_annotations + \"transformed_lipids_brain_2.csv\" ) else : self . _df_annotations_MAIA_transformed_lipids_brain_2 = None logging . info ( \"MaldiData object instantiated\" + logmem ()) clean_memory ( slice_index = None , array = None , cache = None ) Cleans the memory (reset the memory-mapped arrays) of the app. slice_index and array allow for a more fine-grained cleaning. If \"cache\" is provided, it will be used to lock the dataset while cleaning. Overall, this function takes about 5ms to run on all memmaps, and 1ms on a given slice. Parameters: Name Type Description Default slice_index int Index of the slice whose corresponding mmap must be cleaned. Defaults to None. None array str Name of the array whose corresponding mmap must be cleaned. Defaults to None. None cache flask_caching . Cache Cache of the database. Defaults to None. None Source code in modules/maldi_data.py 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 def clean_memory ( self , slice_index = None , array = None , cache = None ): \"\"\"Cleans the memory (reset the memory-mapped arrays) of the app. slice_index and array allow for a more fine-grained cleaning. If \"cache\" is provided, it will be used to lock the dataset while cleaning. Overall, this function takes about 5ms to run on all memmaps, and 1ms on a given slice. Args: slice_index (int, optional): Index of the slice whose corresponding mmap must be cleaned. Defaults to None. array (str, optional): Name of the array whose corresponding mmap must be cleaned. Defaults to None. cache (flask_caching.Cache, optional): Cache of the database. Defaults to None. \"\"\" if self . _sample_data : logging . warning ( \"Cleaning memory-mapped dictionnary has been requested, but the sample dataset if\" \" currently being used.\" ) return None # Wait for memory to be released before taking action if cache is not None : while cache . get ( \"locked-reading\" ) or cache . get ( \"locked-cleaning\" ): time . sleep ( 0.05 ) # Lock memory to prevent other processes from accessing it cache . set ( \"locked-cleaning\" , True ) # Case no array name has been provided if array is None : l_array_names = [ \"array_spectra\" , \"array_avg_spectrum\" , \"array_avg_spectrum_after_standardization\" , \"array_lookup_mz\" , \"array_cumulated_lookup_mz_image\" , \"array_corrective_factors\" , ] # Clean all memmaps if no slice index have been given if slice_index is None : for index in self . _l_slices : for array_name in l_array_names : self . _dic_memmap [ index ][ array_name ] = np . memmap ( self . _path_data + array_name + \"_\" + str ( index ) + \".mmap\" , dtype = \"float32\" if array_name != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ index ][ array_name + \"_shape\" ], ) # Else clean all memmaps of a given slice index else : for array_name in l_array_names : self . _dic_memmap [ slice_index ][ array_name ] = np . memmap ( self . _path_data + array_name + \"_\" + str ( slice_index ) + \".mmap\" , dtype = \"float32\" if array_name != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ slice_index ][ array_name + \"_shape\" ], ) # Case an array name has been provided else : # Clean all memmaps corresponding to the current array if no slice_index have been given if slice_index is None : for index in self . _l_slices : self . _dic_memmap [ index ][ array ] = np . memmap ( self . _path_data + array + \"_\" + str ( index ) + \".mmap\" , dtype = \"float32\" if array != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ index ][ array + \"_shape\" ], ) # Else clean the memap of the given slice index else : self . _dic_memmap [ slice_index ][ array ] = np . memmap ( self . _path_data + array + \"_\" + str ( slice_index ) + \".mmap\" , dtype = \"float32\" if array != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ slice_index ][ array + \"_shape\" ], ) # Release memory if cache is not None : cache . set ( \"locked-cleaning\" , False ) logging . info ( \"Memory cleaned\" ) compute_l_labels () Computes the list of labels of the dataset. Returns: Type Description list List of labels of the dataset. Source code in modules/maldi_data.py 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 def compute_l_labels ( self ): \"\"\"Computes the list of labels of the dataset. Returns: (list): List of labels of the dataset. \"\"\" l_labels = ( self . _df_annotations [ \"name\" ] + \"_\" + self . _df_annotations [ \"structure\" ] + \"_\" + self . _df_annotations [ \"cation\" ] ) . to_list () return l_labels compute_padded_original_images () Pads the original images of the dataset so that they are all the same size. Returns: Type Description np . ndarray A 3D numpy array, where the first dimension corresponds to the slice index, and the second and third dimensions correspond to the padded images. Source code in modules/maldi_data.py 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 def compute_padded_original_images ( self ): \"\"\"Pads the original images of the dataset so that they are all the same size. Returns: (np.ndarray): A 3D numpy array, where the first dimension corresponds to the slice index, and the second and third dimensions correspond to the padded images. \"\"\" # Compute number of slices from the original acquisition are present in the folder if self . _sample_data : path = \"data_sample/tiff_files/original_data/\" else : path = \"data/tiff_files/original_data/\" n_slices = len ([ x for x in os . listdir ( path ) if \"slice_\" in x ]) if n_slices != self . get_slice_number (): logging . warning ( \"The number of slices computed from the original tiff files is different from\" + \" the number of slice \" + \"recorded in the MaldiData object.\" ) # Store them as arrays in a list l_array_slices = [] for i in range ( n_slices ): filename = path + \"slice_\" + str ( i + 1 ) + \".tiff\" if self . _sample_data : l_array_slices . append ( np . array ( io . imread ( filename ), dtype = np . int16 )) else : l_array_slices . append ( np . array ( io . imread ( filename ), dtype = np . int16 )[:, :, 2 ]) # Find the size of the biggest image max_size = ( np . max ([ array_slice . shape [ 0 ] for array_slice in l_array_slices ]), np . max ([ array_slice . shape [ 1 ] for array_slice in l_array_slices ]), ) # Pad the images with zeros (we add +-0.1 in case we need to round above or below 0.5 # if odd dimension) l_array_slices = [ np . pad ( array_slice , ( ( int ( round ( max_size [ 0 ] - array_slice . shape [ 0 ] / 2 - 0.1 )), int ( round ( max_size [ 0 ] - array_slice . shape [ 0 ] / 2 + 0.1 )), ), ( int ( round ( max_size [ 1 ] - array_slice . shape [ 1 ] / 2 - 0.1 )), int ( round ( max_size [ 1 ] - array_slice . shape [ 1 ] / 2 + 0.1 )), ), ), ) for array_slice in l_array_slices ] return np . array ( l_array_slices ) get_annotations () Getter for the lipid annotation of each slice, contained in a pandas dataframe. Returns: Type Description pd . DataFrame A dataframe of annotations. Source code in modules/maldi_data.py 258 259 260 261 262 263 264 265 def get_annotations ( self ): \"\"\"Getter for the lipid annotation of each slice, contained in a pandas dataframe. Returns: (pd.DataFrame): A dataframe of annotations. \"\"\" return self . _df_annotations get_annotations_MAIA_transformed_lipids ( brain_1 = True ) Getter for the MAIA transformed lipid annotation, contained in a pandas dataframe. Parameters: Name Type Description Default brain_1 bool If True, return the lipid annotions for brain 1. Else for brain 2. Defaults to True. True Returns: Type Description pd . DataFrame A dataframe of lipid annotations for the MAIA transformed lipids. Source code in modules/maldi_data.py 267 268 269 270 271 272 273 274 275 276 277 278 279 280 def get_annotations_MAIA_transformed_lipids ( self , brain_1 = True ): \"\"\"Getter for the MAIA transformed lipid annotation, contained in a pandas dataframe. Args: brain_1 (bool, optional): If True, return the lipid annotions for brain 1. Else for brain 2. Defaults to True. Returns: (pd.DataFrame): A dataframe of lipid annotations for the MAIA transformed lipids. \"\"\" if brain_1 : return self . _df_annotations_MAIA_transformed_lipids_brain_1 else : return self . _df_annotations_MAIA_transformed_lipids_brain_2 get_array_avg_spectrum ( slice_index , standardization = True ) Getter for array_avg_spectrum, which is a numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice for which the average spectrum is requested. required standardization bool If True, the average spectrum is standardized with MAIA. True Returns: Type Description np.ndarray (mmaped if not sampled dataset) The requested average spectrum. Source code in modules/maldi_data.py 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 def get_array_avg_spectrum ( self , slice_index , standardization = True ): \"\"\"Getter for array_avg_spectrum, which is a numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the average spectrum is requested. standardization (bool): If True, the average spectrum is standardized with MAIA. Returns: (np.ndarray (mmaped if not sampled dataset)): The requested average spectrum. \"\"\" if not standardization : if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_avg_spectrum\" ] else : return self . _dic_memmap [ slice_index ][ \"array_avg_spectrum\" ] else : if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_avg_spectrum_after_standardization\" ] else : return self . _dic_memmap [ slice_index ][ \"array_avg_spectrum_after_standardization\" ] get_array_avg_spectrum_downsampled ( slice_index ) Getter for array_avg_spectrum_downsampled, which is a low-resolution version of the average spectrum of the acquisition indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice whose spectrum data is requested. required Returns: Type Description np . ndarray A low-resolution version of the average spectrum of the acquisition indexed by slice_index. Source code in modules/maldi_data.py 334 335 336 337 338 339 340 341 342 343 344 345 346 def get_array_avg_spectrum_downsampled ( self , slice_index ): \"\"\"Getter for array_avg_spectrum_downsampled, which is a low-resolution version of the average spectrum of the acquisition indexed by slice_index. Args: slice_index (int): Index of the slice whose spectrum data is requested. Returns: (np.ndarray): A low-resolution version of the average spectrum of the acquisition indexed by slice_index. \"\"\" # Previously called array_averaged_mz_intensity_low_res return self . _dic_lightweight [ slice_index ][ \"array_avg_spectrum_downsampled\" ] get_array_corrective_factors ( slice_index ) Getter for array_corrective_factors, which is a numpy array containing the MAIA corrective factors for each pixel of the requested acquired slice. Parameters: Name Type Description Default slice_index int Index of the slice for which the corrective factors are requested. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) Three-dimensional array containing the MAIA corrective factor used for lipids and each pixel. Source code in modules/maldi_data.py 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 def get_array_corrective_factors ( self , slice_index ): \"\"\"Getter for array_corrective_factors, which is a numpy array containing the MAIA corrective factors for each pixel of the requested acquired slice. Args: slice_index (int): Index of the slice for which the corrective factors are requested. Returns: (np.ndarray (mmaped if not sampled dataset)): Three-dimensional array containing the MAIA corrective factor used for lipids and each pixel. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_corrective_factors\" ] else : return self . _dic_memmap [ slice_index ][ \"array_corrective_factors\" ] get_array_cumulated_lookup_mz_image ( slice_index ) Getter for array_cumulated_lookup_mz_image, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. Parameters: Name Type Description Default slice_index int Index of the slice for which the lookup table is requested. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) The requested lookup table. Source code in modules/maldi_data.py 489 490 491 492 493 494 495 496 497 498 499 500 501 502 def get_array_cumulated_lookup_mz_image ( self , slice_index ): \"\"\"Getter for array_cumulated_lookup_mz_image, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. Args: slice_index (int): Index of the slice for which the lookup table is requested. Returns: (np.ndarray (mmaped if not sampled dataset)): The requested lookup table. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_cumulated_lookup_mz_image\" ] else : return self . _dic_memmap [ slice_index ][ \"array_cumulated_lookup_mz_image\" ] get_array_intensity ( slice_index ) Getter for array_intensity, which corresponds to the second row of array_spectra, i.e. the intensity values of the spectral data. Parameters: Name Type Description Default slice_index int Index of the slice for which the intensity values are requested. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) Intensity values of the spectral data of the requested slice. Source code in modules/maldi_data.py 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 def get_array_intensity ( self , slice_index ): \"\"\"Getter for array_intensity, which corresponds to the second row of array_spectra, i.e. the intensity values of the spectral data. Args: slice_index (int): Index of the slice for which the intensity values are requested. Returns: (np.ndarray (mmaped if not sampled dataset)): Intensity values of the spectral data of the requested slice. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_spectra\" ][ 1 , :] else : return self . _dic_memmap [ slice_index ][ \"array_spectra\" ][ 1 , :] get_array_lookup_mz ( slice_index ) Getter for array_lookup_mz, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. Parameters: Name Type Description Default slice_index int Index of the slice for which the lookup table is requested. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) The requested lookup table. Source code in modules/maldi_data.py 474 475 476 477 478 479 480 481 482 483 484 485 486 487 def get_array_lookup_mz ( self , slice_index ): \"\"\"Getter for array_lookup_mz, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. Args: slice_index (int): Index of the slice for which the lookup table is requested. Returns: (np.ndarray (mmaped if not sampled dataset)): The requested lookup table. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_lookup_mz\" ] else : return self . _dic_memmap [ slice_index ][ \"array_lookup_mz\" ] get_array_lookup_mz_avg ( slice_index ) Getter for array_lookup_mz_avg, which is a lookup table that maps m/z values to the corresponding indices in the averaged sectral data. Parameters: Name Type Description Default slice_index int Index of the slice for which the lookup table is requested. required Returns: Type Description np . ndarray The requested lookup table. Source code in modules/maldi_data.py 361 362 363 364 365 366 367 368 369 370 371 372 def get_array_lookup_mz_avg ( self , slice_index ): \"\"\"Getter for array_lookup_mz_avg, which is a lookup table that maps m/z values to the corresponding indices in the averaged sectral data. Args: slice_index (int): Index of the slice for which the lookup table is requested. Returns: (np.ndarray): The requested lookup table. \"\"\" # Previously called lookup_table_averaged_spectrum_high_res return self . _dic_lightweight [ slice_index ][ \"array_lookup_mz_avg\" ] get_array_lookup_pixels ( slice_index ) Getter for array_lookup_pixels, which is a lookup table that maps pixel value to the corresponding spectrum indices in the corresponding spectrum data. Parameters: Name Type Description Default slice_index int Index of the slice whose pixel lookup table is requested. required Returns: Type Description np . ndarray The requested lookup table. Source code in modules/maldi_data.py 348 349 350 351 352 353 354 355 356 357 358 359 def get_array_lookup_pixels ( self , slice_index ): \"\"\"Getter for array_lookup_pixels, which is a lookup table that maps pixel value to the corresponding spectrum indices in the corresponding spectrum data. Args: slice_index (int): Index of the slice whose pixel lookup table is requested. Returns: (np.ndarray): The requested lookup table. \"\"\" # Previously called array_pixel_indexes_high_res return self . _dic_lightweight [ slice_index ][ \"array_lookup_pixels\" ] get_array_mz ( slice_index ) Getter for array_mz, which corresponds to the first row of array_spectra, i.e. the m/z values of the spectral data. Parameters: Name Type Description Default slice_index int Index of the slice for which the m/z values are requested. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) m/z values of the spectral data of the requested slice. Source code in modules/maldi_data.py 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 def get_array_mz ( self , slice_index ): \"\"\"Getter for array_mz, which corresponds to the first row of array_spectra, i.e. the m/z values of the spectral data. Args: slice_index (int): Index of the slice for which the m/z values are requested. Returns: (np.ndarray (mmaped if not sampled dataset)): m/z values of the spectral data of the requested slice. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_spectra\" ][ 0 , :] else : return self . _dic_memmap [ slice_index ][ \"array_spectra\" ][ 0 , :] get_array_peaks_transformed_lipids ( slice_index ) Getter for array_peaks_transformed_lipids, which is a lookup table for the indices of the peaks of the transformed lipids in the spectral data. Parameters: Name Type Description Default slice_index int Index of the slice for which the peaks lookup table is requested. required Returns: Type Description np . ndarray Bidimensional array of peak annotations for the requested slice. Source code in modules/maldi_data.py 374 375 376 377 378 379 380 381 382 383 384 def get_array_peaks_transformed_lipids ( self , slice_index ): \"\"\"Getter for array_peaks_transformed_lipids, which is a lookup table for the indices of the peaks of the transformed lipids in the spectral data. Args: slice_index (int): Index of the slice for which the peaks lookup table is requested. Returns: (np.ndarray): Bidimensional array of peak annotations for the requested slice. \"\"\" return self . _dic_lightweight [ slice_index ][ \"array_peaks_transformed_lipids\" ] get_array_spectra ( slice_index ) Getter for array_spectra, which is a numpy array containing the spectral data of slice indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice for which the spectral data is requested. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) Spectral data of the requested slice. Source code in modules/maldi_data.py 402 403 404 405 406 407 408 409 410 411 412 413 414 415 def get_array_spectra ( self , slice_index ): \"\"\"Getter for array_spectra, which is a numpy array containing the spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the spectral data is requested. Returns: (np.ndarray (mmaped if not sampled dataset)): Spectral data of the requested slice. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_spectra\" ] else : return self . _dic_memmap [ slice_index ][ \"array_spectra\" ] get_cumulated_lookup_mz_image ( slice_index , index ) Returns the cumulated spectrum until the corresponding m/z value for the pixel corresponding to the index in the spectral data of slice indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice for which the m/z value is requested. required index int Index of the slice of the requested spectrum. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) Cumulated m/z value of the spectral data of the requested slice and requested lookup. Source code in modules/maldi_data.py 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 def get_cumulated_lookup_mz_image ( self , slice_index , index ): \"\"\"Returns the cumulated spectrum until the corresponding m/z value for the pixel corresponding to the index in the spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the m/z value is requested. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): Cumulated m/z value of the spectral data of the requested slice and requested lookup. \"\"\" # Just return the (one) required lookup to go faster if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_cumulated_lookup_mz_image\" ][ index ] else : return self . _dic_memmap [ slice_index ][ \"array_cumulated_lookup_mz_image\" ][ index ] get_divider_lookup ( slice_index ) Getter for divider_lookup, which sets the resolution of the lookup of the acquisition indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice whose divider lookup value is requested. required Returns: Type Description int The divider lookup value for the requested slice. Source code in modules/maldi_data.py 322 323 324 325 326 327 328 329 330 331 332 def get_divider_lookup ( self , slice_index ): \"\"\"Getter for divider_lookup, which sets the resolution of the lookup of the acquisition indexed by slice_index. Args: slice_index (int): Index of the slice whose divider lookup value is requested. Returns: (int): The divider lookup value for the requested slice. \"\"\" return self . _dic_lightweight [ slice_index ][ \"divider_lookup\" ] get_image_shape ( slice_index ) Getter for image_shape, which indicates the shape of the image corresponding to the acquisition indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice whose shape is requested. required Returns: Type Description np . ndarray The shape of the requested slice image. Source code in modules/maldi_data.py 310 311 312 313 314 315 316 317 318 319 320 def get_image_shape ( self , slice_index ): \"\"\"Getter for image_shape, which indicates the shape of the image corresponding to the acquisition indexed by slice_index. Args: slice_index (int): Index of the slice whose shape is requested. Returns: (np.ndarray): The shape of the requested slice image. \"\"\" return self . _dic_lightweight [ slice_index ][ \"image_shape\" ] get_lookup_mz ( slice_index , index ) Returns the m/z value corresponding to the index in the spectral data of the slice indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice for which the m/z value is requested. required index int Index of the slice of the requested spectrum. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) m/z value of the spectral data of the requested slice and requested lookup. Source code in modules/maldi_data.py 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 def get_lookup_mz ( self , slice_index , index ): \"\"\"Returns the m/z value corresponding to the index in the spectral data of the slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the m/z value is requested. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): m/z value of the spectral data of the requested slice and requested lookup. \"\"\" # Just return the (one) required lookup to go faster if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_lookup_mz\" ][ index ] else : return self . _dic_memmap [ slice_index ][ \"array_lookup_mz\" ][ index ] get_partial_array_avg_spectrum ( slice_index , lb = None , hb = None , standardization = True ) Getter for partial_array_avg_spectrum, which corresponds to the average spectrum of the spectral data, between lb and hb. Parameters: Name Type Description Default slice_index int Index of the slice for which the average spectrum is requested. required lb int Lower bound of the requested spectrum. None hb int Upper bound of the requested spectrum. None standardization bool If True, the average spectrum is normalized. True Returns: Type Description np.ndarray, mmaped if not sampled dataset) Average spectrum of the spectral data of the requested slice between lb and hb. Source code in modules/maldi_data.py 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 def get_partial_array_avg_spectrum ( self , slice_index , lb = None , hb = None , standardization = True ): \"\"\"Getter for partial_array_avg_spectrum, which corresponds to the average spectrum of the spectral data, between lb and hb. Args: slice_index (int): Index of the slice for which the average spectrum is requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. standardization (bool): If True, the average spectrum is normalized. Returns: (np.ndarray, mmaped if not sampled dataset)): Average spectrum of the spectral data of the requested slice between lb and hb. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] # Start with most likely case if hb is not None and lb is not None : if standardization : return dic [ slice_index ][ \"array_avg_spectrum\" ][:, lb : hb ] else : return dic [ slice_index ][ \"array_avg_spectrum_before_standardization\" ][:, lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_avg_spectrum ( slice_index , standardization ) # Most likely the remaining cases won't be used elif lb is None : if standardization : return dic [ slice_index ][ \"array_avg_spectrum\" ][:, : hb ] else : return dic [ slice_index ][ \"array_avg_spectrum_before_standardization\" ][:, : hb ] else : if standardization : return dic [ slice_index ][ \"array_avg_spectrum\" ][:, lb :] else : return dic [ slice_index ][ \"array_avg_spectrum_before_standardization\" ][:, lb :] get_partial_array_intensity ( slice_index , lb = None , hb = None , index = None ) Getter for partial_array_intensity, which corresponds to the second row of partial_array_spectra, i.e. the intensity values of the spectral data, between lb and hb. Parameters: Name Type Description Default slice_index int Index of the slice for which the intensity values are requested. required lb int Lower bound of the requested spectrum. None hb int Upper bound of the requested spectrum. None index int Index of the slice of the requested spectrum. None Returns: Type Description np.ndarray, mmaped if not sampled dataset Intensity values of the spectral data of the requested slice between lb and hb. Source code in modules/maldi_data.py 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 def get_partial_array_intensity ( self , slice_index , lb = None , hb = None , index = None ): \"\"\"Getter for partial_array_intensity, which corresponds to the second row of partial_array_spectra, i.e. the intensity values of the spectral data, between lb and hb. Args: slice_index (int): Index of the slice for which the intensity values are requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray, mmaped if not sampled dataset): Intensity values of the spectral data of the requested slice between lb and hb. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] if lb is None and hb is None and index is None : # Previously called array_spectra_high_res return dic [ \"array_spectra\" ][ 1 , :] elif lb is not None and hb is not None : return dic [ \"array_spectra\" ][ 1 , lb : hb ] elif index is not None : return dic [ \"array_spectra\" ][ 1 , index ] # If not specific index has been provided, it returns a range if index is None : # Start with most likely case if hb is not None and lb is not None : return dic [ \"array_spectra\" ][ 1 , lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_intensity ( slice_index ) # Most likely the remaining cases won't be used elif lb is None : return dic [ \"array_spectra\" ][ 1 , : hb ] else : return dic [ \"array_spectra\" ][ 1 , lb :] # Else, it returns the required index else : if lb is not None or hb is not None : logging . warning ( \"Both one or several boundaries and one index have been specified\" + \" when calling array_spectra. \" + \"Only the index request will be satisfied.\" ) return dic [ \"array_spectra\" ][ 1 , index ] get_partial_array_mz ( slice_index , lb = None , hb = None , index = None ) Getter for partial_array_mz, which corresponds to the first row of partial_array_spectra, i.e. the m/z values of the spectral data, between lb and hb. Parameters: Name Type Description Default slice_index int Index of the slice for which the m/z values are requested. required lb int Lower bound of the requested spectrum. None hb int Upper bound of the requested spectrum. None index int Index of the slice of the requested spectrum. None Returns: Type Description np.ndarray (mmaped if not sampled dataset) m/z values of the spectral data of the requested slice between lb and hb. Source code in modules/maldi_data.py 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 def get_partial_array_mz ( self , slice_index , lb = None , hb = None , index = None ): \"\"\"Getter for partial_array_mz, which corresponds to the first row of partial_array_spectra, i.e. the m/z values of the spectral data, between lb and hb. Args: slice_index (int): Index of the slice for which the m/z values are requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): m/z values of the spectral data of the requested slice between lb and hb. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] if lb is None and hb is None and index is None : # Previously called array_spectra_high_res return dic [ \"array_spectra\" ][ 0 , :] elif lb is not None and hb is not None : return dic [ \"array_spectra\" ][ 0 , lb : hb ] elif index is not None : return dic [ \"array_spectra\" ][ 0 , index ] # If not specific index has been provided, it returns a range if index is None : # Start with most likely case if hb is not None and lb is not None : return dic [ \"array_spectra\" ][ 0 , lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_mz ( slice_index ) # Most likely the remaining cases won't be used elif lb is None : return dic [ \"array_spectra\" ][ 0 , : hb ] else : return dic [ \"array_spectra\" ][ 0 , lb :] # Else, it returns the required index else : if lb is not None or hb is not None : logging . warning ( \"Both one or several boundaries and one index have been specified\" + \" when calling array_spectra. \" + \"Only the index request will be satisfied.\" ) return dic [ \"array_spectra\" ][ 0 , index ] get_partial_array_spectra ( slice_index , lb = None , hb = None , index = None ) Getter for partial_array_spectra, which is a numpy array containing the spectral data of slice indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice for which the spectral data is requested. required lb int Lower bound of the requested spectrum. None hb int Upper bound of the requested spectrum. None index int Index of the requested spectrum. None Returns: Type Description np.ndarray (mmaped if not sampled dataset) Spectral data of the requested slice. Source code in modules/maldi_data.py 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 def get_partial_array_spectra ( self , slice_index , lb = None , hb = None , index = None ): \"\"\"Getter for partial_array_spectra, which is a numpy array containing the spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the spectral data is requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. index (int): Index of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): Spectral data of the requested slice. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] if lb is None and hb is None and index is None : # Previously called array_spectra_high_res. return dic [ \"array_spectra\" ] elif lb is not None and hb is not None : return dic [ \"array_spectra\" ][:, lb : hb ] elif index is not None : return dic [ \"array_spectra\" ][:, index ] # If not specific index has been provided, it returns a range if index is None : # Start with most likely case if hb is not None and lb is not None : return dic [ \"array_spectra\" ][:, lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_intensity ( slice_index ) # Most likely the remaining cases won't be used elif lb is None : return dic [ \"array_spectra\" ][:, : hb ] else : return dic [ \"array_spectra\" ][:, lb :] # Else, it returns the required index else : if lb is not None or hb is not None : logging . warning ( \"Both one or several boundaries and one index have been specified\" + \" when calling array_spectra. \" + \"Only the index request will be satisfied.\" ) return dic [ \"array_spectra\" ][:, index ] get_slice_list ( indices = 'all' ) Getter for the list of slice indices. Parameters: Name Type Description Default indices str If \"all\", return the list of all slice indices. If \"brain_1\", return the list of slice indices for brain 1. If \"brain_2\", return the list of slice indices for brain 2. Defaults to \"all\". Indices start at 1. 'all' Returns: Type Description list The list of requested slice indices. Source code in modules/maldi_data.py 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 def get_slice_list ( self , indices = \"all\" ): \"\"\"Getter for the list of slice indices. Args: indices (str, optional): If \"all\", return the list of all slice indices. If \"brain_1\", return the list of slice indices for brain 1. If \"brain_2\", return the list of slice indices for brain 2. Defaults to \"all\". Indices start at 1. Returns: (list): The list of requested slice indices. \"\"\" if indices == \"all\" : return self . _l_slices elif indices == \"brain_1\" : return self . _l_slices_brain_1 elif indices == \"brain_2\" : return self . _l_slices_brain_2 else : raise ValueError ( \"Invalid string for indices\" ) get_slice_number () Getter for the number of slice present in the dataset. Returns: Type Description int The number of slices in the dataset. Source code in modules/maldi_data.py 282 283 284 285 286 287 288 def get_slice_number ( self ): \"\"\"Getter for the number of slice present in the dataset. Returns: (int): The number of slices in the dataset. \"\"\" return self . _n_slices is_brain_1 ( slice_index ) Returns True if the slice indexed by slice_index is a brain 1. Else, returns False. Parameters: Name Type Description Default slice_index int Index of the slice for which the status is requested. required Returns: Type Description bool True if the slice indexed by slice_index is a brain 1. Else, returns False. Source code in modules/maldi_data.py 748 749 750 751 752 753 754 755 756 757 def is_brain_1 ( self , slice_index ): \"\"\"Returns True if the slice indexed by slice_index is a brain 1. Else, returns False. Args: slice_index (int): Index of the slice for which the status is requested. Returns: (bool): True if the slice indexed by slice_index is a brain 1. Else, returns False. \"\"\" return self . _dic_lightweight [ slice_index ][ \"is_brain_1\" ] return_lipid_options () Computes and returns the list of lipid names, structures and cation. Returns: Type Description list List of lipid names, structures and cations. Source code in modules/maldi_data.py 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 def return_lipid_options ( self ): \"\"\"Computes and returns the list of lipid names, structures and cation. Returns: (list): List of lipid names, structures and cations. \"\"\" return [ { \"label\" : name + \" \" + structure + \" \" + cation , \"value\" : name + \" \" + structure + \" \" + cation , \"group\" : name , } for name in sorted ( self . get_annotations () . name . unique ()) for structure in sorted ( self . get_annotations ()[( self . get_annotations ()[ \"name\" ] == name )] . structure . unique () ) for cation in sorted ( self . get_annotations ()[ ( self . get_annotations ()[ \"name\" ] == name ) & ( self . get_annotations ()[ \"structure\" ] == structure ) ] . cation . unique () ) ]","title":"maldi_data"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData","text":"A class to access the various arrays in the dataset from two dictionnaries, lightweight (always kept in ram), and memmap (remains on disk). It uses the special attribute slots for faster access to the attributes. If _sample_data is True, all the dataset is stored in the lightweight dictionnary, and the memmap dictionnary is empty. Attributes: Name Type Description _sample_data bool if True, use the sampled dataset. Else use the whole dataset. _dic_lightweight dictionnary a dictionnary containing the following lightweights arrays, which remain in memory as long as the app is running, as well as the shape of thoses stored in memory maps: - image_shape: a tuple of integers, indicating the vertical and horizontal sizes of the corresponding slice. - divider_lookup: integer that sets the resolution of the lookup tables. - array_avg_spectrum_downsampled: bidimensional, it contains the low-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_lookup_pixels: bidimensional, it maps each pixel to two array_spectra_high_res indices, delimiting the corresponding spectrum. - array_lookup_mz_avg: unidimensional, it maps m/z values to indexes in the averaged array_spectra for each pixel. - array_peaks_transformed_lipids: bidimensional, it contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. In addition, it contains the shape of all the arrays stored in the numpy memory maps. Dictionnary indices start at 1. _n_slices int number of slices present in the dataset. _l_slices list list of slices indices in the dataset. Indices start at 1. _l_slices_brain_1 list list of slices indices belonging to brain 1. _l_slices_brain_2 list list of slices indices belonging to brain 2. _dic_memmap dictionnary a dictionnary containing numpy memory maps allowing to access the heavyweights arrays of the datasets, without saturating the disk (ONLY IF _sample_data IS FALSE. ELSE ALL THE DATASET IS STORED IN _dic_lightweight). The arrays in the dictionnary are: - array_spectra: bidimensional, it contains the concatenated spectra of each pixel. First row contains the m/z values, while second row contains the corresponding intensities. - array_avg_spectrum: bidimensional, it contains the high-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_avg_spectrum_after_standardization: Same as array_avg_spectrum, but after MAIA standardization. - array_lookup_mz: bidimensional, it maps m/z values to indexes in array_spectra for each pixel. - array_cumulated_lookup_mz_image: bidimensional, it maps m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. - array_corrective_factors: three-dimensional, it contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). _path_data str path were the data files are stored. _df_annotations pd . dataframe a dataframe containing for each slice and each annotated peak the name of the lipid in between the two annotated peak boundaries. Columns are 'slice', 'name', 'structure', 'cation', 'theoretical m/z', 'min', 'max', 'num_pixels', and 'mz_estimated'. _df_annotations_MAIA_transformed_lipids_brain_1 pd . dataframe a dataframe containing the average m/z value of each MAIA transformed lipid. Columns are 'name', 'structure', 'cation', 'estimated_mz', for brain 1. _df_annotations_MAIA_transformed_lipids_brain_2 pd . dataframe Same as _df_annotations_MAIA_transformed_lipids_brain_1 for brain 2. Methods init (path_data=\"data/whole_dataset/\", path_annotations=\"data/annotations/\"): Initialize the class MaldiData. get_annotations(): Getter for the lipid annotation of each slice, contained in a pandas dataframe. get_annotations_MAIA_transformed_lipids(brain_1=True): Getter for the MAIA transformed lipid annotation, contained in a pandas dataframe. get_slice_number(): Getter for the number of slice present in the dataset. get_slice_list(indices=\"all\"): Getter for the list of slice indices in the dataset. get_image_shape(slice_index): Getter for image_shape, which indicates the shape of the image corresponding to the acquisition indexed by slice_index. get_divider_lookup(slice_index): Getter for divider_lookup, which sets the resolution of the lookup of the acquisition indexed by slice_index. get_array_avg_spectrum_downsampled(slice_index): Getter for array_avg_spectrum_downsampled, which is a low resolution version of average spectrum of the acquisition indexed by slice_index. get_array_lookup_pixels(slice_index): Getter for array_lookup_pixels, which is a lookup table that maps pixel value to the corresponding spectrum indices in the corresponding spectrum data. get_array_lookup_mz_avg(slice_index): Getter for array_lookup_mz_avg, which is a lookup table that maps m/z values to the corresponding indices in the averaged sectral data. get_array_peaks_transformed_lipids(slice_index): Getter for array_peaks_transformed_lipids, which is a lookup table for the indices of the peaks of the transformed lipids in the spectral data. get_array_corrective_factors(slice_index): Getter for array_corrective_factors, which is a numpy array containing the MAIA corrective factors for each pixel of the requested acquired slice. get_array_spectra(slice_index): Getter for array_spectra, which is a (memmaped) numpy array containing the spectral data of slice indexed by slice_index. get_array_mz(slice_index): Getter for array_mz, which corresponds to the first row of array_spectra, i.e. the m/z values of the spectral data. get_array_intensity(slice_index): Getter for array_intensity, which corresponds to the second row of array_spectra, i.e. the intensity values of the spectral data. get_array_avg_spectrum(slice_index, standardization=True): Getter for array_avg_spectrum, which is a (memmaped) numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index. get_array_lookup_mz(slice_index): Getter for array_lookup_mz, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. get_array_cumulated_lookup_mz_image(slice_index): Getter for array_cumulated_lookup_mz_image, which is a lookup table that maps m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. get_partial_array_spectra(slice_index, lb=None, hb=None, index=None): Getter for partial_array_spectra, which is a (memmaped) numpy array containing the spectral data of slice indexed by slice_index, between lb and hb m/z values. get_partial_array_mz(slice_index, lb=None, hb=None, index=None): Getter for partial_array_mz, which corresponds to the first row of partial_array_spectra, i.e. the m/z values of the spectral data, between lb and hb. get_partial_array_intensity(slice_index, lb=None, hb=None, index=None): Getter for partial_array_intensity, which corresponds to the second row of partial_array_spectra, i.e. the intensity values of the spectral data, between lb and hb. get_partial_array_avg_spectrum(slice_index, lb=None, hb=None, standardization=True): Getter for partial_array_avg_spectrum, which is a (memmaped) numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index, between lb and hb m/z values. get_lookup_mz(slice_index, index): Returns the m/z value corresponding to the index in the spectral data of slice indexed by slice_index. get_cumulated_lookup_mz_image(slice_index, index): Returns the cumulated spectrum until the corresponding m/z value for the pixel corresponding to the index in the spectral data of slice indexed by slice_index. is_brain_1(self, slice_index): Returns True if the slice indexed by slice_index is from brain 1, False otherwise. clean_memory(slice_index=None, array=None, cache=None): Cleans the memory (reset the memory-mapped arrays) of the app. compute_l_labels(): Computes and returns the labels of the lipids in the dataset. return_lipid_options(): Computes and returns the list of lipid names, structures and cation. compute_padded_original_images(): Pads the original slice images of the dataset so that they all have the same size. Source code in modules/maldi_data.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 class MaldiData : \"\"\"A class to access the various arrays in the dataset from two dictionnaries, lightweight (always kept in ram), and memmap (remains on disk). It uses the special attribute __slots__ for faster access to the attributes. If _sample_data is True, all the dataset is stored in the lightweight dictionnary, and the memmap dictionnary is empty. Attributes: _sample_data (bool): if True, use the sampled dataset. Else use the whole dataset. _dic_lightweight (dictionnary): a dictionnary containing the following lightweights arrays, which remain in memory as long as the app is running, as well as the shape of thoses stored in memory maps: - image_shape: a tuple of integers, indicating the vertical and horizontal sizes of the corresponding slice. - divider_lookup: integer that sets the resolution of the lookup tables. - array_avg_spectrum_downsampled: bidimensional, it contains the low-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_lookup_pixels: bidimensional, it maps each pixel to two array_spectra_high_res indices, delimiting the corresponding spectrum. - array_lookup_mz_avg: unidimensional, it maps m/z values to indexes in the averaged array_spectra for each pixel. - array_peaks_transformed_lipids: bidimensional, it contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. In addition, it contains the shape of all the arrays stored in the numpy memory maps. Dictionnary indices start at 1. _n_slices (int): number of slices present in the dataset. _l_slices (list): list of slices indices in the dataset. Indices start at 1. _l_slices_brain_1 (list): list of slices indices belonging to brain 1. _l_slices_brain_2 (list): list of slices indices belonging to brain 2. _dic_memmap (dictionnary): a dictionnary containing numpy memory maps allowing to access the heavyweights arrays of the datasets, without saturating the disk (ONLY IF _sample_data IS FALSE. ELSE ALL THE DATASET IS STORED IN _dic_lightweight). The arrays in the dictionnary are: - array_spectra: bidimensional, it contains the concatenated spectra of each pixel. First row contains the m/z values, while second row contains the corresponding intensities. - array_avg_spectrum: bidimensional, it contains the high-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_avg_spectrum_after_standardization: Same as array_avg_spectrum, but after MAIA standardization. - array_lookup_mz: bidimensional, it maps m/z values to indexes in array_spectra for each pixel. - array_cumulated_lookup_mz_image: bidimensional, it maps m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. - array_corrective_factors: three-dimensional, it contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). _path_data (str): path were the data files are stored. _df_annotations (pd.dataframe): a dataframe containing for each slice and each annotated peak the name of the lipid in between the two annotated peak boundaries. Columns are 'slice', 'name', 'structure', 'cation', 'theoretical m/z', 'min', 'max', 'num_pixels', and 'mz_estimated'. _df_annotations_MAIA_transformed_lipids_brain_1 (pd.dataframe): a dataframe containing the average m/z value of each MAIA transformed lipid. Columns are 'name', 'structure', 'cation', 'estimated_mz', for brain 1. _df_annotations_MAIA_transformed_lipids_brain_2 (pd.dataframe): Same as _df_annotations_MAIA_transformed_lipids_brain_1 for brain 2. Methods: __init__(path_data=\"data/whole_dataset/\", path_annotations=\"data/annotations/\"): Initialize the class MaldiData. get_annotations(): Getter for the lipid annotation of each slice, contained in a pandas dataframe. get_annotations_MAIA_transformed_lipids(brain_1=True): Getter for the MAIA transformed lipid annotation, contained in a pandas dataframe. get_slice_number(): Getter for the number of slice present in the dataset. get_slice_list(indices=\"all\"): Getter for the list of slice indices in the dataset. get_image_shape(slice_index): Getter for image_shape, which indicates the shape of the image corresponding to the acquisition indexed by slice_index. get_divider_lookup(slice_index): Getter for divider_lookup, which sets the resolution of the lookup of the acquisition indexed by slice_index. get_array_avg_spectrum_downsampled(slice_index): Getter for array_avg_spectrum_downsampled, which is a low resolution version of average spectrum of the acquisition indexed by slice_index. get_array_lookup_pixels(slice_index): Getter for array_lookup_pixels, which is a lookup table that maps pixel value to the corresponding spectrum indices in the corresponding spectrum data. get_array_lookup_mz_avg(slice_index): Getter for array_lookup_mz_avg, which is a lookup table that maps m/z values to the corresponding indices in the averaged sectral data. get_array_peaks_transformed_lipids(slice_index): Getter for array_peaks_transformed_lipids, which is a lookup table for the indices of the peaks of the transformed lipids in the spectral data. get_array_corrective_factors(slice_index): Getter for array_corrective_factors, which is a numpy array containing the MAIA corrective factors for each pixel of the requested acquired slice. get_array_spectra(slice_index): Getter for array_spectra, which is a (memmaped) numpy array containing the spectral data of slice indexed by slice_index. get_array_mz(slice_index): Getter for array_mz, which corresponds to the first row of array_spectra, i.e. the m/z values of the spectral data. get_array_intensity(slice_index): Getter for array_intensity, which corresponds to the second row of array_spectra, i.e. the intensity values of the spectral data. get_array_avg_spectrum(slice_index, standardization=True): Getter for array_avg_spectrum, which is a (memmaped) numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index. get_array_lookup_mz(slice_index): Getter for array_lookup_mz, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. get_array_cumulated_lookup_mz_image(slice_index): Getter for array_cumulated_lookup_mz_image, which is a lookup table that maps m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. get_partial_array_spectra(slice_index, lb=None, hb=None, index=None): Getter for partial_array_spectra, which is a (memmaped) numpy array containing the spectral data of slice indexed by slice_index, between lb and hb m/z values. get_partial_array_mz(slice_index, lb=None, hb=None, index=None): Getter for partial_array_mz, which corresponds to the first row of partial_array_spectra, i.e. the m/z values of the spectral data, between lb and hb. get_partial_array_intensity(slice_index, lb=None, hb=None, index=None): Getter for partial_array_intensity, which corresponds to the second row of partial_array_spectra, i.e. the intensity values of the spectral data, between lb and hb. get_partial_array_avg_spectrum(slice_index, lb=None, hb=None, standardization=True): Getter for partial_array_avg_spectrum, which is a (memmaped) numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index, between lb and hb m/z values. get_lookup_mz(slice_index, index): Returns the m/z value corresponding to the index in the spectral data of slice indexed by slice_index. get_cumulated_lookup_mz_image(slice_index, index): Returns the cumulated spectrum until the corresponding m/z value for the pixel corresponding to the index in the spectral data of slice indexed by slice_index. is_brain_1(self, slice_index): Returns True if the slice indexed by slice_index is from brain 1, False otherwise. clean_memory(slice_index=None, array=None, cache=None): Cleans the memory (reset the memory-mapped arrays) of the app. compute_l_labels(): Computes and returns the labels of the lipids in the dataset. return_lipid_options(): Computes and returns the list of lipid names, structures and cation. compute_padded_original_images(): Pads the original slice images of the dataset so that they all have the same size. \"\"\" __slots__ = [ \"_dic_lightweight\" , \"_dic_memmap\" , \"_l_slices\" , \"_n_slices\" , \"_l_slices_brain_1\" , \"_l_slices_brain_2\" , \"_sample_data\" , \"_df_annotations\" , \"_df_annotations_MAIA_transformed_lipids_brain_1\" , \"_df_annotations_MAIA_transformed_lipids_brain_2\" , \"_path_data\" , ] # ============================================================================================== # --- Constructor # ============================================================================================== def __init__ ( self , path_data = \"data/whole_dataset/\" , path_annotations = \"data/annotations/\" , sample_data = False , ): \"\"\"Initialize the class MaldiData. Args: path_data (str): Path used to load the files containing the MALDI data. path_annotations (str): Path used to load the files containing the annotations. \"\"\" logging . info ( \"Initializing MaldiData object\" + logmem ()) # Set if use the sampled dataset or not self . _sample_data = sample_data # Load the dictionnary containing small-size data for all slices if self . _sample_data : with lzma . open ( path_data + \"light_arrays.pickle\" , \"rb\" ) as handle : self . _dic_lightweight = pickle . load ( handle ) else : with open ( path_data + \"light_arrays.pickle\" , \"rb\" ) as handle : self . _dic_lightweight = pickle . load ( handle ) # Simple variable to get the number of slices self . _n_slices = len ( self . _dic_lightweight ) self . _l_slices = sorted ( list ( self . _dic_lightweight . keys ())) self . _l_slices_brain_1 = sorted ( [ slice_idx for slice_idx , val in self . _dic_lightweight . items () if val [ \"is_brain_1\" ]] ) self . _l_slices_brain_2 = sorted ( [ slice_idx for slice_idx , val in self . _dic_lightweight . items () if not val [ \"is_brain_1\" ]] ) # Set the accesser to the mmap files self . _dic_memmap = {} if not self . _sample_data : for slice_index in self . _l_slices : self . _dic_memmap [ slice_index ] = {} for array_name in [ \"array_spectra\" , \"array_avg_spectrum\" , \"array_avg_spectrum_after_standardization\" , \"array_lookup_mz\" , \"array_cumulated_lookup_mz_image\" , \"array_corrective_factors\" , ]: self . _dic_memmap [ slice_index ][ array_name ] = np . memmap ( path_data + array_name + \"_\" + str ( slice_index ) + \".mmap\" , dtype = \"float32\" if array_name != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ slice_index ][ array_name + \"_shape\" ], ) # Save path_data for cleaning memmap in case self . _path_data = path_data # Load lipid annotation (not user-session specific) self . _df_annotations = pd . read_csv ( path_annotations + \"lipid_annotation.csv\" ) # Load lipid annotations of MAIA-transformed lipids for brain 1 self . _df_annotations_MAIA_transformed_lipids_brain_1 = pd . read_csv ( path_annotations + \"transformed_lipids_brain_1.csv\" ) # Brain 2 is not contained in the sampled dataset if not self . _sample_data : # Load lipid annotations of MAIA-transformed lipids for brain 2 self . _df_annotations_MAIA_transformed_lipids_brain_2 = pd . read_csv ( path_annotations + \"transformed_lipids_brain_2.csv\" ) else : self . _df_annotations_MAIA_transformed_lipids_brain_2 = None logging . info ( \"MaldiData object instantiated\" + logmem ()) # ============================================================================================== # --- Methods # ============================================================================================== def get_annotations ( self ): \"\"\"Getter for the lipid annotation of each slice, contained in a pandas dataframe. Returns: (pd.DataFrame): A dataframe of annotations. \"\"\" return self . _df_annotations def get_annotations_MAIA_transformed_lipids ( self , brain_1 = True ): \"\"\"Getter for the MAIA transformed lipid annotation, contained in a pandas dataframe. Args: brain_1 (bool, optional): If True, return the lipid annotions for brain 1. Else for brain 2. Defaults to True. Returns: (pd.DataFrame): A dataframe of lipid annotations for the MAIA transformed lipids. \"\"\" if brain_1 : return self . _df_annotations_MAIA_transformed_lipids_brain_1 else : return self . _df_annotations_MAIA_transformed_lipids_brain_2 def get_slice_number ( self ): \"\"\"Getter for the number of slice present in the dataset. Returns: (int): The number of slices in the dataset. \"\"\" return self . _n_slices def get_slice_list ( self , indices = \"all\" ): \"\"\"Getter for the list of slice indices. Args: indices (str, optional): If \"all\", return the list of all slice indices. If \"brain_1\", return the list of slice indices for brain 1. If \"brain_2\", return the list of slice indices for brain 2. Defaults to \"all\". Indices start at 1. Returns: (list): The list of requested slice indices. \"\"\" if indices == \"all\" : return self . _l_slices elif indices == \"brain_1\" : return self . _l_slices_brain_1 elif indices == \"brain_2\" : return self . _l_slices_brain_2 else : raise ValueError ( \"Invalid string for indices\" ) def get_image_shape ( self , slice_index ): \"\"\"Getter for image_shape, which indicates the shape of the image corresponding to the acquisition indexed by slice_index. Args: slice_index (int): Index of the slice whose shape is requested. Returns: (np.ndarray): The shape of the requested slice image. \"\"\" return self . _dic_lightweight [ slice_index ][ \"image_shape\" ] def get_divider_lookup ( self , slice_index ): \"\"\"Getter for divider_lookup, which sets the resolution of the lookup of the acquisition indexed by slice_index. Args: slice_index (int): Index of the slice whose divider lookup value is requested. Returns: (int): The divider lookup value for the requested slice. \"\"\" return self . _dic_lightweight [ slice_index ][ \"divider_lookup\" ] def get_array_avg_spectrum_downsampled ( self , slice_index ): \"\"\"Getter for array_avg_spectrum_downsampled, which is a low-resolution version of the average spectrum of the acquisition indexed by slice_index. Args: slice_index (int): Index of the slice whose spectrum data is requested. Returns: (np.ndarray): A low-resolution version of the average spectrum of the acquisition indexed by slice_index. \"\"\" # Previously called array_averaged_mz_intensity_low_res return self . _dic_lightweight [ slice_index ][ \"array_avg_spectrum_downsampled\" ] def get_array_lookup_pixels ( self , slice_index ): \"\"\"Getter for array_lookup_pixels, which is a lookup table that maps pixel value to the corresponding spectrum indices in the corresponding spectrum data. Args: slice_index (int): Index of the slice whose pixel lookup table is requested. Returns: (np.ndarray): The requested lookup table. \"\"\" # Previously called array_pixel_indexes_high_res return self . _dic_lightweight [ slice_index ][ \"array_lookup_pixels\" ] def get_array_lookup_mz_avg ( self , slice_index ): \"\"\"Getter for array_lookup_mz_avg, which is a lookup table that maps m/z values to the corresponding indices in the averaged sectral data. Args: slice_index (int): Index of the slice for which the lookup table is requested. Returns: (np.ndarray): The requested lookup table. \"\"\" # Previously called lookup_table_averaged_spectrum_high_res return self . _dic_lightweight [ slice_index ][ \"array_lookup_mz_avg\" ] def get_array_peaks_transformed_lipids ( self , slice_index ): \"\"\"Getter for array_peaks_transformed_lipids, which is a lookup table for the indices of the peaks of the transformed lipids in the spectral data. Args: slice_index (int): Index of the slice for which the peaks lookup table is requested. Returns: (np.ndarray): Bidimensional array of peak annotations for the requested slice. \"\"\" return self . _dic_lightweight [ slice_index ][ \"array_peaks_transformed_lipids\" ] def get_array_corrective_factors ( self , slice_index ): \"\"\"Getter for array_corrective_factors, which is a numpy array containing the MAIA corrective factors for each pixel of the requested acquired slice. Args: slice_index (int): Index of the slice for which the corrective factors are requested. Returns: (np.ndarray (mmaped if not sampled dataset)): Three-dimensional array containing the MAIA corrective factor used for lipids and each pixel. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_corrective_factors\" ] else : return self . _dic_memmap [ slice_index ][ \"array_corrective_factors\" ] def get_array_spectra ( self , slice_index ): \"\"\"Getter for array_spectra, which is a numpy array containing the spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the spectral data is requested. Returns: (np.ndarray (mmaped if not sampled dataset)): Spectral data of the requested slice. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_spectra\" ] else : return self . _dic_memmap [ slice_index ][ \"array_spectra\" ] def get_array_mz ( self , slice_index ): \"\"\"Getter for array_mz, which corresponds to the first row of array_spectra, i.e. the m/z values of the spectral data. Args: slice_index (int): Index of the slice for which the m/z values are requested. Returns: (np.ndarray (mmaped if not sampled dataset)): m/z values of the spectral data of the requested slice. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_spectra\" ][ 0 , :] else : return self . _dic_memmap [ slice_index ][ \"array_spectra\" ][ 0 , :] def get_array_intensity ( self , slice_index ): \"\"\"Getter for array_intensity, which corresponds to the second row of array_spectra, i.e. the intensity values of the spectral data. Args: slice_index (int): Index of the slice for which the intensity values are requested. Returns: (np.ndarray (mmaped if not sampled dataset)): Intensity values of the spectral data of the requested slice. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_spectra\" ][ 1 , :] else : return self . _dic_memmap [ slice_index ][ \"array_spectra\" ][ 1 , :] def get_array_avg_spectrum ( self , slice_index , standardization = True ): \"\"\"Getter for array_avg_spectrum, which is a numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the average spectrum is requested. standardization (bool): If True, the average spectrum is standardized with MAIA. Returns: (np.ndarray (mmaped if not sampled dataset)): The requested average spectrum. \"\"\" if not standardization : if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_avg_spectrum\" ] else : return self . _dic_memmap [ slice_index ][ \"array_avg_spectrum\" ] else : if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_avg_spectrum_after_standardization\" ] else : return self . _dic_memmap [ slice_index ][ \"array_avg_spectrum_after_standardization\" ] def get_array_lookup_mz ( self , slice_index ): \"\"\"Getter for array_lookup_mz, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. Args: slice_index (int): Index of the slice for which the lookup table is requested. Returns: (np.ndarray (mmaped if not sampled dataset)): The requested lookup table. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_lookup_mz\" ] else : return self . _dic_memmap [ slice_index ][ \"array_lookup_mz\" ] def get_array_cumulated_lookup_mz_image ( self , slice_index ): \"\"\"Getter for array_cumulated_lookup_mz_image, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. Args: slice_index (int): Index of the slice for which the lookup table is requested. Returns: (np.ndarray (mmaped if not sampled dataset)): The requested lookup table. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_cumulated_lookup_mz_image\" ] else : return self . _dic_memmap [ slice_index ][ \"array_cumulated_lookup_mz_image\" ] def get_partial_array_spectra ( self , slice_index , lb = None , hb = None , index = None ): \"\"\"Getter for partial_array_spectra, which is a numpy array containing the spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the spectral data is requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. index (int): Index of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): Spectral data of the requested slice. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] if lb is None and hb is None and index is None : # Previously called array_spectra_high_res. return dic [ \"array_spectra\" ] elif lb is not None and hb is not None : return dic [ \"array_spectra\" ][:, lb : hb ] elif index is not None : return dic [ \"array_spectra\" ][:, index ] # If not specific index has been provided, it returns a range if index is None : # Start with most likely case if hb is not None and lb is not None : return dic [ \"array_spectra\" ][:, lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_intensity ( slice_index ) # Most likely the remaining cases won't be used elif lb is None : return dic [ \"array_spectra\" ][:, : hb ] else : return dic [ \"array_spectra\" ][:, lb :] # Else, it returns the required index else : if lb is not None or hb is not None : logging . warning ( \"Both one or several boundaries and one index have been specified\" + \" when calling array_spectra. \" + \"Only the index request will be satisfied.\" ) return dic [ \"array_spectra\" ][:, index ] def get_partial_array_mz ( self , slice_index , lb = None , hb = None , index = None ): \"\"\"Getter for partial_array_mz, which corresponds to the first row of partial_array_spectra, i.e. the m/z values of the spectral data, between lb and hb. Args: slice_index (int): Index of the slice for which the m/z values are requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): m/z values of the spectral data of the requested slice between lb and hb. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] if lb is None and hb is None and index is None : # Previously called array_spectra_high_res return dic [ \"array_spectra\" ][ 0 , :] elif lb is not None and hb is not None : return dic [ \"array_spectra\" ][ 0 , lb : hb ] elif index is not None : return dic [ \"array_spectra\" ][ 0 , index ] # If not specific index has been provided, it returns a range if index is None : # Start with most likely case if hb is not None and lb is not None : return dic [ \"array_spectra\" ][ 0 , lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_mz ( slice_index ) # Most likely the remaining cases won't be used elif lb is None : return dic [ \"array_spectra\" ][ 0 , : hb ] else : return dic [ \"array_spectra\" ][ 0 , lb :] # Else, it returns the required index else : if lb is not None or hb is not None : logging . warning ( \"Both one or several boundaries and one index have been specified\" + \" when calling array_spectra. \" + \"Only the index request will be satisfied.\" ) return dic [ \"array_spectra\" ][ 0 , index ] def get_partial_array_intensity ( self , slice_index , lb = None , hb = None , index = None ): \"\"\"Getter for partial_array_intensity, which corresponds to the second row of partial_array_spectra, i.e. the intensity values of the spectral data, between lb and hb. Args: slice_index (int): Index of the slice for which the intensity values are requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray, mmaped if not sampled dataset): Intensity values of the spectral data of the requested slice between lb and hb. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] if lb is None and hb is None and index is None : # Previously called array_spectra_high_res return dic [ \"array_spectra\" ][ 1 , :] elif lb is not None and hb is not None : return dic [ \"array_spectra\" ][ 1 , lb : hb ] elif index is not None : return dic [ \"array_spectra\" ][ 1 , index ] # If not specific index has been provided, it returns a range if index is None : # Start with most likely case if hb is not None and lb is not None : return dic [ \"array_spectra\" ][ 1 , lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_intensity ( slice_index ) # Most likely the remaining cases won't be used elif lb is None : return dic [ \"array_spectra\" ][ 1 , : hb ] else : return dic [ \"array_spectra\" ][ 1 , lb :] # Else, it returns the required index else : if lb is not None or hb is not None : logging . warning ( \"Both one or several boundaries and one index have been specified\" + \" when calling array_spectra. \" + \"Only the index request will be satisfied.\" ) return dic [ \"array_spectra\" ][ 1 , index ] def get_partial_array_avg_spectrum ( self , slice_index , lb = None , hb = None , standardization = True ): \"\"\"Getter for partial_array_avg_spectrum, which corresponds to the average spectrum of the spectral data, between lb and hb. Args: slice_index (int): Index of the slice for which the average spectrum is requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. standardization (bool): If True, the average spectrum is normalized. Returns: (np.ndarray, mmaped if not sampled dataset)): Average spectrum of the spectral data of the requested slice between lb and hb. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] # Start with most likely case if hb is not None and lb is not None : if standardization : return dic [ slice_index ][ \"array_avg_spectrum\" ][:, lb : hb ] else : return dic [ slice_index ][ \"array_avg_spectrum_before_standardization\" ][:, lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_avg_spectrum ( slice_index , standardization ) # Most likely the remaining cases won't be used elif lb is None : if standardization : return dic [ slice_index ][ \"array_avg_spectrum\" ][:, : hb ] else : return dic [ slice_index ][ \"array_avg_spectrum_before_standardization\" ][:, : hb ] else : if standardization : return dic [ slice_index ][ \"array_avg_spectrum\" ][:, lb :] else : return dic [ slice_index ][ \"array_avg_spectrum_before_standardization\" ][:, lb :] def get_lookup_mz ( self , slice_index , index ): \"\"\"Returns the m/z value corresponding to the index in the spectral data of the slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the m/z value is requested. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): m/z value of the spectral data of the requested slice and requested lookup. \"\"\" # Just return the (one) required lookup to go faster if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_lookup_mz\" ][ index ] else : return self . _dic_memmap [ slice_index ][ \"array_lookup_mz\" ][ index ] def get_cumulated_lookup_mz_image ( self , slice_index , index ): \"\"\"Returns the cumulated spectrum until the corresponding m/z value for the pixel corresponding to the index in the spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the m/z value is requested. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): Cumulated m/z value of the spectral data of the requested slice and requested lookup. \"\"\" # Just return the (one) required lookup to go faster if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_cumulated_lookup_mz_image\" ][ index ] else : return self . _dic_memmap [ slice_index ][ \"array_cumulated_lookup_mz_image\" ][ index ] def is_brain_1 ( self , slice_index ): \"\"\"Returns True if the slice indexed by slice_index is a brain 1. Else, returns False. Args: slice_index (int): Index of the slice for which the status is requested. Returns: (bool): True if the slice indexed by slice_index is a brain 1. Else, returns False. \"\"\" return self . _dic_lightweight [ slice_index ][ \"is_brain_1\" ] def clean_memory ( self , slice_index = None , array = None , cache = None ): \"\"\"Cleans the memory (reset the memory-mapped arrays) of the app. slice_index and array allow for a more fine-grained cleaning. If \"cache\" is provided, it will be used to lock the dataset while cleaning. Overall, this function takes about 5ms to run on all memmaps, and 1ms on a given slice. Args: slice_index (int, optional): Index of the slice whose corresponding mmap must be cleaned. Defaults to None. array (str, optional): Name of the array whose corresponding mmap must be cleaned. Defaults to None. cache (flask_caching.Cache, optional): Cache of the database. Defaults to None. \"\"\" if self . _sample_data : logging . warning ( \"Cleaning memory-mapped dictionnary has been requested, but the sample dataset if\" \" currently being used.\" ) return None # Wait for memory to be released before taking action if cache is not None : while cache . get ( \"locked-reading\" ) or cache . get ( \"locked-cleaning\" ): time . sleep ( 0.05 ) # Lock memory to prevent other processes from accessing it cache . set ( \"locked-cleaning\" , True ) # Case no array name has been provided if array is None : l_array_names = [ \"array_spectra\" , \"array_avg_spectrum\" , \"array_avg_spectrum_after_standardization\" , \"array_lookup_mz\" , \"array_cumulated_lookup_mz_image\" , \"array_corrective_factors\" , ] # Clean all memmaps if no slice index have been given if slice_index is None : for index in self . _l_slices : for array_name in l_array_names : self . _dic_memmap [ index ][ array_name ] = np . memmap ( self . _path_data + array_name + \"_\" + str ( index ) + \".mmap\" , dtype = \"float32\" if array_name != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ index ][ array_name + \"_shape\" ], ) # Else clean all memmaps of a given slice index else : for array_name in l_array_names : self . _dic_memmap [ slice_index ][ array_name ] = np . memmap ( self . _path_data + array_name + \"_\" + str ( slice_index ) + \".mmap\" , dtype = \"float32\" if array_name != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ slice_index ][ array_name + \"_shape\" ], ) # Case an array name has been provided else : # Clean all memmaps corresponding to the current array if no slice_index have been given if slice_index is None : for index in self . _l_slices : self . _dic_memmap [ index ][ array ] = np . memmap ( self . _path_data + array + \"_\" + str ( index ) + \".mmap\" , dtype = \"float32\" if array != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ index ][ array + \"_shape\" ], ) # Else clean the memap of the given slice index else : self . _dic_memmap [ slice_index ][ array ] = np . memmap ( self . _path_data + array + \"_\" + str ( slice_index ) + \".mmap\" , dtype = \"float32\" if array != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ slice_index ][ array + \"_shape\" ], ) # Release memory if cache is not None : cache . set ( \"locked-cleaning\" , False ) logging . info ( \"Memory cleaned\" ) def compute_l_labels ( self ): \"\"\"Computes the list of labels of the dataset. Returns: (list): List of labels of the dataset. \"\"\" l_labels = ( self . _df_annotations [ \"name\" ] + \"_\" + self . _df_annotations [ \"structure\" ] + \"_\" + self . _df_annotations [ \"cation\" ] ) . to_list () return l_labels def return_lipid_options ( self ): \"\"\"Computes and returns the list of lipid names, structures and cation. Returns: (list): List of lipid names, structures and cations. \"\"\" return [ { \"label\" : name + \" \" + structure + \" \" + cation , \"value\" : name + \" \" + structure + \" \" + cation , \"group\" : name , } for name in sorted ( self . get_annotations () . name . unique ()) for structure in sorted ( self . get_annotations ()[( self . get_annotations ()[ \"name\" ] == name )] . structure . unique () ) for cation in sorted ( self . get_annotations ()[ ( self . get_annotations ()[ \"name\" ] == name ) & ( self . get_annotations ()[ \"structure\" ] == structure ) ] . cation . unique () ) ] def compute_padded_original_images ( self ): \"\"\"Pads the original images of the dataset so that they are all the same size. Returns: (np.ndarray): A 3D numpy array, where the first dimension corresponds to the slice index, and the second and third dimensions correspond to the padded images. \"\"\" # Compute number of slices from the original acquisition are present in the folder if self . _sample_data : path = \"data_sample/tiff_files/original_data/\" else : path = \"data/tiff_files/original_data/\" n_slices = len ([ x for x in os . listdir ( path ) if \"slice_\" in x ]) if n_slices != self . get_slice_number (): logging . warning ( \"The number of slices computed from the original tiff files is different from\" + \" the number of slice \" + \"recorded in the MaldiData object.\" ) # Store them as arrays in a list l_array_slices = [] for i in range ( n_slices ): filename = path + \"slice_\" + str ( i + 1 ) + \".tiff\" if self . _sample_data : l_array_slices . append ( np . array ( io . imread ( filename ), dtype = np . int16 )) else : l_array_slices . append ( np . array ( io . imread ( filename ), dtype = np . int16 )[:, :, 2 ]) # Find the size of the biggest image max_size = ( np . max ([ array_slice . shape [ 0 ] for array_slice in l_array_slices ]), np . max ([ array_slice . shape [ 1 ] for array_slice in l_array_slices ]), ) # Pad the images with zeros (we add +-0.1 in case we need to round above or below 0.5 # if odd dimension) l_array_slices = [ np . pad ( array_slice , ( ( int ( round ( max_size [ 0 ] - array_slice . shape [ 0 ] / 2 - 0.1 )), int ( round ( max_size [ 0 ] - array_slice . shape [ 0 ] / 2 + 0.1 )), ), ( int ( round ( max_size [ 1 ] - array_slice . shape [ 1 ] / 2 - 0.1 )), int ( round ( max_size [ 1 ] - array_slice . shape [ 1 ] / 2 + 0.1 )), ), ), ) for array_slice in l_array_slices ] return np . array ( l_array_slices )","title":"MaldiData"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.__init__","text":"Initialize the class MaldiData. Parameters: Name Type Description Default path_data str Path used to load the files containing the MALDI data. 'data/whole_dataset/' path_annotations str Path used to load the files containing the annotations. 'data/annotations/' Source code in modules/maldi_data.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 def __init__ ( self , path_data = \"data/whole_dataset/\" , path_annotations = \"data/annotations/\" , sample_data = False , ): \"\"\"Initialize the class MaldiData. Args: path_data (str): Path used to load the files containing the MALDI data. path_annotations (str): Path used to load the files containing the annotations. \"\"\" logging . info ( \"Initializing MaldiData object\" + logmem ()) # Set if use the sampled dataset or not self . _sample_data = sample_data # Load the dictionnary containing small-size data for all slices if self . _sample_data : with lzma . open ( path_data + \"light_arrays.pickle\" , \"rb\" ) as handle : self . _dic_lightweight = pickle . load ( handle ) else : with open ( path_data + \"light_arrays.pickle\" , \"rb\" ) as handle : self . _dic_lightweight = pickle . load ( handle ) # Simple variable to get the number of slices self . _n_slices = len ( self . _dic_lightweight ) self . _l_slices = sorted ( list ( self . _dic_lightweight . keys ())) self . _l_slices_brain_1 = sorted ( [ slice_idx for slice_idx , val in self . _dic_lightweight . items () if val [ \"is_brain_1\" ]] ) self . _l_slices_brain_2 = sorted ( [ slice_idx for slice_idx , val in self . _dic_lightweight . items () if not val [ \"is_brain_1\" ]] ) # Set the accesser to the mmap files self . _dic_memmap = {} if not self . _sample_data : for slice_index in self . _l_slices : self . _dic_memmap [ slice_index ] = {} for array_name in [ \"array_spectra\" , \"array_avg_spectrum\" , \"array_avg_spectrum_after_standardization\" , \"array_lookup_mz\" , \"array_cumulated_lookup_mz_image\" , \"array_corrective_factors\" , ]: self . _dic_memmap [ slice_index ][ array_name ] = np . memmap ( path_data + array_name + \"_\" + str ( slice_index ) + \".mmap\" , dtype = \"float32\" if array_name != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ slice_index ][ array_name + \"_shape\" ], ) # Save path_data for cleaning memmap in case self . _path_data = path_data # Load lipid annotation (not user-session specific) self . _df_annotations = pd . read_csv ( path_annotations + \"lipid_annotation.csv\" ) # Load lipid annotations of MAIA-transformed lipids for brain 1 self . _df_annotations_MAIA_transformed_lipids_brain_1 = pd . read_csv ( path_annotations + \"transformed_lipids_brain_1.csv\" ) # Brain 2 is not contained in the sampled dataset if not self . _sample_data : # Load lipid annotations of MAIA-transformed lipids for brain 2 self . _df_annotations_MAIA_transformed_lipids_brain_2 = pd . read_csv ( path_annotations + \"transformed_lipids_brain_2.csv\" ) else : self . _df_annotations_MAIA_transformed_lipids_brain_2 = None logging . info ( \"MaldiData object instantiated\" + logmem ())","title":"__init__()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.clean_memory","text":"Cleans the memory (reset the memory-mapped arrays) of the app. slice_index and array allow for a more fine-grained cleaning. If \"cache\" is provided, it will be used to lock the dataset while cleaning. Overall, this function takes about 5ms to run on all memmaps, and 1ms on a given slice. Parameters: Name Type Description Default slice_index int Index of the slice whose corresponding mmap must be cleaned. Defaults to None. None array str Name of the array whose corresponding mmap must be cleaned. Defaults to None. None cache flask_caching . Cache Cache of the database. Defaults to None. None Source code in modules/maldi_data.py 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 def clean_memory ( self , slice_index = None , array = None , cache = None ): \"\"\"Cleans the memory (reset the memory-mapped arrays) of the app. slice_index and array allow for a more fine-grained cleaning. If \"cache\" is provided, it will be used to lock the dataset while cleaning. Overall, this function takes about 5ms to run on all memmaps, and 1ms on a given slice. Args: slice_index (int, optional): Index of the slice whose corresponding mmap must be cleaned. Defaults to None. array (str, optional): Name of the array whose corresponding mmap must be cleaned. Defaults to None. cache (flask_caching.Cache, optional): Cache of the database. Defaults to None. \"\"\" if self . _sample_data : logging . warning ( \"Cleaning memory-mapped dictionnary has been requested, but the sample dataset if\" \" currently being used.\" ) return None # Wait for memory to be released before taking action if cache is not None : while cache . get ( \"locked-reading\" ) or cache . get ( \"locked-cleaning\" ): time . sleep ( 0.05 ) # Lock memory to prevent other processes from accessing it cache . set ( \"locked-cleaning\" , True ) # Case no array name has been provided if array is None : l_array_names = [ \"array_spectra\" , \"array_avg_spectrum\" , \"array_avg_spectrum_after_standardization\" , \"array_lookup_mz\" , \"array_cumulated_lookup_mz_image\" , \"array_corrective_factors\" , ] # Clean all memmaps if no slice index have been given if slice_index is None : for index in self . _l_slices : for array_name in l_array_names : self . _dic_memmap [ index ][ array_name ] = np . memmap ( self . _path_data + array_name + \"_\" + str ( index ) + \".mmap\" , dtype = \"float32\" if array_name != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ index ][ array_name + \"_shape\" ], ) # Else clean all memmaps of a given slice index else : for array_name in l_array_names : self . _dic_memmap [ slice_index ][ array_name ] = np . memmap ( self . _path_data + array_name + \"_\" + str ( slice_index ) + \".mmap\" , dtype = \"float32\" if array_name != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ slice_index ][ array_name + \"_shape\" ], ) # Case an array name has been provided else : # Clean all memmaps corresponding to the current array if no slice_index have been given if slice_index is None : for index in self . _l_slices : self . _dic_memmap [ index ][ array ] = np . memmap ( self . _path_data + array + \"_\" + str ( index ) + \".mmap\" , dtype = \"float32\" if array != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ index ][ array + \"_shape\" ], ) # Else clean the memap of the given slice index else : self . _dic_memmap [ slice_index ][ array ] = np . memmap ( self . _path_data + array + \"_\" + str ( slice_index ) + \".mmap\" , dtype = \"float32\" if array != \"array_lookup_mz\" else \"int32\" , mode = \"r\" , shape = self . _dic_lightweight [ slice_index ][ array + \"_shape\" ], ) # Release memory if cache is not None : cache . set ( \"locked-cleaning\" , False ) logging . info ( \"Memory cleaned\" )","title":"clean_memory()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.compute_l_labels","text":"Computes the list of labels of the dataset. Returns: Type Description list List of labels of the dataset. Source code in modules/maldi_data.py 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 def compute_l_labels ( self ): \"\"\"Computes the list of labels of the dataset. Returns: (list): List of labels of the dataset. \"\"\" l_labels = ( self . _df_annotations [ \"name\" ] + \"_\" + self . _df_annotations [ \"structure\" ] + \"_\" + self . _df_annotations [ \"cation\" ] ) . to_list () return l_labels","title":"compute_l_labels()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.compute_padded_original_images","text":"Pads the original images of the dataset so that they are all the same size. Returns: Type Description np . ndarray A 3D numpy array, where the first dimension corresponds to the slice index, and the second and third dimensions correspond to the padded images. Source code in modules/maldi_data.py 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 def compute_padded_original_images ( self ): \"\"\"Pads the original images of the dataset so that they are all the same size. Returns: (np.ndarray): A 3D numpy array, where the first dimension corresponds to the slice index, and the second and third dimensions correspond to the padded images. \"\"\" # Compute number of slices from the original acquisition are present in the folder if self . _sample_data : path = \"data_sample/tiff_files/original_data/\" else : path = \"data/tiff_files/original_data/\" n_slices = len ([ x for x in os . listdir ( path ) if \"slice_\" in x ]) if n_slices != self . get_slice_number (): logging . warning ( \"The number of slices computed from the original tiff files is different from\" + \" the number of slice \" + \"recorded in the MaldiData object.\" ) # Store them as arrays in a list l_array_slices = [] for i in range ( n_slices ): filename = path + \"slice_\" + str ( i + 1 ) + \".tiff\" if self . _sample_data : l_array_slices . append ( np . array ( io . imread ( filename ), dtype = np . int16 )) else : l_array_slices . append ( np . array ( io . imread ( filename ), dtype = np . int16 )[:, :, 2 ]) # Find the size of the biggest image max_size = ( np . max ([ array_slice . shape [ 0 ] for array_slice in l_array_slices ]), np . max ([ array_slice . shape [ 1 ] for array_slice in l_array_slices ]), ) # Pad the images with zeros (we add +-0.1 in case we need to round above or below 0.5 # if odd dimension) l_array_slices = [ np . pad ( array_slice , ( ( int ( round ( max_size [ 0 ] - array_slice . shape [ 0 ] / 2 - 0.1 )), int ( round ( max_size [ 0 ] - array_slice . shape [ 0 ] / 2 + 0.1 )), ), ( int ( round ( max_size [ 1 ] - array_slice . shape [ 1 ] / 2 - 0.1 )), int ( round ( max_size [ 1 ] - array_slice . shape [ 1 ] / 2 + 0.1 )), ), ), ) for array_slice in l_array_slices ] return np . array ( l_array_slices )","title":"compute_padded_original_images()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_annotations","text":"Getter for the lipid annotation of each slice, contained in a pandas dataframe. Returns: Type Description pd . DataFrame A dataframe of annotations. Source code in modules/maldi_data.py 258 259 260 261 262 263 264 265 def get_annotations ( self ): \"\"\"Getter for the lipid annotation of each slice, contained in a pandas dataframe. Returns: (pd.DataFrame): A dataframe of annotations. \"\"\" return self . _df_annotations","title":"get_annotations()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_annotations_MAIA_transformed_lipids","text":"Getter for the MAIA transformed lipid annotation, contained in a pandas dataframe. Parameters: Name Type Description Default brain_1 bool If True, return the lipid annotions for brain 1. Else for brain 2. Defaults to True. True Returns: Type Description pd . DataFrame A dataframe of lipid annotations for the MAIA transformed lipids. Source code in modules/maldi_data.py 267 268 269 270 271 272 273 274 275 276 277 278 279 280 def get_annotations_MAIA_transformed_lipids ( self , brain_1 = True ): \"\"\"Getter for the MAIA transformed lipid annotation, contained in a pandas dataframe. Args: brain_1 (bool, optional): If True, return the lipid annotions for brain 1. Else for brain 2. Defaults to True. Returns: (pd.DataFrame): A dataframe of lipid annotations for the MAIA transformed lipids. \"\"\" if brain_1 : return self . _df_annotations_MAIA_transformed_lipids_brain_1 else : return self . _df_annotations_MAIA_transformed_lipids_brain_2","title":"get_annotations_MAIA_transformed_lipids()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_array_avg_spectrum","text":"Getter for array_avg_spectrum, which is a numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice for which the average spectrum is requested. required standardization bool If True, the average spectrum is standardized with MAIA. True Returns: Type Description np.ndarray (mmaped if not sampled dataset) The requested average spectrum. Source code in modules/maldi_data.py 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 def get_array_avg_spectrum ( self , slice_index , standardization = True ): \"\"\"Getter for array_avg_spectrum, which is a numpy array containing the (high resolution) averaged spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the average spectrum is requested. standardization (bool): If True, the average spectrum is standardized with MAIA. Returns: (np.ndarray (mmaped if not sampled dataset)): The requested average spectrum. \"\"\" if not standardization : if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_avg_spectrum\" ] else : return self . _dic_memmap [ slice_index ][ \"array_avg_spectrum\" ] else : if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_avg_spectrum_after_standardization\" ] else : return self . _dic_memmap [ slice_index ][ \"array_avg_spectrum_after_standardization\" ]","title":"get_array_avg_spectrum()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_array_avg_spectrum_downsampled","text":"Getter for array_avg_spectrum_downsampled, which is a low-resolution version of the average spectrum of the acquisition indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice whose spectrum data is requested. required Returns: Type Description np . ndarray A low-resolution version of the average spectrum of the acquisition indexed by slice_index. Source code in modules/maldi_data.py 334 335 336 337 338 339 340 341 342 343 344 345 346 def get_array_avg_spectrum_downsampled ( self , slice_index ): \"\"\"Getter for array_avg_spectrum_downsampled, which is a low-resolution version of the average spectrum of the acquisition indexed by slice_index. Args: slice_index (int): Index of the slice whose spectrum data is requested. Returns: (np.ndarray): A low-resolution version of the average spectrum of the acquisition indexed by slice_index. \"\"\" # Previously called array_averaged_mz_intensity_low_res return self . _dic_lightweight [ slice_index ][ \"array_avg_spectrum_downsampled\" ]","title":"get_array_avg_spectrum_downsampled()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_array_corrective_factors","text":"Getter for array_corrective_factors, which is a numpy array containing the MAIA corrective factors for each pixel of the requested acquired slice. Parameters: Name Type Description Default slice_index int Index of the slice for which the corrective factors are requested. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) Three-dimensional array containing the MAIA corrective factor used for lipids and each pixel. Source code in modules/maldi_data.py 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 def get_array_corrective_factors ( self , slice_index ): \"\"\"Getter for array_corrective_factors, which is a numpy array containing the MAIA corrective factors for each pixel of the requested acquired slice. Args: slice_index (int): Index of the slice for which the corrective factors are requested. Returns: (np.ndarray (mmaped if not sampled dataset)): Three-dimensional array containing the MAIA corrective factor used for lipids and each pixel. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_corrective_factors\" ] else : return self . _dic_memmap [ slice_index ][ \"array_corrective_factors\" ]","title":"get_array_corrective_factors()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_array_cumulated_lookup_mz_image","text":"Getter for array_cumulated_lookup_mz_image, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. Parameters: Name Type Description Default slice_index int Index of the slice for which the lookup table is requested. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) The requested lookup table. Source code in modules/maldi_data.py 489 490 491 492 493 494 495 496 497 498 499 500 501 502 def get_array_cumulated_lookup_mz_image ( self , slice_index ): \"\"\"Getter for array_cumulated_lookup_mz_image, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. Args: slice_index (int): Index of the slice for which the lookup table is requested. Returns: (np.ndarray (mmaped if not sampled dataset)): The requested lookup table. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_cumulated_lookup_mz_image\" ] else : return self . _dic_memmap [ slice_index ][ \"array_cumulated_lookup_mz_image\" ]","title":"get_array_cumulated_lookup_mz_image()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_array_intensity","text":"Getter for array_intensity, which corresponds to the second row of array_spectra, i.e. the intensity values of the spectral data. Parameters: Name Type Description Default slice_index int Index of the slice for which the intensity values are requested. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) Intensity values of the spectral data of the requested slice. Source code in modules/maldi_data.py 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 def get_array_intensity ( self , slice_index ): \"\"\"Getter for array_intensity, which corresponds to the second row of array_spectra, i.e. the intensity values of the spectral data. Args: slice_index (int): Index of the slice for which the intensity values are requested. Returns: (np.ndarray (mmaped if not sampled dataset)): Intensity values of the spectral data of the requested slice. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_spectra\" ][ 1 , :] else : return self . _dic_memmap [ slice_index ][ \"array_spectra\" ][ 1 , :]","title":"get_array_intensity()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_array_lookup_mz","text":"Getter for array_lookup_mz, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. Parameters: Name Type Description Default slice_index int Index of the slice for which the lookup table is requested. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) The requested lookup table. Source code in modules/maldi_data.py 474 475 476 477 478 479 480 481 482 483 484 485 486 487 def get_array_lookup_mz ( self , slice_index ): \"\"\"Getter for array_lookup_mz, which is a lookup table that maps m/z values to the corresponding indices in the spectral data. Args: slice_index (int): Index of the slice for which the lookup table is requested. Returns: (np.ndarray (mmaped if not sampled dataset)): The requested lookup table. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_lookup_mz\" ] else : return self . _dic_memmap [ slice_index ][ \"array_lookup_mz\" ]","title":"get_array_lookup_mz()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_array_lookup_mz_avg","text":"Getter for array_lookup_mz_avg, which is a lookup table that maps m/z values to the corresponding indices in the averaged sectral data. Parameters: Name Type Description Default slice_index int Index of the slice for which the lookup table is requested. required Returns: Type Description np . ndarray The requested lookup table. Source code in modules/maldi_data.py 361 362 363 364 365 366 367 368 369 370 371 372 def get_array_lookup_mz_avg ( self , slice_index ): \"\"\"Getter for array_lookup_mz_avg, which is a lookup table that maps m/z values to the corresponding indices in the averaged sectral data. Args: slice_index (int): Index of the slice for which the lookup table is requested. Returns: (np.ndarray): The requested lookup table. \"\"\" # Previously called lookup_table_averaged_spectrum_high_res return self . _dic_lightweight [ slice_index ][ \"array_lookup_mz_avg\" ]","title":"get_array_lookup_mz_avg()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_array_lookup_pixels","text":"Getter for array_lookup_pixels, which is a lookup table that maps pixel value to the corresponding spectrum indices in the corresponding spectrum data. Parameters: Name Type Description Default slice_index int Index of the slice whose pixel lookup table is requested. required Returns: Type Description np . ndarray The requested lookup table. Source code in modules/maldi_data.py 348 349 350 351 352 353 354 355 356 357 358 359 def get_array_lookup_pixels ( self , slice_index ): \"\"\"Getter for array_lookup_pixels, which is a lookup table that maps pixel value to the corresponding spectrum indices in the corresponding spectrum data. Args: slice_index (int): Index of the slice whose pixel lookup table is requested. Returns: (np.ndarray): The requested lookup table. \"\"\" # Previously called array_pixel_indexes_high_res return self . _dic_lightweight [ slice_index ][ \"array_lookup_pixels\" ]","title":"get_array_lookup_pixels()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_array_mz","text":"Getter for array_mz, which corresponds to the first row of array_spectra, i.e. the m/z values of the spectral data. Parameters: Name Type Description Default slice_index int Index of the slice for which the m/z values are requested. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) m/z values of the spectral data of the requested slice. Source code in modules/maldi_data.py 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 def get_array_mz ( self , slice_index ): \"\"\"Getter for array_mz, which corresponds to the first row of array_spectra, i.e. the m/z values of the spectral data. Args: slice_index (int): Index of the slice for which the m/z values are requested. Returns: (np.ndarray (mmaped if not sampled dataset)): m/z values of the spectral data of the requested slice. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_spectra\" ][ 0 , :] else : return self . _dic_memmap [ slice_index ][ \"array_spectra\" ][ 0 , :]","title":"get_array_mz()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_array_peaks_transformed_lipids","text":"Getter for array_peaks_transformed_lipids, which is a lookup table for the indices of the peaks of the transformed lipids in the spectral data. Parameters: Name Type Description Default slice_index int Index of the slice for which the peaks lookup table is requested. required Returns: Type Description np . ndarray Bidimensional array of peak annotations for the requested slice. Source code in modules/maldi_data.py 374 375 376 377 378 379 380 381 382 383 384 def get_array_peaks_transformed_lipids ( self , slice_index ): \"\"\"Getter for array_peaks_transformed_lipids, which is a lookup table for the indices of the peaks of the transformed lipids in the spectral data. Args: slice_index (int): Index of the slice for which the peaks lookup table is requested. Returns: (np.ndarray): Bidimensional array of peak annotations for the requested slice. \"\"\" return self . _dic_lightweight [ slice_index ][ \"array_peaks_transformed_lipids\" ]","title":"get_array_peaks_transformed_lipids()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_array_spectra","text":"Getter for array_spectra, which is a numpy array containing the spectral data of slice indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice for which the spectral data is requested. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) Spectral data of the requested slice. Source code in modules/maldi_data.py 402 403 404 405 406 407 408 409 410 411 412 413 414 415 def get_array_spectra ( self , slice_index ): \"\"\"Getter for array_spectra, which is a numpy array containing the spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the spectral data is requested. Returns: (np.ndarray (mmaped if not sampled dataset)): Spectral data of the requested slice. \"\"\" if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_spectra\" ] else : return self . _dic_memmap [ slice_index ][ \"array_spectra\" ]","title":"get_array_spectra()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_cumulated_lookup_mz_image","text":"Returns the cumulated spectrum until the corresponding m/z value for the pixel corresponding to the index in the spectral data of slice indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice for which the m/z value is requested. required index int Index of the slice of the requested spectrum. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) Cumulated m/z value of the spectral data of the requested slice and requested lookup. Source code in modules/maldi_data.py 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 def get_cumulated_lookup_mz_image ( self , slice_index , index ): \"\"\"Returns the cumulated spectrum until the corresponding m/z value for the pixel corresponding to the index in the spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the m/z value is requested. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): Cumulated m/z value of the spectral data of the requested slice and requested lookup. \"\"\" # Just return the (one) required lookup to go faster if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_cumulated_lookup_mz_image\" ][ index ] else : return self . _dic_memmap [ slice_index ][ \"array_cumulated_lookup_mz_image\" ][ index ]","title":"get_cumulated_lookup_mz_image()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_divider_lookup","text":"Getter for divider_lookup, which sets the resolution of the lookup of the acquisition indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice whose divider lookup value is requested. required Returns: Type Description int The divider lookup value for the requested slice. Source code in modules/maldi_data.py 322 323 324 325 326 327 328 329 330 331 332 def get_divider_lookup ( self , slice_index ): \"\"\"Getter for divider_lookup, which sets the resolution of the lookup of the acquisition indexed by slice_index. Args: slice_index (int): Index of the slice whose divider lookup value is requested. Returns: (int): The divider lookup value for the requested slice. \"\"\" return self . _dic_lightweight [ slice_index ][ \"divider_lookup\" ]","title":"get_divider_lookup()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_image_shape","text":"Getter for image_shape, which indicates the shape of the image corresponding to the acquisition indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice whose shape is requested. required Returns: Type Description np . ndarray The shape of the requested slice image. Source code in modules/maldi_data.py 310 311 312 313 314 315 316 317 318 319 320 def get_image_shape ( self , slice_index ): \"\"\"Getter for image_shape, which indicates the shape of the image corresponding to the acquisition indexed by slice_index. Args: slice_index (int): Index of the slice whose shape is requested. Returns: (np.ndarray): The shape of the requested slice image. \"\"\" return self . _dic_lightweight [ slice_index ][ \"image_shape\" ]","title":"get_image_shape()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_lookup_mz","text":"Returns the m/z value corresponding to the index in the spectral data of the slice indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice for which the m/z value is requested. required index int Index of the slice of the requested spectrum. required Returns: Type Description np.ndarray (mmaped if not sampled dataset) m/z value of the spectral data of the requested slice and requested lookup. Source code in modules/maldi_data.py 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 def get_lookup_mz ( self , slice_index , index ): \"\"\"Returns the m/z value corresponding to the index in the spectral data of the slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the m/z value is requested. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): m/z value of the spectral data of the requested slice and requested lookup. \"\"\" # Just return the (one) required lookup to go faster if self . _sample_data : return self . _dic_lightweight [ slice_index ][ \"array_lookup_mz\" ][ index ] else : return self . _dic_memmap [ slice_index ][ \"array_lookup_mz\" ][ index ]","title":"get_lookup_mz()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_partial_array_avg_spectrum","text":"Getter for partial_array_avg_spectrum, which corresponds to the average spectrum of the spectral data, between lb and hb. Parameters: Name Type Description Default slice_index int Index of the slice for which the average spectrum is requested. required lb int Lower bound of the requested spectrum. None hb int Upper bound of the requested spectrum. None standardization bool If True, the average spectrum is normalized. True Returns: Type Description np.ndarray, mmaped if not sampled dataset) Average spectrum of the spectral data of the requested slice between lb and hb. Source code in modules/maldi_data.py 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 def get_partial_array_avg_spectrum ( self , slice_index , lb = None , hb = None , standardization = True ): \"\"\"Getter for partial_array_avg_spectrum, which corresponds to the average spectrum of the spectral data, between lb and hb. Args: slice_index (int): Index of the slice for which the average spectrum is requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. standardization (bool): If True, the average spectrum is normalized. Returns: (np.ndarray, mmaped if not sampled dataset)): Average spectrum of the spectral data of the requested slice between lb and hb. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] # Start with most likely case if hb is not None and lb is not None : if standardization : return dic [ slice_index ][ \"array_avg_spectrum\" ][:, lb : hb ] else : return dic [ slice_index ][ \"array_avg_spectrum_before_standardization\" ][:, lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_avg_spectrum ( slice_index , standardization ) # Most likely the remaining cases won't be used elif lb is None : if standardization : return dic [ slice_index ][ \"array_avg_spectrum\" ][:, : hb ] else : return dic [ slice_index ][ \"array_avg_spectrum_before_standardization\" ][:, : hb ] else : if standardization : return dic [ slice_index ][ \"array_avg_spectrum\" ][:, lb :] else : return dic [ slice_index ][ \"array_avg_spectrum_before_standardization\" ][:, lb :]","title":"get_partial_array_avg_spectrum()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_partial_array_intensity","text":"Getter for partial_array_intensity, which corresponds to the second row of partial_array_spectra, i.e. the intensity values of the spectral data, between lb and hb. Parameters: Name Type Description Default slice_index int Index of the slice for which the intensity values are requested. required lb int Lower bound of the requested spectrum. None hb int Upper bound of the requested spectrum. None index int Index of the slice of the requested spectrum. None Returns: Type Description np.ndarray, mmaped if not sampled dataset Intensity values of the spectral data of the requested slice between lb and hb. Source code in modules/maldi_data.py 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 def get_partial_array_intensity ( self , slice_index , lb = None , hb = None , index = None ): \"\"\"Getter for partial_array_intensity, which corresponds to the second row of partial_array_spectra, i.e. the intensity values of the spectral data, between lb and hb. Args: slice_index (int): Index of the slice for which the intensity values are requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray, mmaped if not sampled dataset): Intensity values of the spectral data of the requested slice between lb and hb. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] if lb is None and hb is None and index is None : # Previously called array_spectra_high_res return dic [ \"array_spectra\" ][ 1 , :] elif lb is not None and hb is not None : return dic [ \"array_spectra\" ][ 1 , lb : hb ] elif index is not None : return dic [ \"array_spectra\" ][ 1 , index ] # If not specific index has been provided, it returns a range if index is None : # Start with most likely case if hb is not None and lb is not None : return dic [ \"array_spectra\" ][ 1 , lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_intensity ( slice_index ) # Most likely the remaining cases won't be used elif lb is None : return dic [ \"array_spectra\" ][ 1 , : hb ] else : return dic [ \"array_spectra\" ][ 1 , lb :] # Else, it returns the required index else : if lb is not None or hb is not None : logging . warning ( \"Both one or several boundaries and one index have been specified\" + \" when calling array_spectra. \" + \"Only the index request will be satisfied.\" ) return dic [ \"array_spectra\" ][ 1 , index ]","title":"get_partial_array_intensity()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_partial_array_mz","text":"Getter for partial_array_mz, which corresponds to the first row of partial_array_spectra, i.e. the m/z values of the spectral data, between lb and hb. Parameters: Name Type Description Default slice_index int Index of the slice for which the m/z values are requested. required lb int Lower bound of the requested spectrum. None hb int Upper bound of the requested spectrum. None index int Index of the slice of the requested spectrum. None Returns: Type Description np.ndarray (mmaped if not sampled dataset) m/z values of the spectral data of the requested slice between lb and hb. Source code in modules/maldi_data.py 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 def get_partial_array_mz ( self , slice_index , lb = None , hb = None , index = None ): \"\"\"Getter for partial_array_mz, which corresponds to the first row of partial_array_spectra, i.e. the m/z values of the spectral data, between lb and hb. Args: slice_index (int): Index of the slice for which the m/z values are requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. index (int): Index of the slice of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): m/z values of the spectral data of the requested slice between lb and hb. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] if lb is None and hb is None and index is None : # Previously called array_spectra_high_res return dic [ \"array_spectra\" ][ 0 , :] elif lb is not None and hb is not None : return dic [ \"array_spectra\" ][ 0 , lb : hb ] elif index is not None : return dic [ \"array_spectra\" ][ 0 , index ] # If not specific index has been provided, it returns a range if index is None : # Start with most likely case if hb is not None and lb is not None : return dic [ \"array_spectra\" ][ 0 , lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_mz ( slice_index ) # Most likely the remaining cases won't be used elif lb is None : return dic [ \"array_spectra\" ][ 0 , : hb ] else : return dic [ \"array_spectra\" ][ 0 , lb :] # Else, it returns the required index else : if lb is not None or hb is not None : logging . warning ( \"Both one or several boundaries and one index have been specified\" + \" when calling array_spectra. \" + \"Only the index request will be satisfied.\" ) return dic [ \"array_spectra\" ][ 0 , index ]","title":"get_partial_array_mz()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_partial_array_spectra","text":"Getter for partial_array_spectra, which is a numpy array containing the spectral data of slice indexed by slice_index. Parameters: Name Type Description Default slice_index int Index of the slice for which the spectral data is requested. required lb int Lower bound of the requested spectrum. None hb int Upper bound of the requested spectrum. None index int Index of the requested spectrum. None Returns: Type Description np.ndarray (mmaped if not sampled dataset) Spectral data of the requested slice. Source code in modules/maldi_data.py 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 def get_partial_array_spectra ( self , slice_index , lb = None , hb = None , index = None ): \"\"\"Getter for partial_array_spectra, which is a numpy array containing the spectral data of slice indexed by slice_index. Args: slice_index (int): Index of the slice for which the spectral data is requested. lb (int): Lower bound of the requested spectrum. hb (int): Upper bound of the requested spectrum. index (int): Index of the requested spectrum. Returns: (np.ndarray (mmaped if not sampled dataset)): Spectral data of the requested slice. \"\"\" # As there are many possibilities, define new dic depending if sampled data or not if self . _sample_data : dic = self . _dic_lightweight [ slice_index ] else : dic = self . _dic_memmap [ slice_index ] if lb is None and hb is None and index is None : # Previously called array_spectra_high_res. return dic [ \"array_spectra\" ] elif lb is not None and hb is not None : return dic [ \"array_spectra\" ][:, lb : hb ] elif index is not None : return dic [ \"array_spectra\" ][:, index ] # If not specific index has been provided, it returns a range if index is None : # Start with most likely case if hb is not None and lb is not None : return dic [ \"array_spectra\" ][:, lb : hb ] # Second most likely case : full slice elif lb is None and hb is None : return self . get_array_intensity ( slice_index ) # Most likely the remaining cases won't be used elif lb is None : return dic [ \"array_spectra\" ][:, : hb ] else : return dic [ \"array_spectra\" ][:, lb :] # Else, it returns the required index else : if lb is not None or hb is not None : logging . warning ( \"Both one or several boundaries and one index have been specified\" + \" when calling array_spectra. \" + \"Only the index request will be satisfied.\" ) return dic [ \"array_spectra\" ][:, index ]","title":"get_partial_array_spectra()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_slice_list","text":"Getter for the list of slice indices. Parameters: Name Type Description Default indices str If \"all\", return the list of all slice indices. If \"brain_1\", return the list of slice indices for brain 1. If \"brain_2\", return the list of slice indices for brain 2. Defaults to \"all\". Indices start at 1. 'all' Returns: Type Description list The list of requested slice indices. Source code in modules/maldi_data.py 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 def get_slice_list ( self , indices = \"all\" ): \"\"\"Getter for the list of slice indices. Args: indices (str, optional): If \"all\", return the list of all slice indices. If \"brain_1\", return the list of slice indices for brain 1. If \"brain_2\", return the list of slice indices for brain 2. Defaults to \"all\". Indices start at 1. Returns: (list): The list of requested slice indices. \"\"\" if indices == \"all\" : return self . _l_slices elif indices == \"brain_1\" : return self . _l_slices_brain_1 elif indices == \"brain_2\" : return self . _l_slices_brain_2 else : raise ValueError ( \"Invalid string for indices\" )","title":"get_slice_list()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.get_slice_number","text":"Getter for the number of slice present in the dataset. Returns: Type Description int The number of slices in the dataset. Source code in modules/maldi_data.py 282 283 284 285 286 287 288 def get_slice_number ( self ): \"\"\"Getter for the number of slice present in the dataset. Returns: (int): The number of slices in the dataset. \"\"\" return self . _n_slices","title":"get_slice_number()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.is_brain_1","text":"Returns True if the slice indexed by slice_index is a brain 1. Else, returns False. Parameters: Name Type Description Default slice_index int Index of the slice for which the status is requested. required Returns: Type Description bool True if the slice indexed by slice_index is a brain 1. Else, returns False. Source code in modules/maldi_data.py 748 749 750 751 752 753 754 755 756 757 def is_brain_1 ( self , slice_index ): \"\"\"Returns True if the slice indexed by slice_index is a brain 1. Else, returns False. Args: slice_index (int): Index of the slice for which the status is requested. Returns: (bool): True if the slice indexed by slice_index is a brain 1. Else, returns False. \"\"\" return self . _dic_lightweight [ slice_index ][ \"is_brain_1\" ]","title":"is_brain_1()"},{"location":"modules/maldi_data/#modules.maldi_data.MaldiData.return_lipid_options","text":"Computes and returns the list of lipid names, structures and cation. Returns: Type Description list List of lipid names, structures and cations. Source code in modules/maldi_data.py 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 def return_lipid_options ( self ): \"\"\"Computes and returns the list of lipid names, structures and cation. Returns: (list): List of lipid names, structures and cations. \"\"\" return [ { \"label\" : name + \" \" + structure + \" \" + cation , \"value\" : name + \" \" + structure + \" \" + cation , \"group\" : name , } for name in sorted ( self . get_annotations () . name . unique ()) for structure in sorted ( self . get_annotations ()[( self . get_annotations ()[ \"name\" ] == name )] . structure . unique () ) for cation in sorted ( self . get_annotations ()[ ( self . get_annotations ()[ \"name\" ] == name ) & ( self . get_annotations ()[ \"structure\" ] == structure ) ] . cation . unique () ) ]","title":"return_lipid_options()"},{"location":"modules/scRNAseq/","text":"This class is used to compare the data coming from acquisitions (MALDI), and the molecular atlas data (scRNAseq). See https://molecularatlas.org/ for more information. ScRNAseq Class used to compare the data coming from acquisitions (MALDI), and the molecular atlas data (scRNAseq). Attributes: array_exp_lipids_brain_1 (np.ndarray): Matrix of lipids expression for brain 1, whose rows correspond to acquired spots and columns to lipids. array_exp_lipids_brain_2 (np.ndarray): Same as for array_exp_lipids_brain_1, but with the data from brain 2. array_exp_genes_brain_1 (np.ndarray): Matrix of genes expression for brain 1, whose rows correspond to acquired spots and columns to genes. array_exp_genes_brain_2 (np.ndarray): Same as for array_exp_genes_brain_1, but with the data from brain 2. l_name_lipids_brain_1 (list(str)): List of lipids names for brain 1. l_name_lipids_brain_2 (list(str)): Same as for l_name_lipids_brain_1, but with the data from brain 2. l_genes_brain_1 (list(str)): List of genes names for brain 1. l_genes_brain_2 (list(str)): Same as for l_genes_brain_1, but with the data from brain 2. array_coef_brain_1 (np.ndarray): Array of coefficients for the LASSO regression for brain 1, explaining lipid expression in terms of gene expression (lipids are rows, genes are columns). array_coef_brain_2 (np.ndarray): Same as for array_coef_brain_1, but with the data from brain 2. l_score_brain_1 (list(float)): List of scores for the LASSO regression for brain 1. l_score_brain_2 (list(float)): Same as for l_score_brain_1, but with the data from brain 2. xmol (np.ndarray): Array of x coordinates of the acquired spots. ymol (np.ndarray): Array of y coordinates of the acquired spots. zmol (np.ndarray): Array of z coordinates of the acquired spots. Methods: __init__(path_scRNAseq=\"data/scRNAseq/\"): Initialize the scRNAseq class. Source code in modules/scRNAseq.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 class ScRNAseq : \"\"\"Class used to compare the data coming from acquisitions (MALDI), and the molecular atlas data (scRNAseq). Attributes: array_exp_lipids_brain_1 (np.ndarray): Matrix of lipids expression for brain 1, whose rows correspond to acquired spots and columns to lipids. array_exp_lipids_brain_2 (np.ndarray): Same as for array_exp_lipids_brain_1, but with the data from brain 2. array_exp_genes_brain_1 (np.ndarray): Matrix of genes expression for brain 1, whose rows correspond to acquired spots and columns to genes. array_exp_genes_brain_2 (np.ndarray): Same as for array_exp_genes_brain_1, but with the data from brain 2. l_name_lipids_brain_1 (list(str)): List of lipids names for brain 1. l_name_lipids_brain_2 (list(str)): Same as for l_name_lipids_brain_1, but with the data from brain 2. l_genes_brain_1 (list(str)): List of genes names for brain 1. l_genes_brain_2 (list(str)): Same as for l_genes_brain_1, but with the data from brain 2. array_coef_brain_1 (np.ndarray): Array of coefficients for the LASSO regression for brain 1, explaining lipid expression in terms of gene expression (lipids are rows, genes are columns). array_coef_brain_2 (np.ndarray): Same as for array_coef_brain_1, but with the data from brain 2. l_score_brain_1 (list(float)): List of scores for the LASSO regression for brain 1. l_score_brain_2 (list(float)): Same as for l_score_brain_1, but with the data from brain 2. xmol (np.ndarray): Array of x coordinates of the acquired spots. ymol (np.ndarray): Array of y coordinates of the acquired spots. zmol (np.ndarray): Array of z coordinates of the acquired spots. Methods: __init__(path_scRNAseq=\"data/scRNAseq/\"): Initialize the scRNAseq class. \"\"\" # ============================================================================================== # --- Constructor # ============================================================================================== def __init__ ( self , path_scRNAseq = \"data/scRNAseq/\" ): \"\"\"Initialize the class ScRNAseq. Args: path_scRNAseq (str): Path of the scRNAseq data. \"\"\" logging . info ( \"Initializing ScRNAseq object\" + logmem ()) # Load the array of lipids and genes and corresponding names for brain 1 self . array_exp_lipids_brain_1 = np . load ( path_scRNAseq + \"array_exp_lipids_True.npy\" ) self . l_name_lipids_brain_1 = np . load ( path_scRNAseq + \"array_name_lipids_True.npy\" ) . tolist () self . array_exp_genes_brain_1 = np . load ( path_scRNAseq + \"array_exp_genes_True.npy\" ) self . l_genes_brain_1 = np . load ( path_scRNAseq + \"array_name_genes_True.npy\" ) . tolist () self . array_coef_brain_1 = np . load ( path_scRNAseq + \"array_coef_True.npy\" ) self . l_score_brain_1 = np . load ( path_scRNAseq + \"array_score_True.npy\" ) . tolist () # Same for brain 2 self . array_exp_lipids_brain_2 = np . load ( path_scRNAseq + \"array_exp_lipids_False.npy\" ) self . l_name_lipids_brain_2 = np . load ( path_scRNAseq + \"array_name_lipids_False.npy\" ) . tolist () self . array_exp_genes_brain_2 = np . load ( path_scRNAseq + \"array_exp_genes_False.npy\" ) self . l_genes_brain_2 = np . load ( path_scRNAseq + \"array_name_genes_False.npy\" ) . tolist () self . array_coef_brain_2 = np . load ( path_scRNAseq + \"array_coef_False.npy\" ) self . l_score_brain_2 = np . load ( path_scRNAseq + \"array_score_False.npy\" ) . tolist () # Load the array of coordinates self . xmol , self . ymol , self . zmol = np . load ( path_scRNAseq + \"array_coordinates.npy\" ) # Normalize gene expression values self . normalize_gene_expression_values () logging . info ( \"ScRNAseq object instantiated\" + logmem ()) # ============================================================================================== # --- Methods # ============================================================================================== def normalize_gene_expression_values ( self , percentile = 75 ): \"\"\"Normalize inplace the gene expression values according to the provided percentile.\"\"\" logging . info ( \"Normalizing gene expression values\" + logmem ()) # Normalize the gene expression values self . array_exp_genes_brain_1 = ( self . array_exp_genes_brain_1 / np . percentile ( self . array_exp_genes_brain_1 , percentile ) * 255 ) self . array_exp_genes_brain_2 = ( self . array_exp_genes_brain_2 / np . percentile ( self . array_exp_genes_brain_2 , percentile ) * 255 ) # Clip the gene expression values above 255 self . array_exp_genes_brain_1 [ self . array_exp_genes_brain_1 > 255 ] = 255 self . array_exp_genes_brain_2 [ self . array_exp_genes_brain_2 > 255 ] = 255 logging . info ( \"Gene expression values normalized\" + logmem ()) __init__ ( path_scRNAseq = 'data/scRNAseq/' ) Initialize the class ScRNAseq. Parameters: Name Type Description Default path_scRNAseq str Path of the scRNAseq data. 'data/scRNAseq/' Source code in modules/scRNAseq.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def __init__ ( self , path_scRNAseq = \"data/scRNAseq/\" ): \"\"\"Initialize the class ScRNAseq. Args: path_scRNAseq (str): Path of the scRNAseq data. \"\"\" logging . info ( \"Initializing ScRNAseq object\" + logmem ()) # Load the array of lipids and genes and corresponding names for brain 1 self . array_exp_lipids_brain_1 = np . load ( path_scRNAseq + \"array_exp_lipids_True.npy\" ) self . l_name_lipids_brain_1 = np . load ( path_scRNAseq + \"array_name_lipids_True.npy\" ) . tolist () self . array_exp_genes_brain_1 = np . load ( path_scRNAseq + \"array_exp_genes_True.npy\" ) self . l_genes_brain_1 = np . load ( path_scRNAseq + \"array_name_genes_True.npy\" ) . tolist () self . array_coef_brain_1 = np . load ( path_scRNAseq + \"array_coef_True.npy\" ) self . l_score_brain_1 = np . load ( path_scRNAseq + \"array_score_True.npy\" ) . tolist () # Same for brain 2 self . array_exp_lipids_brain_2 = np . load ( path_scRNAseq + \"array_exp_lipids_False.npy\" ) self . l_name_lipids_brain_2 = np . load ( path_scRNAseq + \"array_name_lipids_False.npy\" ) . tolist () self . array_exp_genes_brain_2 = np . load ( path_scRNAseq + \"array_exp_genes_False.npy\" ) self . l_genes_brain_2 = np . load ( path_scRNAseq + \"array_name_genes_False.npy\" ) . tolist () self . array_coef_brain_2 = np . load ( path_scRNAseq + \"array_coef_False.npy\" ) self . l_score_brain_2 = np . load ( path_scRNAseq + \"array_score_False.npy\" ) . tolist () # Load the array of coordinates self . xmol , self . ymol , self . zmol = np . load ( path_scRNAseq + \"array_coordinates.npy\" ) # Normalize gene expression values self . normalize_gene_expression_values () logging . info ( \"ScRNAseq object instantiated\" + logmem ()) normalize_gene_expression_values ( percentile = 75 ) Normalize inplace the gene expression values according to the provided percentile. Source code in modules/scRNAseq.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def normalize_gene_expression_values ( self , percentile = 75 ): \"\"\"Normalize inplace the gene expression values according to the provided percentile.\"\"\" logging . info ( \"Normalizing gene expression values\" + logmem ()) # Normalize the gene expression values self . array_exp_genes_brain_1 = ( self . array_exp_genes_brain_1 / np . percentile ( self . array_exp_genes_brain_1 , percentile ) * 255 ) self . array_exp_genes_brain_2 = ( self . array_exp_genes_brain_2 / np . percentile ( self . array_exp_genes_brain_2 , percentile ) * 255 ) # Clip the gene expression values above 255 self . array_exp_genes_brain_1 [ self . array_exp_genes_brain_1 > 255 ] = 255 self . array_exp_genes_brain_2 [ self . array_exp_genes_brain_2 > 255 ] = 255 logging . info ( \"Gene expression values normalized\" + logmem ())","title":"scRNAseq"},{"location":"modules/scRNAseq/#modules.scRNAseq.ScRNAseq","text":"Class used to compare the data coming from acquisitions (MALDI), and the molecular atlas data (scRNAseq). Attributes: array_exp_lipids_brain_1 (np.ndarray): Matrix of lipids expression for brain 1, whose rows correspond to acquired spots and columns to lipids. array_exp_lipids_brain_2 (np.ndarray): Same as for array_exp_lipids_brain_1, but with the data from brain 2. array_exp_genes_brain_1 (np.ndarray): Matrix of genes expression for brain 1, whose rows correspond to acquired spots and columns to genes. array_exp_genes_brain_2 (np.ndarray): Same as for array_exp_genes_brain_1, but with the data from brain 2. l_name_lipids_brain_1 (list(str)): List of lipids names for brain 1. l_name_lipids_brain_2 (list(str)): Same as for l_name_lipids_brain_1, but with the data from brain 2. l_genes_brain_1 (list(str)): List of genes names for brain 1. l_genes_brain_2 (list(str)): Same as for l_genes_brain_1, but with the data from brain 2. array_coef_brain_1 (np.ndarray): Array of coefficients for the LASSO regression for brain 1, explaining lipid expression in terms of gene expression (lipids are rows, genes are columns). array_coef_brain_2 (np.ndarray): Same as for array_coef_brain_1, but with the data from brain 2. l_score_brain_1 (list(float)): List of scores for the LASSO regression for brain 1. l_score_brain_2 (list(float)): Same as for l_score_brain_1, but with the data from brain 2. xmol (np.ndarray): Array of x coordinates of the acquired spots. ymol (np.ndarray): Array of y coordinates of the acquired spots. zmol (np.ndarray): Array of z coordinates of the acquired spots. Methods: __init__(path_scRNAseq=\"data/scRNAseq/\"): Initialize the scRNAseq class. Source code in modules/scRNAseq.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 class ScRNAseq : \"\"\"Class used to compare the data coming from acquisitions (MALDI), and the molecular atlas data (scRNAseq). Attributes: array_exp_lipids_brain_1 (np.ndarray): Matrix of lipids expression for brain 1, whose rows correspond to acquired spots and columns to lipids. array_exp_lipids_brain_2 (np.ndarray): Same as for array_exp_lipids_brain_1, but with the data from brain 2. array_exp_genes_brain_1 (np.ndarray): Matrix of genes expression for brain 1, whose rows correspond to acquired spots and columns to genes. array_exp_genes_brain_2 (np.ndarray): Same as for array_exp_genes_brain_1, but with the data from brain 2. l_name_lipids_brain_1 (list(str)): List of lipids names for brain 1. l_name_lipids_brain_2 (list(str)): Same as for l_name_lipids_brain_1, but with the data from brain 2. l_genes_brain_1 (list(str)): List of genes names for brain 1. l_genes_brain_2 (list(str)): Same as for l_genes_brain_1, but with the data from brain 2. array_coef_brain_1 (np.ndarray): Array of coefficients for the LASSO regression for brain 1, explaining lipid expression in terms of gene expression (lipids are rows, genes are columns). array_coef_brain_2 (np.ndarray): Same as for array_coef_brain_1, but with the data from brain 2. l_score_brain_1 (list(float)): List of scores for the LASSO regression for brain 1. l_score_brain_2 (list(float)): Same as for l_score_brain_1, but with the data from brain 2. xmol (np.ndarray): Array of x coordinates of the acquired spots. ymol (np.ndarray): Array of y coordinates of the acquired spots. zmol (np.ndarray): Array of z coordinates of the acquired spots. Methods: __init__(path_scRNAseq=\"data/scRNAseq/\"): Initialize the scRNAseq class. \"\"\" # ============================================================================================== # --- Constructor # ============================================================================================== def __init__ ( self , path_scRNAseq = \"data/scRNAseq/\" ): \"\"\"Initialize the class ScRNAseq. Args: path_scRNAseq (str): Path of the scRNAseq data. \"\"\" logging . info ( \"Initializing ScRNAseq object\" + logmem ()) # Load the array of lipids and genes and corresponding names for brain 1 self . array_exp_lipids_brain_1 = np . load ( path_scRNAseq + \"array_exp_lipids_True.npy\" ) self . l_name_lipids_brain_1 = np . load ( path_scRNAseq + \"array_name_lipids_True.npy\" ) . tolist () self . array_exp_genes_brain_1 = np . load ( path_scRNAseq + \"array_exp_genes_True.npy\" ) self . l_genes_brain_1 = np . load ( path_scRNAseq + \"array_name_genes_True.npy\" ) . tolist () self . array_coef_brain_1 = np . load ( path_scRNAseq + \"array_coef_True.npy\" ) self . l_score_brain_1 = np . load ( path_scRNAseq + \"array_score_True.npy\" ) . tolist () # Same for brain 2 self . array_exp_lipids_brain_2 = np . load ( path_scRNAseq + \"array_exp_lipids_False.npy\" ) self . l_name_lipids_brain_2 = np . load ( path_scRNAseq + \"array_name_lipids_False.npy\" ) . tolist () self . array_exp_genes_brain_2 = np . load ( path_scRNAseq + \"array_exp_genes_False.npy\" ) self . l_genes_brain_2 = np . load ( path_scRNAseq + \"array_name_genes_False.npy\" ) . tolist () self . array_coef_brain_2 = np . load ( path_scRNAseq + \"array_coef_False.npy\" ) self . l_score_brain_2 = np . load ( path_scRNAseq + \"array_score_False.npy\" ) . tolist () # Load the array of coordinates self . xmol , self . ymol , self . zmol = np . load ( path_scRNAseq + \"array_coordinates.npy\" ) # Normalize gene expression values self . normalize_gene_expression_values () logging . info ( \"ScRNAseq object instantiated\" + logmem ()) # ============================================================================================== # --- Methods # ============================================================================================== def normalize_gene_expression_values ( self , percentile = 75 ): \"\"\"Normalize inplace the gene expression values according to the provided percentile.\"\"\" logging . info ( \"Normalizing gene expression values\" + logmem ()) # Normalize the gene expression values self . array_exp_genes_brain_1 = ( self . array_exp_genes_brain_1 / np . percentile ( self . array_exp_genes_brain_1 , percentile ) * 255 ) self . array_exp_genes_brain_2 = ( self . array_exp_genes_brain_2 / np . percentile ( self . array_exp_genes_brain_2 , percentile ) * 255 ) # Clip the gene expression values above 255 self . array_exp_genes_brain_1 [ self . array_exp_genes_brain_1 > 255 ] = 255 self . array_exp_genes_brain_2 [ self . array_exp_genes_brain_2 > 255 ] = 255 logging . info ( \"Gene expression values normalized\" + logmem ())","title":"ScRNAseq"},{"location":"modules/scRNAseq/#modules.scRNAseq.ScRNAseq.__init__","text":"Initialize the class ScRNAseq. Parameters: Name Type Description Default path_scRNAseq str Path of the scRNAseq data. 'data/scRNAseq/' Source code in modules/scRNAseq.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def __init__ ( self , path_scRNAseq = \"data/scRNAseq/\" ): \"\"\"Initialize the class ScRNAseq. Args: path_scRNAseq (str): Path of the scRNAseq data. \"\"\" logging . info ( \"Initializing ScRNAseq object\" + logmem ()) # Load the array of lipids and genes and corresponding names for brain 1 self . array_exp_lipids_brain_1 = np . load ( path_scRNAseq + \"array_exp_lipids_True.npy\" ) self . l_name_lipids_brain_1 = np . load ( path_scRNAseq + \"array_name_lipids_True.npy\" ) . tolist () self . array_exp_genes_brain_1 = np . load ( path_scRNAseq + \"array_exp_genes_True.npy\" ) self . l_genes_brain_1 = np . load ( path_scRNAseq + \"array_name_genes_True.npy\" ) . tolist () self . array_coef_brain_1 = np . load ( path_scRNAseq + \"array_coef_True.npy\" ) self . l_score_brain_1 = np . load ( path_scRNAseq + \"array_score_True.npy\" ) . tolist () # Same for brain 2 self . array_exp_lipids_brain_2 = np . load ( path_scRNAseq + \"array_exp_lipids_False.npy\" ) self . l_name_lipids_brain_2 = np . load ( path_scRNAseq + \"array_name_lipids_False.npy\" ) . tolist () self . array_exp_genes_brain_2 = np . load ( path_scRNAseq + \"array_exp_genes_False.npy\" ) self . l_genes_brain_2 = np . load ( path_scRNAseq + \"array_name_genes_False.npy\" ) . tolist () self . array_coef_brain_2 = np . load ( path_scRNAseq + \"array_coef_False.npy\" ) self . l_score_brain_2 = np . load ( path_scRNAseq + \"array_score_False.npy\" ) . tolist () # Load the array of coordinates self . xmol , self . ymol , self . zmol = np . load ( path_scRNAseq + \"array_coordinates.npy\" ) # Normalize gene expression values self . normalize_gene_expression_values () logging . info ( \"ScRNAseq object instantiated\" + logmem ())","title":"__init__()"},{"location":"modules/scRNAseq/#modules.scRNAseq.ScRNAseq.normalize_gene_expression_values","text":"Normalize inplace the gene expression values according to the provided percentile. Source code in modules/scRNAseq.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def normalize_gene_expression_values ( self , percentile = 75 ): \"\"\"Normalize inplace the gene expression values according to the provided percentile.\"\"\" logging . info ( \"Normalizing gene expression values\" + logmem ()) # Normalize the gene expression values self . array_exp_genes_brain_1 = ( self . array_exp_genes_brain_1 / np . percentile ( self . array_exp_genes_brain_1 , percentile ) * 255 ) self . array_exp_genes_brain_2 = ( self . array_exp_genes_brain_2 / np . percentile ( self . array_exp_genes_brain_2 , percentile ) * 255 ) # Clip the gene expression values above 255 self . array_exp_genes_brain_1 [ self . array_exp_genes_brain_1 > 255 ] = 255 self . array_exp_genes_brain_2 [ self . array_exp_genes_brain_2 > 255 ] = 255 logging . info ( \"Gene expression values normalized\" + logmem ())","title":"normalize_gene_expression_values()"},{"location":"modules/storage/","text":"This class is used to handle the loading/dumping of the data used in the app. Storage A class used to handle the loading/dumping of the data used in the app (memmaps excluded), e.g. figures or masks, are defined. The storage relies on a shelve database. Attributes: Name Type Description path_db str Path of the shelve database. Methods init (path_db=\"data/whole_dataset/\"): Initializes the class Storage. dump_shelved_object(data_folder, file_name, object): Dumps an object in a shelve database. load_shelved_object(data_folder, file_name): Loads an object from a shelve database. check_shelved_object(data_folder, file_name): Checks if an object is in a shelve database. return_shelved_object(data_folder, file_name, force_update, compute_function, ignore_arguments_naming=False, **compute_function_args): Returns an object from a shelve database. If the object is not in the database, it is computed and dumped in the database. empty_shelve(): Erases all entries in the shelve database. list_shelve_objects_size(): Lists the size of all objects in the shelve database. Source code in modules/storage.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 class Storage : \"\"\"A class used to handle the loading/dumping of the data used in the app (memmaps excluded), e.g. figures or masks, are defined. The storage relies on a shelve database. Attributes: path_db (str): Path of the shelve database. Methods: __init__(path_db=\"data/whole_dataset/\"): Initializes the class Storage. dump_shelved_object(data_folder, file_name, object): Dumps an object in a shelve database. load_shelved_object(data_folder, file_name): Loads an object from a shelve database. check_shelved_object(data_folder, file_name): Checks if an object is in a shelve database. return_shelved_object(data_folder, file_name, force_update, compute_function, ignore_arguments_naming=False, **compute_function_args): Returns an object from a shelve database. If the object is not in the database, it is computed and dumped in the database. empty_shelve(): Erases all entries in the shelve database. list_shelve_objects_size(): Lists the size of all objects in the shelve database. \"\"\" # ============================================================================================== # --- Constructor # ============================================================================================== def __init__ ( self , path_db = \"data/whole_dataset/\" ): \"\"\"Initialize the class Storage. Args: path_db (str): Path of the shelve database. \"\"\" # Create database folder if not existing self . path_db = path_db if not os . path . exists ( self . path_db ): os . makedirs ( self . path_db ) # self.list_shelve_objects_size() def dump_shelved_object ( self , data_folder , file_name , object ): \"\"\"This method dumps an object in a shelve database. Args: data_folder (str): The path of the folder in which the object must be saved. file_name (str): The name of the file to save/load. object (object): The object to save. \"\"\" # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Dump in db with shelve . open ( self . path_db ) as db : db [ complete_file_name ] = object def load_shelved_object ( self , data_folder , file_name ): \"\"\"This method loads an object from a shelve database. Args: data_folder (str): The path of the folder in which the object must be saved. file_name (str): The name of the file to save/load. \"\"\" # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Load from in db with shelve . open ( self . path_db ) as db : return db [ complete_file_name ] def check_shelved_object ( self , data_folder , file_name ): \"\"\"This method checks if an object is in a shelve database. Args: data_folder (str): The path of the folder in which the object must be saved. file_name (str): The name of the file to save/load. \"\"\" # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Load from in db with shelve . open ( self . path_db ) as db : if complete_file_name in db : return True else : return False def return_shelved_object ( self , data_folder , file_name , force_update , compute_function , ignore_arguments_naming = False , ** compute_function_args ): \"\"\"This method checks if the result of the method or function compute_function has not been computed and saved already. If yes, it returns this result from the corresponding shelve. Else, it executes compute_function, saves the result in a shelve file, and returns the result. Args: data_folder (str): The path of the folder in which the result of compute_function must be saved. file_name (str): The name of the object to save/load. Arguments will potentially be contatenated to file_name depending on the value of ignore_arguments_naming. force_update (bool): If True, compute_function will be re-executed and saved despite the file result already existing. compute_function (func): The function/method whose result must be loaded/saved. ignore_arguments_naming (bool, optional): If True, the arguments of compute_function won't be added to the filename of the result file. Defaults to False. **compute_function_args: Arguments of compute_function. Returns: The result of compute_function. Type may vary depending on compute_function. \"\"\" # Define database path db_path = self . path_db # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Complete filename with function arguments if not ignore_arguments_naming : for key , value in compute_function_args . items (): complete_file_name += \"_\" + str ( value ) # Load the shelve db = shelve . open ( db_path ) # Check if the object is in the folder already and return it if complete_file_name in db and not force_update : logging . info ( \"Returning \" + complete_file_name + \" from shelve file.\" + logmem ()) object = db [ complete_file_name ] else : logging . info ( complete_file_name + \" could not be found or force_update is True. \" + \"Computing the object and shelving it now.\" ) # Close shelve to prevent nesting issues with compute function db . close () # Execute compute_function object = compute_function ( ** compute_function_args ) # Reopen shelve db = shelve . open ( db_path ) # Save the result in a pickle file db [ complete_file_name ] = object logging . info ( complete_file_name + \" being returned now from computation.\" ) # Close shelve for good this time db . close () return object def empty_shelve ( self ): \"\"\"This method erases all entries in the shelve database.\"\"\" # Load from in db with shelve . open ( self . path_db ) as db : # Completely empty database for key in db : del db [ key ] def list_shelve_objects_size ( self ): \"\"\"This method list the size of all objects in the shelve database.\"\"\" # Load from in db with shelve . open ( self . path_db ) as db : tot_size = 0 # List size for key in db : try : size_obj = asizeof . asizeof ( db [ key ]) / 1024 / 1024 tot_size += size_obj logging . info ( key + \": \\t \" + str ( size_obj ) + \", tot_size: \\t \" + str ( tot_size )) except : pass __init__ ( path_db = 'data/whole_dataset/' ) Initialize the class Storage. Parameters: Name Type Description Default path_db str Path of the shelve database. 'data/whole_dataset/' Source code in modules/storage.py 46 47 48 49 50 51 52 53 54 55 56 def __init__ ( self , path_db = \"data/whole_dataset/\" ): \"\"\"Initialize the class Storage. Args: path_db (str): Path of the shelve database. \"\"\" # Create database folder if not existing self . path_db = path_db if not os . path . exists ( self . path_db ): os . makedirs ( self . path_db ) check_shelved_object ( data_folder , file_name ) This method checks if an object is in a shelve database. Parameters: Name Type Description Default data_folder str The path of the folder in which the object must be saved. required file_name str The name of the file to save/load. required Source code in modules/storage.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def check_shelved_object ( self , data_folder , file_name ): \"\"\"This method checks if an object is in a shelve database. Args: data_folder (str): The path of the folder in which the object must be saved. file_name (str): The name of the file to save/load. \"\"\" # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Load from in db with shelve . open ( self . path_db ) as db : if complete_file_name in db : return True else : return False dump_shelved_object ( data_folder , file_name , object ) This method dumps an object in a shelve database. Parameters: Name Type Description Default data_folder str The path of the folder in which the object must be saved. required file_name str The name of the file to save/load. required object object The object to save. required Source code in modules/storage.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def dump_shelved_object ( self , data_folder , file_name , object ): \"\"\"This method dumps an object in a shelve database. Args: data_folder (str): The path of the folder in which the object must be saved. file_name (str): The name of the file to save/load. object (object): The object to save. \"\"\" # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Dump in db with shelve . open ( self . path_db ) as db : db [ complete_file_name ] = object empty_shelve () This method erases all entries in the shelve database. Source code in modules/storage.py 180 181 182 183 184 185 186 187 def empty_shelve ( self ): \"\"\"This method erases all entries in the shelve database.\"\"\" # Load from in db with shelve . open ( self . path_db ) as db : # Completely empty database for key in db : del db [ key ] list_shelve_objects_size () This method list the size of all objects in the shelve database. Source code in modules/storage.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 def list_shelve_objects_size ( self ): \"\"\"This method list the size of all objects in the shelve database.\"\"\" # Load from in db with shelve . open ( self . path_db ) as db : tot_size = 0 # List size for key in db : try : size_obj = asizeof . asizeof ( db [ key ]) / 1024 / 1024 tot_size += size_obj logging . info ( key + \": \\t \" + str ( size_obj ) + \", tot_size: \\t \" + str ( tot_size )) except : pass load_shelved_object ( data_folder , file_name ) This method loads an object from a shelve database. Parameters: Name Type Description Default data_folder str The path of the folder in which the object must be saved. required file_name str The name of the file to save/load. required Source code in modules/storage.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def load_shelved_object ( self , data_folder , file_name ): \"\"\"This method loads an object from a shelve database. Args: data_folder (str): The path of the folder in which the object must be saved. file_name (str): The name of the file to save/load. \"\"\" # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Load from in db with shelve . open ( self . path_db ) as db : return db [ complete_file_name ] return_shelved_object ( data_folder , file_name , force_update , compute_function , ignore_arguments_naming = False , ** compute_function_args ) This method checks if the result of the method or function compute_function has not been computed and saved already. If yes, it returns this result from the corresponding shelve. Else, it executes compute_function, saves the result in a shelve file, and returns the result. Parameters: Name Type Description Default data_folder str The path of the folder in which the result of compute_function must be saved. required file_name str The name of the object to save/load. Arguments will potentially be contatenated to file_name depending on the value of ignore_arguments_naming. required force_update bool If True, compute_function will be re-executed and saved despite the file result already existing. required compute_function func The function/method whose result must be loaded/saved. required ignore_arguments_naming bool If True, the arguments of compute_function won't be added to the filename of the result file. Defaults to False. False **compute_function_args Arguments of compute_function. {} Returns: Type Description The result of compute_function. Type may vary depending on compute_function. Source code in modules/storage.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def return_shelved_object ( self , data_folder , file_name , force_update , compute_function , ignore_arguments_naming = False , ** compute_function_args ): \"\"\"This method checks if the result of the method or function compute_function has not been computed and saved already. If yes, it returns this result from the corresponding shelve. Else, it executes compute_function, saves the result in a shelve file, and returns the result. Args: data_folder (str): The path of the folder in which the result of compute_function must be saved. file_name (str): The name of the object to save/load. Arguments will potentially be contatenated to file_name depending on the value of ignore_arguments_naming. force_update (bool): If True, compute_function will be re-executed and saved despite the file result already existing. compute_function (func): The function/method whose result must be loaded/saved. ignore_arguments_naming (bool, optional): If True, the arguments of compute_function won't be added to the filename of the result file. Defaults to False. **compute_function_args: Arguments of compute_function. Returns: The result of compute_function. Type may vary depending on compute_function. \"\"\" # Define database path db_path = self . path_db # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Complete filename with function arguments if not ignore_arguments_naming : for key , value in compute_function_args . items (): complete_file_name += \"_\" + str ( value ) # Load the shelve db = shelve . open ( db_path ) # Check if the object is in the folder already and return it if complete_file_name in db and not force_update : logging . info ( \"Returning \" + complete_file_name + \" from shelve file.\" + logmem ()) object = db [ complete_file_name ] else : logging . info ( complete_file_name + \" could not be found or force_update is True. \" + \"Computing the object and shelving it now.\" ) # Close shelve to prevent nesting issues with compute function db . close () # Execute compute_function object = compute_function ( ** compute_function_args ) # Reopen shelve db = shelve . open ( db_path ) # Save the result in a pickle file db [ complete_file_name ] = object logging . info ( complete_file_name + \" being returned now from computation.\" ) # Close shelve for good this time db . close () return object","title":"storage"},{"location":"modules/storage/#modules.storage.Storage","text":"A class used to handle the loading/dumping of the data used in the app (memmaps excluded), e.g. figures or masks, are defined. The storage relies on a shelve database. Attributes: Name Type Description path_db str Path of the shelve database. Methods init (path_db=\"data/whole_dataset/\"): Initializes the class Storage. dump_shelved_object(data_folder, file_name, object): Dumps an object in a shelve database. load_shelved_object(data_folder, file_name): Loads an object from a shelve database. check_shelved_object(data_folder, file_name): Checks if an object is in a shelve database. return_shelved_object(data_folder, file_name, force_update, compute_function, ignore_arguments_naming=False, **compute_function_args): Returns an object from a shelve database. If the object is not in the database, it is computed and dumped in the database. empty_shelve(): Erases all entries in the shelve database. list_shelve_objects_size(): Lists the size of all objects in the shelve database. Source code in modules/storage.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 class Storage : \"\"\"A class used to handle the loading/dumping of the data used in the app (memmaps excluded), e.g. figures or masks, are defined. The storage relies on a shelve database. Attributes: path_db (str): Path of the shelve database. Methods: __init__(path_db=\"data/whole_dataset/\"): Initializes the class Storage. dump_shelved_object(data_folder, file_name, object): Dumps an object in a shelve database. load_shelved_object(data_folder, file_name): Loads an object from a shelve database. check_shelved_object(data_folder, file_name): Checks if an object is in a shelve database. return_shelved_object(data_folder, file_name, force_update, compute_function, ignore_arguments_naming=False, **compute_function_args): Returns an object from a shelve database. If the object is not in the database, it is computed and dumped in the database. empty_shelve(): Erases all entries in the shelve database. list_shelve_objects_size(): Lists the size of all objects in the shelve database. \"\"\" # ============================================================================================== # --- Constructor # ============================================================================================== def __init__ ( self , path_db = \"data/whole_dataset/\" ): \"\"\"Initialize the class Storage. Args: path_db (str): Path of the shelve database. \"\"\" # Create database folder if not existing self . path_db = path_db if not os . path . exists ( self . path_db ): os . makedirs ( self . path_db ) # self.list_shelve_objects_size() def dump_shelved_object ( self , data_folder , file_name , object ): \"\"\"This method dumps an object in a shelve database. Args: data_folder (str): The path of the folder in which the object must be saved. file_name (str): The name of the file to save/load. object (object): The object to save. \"\"\" # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Dump in db with shelve . open ( self . path_db ) as db : db [ complete_file_name ] = object def load_shelved_object ( self , data_folder , file_name ): \"\"\"This method loads an object from a shelve database. Args: data_folder (str): The path of the folder in which the object must be saved. file_name (str): The name of the file to save/load. \"\"\" # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Load from in db with shelve . open ( self . path_db ) as db : return db [ complete_file_name ] def check_shelved_object ( self , data_folder , file_name ): \"\"\"This method checks if an object is in a shelve database. Args: data_folder (str): The path of the folder in which the object must be saved. file_name (str): The name of the file to save/load. \"\"\" # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Load from in db with shelve . open ( self . path_db ) as db : if complete_file_name in db : return True else : return False def return_shelved_object ( self , data_folder , file_name , force_update , compute_function , ignore_arguments_naming = False , ** compute_function_args ): \"\"\"This method checks if the result of the method or function compute_function has not been computed and saved already. If yes, it returns this result from the corresponding shelve. Else, it executes compute_function, saves the result in a shelve file, and returns the result. Args: data_folder (str): The path of the folder in which the result of compute_function must be saved. file_name (str): The name of the object to save/load. Arguments will potentially be contatenated to file_name depending on the value of ignore_arguments_naming. force_update (bool): If True, compute_function will be re-executed and saved despite the file result already existing. compute_function (func): The function/method whose result must be loaded/saved. ignore_arguments_naming (bool, optional): If True, the arguments of compute_function won't be added to the filename of the result file. Defaults to False. **compute_function_args: Arguments of compute_function. Returns: The result of compute_function. Type may vary depending on compute_function. \"\"\" # Define database path db_path = self . path_db # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Complete filename with function arguments if not ignore_arguments_naming : for key , value in compute_function_args . items (): complete_file_name += \"_\" + str ( value ) # Load the shelve db = shelve . open ( db_path ) # Check if the object is in the folder already and return it if complete_file_name in db and not force_update : logging . info ( \"Returning \" + complete_file_name + \" from shelve file.\" + logmem ()) object = db [ complete_file_name ] else : logging . info ( complete_file_name + \" could not be found or force_update is True. \" + \"Computing the object and shelving it now.\" ) # Close shelve to prevent nesting issues with compute function db . close () # Execute compute_function object = compute_function ( ** compute_function_args ) # Reopen shelve db = shelve . open ( db_path ) # Save the result in a pickle file db [ complete_file_name ] = object logging . info ( complete_file_name + \" being returned now from computation.\" ) # Close shelve for good this time db . close () return object def empty_shelve ( self ): \"\"\"This method erases all entries in the shelve database.\"\"\" # Load from in db with shelve . open ( self . path_db ) as db : # Completely empty database for key in db : del db [ key ] def list_shelve_objects_size ( self ): \"\"\"This method list the size of all objects in the shelve database.\"\"\" # Load from in db with shelve . open ( self . path_db ) as db : tot_size = 0 # List size for key in db : try : size_obj = asizeof . asizeof ( db [ key ]) / 1024 / 1024 tot_size += size_obj logging . info ( key + \": \\t \" + str ( size_obj ) + \", tot_size: \\t \" + str ( tot_size )) except : pass","title":"Storage"},{"location":"modules/storage/#modules.storage.Storage.__init__","text":"Initialize the class Storage. Parameters: Name Type Description Default path_db str Path of the shelve database. 'data/whole_dataset/' Source code in modules/storage.py 46 47 48 49 50 51 52 53 54 55 56 def __init__ ( self , path_db = \"data/whole_dataset/\" ): \"\"\"Initialize the class Storage. Args: path_db (str): Path of the shelve database. \"\"\" # Create database folder if not existing self . path_db = path_db if not os . path . exists ( self . path_db ): os . makedirs ( self . path_db )","title":"__init__()"},{"location":"modules/storage/#modules.storage.Storage.check_shelved_object","text":"This method checks if an object is in a shelve database. Parameters: Name Type Description Default data_folder str The path of the folder in which the object must be saved. required file_name str The name of the file to save/load. required Source code in modules/storage.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def check_shelved_object ( self , data_folder , file_name ): \"\"\"This method checks if an object is in a shelve database. Args: data_folder (str): The path of the folder in which the object must be saved. file_name (str): The name of the file to save/load. \"\"\" # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Load from in db with shelve . open ( self . path_db ) as db : if complete_file_name in db : return True else : return False","title":"check_shelved_object()"},{"location":"modules/storage/#modules.storage.Storage.dump_shelved_object","text":"This method dumps an object in a shelve database. Parameters: Name Type Description Default data_folder str The path of the folder in which the object must be saved. required file_name str The name of the file to save/load. required object object The object to save. required Source code in modules/storage.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def dump_shelved_object ( self , data_folder , file_name , object ): \"\"\"This method dumps an object in a shelve database. Args: data_folder (str): The path of the folder in which the object must be saved. file_name (str): The name of the file to save/load. object (object): The object to save. \"\"\" # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Dump in db with shelve . open ( self . path_db ) as db : db [ complete_file_name ] = object","title":"dump_shelved_object()"},{"location":"modules/storage/#modules.storage.Storage.empty_shelve","text":"This method erases all entries in the shelve database. Source code in modules/storage.py 180 181 182 183 184 185 186 187 def empty_shelve ( self ): \"\"\"This method erases all entries in the shelve database.\"\"\" # Load from in db with shelve . open ( self . path_db ) as db : # Completely empty database for key in db : del db [ key ]","title":"empty_shelve()"},{"location":"modules/storage/#modules.storage.Storage.list_shelve_objects_size","text":"This method list the size of all objects in the shelve database. Source code in modules/storage.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 def list_shelve_objects_size ( self ): \"\"\"This method list the size of all objects in the shelve database.\"\"\" # Load from in db with shelve . open ( self . path_db ) as db : tot_size = 0 # List size for key in db : try : size_obj = asizeof . asizeof ( db [ key ]) / 1024 / 1024 tot_size += size_obj logging . info ( key + \": \\t \" + str ( size_obj ) + \", tot_size: \\t \" + str ( tot_size )) except : pass","title":"list_shelve_objects_size()"},{"location":"modules/storage/#modules.storage.Storage.load_shelved_object","text":"This method loads an object from a shelve database. Parameters: Name Type Description Default data_folder str The path of the folder in which the object must be saved. required file_name str The name of the file to save/load. required Source code in modules/storage.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def load_shelved_object ( self , data_folder , file_name ): \"\"\"This method loads an object from a shelve database. Args: data_folder (str): The path of the folder in which the object must be saved. file_name (str): The name of the file to save/load. \"\"\" # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Load from in db with shelve . open ( self . path_db ) as db : return db [ complete_file_name ]","title":"load_shelved_object()"},{"location":"modules/storage/#modules.storage.Storage.return_shelved_object","text":"This method checks if the result of the method or function compute_function has not been computed and saved already. If yes, it returns this result from the corresponding shelve. Else, it executes compute_function, saves the result in a shelve file, and returns the result. Parameters: Name Type Description Default data_folder str The path of the folder in which the result of compute_function must be saved. required file_name str The name of the object to save/load. Arguments will potentially be contatenated to file_name depending on the value of ignore_arguments_naming. required force_update bool If True, compute_function will be re-executed and saved despite the file result already existing. required compute_function func The function/method whose result must be loaded/saved. required ignore_arguments_naming bool If True, the arguments of compute_function won't be added to the filename of the result file. Defaults to False. False **compute_function_args Arguments of compute_function. {} Returns: Type Description The result of compute_function. Type may vary depending on compute_function. Source code in modules/storage.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def return_shelved_object ( self , data_folder , file_name , force_update , compute_function , ignore_arguments_naming = False , ** compute_function_args ): \"\"\"This method checks if the result of the method or function compute_function has not been computed and saved already. If yes, it returns this result from the corresponding shelve. Else, it executes compute_function, saves the result in a shelve file, and returns the result. Args: data_folder (str): The path of the folder in which the result of compute_function must be saved. file_name (str): The name of the object to save/load. Arguments will potentially be contatenated to file_name depending on the value of ignore_arguments_naming. force_update (bool): If True, compute_function will be re-executed and saved despite the file result already existing. compute_function (func): The function/method whose result must be loaded/saved. ignore_arguments_naming (bool, optional): If True, the arguments of compute_function won't be added to the filename of the result file. Defaults to False. **compute_function_args: Arguments of compute_function. Returns: The result of compute_function. Type may vary depending on compute_function. \"\"\" # Define database path db_path = self . path_db # Get complete file name complete_file_name = data_folder + \"/\" + file_name # Complete filename with function arguments if not ignore_arguments_naming : for key , value in compute_function_args . items (): complete_file_name += \"_\" + str ( value ) # Load the shelve db = shelve . open ( db_path ) # Check if the object is in the folder already and return it if complete_file_name in db and not force_update : logging . info ( \"Returning \" + complete_file_name + \" from shelve file.\" + logmem ()) object = db [ complete_file_name ] else : logging . info ( complete_file_name + \" could not be found or force_update is True. \" + \"Computing the object and shelving it now.\" ) # Close shelve to prevent nesting issues with compute function db . close () # Execute compute_function object = compute_function ( ** compute_function_args ) # Reopen shelve db = shelve . open ( db_path ) # Save the result in a pickle file db [ complete_file_name ] = object logging . info ( complete_file_name + \" being returned now from computation.\" ) # Close shelve for good this time db . close () return object","title":"return_shelved_object()"},{"location":"modules/tools/atlas/","text":"In this module, functions linking the MALDI data to the CCFv3 (e.g. getting mask or resolution change) are defined. compute_array_images_atlas ( array_coordinates_warped_data , simplified_atlas_annotation , atlas_reference , resolution , zero_out_of_annotation = False ) This function is used to build a list of atlas images corresponding to the slices acquired during the MALDI acquisition. Parameters: Name Type Description Default array_coordinates_warped_data np . ndarray Array of coordinates of the warped, high-resolution slices. required simplified_atlas_annotation np . ndarray Simplified 3D array of annotations. required atlas_reference np . ndarray 3D array of the atlas data. required resolution int Resolution of the atlas. required zero_out_of_annotation bool If True, the produced set of images is such that all the data that doesn't belong to a given structure is zeroed-out. Defaults to False. False Returns: Type Description np . ndarray , np . ndarray The first array is basically a list of atlas images corresponding to the slices acquired during the MALDI acquisition. The second array is the corresponding set of annotations. Source code in modules/tools/atlas.py 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 @njit def compute_array_images_atlas ( array_coordinates_warped_data , simplified_atlas_annotation , atlas_reference , resolution , zero_out_of_annotation = False , ): \"\"\"This function is used to build a list of atlas images corresponding to the slices acquired during the MALDI acquisition. Args: array_coordinates_warped_data (np.ndarray): Array of coordinates of the warped, high-resolution slices. simplified_atlas_annotation (np.ndarray): Simplified 3D array of annotations. atlas_reference (np.ndarray): 3D array of the atlas data. resolution (int): Resolution of the atlas. zero_out_of_annotation (bool, optional): If True, the produced set of images is such that all the data that doesn't belong to a given structure is zeroed-out. Defaults to False. Returns: (np.ndarray, np.ndarray): The first array is basically a list of atlas images corresponding to the slices acquired during the MALDI acquisition. The second array is the corresponding set of annotations. \"\"\" array_images = np . zeros ( array_coordinates_warped_data . shape [: - 1 ], dtype = np . uint8 ) array_projected_simplified_id = np . full ( array_images . shape , simplified_atlas_annotation [ 0 , 0 , 0 ], dtype = np . int32 ) array_coor_rescaled = np . empty_like ( array_coordinates_warped_data , dtype = np . int16 ) # Inplace rounding for numba np . round_ ( array_coordinates_warped_data * 1000 / resolution , 0 , array_coor_rescaled ) for x in range ( array_images . shape [ 0 ]): for y in range ( array_images . shape [ 1 ]): for z in range ( array_images . shape [ 2 ]): if ( min ( array_coor_rescaled [ x , y , z ]) >= 0 and array_coor_rescaled [ x , y , z ][ 0 ] < atlas_reference . shape [ 0 ] and array_coor_rescaled [ x , y , z ][ 1 ] < atlas_reference . shape [ 1 ] and array_coor_rescaled [ x , y , z ][ 2 ] < atlas_reference . shape [ 2 ] ): l , m , n = array_coor_rescaled [ x , y , z ] array_projected_simplified_id [ x , y , z ] = simplified_atlas_annotation [ l , m , n ] if array_projected_simplified_id [ x , y , z ] == 0 and zero_out_of_annotation : continue else : array_images [ x , y , z ] = atlas_reference [ l , m , n ] else : array_images [ x , y , z ] = 0 # Correct for bug on inferior right margin array_images [:, :, : 10 ] = 0 return array_images , array_projected_simplified_id compute_simplified_atlas_annotation ( atlas_annotation ) This function is used to map the array of annotations (which can initially be very large integers) to an array of annotations of similar size, but with annotations ranging from 0 to the number of structures in the atlas. Parameters: Name Type Description Default atlas_annotation np . ndarray Initial 3D array of annotations. required Returns: Type Description np . ndarray Simplified 3D array of annotations. Source code in modules/tools/atlas.py 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 @njit def compute_simplified_atlas_annotation ( atlas_annotation ): \"\"\"This function is used to map the array of annotations (which can initially be very large integers) to an array of annotations of similar size, but with annotations ranging from 0 to the number of structures in the atlas. Args: atlas_annotation (np.ndarray): Initial 3D array of annotations. Returns: (np.ndarray): Simplified 3D array of annotations. \"\"\" # Compute an array which map labels ids to increasing integers unique_id_dic = { ni : indi for indi , ni in enumerate ( set ( atlas_annotation . flatten ()))} simplified_atlas_annotation = np . zeros ( atlas_annotation . shape , dtype = np . int32 ) for x in range ( atlas_annotation . shape [ 0 ]): for y in range ( atlas_annotation . shape [ 1 ]): for z in range ( atlas_annotation . shape [ 2 ]): simplified_atlas_annotation [ x , y , z ] = unique_id_dic [ atlas_annotation [ x , y , z ]] return simplified_atlas_annotation fill_array_projection ( slice_index , array_projection , array_projection_filling , array_projection_correspondence , original_coor , atlas_resolution , a , u , v , original_slice , array_coordinates_high_res_slice , array_annotation , nearest_neighbour_correction = False , atlas_correction = False , sample_data = False ) This function computes the correspondance between our initial, low-resolution, data from the MALDI imaging, to the high-resolution space in which the registered data lives. To that end, it computes and returns two arrays (which are passed as imputs, although empty, since numba won't accept to create them in the scope of the function) : array_projection, which is the high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, array_projection_correspondence. Parameters: Name Type Description Default slice_index int Index of the slice to parametrize in space. required array_projection np . ndarray An empty, high-resolution, three-dimensional array which, at the end of the function, should contain the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. Note that, if no correction is applied, since the original acquisition has a way lower resolution than array_projection, the latter may be quite sparse. required array_projection_filling np . ndarray An empty, high-resolution, three-dimensional array which is used to keep track of the state of array_projection; that is, which elements have already been filled. required array_projection_correspondence np . ndarray An empty three-dimensional array which, at the end of the function, associates, to each tripled of coordinates of the original acquisition (slice_index, row_index, column_index), a tuple of coordinates corresponding to the row_index and column_index of the warped higher-resolution image. required original_coor np . ndarray A two-dimensional array which maps our initial (low-resolution) data to the atlas coordinate system. That is, for each 2-D coordinate (x,y), it associates a 3D coordinate (i,j,k) in the ccfv3. required atlas_resolution int The resolution used for the atlas, in um. required a tuple(float The first of the three vectors used to parametrize the plane is space. required u tuple(float The second of the three vectors used to parametrize the plane in space. required v tuple(float The third of the three vectors used to parametrize the plane in space. required original_slice np . ndarray A two-dimensional array representing an image of the MALDI acquisition. required array_coordinates_high_res_slice np . ndarray A two-dimensional array which maps the high-dimensional warped data to the atlas coordinate system. That is, for each 2-D coordinate (x,y), it associates a 3D coordinate (i,j,k) in the ccfv3. required array_annotation np . ndarray A three-dimensional array containing the atlas annotation, used to filter out the regions of our data which are outside the annotated brain, if atlas_correction is True. required nearest_neighbour_correction bool If True, applies a neared-neighbour correction, that is, for every empty pixel far from the image boundaries, it looks for neighbours that are filled in a close window, and used the most represented value to fill the empty pixel. Defaults to False. False atlas_correction bool If True, filters out pixels that are not annotated in the ccfv3. Defaults to False. False sample_data bool If True, the function will use the sampled version of the slice data for the computations. Defaults to False. False Returns: Type Description np . ndarray , np . ndarray The first array is a high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, which acts as a mapping table. Source code in modules/tools/atlas.py 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 @njit def fill_array_projection ( slice_index , array_projection , array_projection_filling , array_projection_correspondence , original_coor , atlas_resolution , a , u , v , original_slice , array_coordinates_high_res_slice , array_annotation , nearest_neighbour_correction = False , atlas_correction = False , sample_data = False , ): \"\"\"This function computes the correspondance between our initial, low-resolution, data from the MALDI imaging, to the high-resolution space in which the registered data lives. To that end, it computes and returns two arrays (which are passed as imputs, although empty, since numba won't accept to create them in the scope of the function) : array_projection, which is the high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, array_projection_correspondence. Args: slice_index (int): Index of the slice to parametrize in space. array_projection (np.ndarray): An empty, high-resolution, three-dimensional array which, at the end of the function, should contain the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. Note that, if no correction is applied, since the original acquisition has a way lower resolution than array_projection, the latter may be quite sparse. array_projection_filling (np.ndarray): An empty, high-resolution, three-dimensional array which is used to keep track of the state of array_projection; that is, which elements have already been filled. array_projection_correspondence (np.ndarray): An empty three-dimensional array which, at the end of the function, associates, to each tripled of coordinates of the original acquisition (slice_index, row_index, column_index), a tuple of coordinates corresponding to the row_index and column_index of the warped higher-resolution image. original_coor (np.ndarray): A two-dimensional array which maps our initial (low-resolution) data to the atlas coordinate system. That is, for each 2-D coordinate (x,y), it associates a 3D coordinate (i,j,k) in the ccfv3. atlas_resolution (int): The resolution used for the atlas, in um. a (tuple(float)): The first of the three vectors used to parametrize the plane is space. u (tuple(float)): The second of the three vectors used to parametrize the plane in space. v (tuple(float)): The third of the three vectors used to parametrize the plane in space. original_slice (np.ndarray): A two-dimensional array representing an image of the MALDI acquisition. array_coordinates_high_res_slice (np.ndarray): A two-dimensional array which maps the high-dimensional warped data to the atlas coordinate system. That is, for each 2-D coordinate (x,y), it associates a 3D coordinate (i,j,k) in the ccfv3. array_annotation (np.ndarray): A three-dimensional array containing the atlas annotation, used to filter out the regions of our data which are outside the annotated brain, if atlas_correction is True. nearest_neighbour_correction (bool, optional): If True, applies a neared-neighbour correction, that is, for every empty pixel far from the image boundaries, it looks for neighbours that are filled in a close window, and used the most represented value to fill the empty pixel. Defaults to False. atlas_correction (bool, optional): If True, filters out pixels that are not annotated in the ccfv3. Defaults to False. sample_data (bool, optional): If True, the function will use the sampled version of the slice data for the computations. Defaults to False. Returns: (np.ndarray, np.ndarray): The first array is a high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, which acts as a mapping table. \"\"\" # Start by inverting a simple system of linear equations for each coordinate in the initial data # to find the corresponding coordinate in the high-resolution space (this is not a trivial # problem as slices can be tilted) A = np . empty (( 2 , 2 ), dtype = np . float64 ) A [ 0 ] = [ u [ 1 ], v [ 1 ]] A [ 1 ] = [ u [ 2 ], v [ 2 ]] A += np . random . normal ( 0 , 0.000000001 , ( 2 , 2 ) ) # add small noise to solve singularity issues when inversion for i_original_slice in range ( original_coor . shape [ 0 ]): for j_original_slice in range ( original_coor . shape [ 1 ]): x_atlas , y_atlas , z_atlas = original_coor [ i_original_slice , j_original_slice ] # Solve the system of linear equations b = np . array ([ y_atlas - a [ 1 ], z_atlas - a [ 2 ]], dtype = np . float64 ) i , j = np . linalg . solve ( A , b ) # Ugly but numba won't accept any other way i = int ( round ( i )) j = int ( round ( j )) # If the high-resolution coordinate found be inversion exists, fill array_projection if i < array_projection . shape [ 1 ] and j < array_projection . shape [ 2 ] and i > 0 and j > 0 : try : array_projection [ slice_index , i , j ] = original_slice [ i_original_slice , j_original_slice ] array_projection_filling [ slice_index , i , j ] = 1 array_projection_correspondence [ slice_index , i , j ] = [ i_original_slice , j_original_slice , ] except : print ( i , j , array_projection . shape , i_original_slice , j_original_slice , original_slice . shape , ) raise ValueError # Apply potential corrections if nearest_neighbour_correction or atlas_correction : for i in range ( array_projection . shape [ 1 ]): for j in range ( array_projection . shape [ 2 ]): # Look for the 3D atlas coordinate of out data x_atlas , y_atlas , z_atlas = ( array_coordinates_high_res_slice [ i , j ] * 1000 / atlas_resolution ) # Ugly again, but numba doesn't support np.round x_atlas = int ( round ( x_atlas )) y_atlas = int ( round ( y_atlas )) z_atlas = int ( round ( z_atlas )) # If the current coordinate is contained in the ccfv3, proceed if ( x_atlas < array_annotation . shape [ 0 ] and x_atlas >= 0 and y_atlas < array_annotation . shape [ 1 ] and y_atlas >= 0 and z_atlas < array_annotation . shape [ 2 ] and z_atlas >= 0 ): # If the current annotation in the ccfv3 maps to an existing structure if array_annotation [ x_atlas , y_atlas , z_atlas ] != 0 : # Nearest neighbour correction to fill most of the empty pixels in the # high-resolution image if nearest_neighbour_correction : # If the pixel hasn't already been dealt with before (because of the # way the projection is done and warping, this may happen) if array_projection_filling [ slice_index , i , j ] == 0 : # Only fill missing areas if far from the sides if ( i > 20 and i < array_projection . shape [ 1 ] - 20 and j > 20 and j < array_projection . shape [ 2 ] - 20 ): # Look for neighbours that are filled in a close window radius = 3 array_window = np . empty ( ( 2 * radius + 1 , 2 * radius + 1 ), dtype = np . float32 ) # Temporary fill the window not to modify the value as they are # browsed and end up having an incremental nearest neighbor # correction for x in range ( - radius , radius + 1 ): for y in range ( - radius , radius + 1 ): if ( i + x > 0 and i + x < array_projection . shape [ 1 ] and j + x > 0 and j + y < array_projection . shape [ 2 ] ): if ( array_projection_filling [ slice_index , i + x , j + y ] == 0 ): array_window [ x + radius , y + radius ] = np . nan else : array_window [ x + radius , y + radius ] = array_projection [ slice_index , i + x , j + y ] avg = np . nanmean ( array_window ) if np . isnan ( avg ): continue clean_window = np . abs ( array_window - avg ) # Numba doesn't support nanargmin, so I have to implement it # myself... mini = 10000 selected_pixel_x = 0 selected_pixel_y = 0 for x in range ( 2 * radius + 1 ): for y in range ( 2 * radius + 1 ): if clean_window [ x , y ] < mini : mini = clean_window [ x , y ] selected_pixel_x = x selected_pixel_y = y # Fill the pixel in array projection with the most represented # value in the window array_projection [ slice_index , i , j ] = array_window [ selected_pixel_x , selected_pixel_y ] array_projection_correspondence [ slice_index , i , j ] = array_projection_correspondence [ slice_index , i + selected_pixel_x - radius , j + selected_pixel_y - radius , ] # Wipe the pixels values that are not annotated in the atlas elif atlas_correction : array_projection [ slice_index , i , j ] = 0 array_projection_filling [ slice_index , i , j ] = 1 array_projection_correspondence [ slice_index , i , j ] = [ - 1 , - 1 ] # Wipe the pixels values that are not in the ccfv3 elif atlas_correction : array_projection [ slice_index , i , j ] = 0 array_projection_filling [ slice_index , i , j ] = 1 array_projection_correspondence [ slice_index , i , j ] = [ - 1 , - 1 ] return array_projection , array_projection_correspondence get_array_rows_from_atlas_mask ( mask , mask_remapped , array_projection_correspondence_sliced ) This function is similar to spectra.sample_rows_from_path(), in that it returns the lower and upper indexes of the rows belonging to the current mask (instead of path), as well as the corresponding column boundaries for each row. Parameters: Name Type Description Default mask np . ndarray A two-dimensional array representing the (high-resolution, warped) mask projected on the requested slice. required mask_remapped np . ndarray An empty two-dimensional array of the shape of the original acquisition, passed a parameter as numba won't allow for np.uint8 creation inside of the scope of the function. It is initially filled with the high-resolution warped mask values, whose coordinates have been mapped back to the original data. required array_projection_correspondence_sliced np . ndarray A two-dimensional array which associates, to each couple of coordinates of the original acquisition (row_index, column_index), a tuple of coordinates corresponding to the row_index and column_index of the warped higher-resolution image. required Returns: Type Description np . ndarray , np . ndarray The first array contains the lower and upper indexes of the rows belonging to the mask. The second array contains, for each row, the corresponding column boundaries of the mask (there can be more than 2 for non-convex shapes). Source code in modules/tools/atlas.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 @njit def get_array_rows_from_atlas_mask ( mask , mask_remapped , array_projection_correspondence_sliced ): \"\"\"This function is similar to spectra.sample_rows_from_path(), in that it returns the lower and upper indexes of the rows belonging to the current mask (instead of path), as well as the corresponding column boundaries for each row. Args: mask (np.ndarray): A two-dimensional array representing the (high-resolution, warped) mask projected on the requested slice. mask_remapped (np.ndarray): An empty two-dimensional array of the shape of the original acquisition, passed a parameter as numba won't allow for np.uint8 creation inside of the scope of the function. It is initially filled with the high-resolution warped mask values, whose coordinates have been mapped back to the original data. array_projection_correspondence_sliced (np.ndarray): A two-dimensional array which associates, to each couple of coordinates of the original acquisition (row_index, column_index), a tuple of coordinates corresponding to the row_index and column_index of the warped higher-resolution image. Returns: (np.ndarray, np.ndarray): The first array contains the lower and upper indexes of the rows belonging to the mask. The second array contains, for each row, the corresponding column boundaries of the mask (there can be more than 2 for non-convex shapes). \"\"\" # Map back the mask coordinates to original data for x in range ( mask . shape [ 0 ]): for y in range ( mask . shape [ 1 ]): x_original , y_original = array_projection_correspondence_sliced [ x , y ] if ( x_original >= 0 and x_original < mask_remapped . shape [ 0 ] and y_original >= 0 and y_original < mask_remapped . shape [ 0 ] ): mask_remapped [ x_original , y_original ] = mask [ x , y ] # Then compute the column boundaries for each row ll_rows = [] for x in range ( mask_remapped . shape [ 0 ]): first = False ymin = - 1 ymax = - 1 l_rows = [ x ] for y in range ( mask_remapped . shape [ 1 ]): if mask_remapped [ x , y ] != 0 and not first : ymin = y first = True elif mask_remapped [ x , y ] == 0 and first : # Correct for bug due to mask assignment with different resolution if np . max ( mask_remapped [ x , y : y + 5 ]) != 0 : continue else : ymax = y first = False l_rows . extend ([ ymin , ymax - 1 ]) # If two boundaries have been obtained, add them to the list if len ( l_rows ) > 1 : ll_rows . append ( l_rows ) # Get the indices of the first and last rows if len ( ll_rows ) > 0 : xmin = ll_rows [ 0 ][ 0 ] xmax = ll_rows [ - 1 ][ 0 ] max_len = max ([ len ( l_rows ) - 1 for l_rows in ll_rows ]) else : xmax = 0 xmin = 0 max_len = 0 # Convert list of np.array to np array padded with zeros (for numba compatibility) array_index_bound_column_per_row = np . zeros (( xmax - xmin + 1 , max_len ), dtype = np . int32 ) for i , l_rows in enumerate ( ll_rows ): array_index_bound_column_per_row [ i , : len ( l_rows ) - 1 ] = l_rows [ 1 :] return np . array ([ xmin , xmax ], dtype = np . int32 ), array_index_bound_column_per_row project_atlas_mask ( stack_mask , slice_coordinates_rescaled , shape_atlas ) This function projects a mask array_annotation (obtained from the atlas, sliced from a 3-dimensional object) on our two-dimensional, high-resolution warped data, for a given slice. Parameters: Name Type Description Default stack_mask np . ndarray A three-dimensional array indexed with the ccfv3. It contains a zero if the selected coordinate is outside the mask array_annotation, and 1 otherwise. required slice_coordinates_rescaled np . ndarray A two-dimensional array mapping our slice coordinate (rescaled and discretized) to the ccfv3. required shape_atlas tuple(int A tuple of three integers representing the shape of the ccfv3-indexed atlas. required Returns: Type Description np . ndarray A two-dimensional array representing the projected mask on the requested slice. Source code in modules/tools/atlas.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 @njit def project_atlas_mask ( stack_mask , slice_coordinates_rescaled , shape_atlas ): \"\"\"This function projects a mask array_annotation (obtained from the atlas, sliced from a 3-dimensional object) on our two-dimensional, high-resolution warped data, for a given slice. Args: stack_mask (np.ndarray): A three-dimensional array indexed with the ccfv3. It contains a zero if the selected coordinate is outside the mask array_annotation, and 1 otherwise. slice_coordinates_rescaled (np.ndarray): A two-dimensional array mapping our slice coordinate (rescaled and discretized) to the ccfv3. shape_atlas (tuple(int)): A tuple of three integers representing the shape of the ccfv3-indexed atlas. Returns: (np.ndarray): A two-dimensional array representing the projected mask on the requested slice. \"\"\" # Define empty array for the projected mask, with the same dimension as the current slice # ! Delete this comment if everything is working, else switch back to int16 or int32 projected_mask = np . full ( slice_coordinates_rescaled . shape [: - 1 ], stack_mask [ 0 , 0 , 0 ], dtype = np . uint8 ) for x in range ( slice_coordinates_rescaled . shape [ 0 ]): for y in range ( slice_coordinates_rescaled . shape [ 1 ]): current_coor_rescaled = slice_coordinates_rescaled [ x , y ] # If the current slice coordinate actually exists in the atlas, maps it to the # corresponding mask value if ( min ( current_coor_rescaled ) >= 0 and current_coor_rescaled [ 0 ] < shape_atlas [ 0 ] and current_coor_rescaled [ 1 ] < shape_atlas [ 1 ] and current_coor_rescaled [ 2 ] < shape_atlas [ 2 ] ): projected_mask [ x , y ] = stack_mask [ current_coor_rescaled [ 0 ], current_coor_rescaled [ 1 ], current_coor_rescaled [ 2 ] ] return projected_mask project_image ( slice_index , original_image , array_projection_correspondence ) This function is used to project the original maldi acquisition (low-resolution, possibly tilted, and) into a warped and higher resolution, indexed with the Allen Mouse Brain Common Coordinate Framework (ccfv3). Parameters: Name Type Description Default slice_index int Index of the slice to project. required original_image np . ndarray A two-dimensional array representing the MADI data of the current slice (e.g. for a given lipid selection). required array_projection_correspondence np . ndarray A three-dimensional array which associates, to each triplet of coordinates of the original acquisition (slice_index, row_index, column_index), a tuple of coordinates corresponding to the row_index and column_index of the warped higher-resolution image. required Returns: Type Description np . ndarray A warped, high-resolution image, corresponding to the clean, registered version, of our acquisition. Source code in modules/tools/atlas.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 @njit def project_image ( slice_index , original_image , array_projection_correspondence ): \"\"\"This function is used to project the original maldi acquisition (low-resolution, possibly tilted, and) into a warped and higher resolution, indexed with the Allen Mouse Brain Common Coordinate Framework (ccfv3). Args: slice_index (int): Index of the slice to project. original_image (np.ndarray): A two-dimensional array representing the MADI data of the current slice (e.g. for a given lipid selection). array_projection_correspondence (np.ndarray): A three-dimensional array which associates, to each triplet of coordinates of the original acquisition (slice_index, row_index, column_index), a tuple of coordinates corresponding to the row_index and column_index of the warped higher-resolution image. Returns: (np.ndarray): A warped, high-resolution image, corresponding to the clean, registered version, of our acquisition. \"\"\" # Correct index as slice names start at 1 slice_index -= 1 # Define empty array for the high-resolution image new_image = np . zeros ( array_projection_correspondence . shape [ 1 : - 1 ], dtype = original_image . dtype ) # Exclude the borders of the image to gain some time for i in range ( 50 , array_projection_correspondence [ slice_index ] . shape [ 0 ] - 50 ): for j in range ( 50 , array_projection_correspondence [ slice_index ] . shape [ 1 ] - 50 ): # Maps the original coordinates to the new one, with coordinate -1 corresponding # to unassigned if array_projection_correspondence [ slice_index , i , j , 0 ] != - 1 : x , y = array_projection_correspondence [ slice_index , i , j ] new_image [ i , j ] = original_image [ x , y ] return new_image slice_to_atlas_transform ( a , u , v , lambd , mu ) This function returns a 3D coordinate (in the ccfv3) from a 2D slice coordinate, using the parameters obtained from the inversion made in solve_plane_equation(). Parameters: Name Type Description Default a tuple(float The first of the three vectors used to parametrize the plane is space. required u tuple(float The second of the three vectors used to parametrize the plane in space. required v tuple(float The third of the three vectors used to parametrize the plane in space. required lambd int The first coordinate of our slice (height of the required point). required mu int The second coordinate of our slice (width of the required point). required Returns: Type Description int , int , int A 3D coordinate in the ccfv3, mapping our flat (2D) data to the atlas coordinate system. Source code in modules/tools/atlas.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 @njit def slice_to_atlas_transform ( a , u , v , lambd , mu ): \"\"\"This function returns a 3D coordinate (in the ccfv3) from a 2D slice coordinate, using the parameters obtained from the inversion made in solve_plane_equation(). Args: a (tuple(float)): The first of the three vectors used to parametrize the plane is space. u (tuple(float)): The second of the three vectors used to parametrize the plane in space. v (tuple(float)): The third of the three vectors used to parametrize the plane in space. lambd (int): The first coordinate of our slice (height of the required point). mu (int): The second coordinate of our slice (width of the required point). Returns: (int, int, int): A 3D coordinate in the ccfv3, mapping our flat (2D) data to the atlas coordinate system. \"\"\" # Equation of a plan in space x_atlas = a [ 0 ] + lambd * u [ 0 ] + mu * v [ 0 ] y_atlas = a [ 1 ] + lambd * u [ 1 ] + mu * v [ 1 ] z_atlas = a [ 2 ] + lambd * u [ 2 ] + mu * v [ 2 ] return x_atlas , y_atlas , z_atlas solve_plane_equation ( array_coordinates_high_res_slice , point_1 = ( 50 , 51 ), point_2 = ( 200 , 200 ), point_3 = ( 100 , 101 )) This function defines and solves a system of linear equations for three points of the plane (which corresponds to a slice in the ccfv3). The vectors returned by the function enable to index the 2D slice in the 3D atlas space (ccfv3), cf. slice_to_atlas_transform(). Note that the three points can not be taken at the extremities of the slice, as the registration made with ABBA is buggued and the origin doesn't linearly maps to the 3D plane. Parameters: Name Type Description Default array_coordinates_high_res_slice np . ndarray A two-dimensional array which maps the high-dimensional warped data to the atlas coordinate system. That is, for each 2-D coordinate (x,y), it associates a 3D coordinate (i,j,k) in the ccfv3. required point_1 tuple Couple of coordinates corresponding to the first point indexed on the 3D plane. Defaults to (50, 51). (50, 51) point_2 tuple Couple of coordinates corresponding to the first point indexed on the 3D plane. Defaults to (400, 200). (200, 200) point_3 tuple Couple of coordinates corresponding to the first point indexed on the 3D plane. Defaults to (100, 101). (100, 101) Returns: Type Description tuple ( float ), tuple ( float ), tuple ( float ) Three vectors allowing to parametrize the coordinate of our slice in the ccfv3. Source code in modules/tools/atlas.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 @njit def solve_plane_equation ( array_coordinates_high_res_slice , point_1 = ( 50 , 51 ), point_2 = ( 200 , 200 ), point_3 = ( 100 , 101 ), ): \"\"\"This function defines and solves a system of linear equations for three points of the plane (which corresponds to a slice in the ccfv3). The vectors returned by the function enable to index the 2D slice in the 3D atlas space (ccfv3), cf. slice_to_atlas_transform(). Note that the three points can not be taken at the extremities of the slice, as the registration made with ABBA is buggued and the origin doesn't linearly maps to the 3D plane. Args: array_coordinates_high_res_slice (np.ndarray): A two-dimensional array which maps the high-dimensional warped data to the atlas coordinate system. That is, for each 2-D coordinate (x,y), it associates a 3D coordinate (i,j,k) in the ccfv3. point_1 (tuple, optional): Couple of coordinates corresponding to the first point indexed on the 3D plane. Defaults to (50, 51). point_2 (tuple, optional): Couple of coordinates corresponding to the first point indexed on the 3D plane. Defaults to (400, 200). point_3 (tuple, optional): Couple of coordinates corresponding to the first point indexed on the 3D plane. Defaults to (100, 101). Returns: (tuple(float), tuple(float), tuple(float)): Three vectors allowing to parametrize the coordinate of our slice in the ccfv3. \"\"\" # Define empty array for the linear system of equations A = np . zeros (( 9 , 9 ), dtype = np . float32 ) b = np . zeros (( 9 ,), dtype = np . float32 ) # Fill the matrices, such that Ax=b, where A represents the projection from 2D coordinates (x) # to the ccfv3 (b) A [ 0 ] = [ point_1 [ 0 ], 0 , 0 , point_1 [ 1 ], 0 , 0 , 1 , 0 , 0 ] A [ 1 ] = [ 0 , point_1 [ 0 ], 0 , 0 , point_1 [ 1 ], 0 , 0 , 1 , 0 ] A [ 2 ] = [ 0 , 0 , point_1 [ 0 ], 0 , 0 , point_1 [ 1 ], 0 , 0 , 1 ] A [ 3 ] = [ point_2 [ 0 ], 0 , 0 , point_2 [ 1 ], 0 , 0 , 1 , 0 , 0 ] A [ 4 ] = [ 0 , point_2 [ 0 ], 0 , 0 , point_2 [ 1 ], 0 , 0 , 1 , 0 ] A [ 5 ] = [ 0 , 0 , point_2 [ 0 ], 0 , 0 , point_2 [ 1 ], 0 , 0 , 1 ] A [ 6 ] = [ point_3 [ 0 ], 0 , 0 , point_3 [ 1 ], 0 , 0 , 1 , 0 , 0 ] A [ 7 ] = [ 0 , point_3 [ 0 ], 0 , 0 , point_3 [ 1 ], 0 , 0 , 1 , 0 ] A [ 8 ] = [ 0 , 0 , point_3 [ 0 ], 0 , 0 , point_3 [ 1 ], 0 , 0 , 1 ] b [ 0 ] = array_coordinates_high_res_slice [ point_1 [ 0 ], point_1 [ 1 ], 0 ] b [ 1 ] = array_coordinates_high_res_slice [ point_1 [ 0 ], point_1 [ 1 ], 1 ] b [ 2 ] = array_coordinates_high_res_slice [ point_1 [ 0 ], point_1 [ 1 ], 2 ] b [ 3 ] = array_coordinates_high_res_slice [ point_2 [ 0 ], point_2 [ 1 ], 0 ] b [ 4 ] = array_coordinates_high_res_slice [ point_2 [ 0 ], point_2 [ 1 ], 1 ] b [ 5 ] = array_coordinates_high_res_slice [ point_2 [ 0 ], point_2 [ 1 ], 2 ] b [ 6 ] = array_coordinates_high_res_slice [ point_3 [ 0 ], point_3 [ 1 ], 0 ] b [ 7 ] = array_coordinates_high_res_slice [ point_3 [ 0 ], point_3 [ 1 ], 1 ] b [ 8 ] = array_coordinates_high_res_slice [ point_3 [ 0 ], point_3 [ 1 ], 2 ] # Invert the system of equation u1 , u2 , u3 , v1 , v2 , v3 , a1 , a2 , a3 = np . linalg . solve ( A , b ) u_atlas = ( u1 , u2 , u3 ) v_atlas = ( v1 , v2 , v3 ) a_atlas = ( a1 , a2 , a3 ) return a_atlas , u_atlas , v_atlas","title":"Atlas"},{"location":"modules/tools/atlas/#modules.tools.atlas.compute_array_images_atlas","text":"This function is used to build a list of atlas images corresponding to the slices acquired during the MALDI acquisition. Parameters: Name Type Description Default array_coordinates_warped_data np . ndarray Array of coordinates of the warped, high-resolution slices. required simplified_atlas_annotation np . ndarray Simplified 3D array of annotations. required atlas_reference np . ndarray 3D array of the atlas data. required resolution int Resolution of the atlas. required zero_out_of_annotation bool If True, the produced set of images is such that all the data that doesn't belong to a given structure is zeroed-out. Defaults to False. False Returns: Type Description np . ndarray , np . ndarray The first array is basically a list of atlas images corresponding to the slices acquired during the MALDI acquisition. The second array is the corresponding set of annotations. Source code in modules/tools/atlas.py 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 @njit def compute_array_images_atlas ( array_coordinates_warped_data , simplified_atlas_annotation , atlas_reference , resolution , zero_out_of_annotation = False , ): \"\"\"This function is used to build a list of atlas images corresponding to the slices acquired during the MALDI acquisition. Args: array_coordinates_warped_data (np.ndarray): Array of coordinates of the warped, high-resolution slices. simplified_atlas_annotation (np.ndarray): Simplified 3D array of annotations. atlas_reference (np.ndarray): 3D array of the atlas data. resolution (int): Resolution of the atlas. zero_out_of_annotation (bool, optional): If True, the produced set of images is such that all the data that doesn't belong to a given structure is zeroed-out. Defaults to False. Returns: (np.ndarray, np.ndarray): The first array is basically a list of atlas images corresponding to the slices acquired during the MALDI acquisition. The second array is the corresponding set of annotations. \"\"\" array_images = np . zeros ( array_coordinates_warped_data . shape [: - 1 ], dtype = np . uint8 ) array_projected_simplified_id = np . full ( array_images . shape , simplified_atlas_annotation [ 0 , 0 , 0 ], dtype = np . int32 ) array_coor_rescaled = np . empty_like ( array_coordinates_warped_data , dtype = np . int16 ) # Inplace rounding for numba np . round_ ( array_coordinates_warped_data * 1000 / resolution , 0 , array_coor_rescaled ) for x in range ( array_images . shape [ 0 ]): for y in range ( array_images . shape [ 1 ]): for z in range ( array_images . shape [ 2 ]): if ( min ( array_coor_rescaled [ x , y , z ]) >= 0 and array_coor_rescaled [ x , y , z ][ 0 ] < atlas_reference . shape [ 0 ] and array_coor_rescaled [ x , y , z ][ 1 ] < atlas_reference . shape [ 1 ] and array_coor_rescaled [ x , y , z ][ 2 ] < atlas_reference . shape [ 2 ] ): l , m , n = array_coor_rescaled [ x , y , z ] array_projected_simplified_id [ x , y , z ] = simplified_atlas_annotation [ l , m , n ] if array_projected_simplified_id [ x , y , z ] == 0 and zero_out_of_annotation : continue else : array_images [ x , y , z ] = atlas_reference [ l , m , n ] else : array_images [ x , y , z ] = 0 # Correct for bug on inferior right margin array_images [:, :, : 10 ] = 0 return array_images , array_projected_simplified_id","title":"compute_array_images_atlas()"},{"location":"modules/tools/atlas/#modules.tools.atlas.compute_simplified_atlas_annotation","text":"This function is used to map the array of annotations (which can initially be very large integers) to an array of annotations of similar size, but with annotations ranging from 0 to the number of structures in the atlas. Parameters: Name Type Description Default atlas_annotation np . ndarray Initial 3D array of annotations. required Returns: Type Description np . ndarray Simplified 3D array of annotations. Source code in modules/tools/atlas.py 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 @njit def compute_simplified_atlas_annotation ( atlas_annotation ): \"\"\"This function is used to map the array of annotations (which can initially be very large integers) to an array of annotations of similar size, but with annotations ranging from 0 to the number of structures in the atlas. Args: atlas_annotation (np.ndarray): Initial 3D array of annotations. Returns: (np.ndarray): Simplified 3D array of annotations. \"\"\" # Compute an array which map labels ids to increasing integers unique_id_dic = { ni : indi for indi , ni in enumerate ( set ( atlas_annotation . flatten ()))} simplified_atlas_annotation = np . zeros ( atlas_annotation . shape , dtype = np . int32 ) for x in range ( atlas_annotation . shape [ 0 ]): for y in range ( atlas_annotation . shape [ 1 ]): for z in range ( atlas_annotation . shape [ 2 ]): simplified_atlas_annotation [ x , y , z ] = unique_id_dic [ atlas_annotation [ x , y , z ]] return simplified_atlas_annotation","title":"compute_simplified_atlas_annotation()"},{"location":"modules/tools/atlas/#modules.tools.atlas.fill_array_projection","text":"This function computes the correspondance between our initial, low-resolution, data from the MALDI imaging, to the high-resolution space in which the registered data lives. To that end, it computes and returns two arrays (which are passed as imputs, although empty, since numba won't accept to create them in the scope of the function) : array_projection, which is the high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, array_projection_correspondence. Parameters: Name Type Description Default slice_index int Index of the slice to parametrize in space. required array_projection np . ndarray An empty, high-resolution, three-dimensional array which, at the end of the function, should contain the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. Note that, if no correction is applied, since the original acquisition has a way lower resolution than array_projection, the latter may be quite sparse. required array_projection_filling np . ndarray An empty, high-resolution, three-dimensional array which is used to keep track of the state of array_projection; that is, which elements have already been filled. required array_projection_correspondence np . ndarray An empty three-dimensional array which, at the end of the function, associates, to each tripled of coordinates of the original acquisition (slice_index, row_index, column_index), a tuple of coordinates corresponding to the row_index and column_index of the warped higher-resolution image. required original_coor np . ndarray A two-dimensional array which maps our initial (low-resolution) data to the atlas coordinate system. That is, for each 2-D coordinate (x,y), it associates a 3D coordinate (i,j,k) in the ccfv3. required atlas_resolution int The resolution used for the atlas, in um. required a tuple(float The first of the three vectors used to parametrize the plane is space. required u tuple(float The second of the three vectors used to parametrize the plane in space. required v tuple(float The third of the three vectors used to parametrize the plane in space. required original_slice np . ndarray A two-dimensional array representing an image of the MALDI acquisition. required array_coordinates_high_res_slice np . ndarray A two-dimensional array which maps the high-dimensional warped data to the atlas coordinate system. That is, for each 2-D coordinate (x,y), it associates a 3D coordinate (i,j,k) in the ccfv3. required array_annotation np . ndarray A three-dimensional array containing the atlas annotation, used to filter out the regions of our data which are outside the annotated brain, if atlas_correction is True. required nearest_neighbour_correction bool If True, applies a neared-neighbour correction, that is, for every empty pixel far from the image boundaries, it looks for neighbours that are filled in a close window, and used the most represented value to fill the empty pixel. Defaults to False. False atlas_correction bool If True, filters out pixels that are not annotated in the ccfv3. Defaults to False. False sample_data bool If True, the function will use the sampled version of the slice data for the computations. Defaults to False. False Returns: Type Description np . ndarray , np . ndarray The first array is a high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, which acts as a mapping table. Source code in modules/tools/atlas.py 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 @njit def fill_array_projection ( slice_index , array_projection , array_projection_filling , array_projection_correspondence , original_coor , atlas_resolution , a , u , v , original_slice , array_coordinates_high_res_slice , array_annotation , nearest_neighbour_correction = False , atlas_correction = False , sample_data = False , ): \"\"\"This function computes the correspondance between our initial, low-resolution, data from the MALDI imaging, to the high-resolution space in which the registered data lives. To that end, it computes and returns two arrays (which are passed as imputs, although empty, since numba won't accept to create them in the scope of the function) : array_projection, which is the high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, array_projection_correspondence. Args: slice_index (int): Index of the slice to parametrize in space. array_projection (np.ndarray): An empty, high-resolution, three-dimensional array which, at the end of the function, should contain the data (one integer per coordinate, corresponding to a pixel intensity) from our original acquisition. Note that, if no correction is applied, since the original acquisition has a way lower resolution than array_projection, the latter may be quite sparse. array_projection_filling (np.ndarray): An empty, high-resolution, three-dimensional array which is used to keep track of the state of array_projection; that is, which elements have already been filled. array_projection_correspondence (np.ndarray): An empty three-dimensional array which, at the end of the function, associates, to each tripled of coordinates of the original acquisition (slice_index, row_index, column_index), a tuple of coordinates corresponding to the row_index and column_index of the warped higher-resolution image. original_coor (np.ndarray): A two-dimensional array which maps our initial (low-resolution) data to the atlas coordinate system. That is, for each 2-D coordinate (x,y), it associates a 3D coordinate (i,j,k) in the ccfv3. atlas_resolution (int): The resolution used for the atlas, in um. a (tuple(float)): The first of the three vectors used to parametrize the plane is space. u (tuple(float)): The second of the three vectors used to parametrize the plane in space. v (tuple(float)): The third of the three vectors used to parametrize the plane in space. original_slice (np.ndarray): A two-dimensional array representing an image of the MALDI acquisition. array_coordinates_high_res_slice (np.ndarray): A two-dimensional array which maps the high-dimensional warped data to the atlas coordinate system. That is, for each 2-D coordinate (x,y), it associates a 3D coordinate (i,j,k) in the ccfv3. array_annotation (np.ndarray): A three-dimensional array containing the atlas annotation, used to filter out the regions of our data which are outside the annotated brain, if atlas_correction is True. nearest_neighbour_correction (bool, optional): If True, applies a neared-neighbour correction, that is, for every empty pixel far from the image boundaries, it looks for neighbours that are filled in a close window, and used the most represented value to fill the empty pixel. Defaults to False. atlas_correction (bool, optional): If True, filters out pixels that are not annotated in the ccfv3. Defaults to False. sample_data (bool, optional): If True, the function will use the sampled version of the slice data for the computations. Defaults to False. Returns: (np.ndarray, np.ndarray): The first array is a high-resolution version of our initial data, in which each individual pixel has been mapped according to the second array, which acts as a mapping table. \"\"\" # Start by inverting a simple system of linear equations for each coordinate in the initial data # to find the corresponding coordinate in the high-resolution space (this is not a trivial # problem as slices can be tilted) A = np . empty (( 2 , 2 ), dtype = np . float64 ) A [ 0 ] = [ u [ 1 ], v [ 1 ]] A [ 1 ] = [ u [ 2 ], v [ 2 ]] A += np . random . normal ( 0 , 0.000000001 , ( 2 , 2 ) ) # add small noise to solve singularity issues when inversion for i_original_slice in range ( original_coor . shape [ 0 ]): for j_original_slice in range ( original_coor . shape [ 1 ]): x_atlas , y_atlas , z_atlas = original_coor [ i_original_slice , j_original_slice ] # Solve the system of linear equations b = np . array ([ y_atlas - a [ 1 ], z_atlas - a [ 2 ]], dtype = np . float64 ) i , j = np . linalg . solve ( A , b ) # Ugly but numba won't accept any other way i = int ( round ( i )) j = int ( round ( j )) # If the high-resolution coordinate found be inversion exists, fill array_projection if i < array_projection . shape [ 1 ] and j < array_projection . shape [ 2 ] and i > 0 and j > 0 : try : array_projection [ slice_index , i , j ] = original_slice [ i_original_slice , j_original_slice ] array_projection_filling [ slice_index , i , j ] = 1 array_projection_correspondence [ slice_index , i , j ] = [ i_original_slice , j_original_slice , ] except : print ( i , j , array_projection . shape , i_original_slice , j_original_slice , original_slice . shape , ) raise ValueError # Apply potential corrections if nearest_neighbour_correction or atlas_correction : for i in range ( array_projection . shape [ 1 ]): for j in range ( array_projection . shape [ 2 ]): # Look for the 3D atlas coordinate of out data x_atlas , y_atlas , z_atlas = ( array_coordinates_high_res_slice [ i , j ] * 1000 / atlas_resolution ) # Ugly again, but numba doesn't support np.round x_atlas = int ( round ( x_atlas )) y_atlas = int ( round ( y_atlas )) z_atlas = int ( round ( z_atlas )) # If the current coordinate is contained in the ccfv3, proceed if ( x_atlas < array_annotation . shape [ 0 ] and x_atlas >= 0 and y_atlas < array_annotation . shape [ 1 ] and y_atlas >= 0 and z_atlas < array_annotation . shape [ 2 ] and z_atlas >= 0 ): # If the current annotation in the ccfv3 maps to an existing structure if array_annotation [ x_atlas , y_atlas , z_atlas ] != 0 : # Nearest neighbour correction to fill most of the empty pixels in the # high-resolution image if nearest_neighbour_correction : # If the pixel hasn't already been dealt with before (because of the # way the projection is done and warping, this may happen) if array_projection_filling [ slice_index , i , j ] == 0 : # Only fill missing areas if far from the sides if ( i > 20 and i < array_projection . shape [ 1 ] - 20 and j > 20 and j < array_projection . shape [ 2 ] - 20 ): # Look for neighbours that are filled in a close window radius = 3 array_window = np . empty ( ( 2 * radius + 1 , 2 * radius + 1 ), dtype = np . float32 ) # Temporary fill the window not to modify the value as they are # browsed and end up having an incremental nearest neighbor # correction for x in range ( - radius , radius + 1 ): for y in range ( - radius , radius + 1 ): if ( i + x > 0 and i + x < array_projection . shape [ 1 ] and j + x > 0 and j + y < array_projection . shape [ 2 ] ): if ( array_projection_filling [ slice_index , i + x , j + y ] == 0 ): array_window [ x + radius , y + radius ] = np . nan else : array_window [ x + radius , y + radius ] = array_projection [ slice_index , i + x , j + y ] avg = np . nanmean ( array_window ) if np . isnan ( avg ): continue clean_window = np . abs ( array_window - avg ) # Numba doesn't support nanargmin, so I have to implement it # myself... mini = 10000 selected_pixel_x = 0 selected_pixel_y = 0 for x in range ( 2 * radius + 1 ): for y in range ( 2 * radius + 1 ): if clean_window [ x , y ] < mini : mini = clean_window [ x , y ] selected_pixel_x = x selected_pixel_y = y # Fill the pixel in array projection with the most represented # value in the window array_projection [ slice_index , i , j ] = array_window [ selected_pixel_x , selected_pixel_y ] array_projection_correspondence [ slice_index , i , j ] = array_projection_correspondence [ slice_index , i + selected_pixel_x - radius , j + selected_pixel_y - radius , ] # Wipe the pixels values that are not annotated in the atlas elif atlas_correction : array_projection [ slice_index , i , j ] = 0 array_projection_filling [ slice_index , i , j ] = 1 array_projection_correspondence [ slice_index , i , j ] = [ - 1 , - 1 ] # Wipe the pixels values that are not in the ccfv3 elif atlas_correction : array_projection [ slice_index , i , j ] = 0 array_projection_filling [ slice_index , i , j ] = 1 array_projection_correspondence [ slice_index , i , j ] = [ - 1 , - 1 ] return array_projection , array_projection_correspondence","title":"fill_array_projection()"},{"location":"modules/tools/atlas/#modules.tools.atlas.get_array_rows_from_atlas_mask","text":"This function is similar to spectra.sample_rows_from_path(), in that it returns the lower and upper indexes of the rows belonging to the current mask (instead of path), as well as the corresponding column boundaries for each row. Parameters: Name Type Description Default mask np . ndarray A two-dimensional array representing the (high-resolution, warped) mask projected on the requested slice. required mask_remapped np . ndarray An empty two-dimensional array of the shape of the original acquisition, passed a parameter as numba won't allow for np.uint8 creation inside of the scope of the function. It is initially filled with the high-resolution warped mask values, whose coordinates have been mapped back to the original data. required array_projection_correspondence_sliced np . ndarray A two-dimensional array which associates, to each couple of coordinates of the original acquisition (row_index, column_index), a tuple of coordinates corresponding to the row_index and column_index of the warped higher-resolution image. required Returns: Type Description np . ndarray , np . ndarray The first array contains the lower and upper indexes of the rows belonging to the mask. The second array contains, for each row, the corresponding column boundaries of the mask (there can be more than 2 for non-convex shapes). Source code in modules/tools/atlas.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 @njit def get_array_rows_from_atlas_mask ( mask , mask_remapped , array_projection_correspondence_sliced ): \"\"\"This function is similar to spectra.sample_rows_from_path(), in that it returns the lower and upper indexes of the rows belonging to the current mask (instead of path), as well as the corresponding column boundaries for each row. Args: mask (np.ndarray): A two-dimensional array representing the (high-resolution, warped) mask projected on the requested slice. mask_remapped (np.ndarray): An empty two-dimensional array of the shape of the original acquisition, passed a parameter as numba won't allow for np.uint8 creation inside of the scope of the function. It is initially filled with the high-resolution warped mask values, whose coordinates have been mapped back to the original data. array_projection_correspondence_sliced (np.ndarray): A two-dimensional array which associates, to each couple of coordinates of the original acquisition (row_index, column_index), a tuple of coordinates corresponding to the row_index and column_index of the warped higher-resolution image. Returns: (np.ndarray, np.ndarray): The first array contains the lower and upper indexes of the rows belonging to the mask. The second array contains, for each row, the corresponding column boundaries of the mask (there can be more than 2 for non-convex shapes). \"\"\" # Map back the mask coordinates to original data for x in range ( mask . shape [ 0 ]): for y in range ( mask . shape [ 1 ]): x_original , y_original = array_projection_correspondence_sliced [ x , y ] if ( x_original >= 0 and x_original < mask_remapped . shape [ 0 ] and y_original >= 0 and y_original < mask_remapped . shape [ 0 ] ): mask_remapped [ x_original , y_original ] = mask [ x , y ] # Then compute the column boundaries for each row ll_rows = [] for x in range ( mask_remapped . shape [ 0 ]): first = False ymin = - 1 ymax = - 1 l_rows = [ x ] for y in range ( mask_remapped . shape [ 1 ]): if mask_remapped [ x , y ] != 0 and not first : ymin = y first = True elif mask_remapped [ x , y ] == 0 and first : # Correct for bug due to mask assignment with different resolution if np . max ( mask_remapped [ x , y : y + 5 ]) != 0 : continue else : ymax = y first = False l_rows . extend ([ ymin , ymax - 1 ]) # If two boundaries have been obtained, add them to the list if len ( l_rows ) > 1 : ll_rows . append ( l_rows ) # Get the indices of the first and last rows if len ( ll_rows ) > 0 : xmin = ll_rows [ 0 ][ 0 ] xmax = ll_rows [ - 1 ][ 0 ] max_len = max ([ len ( l_rows ) - 1 for l_rows in ll_rows ]) else : xmax = 0 xmin = 0 max_len = 0 # Convert list of np.array to np array padded with zeros (for numba compatibility) array_index_bound_column_per_row = np . zeros (( xmax - xmin + 1 , max_len ), dtype = np . int32 ) for i , l_rows in enumerate ( ll_rows ): array_index_bound_column_per_row [ i , : len ( l_rows ) - 1 ] = l_rows [ 1 :] return np . array ([ xmin , xmax ], dtype = np . int32 ), array_index_bound_column_per_row","title":"get_array_rows_from_atlas_mask()"},{"location":"modules/tools/atlas/#modules.tools.atlas.project_atlas_mask","text":"This function projects a mask array_annotation (obtained from the atlas, sliced from a 3-dimensional object) on our two-dimensional, high-resolution warped data, for a given slice. Parameters: Name Type Description Default stack_mask np . ndarray A three-dimensional array indexed with the ccfv3. It contains a zero if the selected coordinate is outside the mask array_annotation, and 1 otherwise. required slice_coordinates_rescaled np . ndarray A two-dimensional array mapping our slice coordinate (rescaled and discretized) to the ccfv3. required shape_atlas tuple(int A tuple of three integers representing the shape of the ccfv3-indexed atlas. required Returns: Type Description np . ndarray A two-dimensional array representing the projected mask on the requested slice. Source code in modules/tools/atlas.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 @njit def project_atlas_mask ( stack_mask , slice_coordinates_rescaled , shape_atlas ): \"\"\"This function projects a mask array_annotation (obtained from the atlas, sliced from a 3-dimensional object) on our two-dimensional, high-resolution warped data, for a given slice. Args: stack_mask (np.ndarray): A three-dimensional array indexed with the ccfv3. It contains a zero if the selected coordinate is outside the mask array_annotation, and 1 otherwise. slice_coordinates_rescaled (np.ndarray): A two-dimensional array mapping our slice coordinate (rescaled and discretized) to the ccfv3. shape_atlas (tuple(int)): A tuple of three integers representing the shape of the ccfv3-indexed atlas. Returns: (np.ndarray): A two-dimensional array representing the projected mask on the requested slice. \"\"\" # Define empty array for the projected mask, with the same dimension as the current slice # ! Delete this comment if everything is working, else switch back to int16 or int32 projected_mask = np . full ( slice_coordinates_rescaled . shape [: - 1 ], stack_mask [ 0 , 0 , 0 ], dtype = np . uint8 ) for x in range ( slice_coordinates_rescaled . shape [ 0 ]): for y in range ( slice_coordinates_rescaled . shape [ 1 ]): current_coor_rescaled = slice_coordinates_rescaled [ x , y ] # If the current slice coordinate actually exists in the atlas, maps it to the # corresponding mask value if ( min ( current_coor_rescaled ) >= 0 and current_coor_rescaled [ 0 ] < shape_atlas [ 0 ] and current_coor_rescaled [ 1 ] < shape_atlas [ 1 ] and current_coor_rescaled [ 2 ] < shape_atlas [ 2 ] ): projected_mask [ x , y ] = stack_mask [ current_coor_rescaled [ 0 ], current_coor_rescaled [ 1 ], current_coor_rescaled [ 2 ] ] return projected_mask","title":"project_atlas_mask()"},{"location":"modules/tools/atlas/#modules.tools.atlas.project_image","text":"This function is used to project the original maldi acquisition (low-resolution, possibly tilted, and) into a warped and higher resolution, indexed with the Allen Mouse Brain Common Coordinate Framework (ccfv3). Parameters: Name Type Description Default slice_index int Index of the slice to project. required original_image np . ndarray A two-dimensional array representing the MADI data of the current slice (e.g. for a given lipid selection). required array_projection_correspondence np . ndarray A three-dimensional array which associates, to each triplet of coordinates of the original acquisition (slice_index, row_index, column_index), a tuple of coordinates corresponding to the row_index and column_index of the warped higher-resolution image. required Returns: Type Description np . ndarray A warped, high-resolution image, corresponding to the clean, registered version, of our acquisition. Source code in modules/tools/atlas.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 @njit def project_image ( slice_index , original_image , array_projection_correspondence ): \"\"\"This function is used to project the original maldi acquisition (low-resolution, possibly tilted, and) into a warped and higher resolution, indexed with the Allen Mouse Brain Common Coordinate Framework (ccfv3). Args: slice_index (int): Index of the slice to project. original_image (np.ndarray): A two-dimensional array representing the MADI data of the current slice (e.g. for a given lipid selection). array_projection_correspondence (np.ndarray): A three-dimensional array which associates, to each triplet of coordinates of the original acquisition (slice_index, row_index, column_index), a tuple of coordinates corresponding to the row_index and column_index of the warped higher-resolution image. Returns: (np.ndarray): A warped, high-resolution image, corresponding to the clean, registered version, of our acquisition. \"\"\" # Correct index as slice names start at 1 slice_index -= 1 # Define empty array for the high-resolution image new_image = np . zeros ( array_projection_correspondence . shape [ 1 : - 1 ], dtype = original_image . dtype ) # Exclude the borders of the image to gain some time for i in range ( 50 , array_projection_correspondence [ slice_index ] . shape [ 0 ] - 50 ): for j in range ( 50 , array_projection_correspondence [ slice_index ] . shape [ 1 ] - 50 ): # Maps the original coordinates to the new one, with coordinate -1 corresponding # to unassigned if array_projection_correspondence [ slice_index , i , j , 0 ] != - 1 : x , y = array_projection_correspondence [ slice_index , i , j ] new_image [ i , j ] = original_image [ x , y ] return new_image","title":"project_image()"},{"location":"modules/tools/atlas/#modules.tools.atlas.slice_to_atlas_transform","text":"This function returns a 3D coordinate (in the ccfv3) from a 2D slice coordinate, using the parameters obtained from the inversion made in solve_plane_equation(). Parameters: Name Type Description Default a tuple(float The first of the three vectors used to parametrize the plane is space. required u tuple(float The second of the three vectors used to parametrize the plane in space. required v tuple(float The third of the three vectors used to parametrize the plane in space. required lambd int The first coordinate of our slice (height of the required point). required mu int The second coordinate of our slice (width of the required point). required Returns: Type Description int , int , int A 3D coordinate in the ccfv3, mapping our flat (2D) data to the atlas coordinate system. Source code in modules/tools/atlas.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 @njit def slice_to_atlas_transform ( a , u , v , lambd , mu ): \"\"\"This function returns a 3D coordinate (in the ccfv3) from a 2D slice coordinate, using the parameters obtained from the inversion made in solve_plane_equation(). Args: a (tuple(float)): The first of the three vectors used to parametrize the plane is space. u (tuple(float)): The second of the three vectors used to parametrize the plane in space. v (tuple(float)): The third of the three vectors used to parametrize the plane in space. lambd (int): The first coordinate of our slice (height of the required point). mu (int): The second coordinate of our slice (width of the required point). Returns: (int, int, int): A 3D coordinate in the ccfv3, mapping our flat (2D) data to the atlas coordinate system. \"\"\" # Equation of a plan in space x_atlas = a [ 0 ] + lambd * u [ 0 ] + mu * v [ 0 ] y_atlas = a [ 1 ] + lambd * u [ 1 ] + mu * v [ 1 ] z_atlas = a [ 2 ] + lambd * u [ 2 ] + mu * v [ 2 ] return x_atlas , y_atlas , z_atlas","title":"slice_to_atlas_transform()"},{"location":"modules/tools/atlas/#modules.tools.atlas.solve_plane_equation","text":"This function defines and solves a system of linear equations for three points of the plane (which corresponds to a slice in the ccfv3). The vectors returned by the function enable to index the 2D slice in the 3D atlas space (ccfv3), cf. slice_to_atlas_transform(). Note that the three points can not be taken at the extremities of the slice, as the registration made with ABBA is buggued and the origin doesn't linearly maps to the 3D plane. Parameters: Name Type Description Default array_coordinates_high_res_slice np . ndarray A two-dimensional array which maps the high-dimensional warped data to the atlas coordinate system. That is, for each 2-D coordinate (x,y), it associates a 3D coordinate (i,j,k) in the ccfv3. required point_1 tuple Couple of coordinates corresponding to the first point indexed on the 3D plane. Defaults to (50, 51). (50, 51) point_2 tuple Couple of coordinates corresponding to the first point indexed on the 3D plane. Defaults to (400, 200). (200, 200) point_3 tuple Couple of coordinates corresponding to the first point indexed on the 3D plane. Defaults to (100, 101). (100, 101) Returns: Type Description tuple ( float ), tuple ( float ), tuple ( float ) Three vectors allowing to parametrize the coordinate of our slice in the ccfv3. Source code in modules/tools/atlas.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 @njit def solve_plane_equation ( array_coordinates_high_res_slice , point_1 = ( 50 , 51 ), point_2 = ( 200 , 200 ), point_3 = ( 100 , 101 ), ): \"\"\"This function defines and solves a system of linear equations for three points of the plane (which corresponds to a slice in the ccfv3). The vectors returned by the function enable to index the 2D slice in the 3D atlas space (ccfv3), cf. slice_to_atlas_transform(). Note that the three points can not be taken at the extremities of the slice, as the registration made with ABBA is buggued and the origin doesn't linearly maps to the 3D plane. Args: array_coordinates_high_res_slice (np.ndarray): A two-dimensional array which maps the high-dimensional warped data to the atlas coordinate system. That is, for each 2-D coordinate (x,y), it associates a 3D coordinate (i,j,k) in the ccfv3. point_1 (tuple, optional): Couple of coordinates corresponding to the first point indexed on the 3D plane. Defaults to (50, 51). point_2 (tuple, optional): Couple of coordinates corresponding to the first point indexed on the 3D plane. Defaults to (400, 200). point_3 (tuple, optional): Couple of coordinates corresponding to the first point indexed on the 3D plane. Defaults to (100, 101). Returns: (tuple(float), tuple(float), tuple(float)): Three vectors allowing to parametrize the coordinate of our slice in the ccfv3. \"\"\" # Define empty array for the linear system of equations A = np . zeros (( 9 , 9 ), dtype = np . float32 ) b = np . zeros (( 9 ,), dtype = np . float32 ) # Fill the matrices, such that Ax=b, where A represents the projection from 2D coordinates (x) # to the ccfv3 (b) A [ 0 ] = [ point_1 [ 0 ], 0 , 0 , point_1 [ 1 ], 0 , 0 , 1 , 0 , 0 ] A [ 1 ] = [ 0 , point_1 [ 0 ], 0 , 0 , point_1 [ 1 ], 0 , 0 , 1 , 0 ] A [ 2 ] = [ 0 , 0 , point_1 [ 0 ], 0 , 0 , point_1 [ 1 ], 0 , 0 , 1 ] A [ 3 ] = [ point_2 [ 0 ], 0 , 0 , point_2 [ 1 ], 0 , 0 , 1 , 0 , 0 ] A [ 4 ] = [ 0 , point_2 [ 0 ], 0 , 0 , point_2 [ 1 ], 0 , 0 , 1 , 0 ] A [ 5 ] = [ 0 , 0 , point_2 [ 0 ], 0 , 0 , point_2 [ 1 ], 0 , 0 , 1 ] A [ 6 ] = [ point_3 [ 0 ], 0 , 0 , point_3 [ 1 ], 0 , 0 , 1 , 0 , 0 ] A [ 7 ] = [ 0 , point_3 [ 0 ], 0 , 0 , point_3 [ 1 ], 0 , 0 , 1 , 0 ] A [ 8 ] = [ 0 , 0 , point_3 [ 0 ], 0 , 0 , point_3 [ 1 ], 0 , 0 , 1 ] b [ 0 ] = array_coordinates_high_res_slice [ point_1 [ 0 ], point_1 [ 1 ], 0 ] b [ 1 ] = array_coordinates_high_res_slice [ point_1 [ 0 ], point_1 [ 1 ], 1 ] b [ 2 ] = array_coordinates_high_res_slice [ point_1 [ 0 ], point_1 [ 1 ], 2 ] b [ 3 ] = array_coordinates_high_res_slice [ point_2 [ 0 ], point_2 [ 1 ], 0 ] b [ 4 ] = array_coordinates_high_res_slice [ point_2 [ 0 ], point_2 [ 1 ], 1 ] b [ 5 ] = array_coordinates_high_res_slice [ point_2 [ 0 ], point_2 [ 1 ], 2 ] b [ 6 ] = array_coordinates_high_res_slice [ point_3 [ 0 ], point_3 [ 1 ], 0 ] b [ 7 ] = array_coordinates_high_res_slice [ point_3 [ 0 ], point_3 [ 1 ], 1 ] b [ 8 ] = array_coordinates_high_res_slice [ point_3 [ 0 ], point_3 [ 1 ], 2 ] # Invert the system of equation u1 , u2 , u3 , v1 , v2 , v3 , a1 , a2 , a3 = np . linalg . solve ( A , b ) u_atlas = ( u1 , u2 , u3 ) v_atlas = ( v1 , v2 , v3 ) a_atlas = ( a1 , a2 , a3 ) return a_atlas , u_atlas , v_atlas","title":"solve_plane_equation()"},{"location":"modules/tools/image/","text":"This file contains functions used to convert arrays to Pillow images, possibly as b64 strings. black_to_transparency ( img ) This function takes a PIL image and convert the zero-valued pixels to transparent ones in the most efficient way possible. Parameters: Name Type Description Default img PIL . Image The image for which the pixels must be made transparent. required Returns: Type Description PIL . Image The image with transparent pixels. Source code in modules/tools/image.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def black_to_transparency ( img ): \"\"\"This function takes a PIL image and convert the zero-valued pixels to transparent ones in the most efficient way possible. Args: img (PIL.Image): The image for which the pixels must be made transparent. Returns: (PIL.Image): The image with transparent pixels. \"\"\" # Need to copy as PIL arrays are read-only x = np . asarray ( img . convert ( \"RGBA\" )) . copy () x [:, :, 3 ] = ( 255 * ( x [:, :, : 3 ] != 0 ) . any ( axis = 2 )) . astype ( np . uint8 ) return Image . fromarray ( x ) convert_image_to_base64 ( image_array , optimize = True , quality = 85 , colormap = black_viridis , type = None , format = 'png' , overlay = None , decrease_resolution_factor = 1 , binary = False , transparent_zeros = False ) This functions allows for the conversion of a numpy array into a bytestring image using PIL. All images are paletted so save space. Parameters: Name Type Description Default image_array np . ndarray The array containing the image. May be 1D of 3D or 4D. The type argument must match with the dimensionality. required optimize bool If True, PIL will try to optimize the image size, at the expense of a longer computation time. This is not available with all image formats (check PIL documentation). Defaults to True. True quality int Image quality, from 0 to 100, used by PIL for compression. Defaults to 85. 85 colormap cm colormap The colormap used to map 1D uint8 image to colors. Defaults to cm.viridis. black_viridis type str The type of the image. If image_array is in 3D, type must be RGB. If 4D, type must be RGBA. Defaults to None. None format str The output format for the bytestring image. Defaults to \"png\". \"webp\", \"gif\", \"jpeg\" also available. 'png' overlay np . ndarray Another image array to overlay with image_array. Defaults to None. None decrease_resolution_factor int Used to divide the resolution of the initial array, to output a smaller image. Defaults to 1. 1 binary bool Used to convert the output image to binary format (\"LA\", in PIL), to save a lot of space for greyscales images. Defaults to False. False Returns: Type Description str The base 64 image encoded in a string. Source code in modules/tools/image.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def convert_image_to_base64 ( image_array , optimize = True , quality = 85 , colormap = black_viridis , type = None , format = \"png\" , overlay = None , decrease_resolution_factor = 1 , binary = False , transparent_zeros = False , ): \"\"\"This functions allows for the conversion of a numpy array into a bytestring image using PIL. All images are paletted so save space. Args: image_array (np.ndarray): The array containing the image. May be 1D of 3D or 4D. The type argument must match with the dimensionality. optimize (bool, optional): If True, PIL will try to optimize the image size, at the expense of a longer computation time. This is not available with all image formats (check PIL documentation). Defaults to True. quality (int, optional): Image quality, from 0 to 100, used by PIL for compression. Defaults to 85. colormap (cm colormap, optional): The colormap used to map 1D uint8 image to colors. Defaults to cm.viridis. type (str, optional): The type of the image. If image_array is in 3D, type must be RGB. If 4D, type must be RGBA. Defaults to None. format (str, optional): The output format for the bytestring image. Defaults to \"png\". \"webp\", \"gif\", \"jpeg\" also available. overlay (np.ndarray, optional): Another image array to overlay with image_array. Defaults to None. decrease_resolution_factor (int, optional): Used to divide the resolution of the initial array, to output a smaller image. Defaults to 1. binary (bool, optional): Used to convert the output image to binary format (\"LA\", in PIL), to save a lot of space for greyscales images. Defaults to False. Returns: (str): The base 64 image encoded in a string. \"\"\" logging . info ( \"Entering string conversion function\" ) # Convert 1D array into a PIL image if type is None : # Map image to a colormap and convert to uint8 img = np . uint8 ( colormap ( image_array ) * 255 ) # Turn array into PIL image object pil_img = Image . fromarray ( img ) # Convert 3D or 4D array into a PIL image elif type == \"RGB\" or type == \"RGBA\" : pil_img = Image . fromarray ( image_array , type ) logging . info ( \"Image has been converted from array to PIL image\" ) # Overlay is transparent, therefore initial image must be converted to RGBA if overlay is not None : if type != \"RGBA\" : pil_img = pil_img . convert ( \"RGBA\" ) overlay_img = Image . fromarray ( overlay , \"RGBA\" ) pil_img . paste ( overlay_img , ( 0 , 0 ), overlay_img ) logging . info ( \"Overlay has been added to the image\" ) # If we want to decrease resolution to save space if decrease_resolution_factor > 1 : x , y = pil_img . size x2 , y2 = ( int ( round ( x / decrease_resolution_factor )), int ( round ( y / decrease_resolution_factor )), ) pil_img = pil_img . resize (( x2 , y2 ), Image . ANTIALIAS ) logging . info ( \"Resolution has been decreased\" ) if transparent_zeros : # Takes ~5 ms but makes output much nicer pil_img = black_to_transparency ( pil_img ) logging . info ( \"Empty pixels are now transparent\" ) # Convert to base64 base64_string = None with BytesIO () as stream : # Handle image format if format == \"webp\" : logging . info ( \"Webp mode selected, binary or paletted modes are not supported\" ) pil_img . save ( stream , format = format , optimize = optimize , quality = quality , method = 3 , lossless = False ) elif format == \"gif\" : # Convert to paletted image to save space pil_img = pil_img . convert ( \"P\" ) logging . info ( \"gif mode selected, quality argument is not supported\" ) pil_img . save ( stream , format = format , optimize = optimize , transparency = 255 ) elif format == \"jpeg\" : # Convert to paletted image to save space pil_img = pil_img . convert ( \"P\" ) pil_img . save ( stream , format = format , optimize = optimize , quality = quality ) else : # Convert to paletted image to save space if binary : pil_img = pil_img . convert ( \"LA\" ) else : pil_img = pil_img . convert ( \"P\" ) logging . info ( \"png mode selected, quality argument is not supported\" ) pil_img . save ( stream , format = format , optimize = optimize , bits = 9 ) # Encode final image base64_string = ( \"data:image/\" + format + \";base64,\" + base64 . b64encode ( stream . getvalue ()) . decode ( \"utf-8\" ) ) logging . info ( \"Image has been converted to base64. Returning it now.\" ) return base64_string","title":"Image"},{"location":"modules/tools/image/#modules.tools.image.black_to_transparency","text":"This function takes a PIL image and convert the zero-valued pixels to transparent ones in the most efficient way possible. Parameters: Name Type Description Default img PIL . Image The image for which the pixels must be made transparent. required Returns: Type Description PIL . Image The image with transparent pixels. Source code in modules/tools/image.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def black_to_transparency ( img ): \"\"\"This function takes a PIL image and convert the zero-valued pixels to transparent ones in the most efficient way possible. Args: img (PIL.Image): The image for which the pixels must be made transparent. Returns: (PIL.Image): The image with transparent pixels. \"\"\" # Need to copy as PIL arrays are read-only x = np . asarray ( img . convert ( \"RGBA\" )) . copy () x [:, :, 3 ] = ( 255 * ( x [:, :, : 3 ] != 0 ) . any ( axis = 2 )) . astype ( np . uint8 ) return Image . fromarray ( x )","title":"black_to_transparency()"},{"location":"modules/tools/image/#modules.tools.image.convert_image_to_base64","text":"This functions allows for the conversion of a numpy array into a bytestring image using PIL. All images are paletted so save space. Parameters: Name Type Description Default image_array np . ndarray The array containing the image. May be 1D of 3D or 4D. The type argument must match with the dimensionality. required optimize bool If True, PIL will try to optimize the image size, at the expense of a longer computation time. This is not available with all image formats (check PIL documentation). Defaults to True. True quality int Image quality, from 0 to 100, used by PIL for compression. Defaults to 85. 85 colormap cm colormap The colormap used to map 1D uint8 image to colors. Defaults to cm.viridis. black_viridis type str The type of the image. If image_array is in 3D, type must be RGB. If 4D, type must be RGBA. Defaults to None. None format str The output format for the bytestring image. Defaults to \"png\". \"webp\", \"gif\", \"jpeg\" also available. 'png' overlay np . ndarray Another image array to overlay with image_array. Defaults to None. None decrease_resolution_factor int Used to divide the resolution of the initial array, to output a smaller image. Defaults to 1. 1 binary bool Used to convert the output image to binary format (\"LA\", in PIL), to save a lot of space for greyscales images. Defaults to False. False Returns: Type Description str The base 64 image encoded in a string. Source code in modules/tools/image.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def convert_image_to_base64 ( image_array , optimize = True , quality = 85 , colormap = black_viridis , type = None , format = \"png\" , overlay = None , decrease_resolution_factor = 1 , binary = False , transparent_zeros = False , ): \"\"\"This functions allows for the conversion of a numpy array into a bytestring image using PIL. All images are paletted so save space. Args: image_array (np.ndarray): The array containing the image. May be 1D of 3D or 4D. The type argument must match with the dimensionality. optimize (bool, optional): If True, PIL will try to optimize the image size, at the expense of a longer computation time. This is not available with all image formats (check PIL documentation). Defaults to True. quality (int, optional): Image quality, from 0 to 100, used by PIL for compression. Defaults to 85. colormap (cm colormap, optional): The colormap used to map 1D uint8 image to colors. Defaults to cm.viridis. type (str, optional): The type of the image. If image_array is in 3D, type must be RGB. If 4D, type must be RGBA. Defaults to None. format (str, optional): The output format for the bytestring image. Defaults to \"png\". \"webp\", \"gif\", \"jpeg\" also available. overlay (np.ndarray, optional): Another image array to overlay with image_array. Defaults to None. decrease_resolution_factor (int, optional): Used to divide the resolution of the initial array, to output a smaller image. Defaults to 1. binary (bool, optional): Used to convert the output image to binary format (\"LA\", in PIL), to save a lot of space for greyscales images. Defaults to False. Returns: (str): The base 64 image encoded in a string. \"\"\" logging . info ( \"Entering string conversion function\" ) # Convert 1D array into a PIL image if type is None : # Map image to a colormap and convert to uint8 img = np . uint8 ( colormap ( image_array ) * 255 ) # Turn array into PIL image object pil_img = Image . fromarray ( img ) # Convert 3D or 4D array into a PIL image elif type == \"RGB\" or type == \"RGBA\" : pil_img = Image . fromarray ( image_array , type ) logging . info ( \"Image has been converted from array to PIL image\" ) # Overlay is transparent, therefore initial image must be converted to RGBA if overlay is not None : if type != \"RGBA\" : pil_img = pil_img . convert ( \"RGBA\" ) overlay_img = Image . fromarray ( overlay , \"RGBA\" ) pil_img . paste ( overlay_img , ( 0 , 0 ), overlay_img ) logging . info ( \"Overlay has been added to the image\" ) # If we want to decrease resolution to save space if decrease_resolution_factor > 1 : x , y = pil_img . size x2 , y2 = ( int ( round ( x / decrease_resolution_factor )), int ( round ( y / decrease_resolution_factor )), ) pil_img = pil_img . resize (( x2 , y2 ), Image . ANTIALIAS ) logging . info ( \"Resolution has been decreased\" ) if transparent_zeros : # Takes ~5 ms but makes output much nicer pil_img = black_to_transparency ( pil_img ) logging . info ( \"Empty pixels are now transparent\" ) # Convert to base64 base64_string = None with BytesIO () as stream : # Handle image format if format == \"webp\" : logging . info ( \"Webp mode selected, binary or paletted modes are not supported\" ) pil_img . save ( stream , format = format , optimize = optimize , quality = quality , method = 3 , lossless = False ) elif format == \"gif\" : # Convert to paletted image to save space pil_img = pil_img . convert ( \"P\" ) logging . info ( \"gif mode selected, quality argument is not supported\" ) pil_img . save ( stream , format = format , optimize = optimize , transparency = 255 ) elif format == \"jpeg\" : # Convert to paletted image to save space pil_img = pil_img . convert ( \"P\" ) pil_img . save ( stream , format = format , optimize = optimize , quality = quality ) else : # Convert to paletted image to save space if binary : pil_img = pil_img . convert ( \"LA\" ) else : pil_img = pil_img . convert ( \"P\" ) logging . info ( \"png mode selected, quality argument is not supported\" ) pil_img . save ( stream , format = format , optimize = optimize , bits = 9 ) # Encode final image base64_string = ( \"data:image/\" + format + \";base64,\" + base64 . b64encode ( stream . getvalue ()) . decode ( \"utf-8\" ) ) logging . info ( \"Image has been converted to base64. Returning it now.\" ) return base64_string","title":"convert_image_to_base64()"},{"location":"modules/tools/lookup_tables/","text":"This file contains functions used to build the lookup tables for faster/easier access to MALDI data. build_cumulated_image_lookup_table ( array_spectra , array_pixel_indexes , img_shape , divider_lookup , size_spectrum = 2000 ) This function builds a lookup table to map the mz values to the image consisting of cumulated spectrum (for each pixel) until this mz value. Parameters: Name Type Description Default array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required img_shape tuple(int A tuple or arrays of 2 integers describing the shape of the acquisition. required divider_lookup int Sets the resolution of the lookup table. The bigger it is, the bigger the increments between two successive lookups. Must be consistent across lookup tables. required size_spectrum int The total size of the spectrum indexed by the lookup. Defaults to 2000, corresponding to an indexed spectrum ranging from 0 m/z to 2000 m/z. 2000 Returns: Type Description np . ndarray An array of shape (size_spectrum// divider_lookup, image height, image_width), mapping m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. Source code in modules/tools/lookup_tables.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 @njit def build_cumulated_image_lookup_table ( array_spectra , array_pixel_indexes , img_shape , divider_lookup , size_spectrum = 2000 ): \"\"\"This function builds a lookup table to map the mz values to the image consisting of cumulated spectrum (for each pixel) until this mz value. Args: array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. img_shape (tuple(int)): A tuple or arrays of 2 integers describing the shape of the acquisition. divider_lookup (int): Sets the resolution of the lookup table. The bigger it is, the bigger the increments between two successive lookups. Must be consistent across lookup tables. size_spectrum (int): The total size of the spectrum indexed by the lookup. Defaults to 2000, corresponding to an indexed spectrum ranging from 0 m/z to 2000 m/z. Returns: (np.ndarray): An array of shape (size_spectrum// divider_lookup, image height, image_width), mapping m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. \"\"\" # Define the empty array for the lookup table image_lookup_table = np . zeros ( ( size_spectrum // divider_lookup , img_shape [ 0 ], img_shape [ 1 ]), dtype = np . float32 ) image_lookup_table [ 0 , :] = np . zeros (( img_shape [ 0 ], img_shape [ 1 ]), dtype = np . float32 ) for idx_pix in range ( array_pixel_indexes . shape [ 0 ]): j = array_pixel_indexes [ idx_pix , 0 ] # If current pixel contains no peak, just skip to next one and add nothing if j == - 1 : continue pix_value = 0 coor_pix = convert_spectrum_idx_to_coor ( idx_pix , img_shape ) # Loop over lookup indexes for index_lookup in range ( size_spectrum // divider_lookup - 1 ): # Find the first mz index corresponding to current lookup for current pixel # (skipped if current mz>lookup) while array_spectra [ 0 , j ] >= ( index_lookup * divider_lookup ) and array_spectra [ 0 , j ] < ( ( index_lookup + 1 ) * divider_lookup ): pix_value += array_spectra [ 1 , j ] j += 1 if j == array_pixel_indexes [ idx_pix , 1 ] + 1 : break # Check that we're still in the good pixel and add mz index to lookup if j < array_pixel_indexes [ idx_pix , 1 ] + 1 : image_lookup_table [ index_lookup + 1 , coor_pix [ 0 ], coor_pix [ 1 ]] = pix_value # If we're not in the requested pixel, this means that the while loop was exited because # the lookup didn't exist, so we fill the rest of the table with biggest possible value else : for i in range ( index_lookup + 1 , size_spectrum // divider_lookup ): image_lookup_table [ i , coor_pix [ 0 ], coor_pix [ 1 ]] = pix_value break return image_lookup_table build_index_lookup_table ( array_spectra , array_pixel_indexes , divider_lookup , size_spectrum = 2000 ) This function builds a lookup table to map mz values to indexes in array_spectra. In practice, for each pixel, the lookup table gives the first index of mz such that mz>=lookup divider_lookup. If no such mz exists, the lookup table gives last possible mz index (i.e. biggest possible mz for the current pixel, but under the lookup). If lookup divider_lookup is smaller than the smallest mz, it returns the first mz index possible for the current pixel, above the current lookup. If there are no peak at all in the spectrum... it returns -1. Parameters: Name Type Description Default array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required divider_lookup int Sets the resolution of the lookup table. The bigger it is, the bigger the increments between two successive lookups. Must be consistent across lookup tables. required size_spectrum int The total size of the spectrum indexed by the lookup. Defaults to 2000, corresponding to an indexed spectrum ranging from 0 m/z to 2000 m/z. 2000 Returns: Type Description np . ndarray An array of shape (size_spectrum// divider_lookup, m), mapping m/z values to indexes in array_spectra for each pixel. Source code in modules/tools/lookup_tables.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 @njit def build_index_lookup_table ( array_spectra , array_pixel_indexes , divider_lookup , size_spectrum = 2000 ): \"\"\"This function builds a lookup table to map mz values to indexes in array_spectra. In practice, for each pixel, the lookup table gives the first index of mz such that mz>=lookup*divider_lookup. If no such mz exists, the lookup table gives last possible mz index (i.e. biggest possible mz for the current pixel, but under the lookup). If lookup*divider_lookup is smaller than the smallest mz, it returns the first mz index possible for the current pixel, above the current lookup. If there are no peak at all in the spectrum... it returns -1. Args: array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. divider_lookup (int): Sets the resolution of the lookup table. The bigger it is, the bigger the increments between two successive lookups. Must be consistent across lookup tables. size_spectrum (int): The total size of the spectrum indexed by the lookup. Defaults to 2000, corresponding to an indexed spectrum ranging from 0 m/z to 2000 m/z. Returns: (np.ndarray): An array of shape (size_spectrum// divider_lookup, m), mapping m/z values to indexes in array_spectra for each pixel. \"\"\" # Define the empty array for the lookup table lookup_table = np . zeros ( ( size_spectrum // divider_lookup , array_pixel_indexes . shape [ 0 ]), dtype = np . int32 ) lookup_table [ 0 , :] = array_pixel_indexes [:, 0 ] # Loop over pixel indexes for idx_pix in range ( array_pixel_indexes . shape [ 0 ]): j = array_pixel_indexes [ idx_pix , 0 ] # If there's no peak for the current pixel, lookup is -1 if j == - 1 : for i in range ( size_spectrum // divider_lookup ): lookup_table [ i , idx_pix ] = - 1 # Loop over lookup indexes for index_lookup in range ( size_spectrum // divider_lookup - 1 ): # First find the first mz index corresponding to current lookup for current pixel # (skipped if current mz>lookup) while array_spectra [ 0 , j ] < (( index_lookup + 1 ) * divider_lookup ): j += 1 if j == array_pixel_indexes [ idx_pix , 1 ] + 1 : break # Check that we're still in the requested pixel and add mz index to lookup if j < array_pixel_indexes [ idx_pix , 1 ] + 1 : lookup_table [ index_lookup + 1 , idx_pix ] = j # If we're not in the requested pixel, this means that the while loop was exited because # the lookup didn't exist, so we fill the rest of the table with biggest possible value else : for i in range ( index_lookup + 1 , size_spectrum // divider_lookup ): lookup_table [ i , idx_pix ] = j - 1 break return lookup_table build_index_lookup_table_averaged_spectrum ( array_mz , size_spectrum = 2000 ) This function builds a lookup table identical to the one defined in build_index_lookup_table(), except that this one maps mz values to indexes in the averaged array_spectra (across all pixels). Parameters: Name Type Description Default array_mz np . ndarray The m/z array of the averaged array spectra (i.e. row 0). required size_spectrum int The total size of the spectrum indexed by the lookup. Defaults to 2000, corresponding to an averaged indexed spectrum ranging from 0 m/z to 2000 m/z. 2000 Returns: Type Description np . ndarray An array of length size_spectrum (i.e. the defaults divider_lookup is 1 for this array), mapping m/z values to indexes in the averaged array_spectra. Source code in modules/tools/lookup_tables.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 @njit def build_index_lookup_table_averaged_spectrum ( array_mz , size_spectrum = 2000 ): \"\"\"This function builds a lookup table identical to the one defined in build_index_lookup_table(), except that this one maps mz values to indexes in the averaged array_spectra (across all pixels). Args: array_mz (np.ndarray): The m/z array of the averaged array spectra (i.e. row 0). size_spectrum (int): The total size of the spectrum indexed by the lookup. Defaults to 2000, corresponding to an averaged indexed spectrum ranging from 0 m/z to 2000 m/z. Returns: (np.ndarray): An array of length size_spectrum (i.e. the defaults divider_lookup is 1 for this array), mapping m/z values to indexes in the averaged array_spectra. \"\"\" # Define the empty array for the lookup table lookup_table = np . empty (( size_spectrum ), dtype = np . int32 ) j = 0 lookup_table [ 0 ] = 0 # Loop over lookup indexes for index_lookup in range ( size_spectrum - 1 ): # Find the first mz index corresponding to current lookup for current pixel while array_mz [ j ] < index_lookup + 1 : j += 1 if j == array_mz . shape [ 0 ]: break # Add the lookup to the table if it exists if j < array_mz . shape [ 0 ]: lookup_table [ index_lookup + 1 ] = j # If the lookup doesn't exist, so we fill the rest of the table with biggest possible m/z # value else : for i in range ( index_lookup + 1 , size_spectrum ): lookup_table [ i ] = j - 1 break return lookup_table process_lookup_tables ( t_index_path , temp_path = '/data/lipidatlas/data/app/data/temp/' , l_arrays_raw_data = None , load_from_file = True , save = True , return_result = False ) This function has been implemented to allow the paralellization of lookup tables processing. It computes and returns/saves the lookup tables for each slice. The output consists of: - array_pixel_indexes_high_res: np.nddaray of shape (n,2), it maps each pixel to two array_spectra_high_res indices, delimiting the corresponding spectrum. - array_spectra_high_res: np.nddaray of shape (2,m), it contains the concatenated spectra of each pixel. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_low_res: np.nddaray of shape (2, k), it contains the low-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_high_res: Same as array_averaged_mz_intensity_low_res, but in higher resolution, with, therefore, a different shape. - image_shape: a tuple of integers, indicating the vertical and horizontal size of the corresponding slice. - divider_lookup: integer that sets the resolution of the lookup tables. - lookup_table_spectra_high_res: np.nddaray of shape (size_spectrum// divider_lookup, m), it maps m/z values to indexes in array_spectra for each pixel. - cumulated_image_lookup_table_high_res: np.nddaray of shape (size_spectrum // divider_lookup, image height, image_width), it maps m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. - lookup_table_averaged_spectrum_high_res: np.nddaray of length size_spectrum, it maps m/z values to indexes in the averaged array_spectra for each pixel. - array_peaks_corrected: A two-dimensional array containing the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. - array_corrective_factors: A three-dimensional numpy array equal to the ratio of 'arrays_after_transfo' and 'arrays_before_transfo' containing the corrective factor used for lipid (first dimension) and each pixel (second and third dimension). Parameters: Name Type Description Default t_index_path tuple(int, str A tuple containing the index of the slice (starting from 1) and the corresponding path for the raw data. required temp_path str Path to load/save the output npz file. Defaults to \"/data/lipidatlas/data/app/data/temp/\". '/data/lipidatlas/data/app/data/temp/' l_arrays_raw_data list A list of arrays containing the data that is processed in the current function. If None, the same arrays must be loaded from the disk. Defaults to None. None load_from_file bool If True, the arrays containing the data processed by the current function are loaded from the disk. If False, the corresponding arrays must be provided through the parameter l_arrays_raw_data. Defaults to True. True save bool If True, output arrays are saved in a npz file. Defaults to True. True return_result bool If True, output arrays are returned by the function. Defaults to False. False Returns: Type Description Depending on 'return result', returns either nothing, either several np.ndarrays, described above. Source code in modules/tools/lookup_tables.py 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 def process_lookup_tables ( t_index_path , temp_path = \"/data/lipidatlas/data/app/data/temp/\" , # \"notebooks/data_processing/data/temp/\", l_arrays_raw_data = None , load_from_file = True , save = True , return_result = False , ): \"\"\"This function has been implemented to allow the paralellization of lookup tables processing. It computes and returns/saves the lookup tables for each slice. The output consists of: - array_pixel_indexes_high_res: np.nddaray of shape (n,2), it maps each pixel to two array_spectra_high_res indices, delimiting the corresponding spectrum. - array_spectra_high_res: np.nddaray of shape (2,m), it contains the concatenated spectra of each pixel. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_low_res: np.nddaray of shape (2, k), it contains the low-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_high_res: Same as array_averaged_mz_intensity_low_res, but in higher resolution, with, therefore, a different shape. - image_shape: a tuple of integers, indicating the vertical and horizontal size of the corresponding slice. - divider_lookup: integer that sets the resolution of the lookup tables. - lookup_table_spectra_high_res: np.nddaray of shape (size_spectrum// divider_lookup, m), it maps m/z values to indexes in array_spectra for each pixel. - cumulated_image_lookup_table_high_res: np.nddaray of shape (size_spectrum // divider_lookup, image height, image_width), it maps m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. - lookup_table_averaged_spectrum_high_res: np.nddaray of length size_spectrum, it maps m/z values to indexes in the averaged array_spectra for each pixel. - array_peaks_corrected: A two-dimensional array containing the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. - array_corrective_factors: A three-dimensional numpy array equal to the ratio of 'arrays_after_transfo' and 'arrays_before_transfo' containing the corrective factor used for lipid (first dimension) and each pixel (second and third dimension). Args: t_index_path (tuple(int, str)): A tuple containing the index of the slice (starting from 1) and the corresponding path for the raw data. temp_path (str, optional): Path to load/save the output npz file. Defaults to \"/data/lipidatlas/data/app/data/temp/\". l_arrays_raw_data (list, optional): A list of arrays containing the data that is processed in the current function. If None, the same arrays must be loaded from the disk. Defaults to None. load_from_file (bool, optional): If True, the arrays containing the data processed by the current function are loaded from the disk. If False, the corresponding arrays must be provided through the parameter l_arrays_raw_data. Defaults to True. save (bool, optional): If True, output arrays are saved in a npz file. Defaults to True. return_result (bool, optional): If True, output arrays are returned by the function. Defaults to False. Returns: Depending on 'return result', returns either nothing, either several np.ndarrays, described above. \"\"\" if l_arrays_raw_data is not None : raise ValueError ( \"Arrays must be loaded from file from now on.\" ) elif load_from_file : # Get slice path slice_index = t_index_path [ 0 ] name = t_index_path [ 1 ] # Correct temp path if \"MouseBrain2\" in name : temp_path += \"brain_2/\" else : temp_path += \"brain_1/\" path = temp_path + \"slice_\" + str ( slice_index ) + \".npz\" npzfile = np . load ( path ) # Load individual arrays array_pixel_indexes_high_res = npzfile [ \"array_pixel_indexes_high_res\" ] array_spectra_high_res = npzfile [ \"array_spectra_high_res\" ] array_averaged_mz_intensity_low_res = npzfile [ \"array_averaged_mz_intensity_low_res\" ] array_averaged_mz_intensity_high_res = npzfile [ \"array_averaged_mz_intensity_high_res\" ] array_averaged_mz_intensity_high_res_after_standardization = npzfile [ \"array_averaged_mz_intensity_high_res_after_standardization\" ] image_shape = npzfile [ \"image_shape\" ] array_peaks_corrected = npzfile [ \"array_peaks_corrected\" ] array_corrective_factors = npzfile [ \"array_corrective_factors\" ] # Try to see if the array has already been processed before if \"divider_lookup\" in npzfile : print ( \"This file has already been processed before\" ) return None else : print ( \"Either the data or a filename must be provided\" ) return None # Define divider_lookup divider_lookup = DIVIDER_LOOKUP # Build lookup table linking mz value to index in array_spectra for each pixel lookup_table_spectra_high_res = build_index_lookup_table ( array_spectra_high_res , array_pixel_indexes_high_res , divider_lookup ) print ( \"Size (in mb) of lookup_table_spectra_high_res: \" , round ( lookup_table_spectra_high_res . nbytes / 1024 / 1024 , 2 ), ) print ( \"Shape of lookup_table_spectra_high_res: \" , lookup_table_spectra_high_res . shape ) # Build lookup table of the cumulated spectrum for each pixel cumulated_image_lookup_table_high_res = build_cumulated_image_lookup_table ( array_spectra_high_res , array_pixel_indexes_high_res , image_shape , divider_lookup ) print ( \"Size (in mb) of cumulated_image_lookup_table_high_res: \" , round ( cumulated_image_lookup_table_high_res . nbytes / 1024 / 1024 , 2 ), ) print ( \"Shape of cumulated_image_lookup_table_high_res: \" , cumulated_image_lookup_table_high_res . shape , ) # Extend averaged arrays with zeros for nicer display array_averaged_mz_intensity_low_res , _ = add_zeros_to_spectrum ( array_averaged_mz_intensity_low_res , pad_individual_peaks = True ) array_averaged_mz_intensity_high_res , _ = add_zeros_to_spectrum ( array_averaged_mz_intensity_high_res , pad_individual_peaks = True ) array_averaged_mz_intensity_high_res_after_standardization , _ = add_zeros_to_spectrum ( array_averaged_mz_intensity_high_res_after_standardization , pad_individual_peaks = True ) # Build lookup table to compute fast the indexes corresponding to the boundaries selected in app lookup_table_averaged_spectrum_high_res = build_index_lookup_table_averaged_spectrum ( array_mz = array_averaged_mz_intensity_high_res [ 0 , :] ) print ( \"Size (in mb) of lookup_table_averaged_spectrum_high_res: \" , round ( lookup_table_averaged_spectrum_high_res . nbytes / 1024 / 1024 , 2 ), ) print ( \"Shape of lookup_table_averaged_spectrum_high_res: \" , lookup_table_averaged_spectrum_high_res . shape , ) if save : # Save as npz file print ( \"Saving...\" ) np . savez ( path , array_pixel_indexes_high_res = array_pixel_indexes_high_res , array_spectra_high_res = array_spectra_high_res , array_averaged_mz_intensity_low_res = array_averaged_mz_intensity_low_res , array_averaged_mz_intensity_high_res = array_averaged_mz_intensity_high_res , array_averaged_mz_intensity_high_res_after_standardization = array_averaged_mz_intensity_high_res_after_standardization , image_shape = image_shape , divider_lookup = divider_lookup , lookup_table_spectra_high_res = lookup_table_spectra_high_res , cumulated_image_lookup_table_high_res = cumulated_image_lookup_table_high_res , lookup_table_averaged_spectrum_high_res = lookup_table_averaged_spectrum_high_res , array_peaks_corrected = array_peaks_corrected , array_corrective_factors = array_corrective_factors , ) # Returns all array if needed if return_result : return ( array_pixel_indexes_high_res , array_spectra_high_res , array_averaged_mz_intensity_low_res , array_averaged_mz_intensity_high_res , array_averaged_mz_intensity_high_res_after_standardization , image_shape , divider_lookup , lookup_table_spectra_high_res , cumulated_image_lookup_table_high_res , lookup_table_averaged_spectrum_high_res , array_peaks_corrected , array_corrective_factors , )","title":"Lookup tables"},{"location":"modules/tools/lookup_tables/#modules.tools.lookup_tables.build_cumulated_image_lookup_table","text":"This function builds a lookup table to map the mz values to the image consisting of cumulated spectrum (for each pixel) until this mz value. Parameters: Name Type Description Default array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required img_shape tuple(int A tuple or arrays of 2 integers describing the shape of the acquisition. required divider_lookup int Sets the resolution of the lookup table. The bigger it is, the bigger the increments between two successive lookups. Must be consistent across lookup tables. required size_spectrum int The total size of the spectrum indexed by the lookup. Defaults to 2000, corresponding to an indexed spectrum ranging from 0 m/z to 2000 m/z. 2000 Returns: Type Description np . ndarray An array of shape (size_spectrum// divider_lookup, image height, image_width), mapping m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. Source code in modules/tools/lookup_tables.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 @njit def build_cumulated_image_lookup_table ( array_spectra , array_pixel_indexes , img_shape , divider_lookup , size_spectrum = 2000 ): \"\"\"This function builds a lookup table to map the mz values to the image consisting of cumulated spectrum (for each pixel) until this mz value. Args: array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. img_shape (tuple(int)): A tuple or arrays of 2 integers describing the shape of the acquisition. divider_lookup (int): Sets the resolution of the lookup table. The bigger it is, the bigger the increments between two successive lookups. Must be consistent across lookup tables. size_spectrum (int): The total size of the spectrum indexed by the lookup. Defaults to 2000, corresponding to an indexed spectrum ranging from 0 m/z to 2000 m/z. Returns: (np.ndarray): An array of shape (size_spectrum// divider_lookup, image height, image_width), mapping m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. \"\"\" # Define the empty array for the lookup table image_lookup_table = np . zeros ( ( size_spectrum // divider_lookup , img_shape [ 0 ], img_shape [ 1 ]), dtype = np . float32 ) image_lookup_table [ 0 , :] = np . zeros (( img_shape [ 0 ], img_shape [ 1 ]), dtype = np . float32 ) for idx_pix in range ( array_pixel_indexes . shape [ 0 ]): j = array_pixel_indexes [ idx_pix , 0 ] # If current pixel contains no peak, just skip to next one and add nothing if j == - 1 : continue pix_value = 0 coor_pix = convert_spectrum_idx_to_coor ( idx_pix , img_shape ) # Loop over lookup indexes for index_lookup in range ( size_spectrum // divider_lookup - 1 ): # Find the first mz index corresponding to current lookup for current pixel # (skipped if current mz>lookup) while array_spectra [ 0 , j ] >= ( index_lookup * divider_lookup ) and array_spectra [ 0 , j ] < ( ( index_lookup + 1 ) * divider_lookup ): pix_value += array_spectra [ 1 , j ] j += 1 if j == array_pixel_indexes [ idx_pix , 1 ] + 1 : break # Check that we're still in the good pixel and add mz index to lookup if j < array_pixel_indexes [ idx_pix , 1 ] + 1 : image_lookup_table [ index_lookup + 1 , coor_pix [ 0 ], coor_pix [ 1 ]] = pix_value # If we're not in the requested pixel, this means that the while loop was exited because # the lookup didn't exist, so we fill the rest of the table with biggest possible value else : for i in range ( index_lookup + 1 , size_spectrum // divider_lookup ): image_lookup_table [ i , coor_pix [ 0 ], coor_pix [ 1 ]] = pix_value break return image_lookup_table","title":"build_cumulated_image_lookup_table()"},{"location":"modules/tools/lookup_tables/#modules.tools.lookup_tables.build_index_lookup_table","text":"This function builds a lookup table to map mz values to indexes in array_spectra. In practice, for each pixel, the lookup table gives the first index of mz such that mz>=lookup divider_lookup. If no such mz exists, the lookup table gives last possible mz index (i.e. biggest possible mz for the current pixel, but under the lookup). If lookup divider_lookup is smaller than the smallest mz, it returns the first mz index possible for the current pixel, above the current lookup. If there are no peak at all in the spectrum... it returns -1. Parameters: Name Type Description Default array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required divider_lookup int Sets the resolution of the lookup table. The bigger it is, the bigger the increments between two successive lookups. Must be consistent across lookup tables. required size_spectrum int The total size of the spectrum indexed by the lookup. Defaults to 2000, corresponding to an indexed spectrum ranging from 0 m/z to 2000 m/z. 2000 Returns: Type Description np . ndarray An array of shape (size_spectrum// divider_lookup, m), mapping m/z values to indexes in array_spectra for each pixel. Source code in modules/tools/lookup_tables.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 @njit def build_index_lookup_table ( array_spectra , array_pixel_indexes , divider_lookup , size_spectrum = 2000 ): \"\"\"This function builds a lookup table to map mz values to indexes in array_spectra. In practice, for each pixel, the lookup table gives the first index of mz such that mz>=lookup*divider_lookup. If no such mz exists, the lookup table gives last possible mz index (i.e. biggest possible mz for the current pixel, but under the lookup). If lookup*divider_lookup is smaller than the smallest mz, it returns the first mz index possible for the current pixel, above the current lookup. If there are no peak at all in the spectrum... it returns -1. Args: array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. divider_lookup (int): Sets the resolution of the lookup table. The bigger it is, the bigger the increments between two successive lookups. Must be consistent across lookup tables. size_spectrum (int): The total size of the spectrum indexed by the lookup. Defaults to 2000, corresponding to an indexed spectrum ranging from 0 m/z to 2000 m/z. Returns: (np.ndarray): An array of shape (size_spectrum// divider_lookup, m), mapping m/z values to indexes in array_spectra for each pixel. \"\"\" # Define the empty array for the lookup table lookup_table = np . zeros ( ( size_spectrum // divider_lookup , array_pixel_indexes . shape [ 0 ]), dtype = np . int32 ) lookup_table [ 0 , :] = array_pixel_indexes [:, 0 ] # Loop over pixel indexes for idx_pix in range ( array_pixel_indexes . shape [ 0 ]): j = array_pixel_indexes [ idx_pix , 0 ] # If there's no peak for the current pixel, lookup is -1 if j == - 1 : for i in range ( size_spectrum // divider_lookup ): lookup_table [ i , idx_pix ] = - 1 # Loop over lookup indexes for index_lookup in range ( size_spectrum // divider_lookup - 1 ): # First find the first mz index corresponding to current lookup for current pixel # (skipped if current mz>lookup) while array_spectra [ 0 , j ] < (( index_lookup + 1 ) * divider_lookup ): j += 1 if j == array_pixel_indexes [ idx_pix , 1 ] + 1 : break # Check that we're still in the requested pixel and add mz index to lookup if j < array_pixel_indexes [ idx_pix , 1 ] + 1 : lookup_table [ index_lookup + 1 , idx_pix ] = j # If we're not in the requested pixel, this means that the while loop was exited because # the lookup didn't exist, so we fill the rest of the table with biggest possible value else : for i in range ( index_lookup + 1 , size_spectrum // divider_lookup ): lookup_table [ i , idx_pix ] = j - 1 break return lookup_table","title":"build_index_lookup_table()"},{"location":"modules/tools/lookup_tables/#modules.tools.lookup_tables.build_index_lookup_table_averaged_spectrum","text":"This function builds a lookup table identical to the one defined in build_index_lookup_table(), except that this one maps mz values to indexes in the averaged array_spectra (across all pixels). Parameters: Name Type Description Default array_mz np . ndarray The m/z array of the averaged array spectra (i.e. row 0). required size_spectrum int The total size of the spectrum indexed by the lookup. Defaults to 2000, corresponding to an averaged indexed spectrum ranging from 0 m/z to 2000 m/z. 2000 Returns: Type Description np . ndarray An array of length size_spectrum (i.e. the defaults divider_lookup is 1 for this array), mapping m/z values to indexes in the averaged array_spectra. Source code in modules/tools/lookup_tables.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 @njit def build_index_lookup_table_averaged_spectrum ( array_mz , size_spectrum = 2000 ): \"\"\"This function builds a lookup table identical to the one defined in build_index_lookup_table(), except that this one maps mz values to indexes in the averaged array_spectra (across all pixels). Args: array_mz (np.ndarray): The m/z array of the averaged array spectra (i.e. row 0). size_spectrum (int): The total size of the spectrum indexed by the lookup. Defaults to 2000, corresponding to an averaged indexed spectrum ranging from 0 m/z to 2000 m/z. Returns: (np.ndarray): An array of length size_spectrum (i.e. the defaults divider_lookup is 1 for this array), mapping m/z values to indexes in the averaged array_spectra. \"\"\" # Define the empty array for the lookup table lookup_table = np . empty (( size_spectrum ), dtype = np . int32 ) j = 0 lookup_table [ 0 ] = 0 # Loop over lookup indexes for index_lookup in range ( size_spectrum - 1 ): # Find the first mz index corresponding to current lookup for current pixel while array_mz [ j ] < index_lookup + 1 : j += 1 if j == array_mz . shape [ 0 ]: break # Add the lookup to the table if it exists if j < array_mz . shape [ 0 ]: lookup_table [ index_lookup + 1 ] = j # If the lookup doesn't exist, so we fill the rest of the table with biggest possible m/z # value else : for i in range ( index_lookup + 1 , size_spectrum ): lookup_table [ i ] = j - 1 break return lookup_table","title":"build_index_lookup_table_averaged_spectrum()"},{"location":"modules/tools/lookup_tables/#modules.tools.lookup_tables.process_lookup_tables","text":"This function has been implemented to allow the paralellization of lookup tables processing. It computes and returns/saves the lookup tables for each slice. The output consists of: - array_pixel_indexes_high_res: np.nddaray of shape (n,2), it maps each pixel to two array_spectra_high_res indices, delimiting the corresponding spectrum. - array_spectra_high_res: np.nddaray of shape (2,m), it contains the concatenated spectra of each pixel. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_low_res: np.nddaray of shape (2, k), it contains the low-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_high_res: Same as array_averaged_mz_intensity_low_res, but in higher resolution, with, therefore, a different shape. - image_shape: a tuple of integers, indicating the vertical and horizontal size of the corresponding slice. - divider_lookup: integer that sets the resolution of the lookup tables. - lookup_table_spectra_high_res: np.nddaray of shape (size_spectrum// divider_lookup, m), it maps m/z values to indexes in array_spectra for each pixel. - cumulated_image_lookup_table_high_res: np.nddaray of shape (size_spectrum // divider_lookup, image height, image_width), it maps m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. - lookup_table_averaged_spectrum_high_res: np.nddaray of length size_spectrum, it maps m/z values to indexes in the averaged array_spectra for each pixel. - array_peaks_corrected: A two-dimensional array containing the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. - array_corrective_factors: A three-dimensional numpy array equal to the ratio of 'arrays_after_transfo' and 'arrays_before_transfo' containing the corrective factor used for lipid (first dimension) and each pixel (second and third dimension). Parameters: Name Type Description Default t_index_path tuple(int, str A tuple containing the index of the slice (starting from 1) and the corresponding path for the raw data. required temp_path str Path to load/save the output npz file. Defaults to \"/data/lipidatlas/data/app/data/temp/\". '/data/lipidatlas/data/app/data/temp/' l_arrays_raw_data list A list of arrays containing the data that is processed in the current function. If None, the same arrays must be loaded from the disk. Defaults to None. None load_from_file bool If True, the arrays containing the data processed by the current function are loaded from the disk. If False, the corresponding arrays must be provided through the parameter l_arrays_raw_data. Defaults to True. True save bool If True, output arrays are saved in a npz file. Defaults to True. True return_result bool If True, output arrays are returned by the function. Defaults to False. False Returns: Type Description Depending on 'return result', returns either nothing, either several np.ndarrays, described above. Source code in modules/tools/lookup_tables.py 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 def process_lookup_tables ( t_index_path , temp_path = \"/data/lipidatlas/data/app/data/temp/\" , # \"notebooks/data_processing/data/temp/\", l_arrays_raw_data = None , load_from_file = True , save = True , return_result = False , ): \"\"\"This function has been implemented to allow the paralellization of lookup tables processing. It computes and returns/saves the lookup tables for each slice. The output consists of: - array_pixel_indexes_high_res: np.nddaray of shape (n,2), it maps each pixel to two array_spectra_high_res indices, delimiting the corresponding spectrum. - array_spectra_high_res: np.nddaray of shape (2,m), it contains the concatenated spectra of each pixel. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_low_res: np.nddaray of shape (2, k), it contains the low-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_high_res: Same as array_averaged_mz_intensity_low_res, but in higher resolution, with, therefore, a different shape. - image_shape: a tuple of integers, indicating the vertical and horizontal size of the corresponding slice. - divider_lookup: integer that sets the resolution of the lookup tables. - lookup_table_spectra_high_res: np.nddaray of shape (size_spectrum// divider_lookup, m), it maps m/z values to indexes in array_spectra for each pixel. - cumulated_image_lookup_table_high_res: np.nddaray of shape (size_spectrum // divider_lookup, image height, image_width), it maps m/z values to the cumulated spectrum until the corresponding m/z value for each pixel. - lookup_table_averaged_spectrum_high_res: np.nddaray of length size_spectrum, it maps m/z values to indexes in the averaged array_spectra for each pixel. - array_peaks_corrected: A two-dimensional array containing the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. - array_corrective_factors: A three-dimensional numpy array equal to the ratio of 'arrays_after_transfo' and 'arrays_before_transfo' containing the corrective factor used for lipid (first dimension) and each pixel (second and third dimension). Args: t_index_path (tuple(int, str)): A tuple containing the index of the slice (starting from 1) and the corresponding path for the raw data. temp_path (str, optional): Path to load/save the output npz file. Defaults to \"/data/lipidatlas/data/app/data/temp/\". l_arrays_raw_data (list, optional): A list of arrays containing the data that is processed in the current function. If None, the same arrays must be loaded from the disk. Defaults to None. load_from_file (bool, optional): If True, the arrays containing the data processed by the current function are loaded from the disk. If False, the corresponding arrays must be provided through the parameter l_arrays_raw_data. Defaults to True. save (bool, optional): If True, output arrays are saved in a npz file. Defaults to True. return_result (bool, optional): If True, output arrays are returned by the function. Defaults to False. Returns: Depending on 'return result', returns either nothing, either several np.ndarrays, described above. \"\"\" if l_arrays_raw_data is not None : raise ValueError ( \"Arrays must be loaded from file from now on.\" ) elif load_from_file : # Get slice path slice_index = t_index_path [ 0 ] name = t_index_path [ 1 ] # Correct temp path if \"MouseBrain2\" in name : temp_path += \"brain_2/\" else : temp_path += \"brain_1/\" path = temp_path + \"slice_\" + str ( slice_index ) + \".npz\" npzfile = np . load ( path ) # Load individual arrays array_pixel_indexes_high_res = npzfile [ \"array_pixel_indexes_high_res\" ] array_spectra_high_res = npzfile [ \"array_spectra_high_res\" ] array_averaged_mz_intensity_low_res = npzfile [ \"array_averaged_mz_intensity_low_res\" ] array_averaged_mz_intensity_high_res = npzfile [ \"array_averaged_mz_intensity_high_res\" ] array_averaged_mz_intensity_high_res_after_standardization = npzfile [ \"array_averaged_mz_intensity_high_res_after_standardization\" ] image_shape = npzfile [ \"image_shape\" ] array_peaks_corrected = npzfile [ \"array_peaks_corrected\" ] array_corrective_factors = npzfile [ \"array_corrective_factors\" ] # Try to see if the array has already been processed before if \"divider_lookup\" in npzfile : print ( \"This file has already been processed before\" ) return None else : print ( \"Either the data or a filename must be provided\" ) return None # Define divider_lookup divider_lookup = DIVIDER_LOOKUP # Build lookup table linking mz value to index in array_spectra for each pixel lookup_table_spectra_high_res = build_index_lookup_table ( array_spectra_high_res , array_pixel_indexes_high_res , divider_lookup ) print ( \"Size (in mb) of lookup_table_spectra_high_res: \" , round ( lookup_table_spectra_high_res . nbytes / 1024 / 1024 , 2 ), ) print ( \"Shape of lookup_table_spectra_high_res: \" , lookup_table_spectra_high_res . shape ) # Build lookup table of the cumulated spectrum for each pixel cumulated_image_lookup_table_high_res = build_cumulated_image_lookup_table ( array_spectra_high_res , array_pixel_indexes_high_res , image_shape , divider_lookup ) print ( \"Size (in mb) of cumulated_image_lookup_table_high_res: \" , round ( cumulated_image_lookup_table_high_res . nbytes / 1024 / 1024 , 2 ), ) print ( \"Shape of cumulated_image_lookup_table_high_res: \" , cumulated_image_lookup_table_high_res . shape , ) # Extend averaged arrays with zeros for nicer display array_averaged_mz_intensity_low_res , _ = add_zeros_to_spectrum ( array_averaged_mz_intensity_low_res , pad_individual_peaks = True ) array_averaged_mz_intensity_high_res , _ = add_zeros_to_spectrum ( array_averaged_mz_intensity_high_res , pad_individual_peaks = True ) array_averaged_mz_intensity_high_res_after_standardization , _ = add_zeros_to_spectrum ( array_averaged_mz_intensity_high_res_after_standardization , pad_individual_peaks = True ) # Build lookup table to compute fast the indexes corresponding to the boundaries selected in app lookup_table_averaged_spectrum_high_res = build_index_lookup_table_averaged_spectrum ( array_mz = array_averaged_mz_intensity_high_res [ 0 , :] ) print ( \"Size (in mb) of lookup_table_averaged_spectrum_high_res: \" , round ( lookup_table_averaged_spectrum_high_res . nbytes / 1024 / 1024 , 2 ), ) print ( \"Shape of lookup_table_averaged_spectrum_high_res: \" , lookup_table_averaged_spectrum_high_res . shape , ) if save : # Save as npz file print ( \"Saving...\" ) np . savez ( path , array_pixel_indexes_high_res = array_pixel_indexes_high_res , array_spectra_high_res = array_spectra_high_res , array_averaged_mz_intensity_low_res = array_averaged_mz_intensity_low_res , array_averaged_mz_intensity_high_res = array_averaged_mz_intensity_high_res , array_averaged_mz_intensity_high_res_after_standardization = array_averaged_mz_intensity_high_res_after_standardization , image_shape = image_shape , divider_lookup = divider_lookup , lookup_table_spectra_high_res = lookup_table_spectra_high_res , cumulated_image_lookup_table_high_res = cumulated_image_lookup_table_high_res , lookup_table_averaged_spectrum_high_res = lookup_table_averaged_spectrum_high_res , array_peaks_corrected = array_peaks_corrected , array_corrective_factors = array_corrective_factors , ) # Returns all array if needed if return_result : return ( array_pixel_indexes_high_res , array_spectra_high_res , array_averaged_mz_intensity_low_res , array_averaged_mz_intensity_high_res , array_averaged_mz_intensity_high_res_after_standardization , image_shape , divider_lookup , lookup_table_spectra_high_res , cumulated_image_lookup_table_high_res , lookup_table_averaged_spectrum_high_res , array_peaks_corrected , array_corrective_factors , )","title":"process_lookup_tables()"},{"location":"modules/tools/maldi_conversion/","text":"This file contains functions used to convert the raw MALDI data to easily readable Numpy arrays. compute_TIC_per_pixel ( array_spectra , n_pixels ) This function computes the Total Ion Content (TIC) per pixel of the raw data. Parameters: Name Type Description Default array_spectra np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity). required n_pixels int Number of pixels in the acquisition. required Returns: Type Description np . ndarray A numpy array of len n_pixels containing the TIC for each pixel. Source code in modules/tools/maldi_conversion.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 @njit def compute_TIC_per_pixel ( array_spectra , n_pixels ): \"\"\"This function computes the Total Ion Content (TIC) per pixel of the raw data. Args: array_spectra (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity). n_pixels (int): Number of pixels in the acquisition. Returns: (np.ndarray): A numpy array of len n_pixels containing the TIC for each pixel. \"\"\" array_TIC = np . zeros (( n_pixels ,), dtype = np . float32 ) for i in range ( array_spectra . shape [ 0 ]): pix_idx , mz , intensity = array_spectra [ i ] array_TIC [ int ( pix_idx )] += intensity return array_TIC compute_standardization ( array_spectra_pixel , idx_pixel , array_peaks , arrays_before_transfo , arrays_after_transfo ) This function takes the spectrum data of a given pixel, along with the corresponding pixel index, and transforms the value of the lipids intensities annotated in 'array_peaks' according to the transformation made in 'arrays_before_transfo' and 'arrays_after_transfo'. Parameters: Name Type Description Default array_spectra_pixel np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity) of pixel 'idx_pixel', sorted by mz. required idx_pixel int Index of the current pixel whose spectrum is transformed. required array_peaks np . ndarray A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), filtered for the lipids who have preliminarily been transformed. Sorted by min_mz. required arrays_before_transfo np . ndarray A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, before these intensities were transformed. required arrays_after_transfo np . ndarray A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, after these intensities were transformed. required Raises: Type Description Exception description Returns: Type Description np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity), of pixel 'idx_pixel', sorted by mz, with lipids values transformed. Source code in modules/tools/maldi_conversion.py 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 @njit def compute_standardization ( array_spectra_pixel , idx_pixel , array_peaks , arrays_before_transfo , arrays_after_transfo ): \"\"\"This function takes the spectrum data of a given pixel, along with the corresponding pixel index, and transforms the value of the lipids intensities annotated in 'array_peaks' according to the transformation made in 'arrays_before_transfo' and 'arrays_after_transfo'. Args: array_spectra_pixel (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity) of pixel 'idx_pixel', sorted by mz. idx_pixel (int): Index of the current pixel whose spectrum is transformed. array_peaks (np.ndarray): A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), filtered for the lipids who have preliminarily been transformed. Sorted by min_mz. arrays_before_transfo (np.ndarray): A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, before these intensities were transformed. arrays_after_transfo (np.ndarray): A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, after these intensities were transformed. Raises: Exception: _description_ Returns: (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity), of pixel 'idx_pixel', sorted by mz, with lipids values transformed. \"\"\" # Define initial values idx_peak = 0 idx_mz = 0 n_peaks_transformed = 0 while idx_mz < array_spectra_pixel . shape [ 0 ] and idx_peak < array_peaks . shape [ 0 ]: idx_pix , mz , intensity = array_spectra_pixel [ idx_mz ] min_mz , max_mz , n_pix , mz_estimated = array_peaks [ idx_peak ] # New window has been discovered if mz >= min_mz and mz <= max_mz : idx_min_mz = idx_mz idx_max_mz = idx_mz for idx_mz in range ( idx_min_mz , array_spectra_pixel . shape [ 0 ]): idx_pix , mz , intensity = array_spectra_pixel [ idx_mz ] if mz > max_mz : idx_max_mz = idx_mz - 1 break # Most likely, the annotation doesn't exist, so skip it if np . abs ( idx_max_mz - idx_min_mz ) <= 0.9 : pass # Else compute a multiplicative factor else : # Get array of intensity before and after correction for current pixel intensity_before = arrays_before_transfo [ idx_peak ] . flatten ()[ idx_pixel ] intensity_after = arrays_after_transfo [ idx_peak ] . flatten ()[ idx_pixel ] # Compute sum of expression between limits integral = np . sum ( array_spectra_pixel [ idx_min_mz : idx_max_mz + 1 , 2 ]) # Assess that this sum is equal to the one precomputed with MAIA if np . abs ( integral - intensity_before ) > 10 **- 4 and ( idx_max_mz - idx_min_mz ) > 1 : print ( \"There seems to be a problem with the computation of the integral\" ) print ( integral , intensity_before ) print ( idx_min_mz , idx_max_mz ) else : # print(integral, intensity_before) # print(idx_min_mz, idx_max_mz) pass # To avoid division by 0 (altough it shouldn't happen) if intensity_before == 0 : intensity_before = 1 correction = intensity_after / intensity_before # Correct for negative values for very small corrections if correction < 0 : correction = 0 # Multiply all intensities in the window by the corrective coefficient array_spectra_pixel [ idx_min_mz : idx_max_mz + 1 , 2 ] *= correction n_peaks_transformed += 1 # Move on to the next peak idx_peak += 1 else : if mz > max_mz : idx_peak += 1 else : idx_mz += 1 return array_spectra_pixel , n_peaks_transformed extract_raw_data ( t_index_path , save = True , output_path = '/data/lipidatlas/data/app/data/temp/' ) This function loads the raw maldi data and turns it into a python friendly numpy array, along with a given shape for the acquisition. Parameters: Name Type Description Default t_index_path tuple(int, str A tuple containing the index of the slice (starting from 1)and the corresponding path for the raw data. required save bool If True, arrays for the extracted data are saved in a npz file. Defaults to True (only option implemented for now for the rest of the pipeline). True output_path str Path to save the output npz file. Defaults to \"/data/lipidatlas/data/app/data/temp/\". '/data/lipidatlas/data/app/data/temp/' Returns: Type Description np . ndarray , np . ndarray The first array, of shape (3,n), contains, for the current acquisition, the mz value (2nd column) and intensity (3rd column) for each pixel (first column). The second array contains two integers representing the acquisition shape. Source code in modules/tools/maldi_conversion.py 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 def extract_raw_data ( t_index_path , save = True , output_path = \"/data/lipidatlas/data/app/data/temp/\" , ): \"\"\"This function loads the raw maldi data and turns it into a python friendly numpy array, along with a given shape for the acquisition. Args: t_index_path (tuple(int, str)): A tuple containing the index of the slice (starting from 1)and the corresponding path for the raw data. save (bool, optional): If True, arrays for the extracted data are saved in a npz file. Defaults to True (only option implemented for now for the rest of the pipeline). output_path (str, optional): Path to save the output npz file. Defaults to \"/data/lipidatlas/data/app/data/temp/\". Returns: (np.ndarray, np.ndarray): The first array, of shape (3,n), contains, for the current acquisition, the mz value (2nd column) and intensity (3rd column) for each pixel (first column). The second array contains two integers representing the acquisition shape. \"\"\" try : # Get slice path slice_index = t_index_path [ 0 ] name = t_index_path [ 1 ] # Correct output path if \"MouseBrain2\" in name : output_path += \"brain_2/\" else : output_path += \"brain_1/\" # Load file in high and low resolution print ( \"Loading files : \" + name ) smz_high_res = load_file ( name , resolution = 1e-5 ) image_shape = smz_high_res . img_shape # Load df with different sortings (low_res will be averaged over m/z afterwards) print ( \"Creating and sorting dataframes\" ) df_high_res = process_sparse_matrix ( smz_high_res , sort = \"m/z\" ) # Convert df into arrays for easier manipulation with numba array_high_res = df_high_res . to_numpy () if save : np . savez ( output_path + \"slice_\" + str ( slice_index ) + \"raw.npz\" , array_high_res = array_high_res , image_shape = image_shape , ) return array_high_res , image_shape except : return None filter_peaks ( array_spectra , array_peaks , array_mz_lipids_per_slice ) This function is used to filter out all the spectrum data in 'array_spectra' that has not been annotated as peak in 'array_peaks' and that do not belong to 'array_mz_lipids_per_slice'. Parameters: Name Type Description Default array_spectra np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity), sorted by mz (but not necessarily by pixel index). required array_peaks np . ndarray A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), sorted by min_mz. required array_mz_lipids_per_slice np . ndarray A 1-D numpy array containing the per-slice mz values of the lipids we want to visualize. required Returns: Type Description list m/z values corresponding to peaks that have been annotated and belong to lipids we want to visualize. list m/z values of the lipids the lipids we want to visualize that have been kept. Source code in modules/tools/maldi_conversion.py 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 @njit def filter_peaks ( array_spectra , array_peaks , array_mz_lipids_per_slice ): \"\"\"This function is used to filter out all the spectrum data in 'array_spectra' that has not been annotated as peak in 'array_peaks' and that do not belong to 'array_mz_lipids_per_slice'. Args: array_spectra (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity), sorted by mz (but not necessarily by pixel index). array_peaks (np.ndarray): A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), sorted by min_mz. array_mz_lipids_per_slice (np.ndarray): A 1-D numpy array containing the per-slice mz values of the lipids we want to visualize. Returns: (list): m/z values corresponding to peaks that have been annotated and belong to lipids we want to visualize. (list): m/z values of the lipids the lipids we want to visualize that have been kept. \"\"\" # Define initial values l_to_keep = [] idx_peak = 0 idx_curr_mz = 0 idx_lipid = 0 l_n_pix = [] mz_lipid = array_mz_lipids_per_slice [ idx_lipid ] l_mz_lipids_kept = [] # Need to initialize the set with an int inside and then delete it because numba is retarded set_pix = { 0 } set_pix . remove ( 0 ) while idx_curr_mz < array_spectra . shape [ 0 ] and idx_peak < array_peaks . shape [ 0 ]: idx_pix , mz , intensity = array_spectra [ idx_curr_mz ] min_mz , max_mz , n_pix , mz_estimated = array_peaks [ idx_peak ] # Either we are before the current window if mz <= min_mz : idx_curr_mz += 1 # Either current mz is in the current window elif mz >= min_mz and mz <= max_mz : # Adapt the index of the current lipid while mz_lipid < min_mz and idx_lipid < array_mz_lipids_per_slice . shape [ 0 ]: idx_lipid += 1 mz_lipid = array_mz_lipids_per_slice [ idx_lipid ] # If we've explored all lipids already, exit the loop if idx_lipid == array_mz_lipids_per_slice . shape [ 0 ]: break # If mz lipid is not in the current peak, move on to the next if mz_lipid > max_mz or np . abs ( mz_estimated - mz_lipid ) > 2 * 10 **- 4 : idx_peak += 1 l_n_pix . append ( len ( set_pix )) set_pix . clear () else : # mz belong to a lipid we want to visualize l_to_keep . append ( idx_curr_mz ) set_pix . add ( idx_pix ) idx_curr_mz += 1 if len ( l_mz_lipids_kept ) == 0 : l_mz_lipids_kept . append ( mz_lipid ) elif mz_lipid != l_mz_lipids_kept [ - 1 ]: l_mz_lipids_kept . append ( mz_lipid ) # Either we're beyond, in which cas we move the window, and record the number of unique # pixels in the window for later check else : idx_peak += 1 l_n_pix . append ( len ( set_pix )) set_pix . clear () # * This piece of code is commented because it is not usable as such since the introduction of # * array_mz_lipids_per_slice as argument in the function, but it should still work if molecules # * not belonging to array_mz_lipids_per_slice are not excluded # if verbose: # # Check that the pixel recorded are identical to the expected number of pixels recorded # print( # \"Difference between number of recorded pixels\", # np.sum(np.array(l_n_pix) - array_peaks[:, 2]), # ) # print(np.array(l_n_pix)[-10:]) # print(array_peaks[-10:, 2]) return l_to_keep , l_mz_lipids_kept get_array_peaks_to_correct ( l_lipids_float , array_mz_lipids , array_peaks , slice_index = None ) This function computes an array similar to 'array_peaks', but containing only the lipids that have been MAIA-transformed. Parameters: Name Type Description Default l_lipids_float list A list containing the estimated m/z values of the lipids we want to visualize. required array_mz_lipids np . ndarray A 1-D numpy array containing the per-slice mz values of the lipids we want to visualize. required array_peaks np . ndarray A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), sorted by min_mz. required Returns: Type Description np . ndarray A numpy array similar to 'array_peaks', but containing only the lipids that have been MAIA-transformed. Source code in modules/tools/maldi_conversion.py 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 def get_array_peaks_to_correct ( l_lipids_float , array_mz_lipids , array_peaks , slice_index = None ): \"\"\"This function computes an array similar to 'array_peaks', but containing only the lipids that have been MAIA-transformed. Args: l_lipids_float (list): A list containing the estimated m/z values of the lipids we want to visualize. array_mz_lipids (np.ndarray): A 1-D numpy array containing the per-slice mz values of the lipids we want to visualize. array_peaks (np.ndarray): A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), sorted by min_mz. Returns: (np.ndarray): A numpy array similar to 'array_peaks', but containing only the lipids that have been MAIA-transformed. \"\"\" # Low precision as the reference can be quite different from the actual m/z value estimated precision = 5 * 10 **- 3 # First get the list of mz of the current slice l_lipids_float_correct = [] for mz_lipid in l_lipids_float : found = False # Find the closest value in the whole array of annotations idx_closest_value = ( np . abs ( array_mz_lipids [:, 1 ] - mz_lipid )) . argmin () mz_per_slice , mz_avg = array_mz_lipids [ idx_closest_value ] diff = np . abs ( mz_avg - mz_lipid ) if diff <= precision : l_lipids_float_correct . append ( mz_per_slice ) found = True if not found : print ( \"Could not find the annotation of the lipid {} in df_match.csv\" . format ( mz_lipid )) print ( \"Closest mz value found was {} \" . format ( mz_avg )) if slice_index is not None : print ( \"Slice index was {} \" . format ( slice_index - 1 )) raise Exception # for mz_per_slice, mz_avg in array_mz_lipids: # if np.abs(mz_avg - mz_lipid) <= precision: # found = True # l_lipids_float_correct.append(mz_per_slice) # break # if not found: # raise Exception(\"No lipid could be found for foldername with mz = \" + str(mz_lipid)) # keep only the peak annotation that correspond to the lipids which have been transformed rows_to_keep = [] # Take higher precision as values should be perfectly identical here precision = 10 **- 4 for mz_lipid in l_lipids_float_correct : found = False for idx , [ mini , maxi , npix , mz_est ] in enumerate ( array_peaks ): if np . abs ( mz_est - mz_lipid ) <= precision : found = True rows_to_keep . append ( idx ) break if not found : print ( \"Lipid with foldername with mz = \" + str ( mz_lipid ) + \" was in df_match.csv but not in ranges.csv\" ) if slice_index is not None : print ( \"Slice index was {} \" . format ( slice_index - 1 )) raise Exception array_peaks_to_correct = array_peaks [ rows_to_keep ] return array_peaks_to_correct get_standardized_values ( slice_index , path_array_data , path_array_transformed_data , remove_non_existing = True ) This function loads the values of the intensities of the the lipids whose expression have been previously corrected using MAIA. Parameters: Name Type Description Default slice_index int Index of the current acquisition. required path_array_data str Path of the lipid intensities before transformation. Defaults to \"/data/lipidatlas/data/processed/BRAIN1\". required path_array_transformed_data str Path of the lipid intensities after transformation. Defaults to \"/data/lipidatlas/data/processed/BRAIN1_normalized\". required Raises: Type Description ValueError Some lipids have been transformed but the initial (untransformed) expression data is missing. Returns: Type Description list , list , np . array , np . array 2 lists and 2 arrays containing respectively: - The name of the folders containing the transformed lipid expression. The name is a string representing the mz value itself. - The corresponding mz values as floats. - The array of expression before transformation (having the same shape as the original acquisition). - The array of expression after transformation (having the same shape as the original acquisition). Source code in modules/tools/maldi_conversion.py 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 def get_standardized_values ( slice_index , path_array_data , path_array_transformed_data , remove_non_existing = True , ): \"\"\"This function loads the values of the intensities of the the lipids whose expression have been previously corrected using MAIA. Args: slice_index (int): Index of the current acquisition. path_array_data (str, optional): Path of the lipid intensities before transformation. Defaults to \"/data/lipidatlas/data/processed/BRAIN1\". path_array_transformed_data (str, optional): Path of the lipid intensities after transformation. Defaults to \"/data/lipidatlas/data/processed/BRAIN1_normalized\". Raises: ValueError: Some lipids have been transformed but the initial (untransformed) expression data is missing. Returns: (list, list, np.array, np.array): 2 lists and 2 arrays containing respectively: - The name of the folders containing the transformed lipid expression. The name is a string representing the mz value itself. - The corresponding mz values as floats. - The array of expression before transformation (having the same shape as the original acquisition). - The array of expression after transformation (having the same shape as the original acquisition). \"\"\" # First get list of lipids for which a transformation has been applied l_lipids_str = os . listdir ( path_array_data ) l_lipids_str_transformed = os . listdir ( path_array_transformed_data ) # Return empty lists if no MALDI files exist yet if len ( l_lipids_str ) == 0 and len ( l_lipids_str_transformed ) == 0 : return [], [], np . array ([], dtype = np . float32 ), np . array ([], dtype = np . float32 ) # Keep only lipid that have been transformed l_lipids_str = [ x for x in l_lipids_str if x in l_lipids_str_transformed ] # Assess that the two lists are identical if l_lipids_str != l_lipids_str_transformed : raise ValueError ( \"The lipids before and after transformation are not the same\" ) # Convert filename to float mz value l_lipids_float = [ float ( x ) for x in l_lipids_str ] # Sort the two lists by increasing m/z l_lipids_str , l_lipids_float = zip ( * sorted ( zip ( l_lipids_str , l_lipids_float ))) # Get the corresponding numpy arrays l_arrays_before_transfo = [] l_arrays_after_transfo = [] set_idx_to_keep = set ([]) for idx , lipid_str in enumerate ( l_lipids_str ): array_after_transfo = np . load ( path_array_transformed_data + \"/\" + lipid_str + \"/\" + str ( slice_index - 1 ) + \".npy\" ) if remove_non_existing : try : array_before_transfo = np . load ( path_array_data + \"/\" + lipid_str + \"/\" + str ( slice_index - 1 ) + \".npy\" ) except : # If the array doesn't exist, it means that the lipid doesn't exist for the current slice continue # Create an array of zeros instead else : try : array_before_transfo = np . load ( path_array_data + \"/\" + lipid_str + \"/\" + str ( slice_index - 1 ) + \".npy\" ) except : array_before_transfo = np . zeros_like ( array_after_transfo ) l_arrays_before_transfo . append ( array_before_transfo ) l_arrays_after_transfo . append ( array_after_transfo ) set_idx_to_keep . add ( idx ) return ( [ x for idx , x in enumerate ( l_lipids_str ) if idx in set_idx_to_keep ], [ x for idx , x in enumerate ( l_lipids_float ) if idx in set_idx_to_keep ], np . array ( l_arrays_before_transfo , dtype = np . float32 ), np . array ( l_arrays_after_transfo , dtype = np . float32 ), ) load_file ( path , resolution = 1e-05 ) This function loads the specified MALDI file from the raw data format (.mzML and .UDP) with the given resolution, and turns it into a scipy sparse matrix. Parameters: Name Type Description Default path string The path of the file to load. required resolution float The resolution of the file to load. Defaults to 1e-5. 1e-05 Returns: Type Description scipy . sparse A sparse matrix containing the intensity for each m/z value. Source code in modules/tools/maldi_conversion.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def load_file ( path , resolution = 1e-5 ): \"\"\"This function loads the specified MALDI file from the raw data format (.mzML and .UDP) with the given resolution, and turns it into a scipy sparse matrix. Args: path (string): The path of the file to load. resolution (float, optional): The resolution of the file to load. Defaults to 1e-5. Returns: (scipy.sparse): A sparse matrix containing the intensity for each m/z value. \"\"\" # Check if imzML exists and load if possible if os . path . exists ( path + \".imzML\" ): smz = SmzMLobj ( path + \".ibd\" , path + \".imzML\" , mz_resolution = resolution ) smz . load ( load_unique_mz = True ) else : # Load object from SmzMLobj smz = SmzMLobj ( path + \".mzML\" , path + \".UDP\" , mz_resolution = resolution ) smz . load ( load_unique_mz = True ) # Compute shape of the spectra matrix to preload matrix smz . S . shape return smz load_lipid_file ( section_index , path ) This function loads a set of specific lipid annotations containing a molecule ID, the average mz for the molecule, the section index and potentially other information, from a csv file located at the provided path. It returns an array of mz values corresponding to the lipids we want to keep for further visualization. Parameters: Name Type Description Default section_index int The index of the current acquisition (first slice having index 1). required path string The path of the csv file containing the lipids annotations. required Returns: Type Description np . ndarray A two-dimensional array of m/z values corrsponding to the lipids that we want to keep for further visualization (first column is per-slice value, second column is averaged value). Sorted by individual slice value in the end. Source code in modules/tools/maldi_conversion.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 def load_lipid_file ( section_index , path ): \"\"\"This function loads a set of specific lipid annotations containing a molecule ID, the average mz for the molecule, the section index and potentially other information, from a csv file located at the provided path. It returns an array of mz values corresponding to the lipids we want to keep for further visualization. Args: section_index (int): The index of the current acquisition (first slice having index 1). path (string): The path of the csv file containing the lipids annotations. Returns: (np.ndarray): A two-dimensional array of m/z values corrsponding to the lipids that we want to keep for further visualization (first column is per-slice value, second column is averaged value). Sorted by individual slice value in the end. \"\"\" # Load the peaks annotations using the last definition used for the csv file df = pd . read_csv ( path , sep = \",\" ) # Drop the columns that we won't use afterwards df = df . drop ( [ \"molecule_ID\" , \"concentration\" , ], axis = 1 , ) # Keep only the current section df = df [ df [ \"section_ix\" ] == section_index - 1 ] # Return a numpy array of mz values sorted by first column array_mz_lipids = np . array ( df [[ \"mz_estimated\" , \"mz_estimated_total\" ]], dtype = np . float32 ) return array_mz_lipids [ np . argsort ( array_mz_lipids [:, 0 ])] load_peak_file ( path , array = True ) This function loads the peaks annotations (including matrix peaks) from a csv file located at the provided path. It returns a numpy array sorted by min peak value (m/z) annotation. Parameters: Name Type Description Default path string The path of the csv file containing the peaks annotations. required Returns: Type Description np . ndarray The sorted dataframe containing the annotations (min peak, max peak, number of pixels containing the current molecule, estimated mz of the current molecule). Source code in modules/tools/maldi_conversion.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 def load_peak_file ( path , array = True ): \"\"\"This function loads the peaks annotations (including matrix peaks) from a csv file located at the provided path. It returns a numpy array sorted by min peak value (m/z) annotation. Args: path (string): The path of the csv file containing the peaks annotations. Returns: (np.ndarray): The sorted dataframe containing the annotations (min peak, max peak, number of pixels containing the current molecule, estimated mz of the current molecule). \"\"\" # Load the peaks annotations using the last definition used for the csv file path = \"/\" . join ( path . split ( \"/\" )[: - 1 ]) + \"/ranges\" df = pd . read_csv ( path + \".csv\" , sep = \",\" ) # Drop the columns that we won't use afterwards df = df . drop ( [ \"Unnamed: 0\" , \"pixel_max_hits\" , \"percent_1_hit\" , \"concentration\" , \"median_intensity\" , \"difference\" , ], axis = 1 , ) # Sort by increasing m/z annotation for the peaks df = df . sort_values ( by = \"min\" , axis = 0 ) if array : return df . to_numpy () else : return df normalize_per_TIC_per_pixel ( array_spectra , array_TIC ) This function normalize each intensity value according to its (TIC), per pixel. Parameters: Name Type Description Default array_spectra np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity). required array_TIC np . ndarray A numpy array of len n_pixels containing the TIC for each pixel. required Returns: Type Description np . ndarray A numpy array containing TIC-normalized spectrum data (pixel index, m/z and intensity). Source code in modules/tools/maldi_conversion.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 @njit def normalize_per_TIC_per_pixel ( array_spectra , array_TIC ): \"\"\"This function normalize each intensity value according to its (TIC), per pixel. Args: array_spectra (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity). array_TIC (np.ndarray): A numpy array of len n_pixels containing the TIC for each pixel. Returns: (np.ndarray): A numpy array containing TIC-normalized spectrum data (pixel index, m/z and intensity). \"\"\" for i in range ( array_spectra . shape [ 0 ]): pix_idx , mz , intensity = array_spectra [ i ] array_spectra [ i , 2 ] /= array_TIC [ int ( pix_idx )] return array_spectra process_raw_data ( t_index_path , save = True , return_result = False , output_path = '/data/lipidatlas/data/app/data/temp/' , load_from_file = True ) This function has been implemented to allow the parallelization of slice processing. It turns the MALDI data into several numpy arrays and lookup tables: - array_pixel_indexes_high_res: A numpy array of shape (n,2), it maps each pixel to two array_spectra_high_res indices, delimiting the corresponding spectrum. - array_spectra_high_res: A numpy array of shape (2,m), it contains the concatenated spectra of each pixel. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_low_res: A numpy array of shape (2, k), it contains the low-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_high_res: Same as array_averaged_mz_intensity_low_res, but in higher resolution, with, therefore, a different shape. - array_averaged_mz_intensity_high_res_after_standardization: Same as array_averaged_mz_intensity_high_res, but before applying MAIA standardization. - image_shape: a tuple of integers, indicating the vertical and horizontal sizes of the corresponding slice. - array_peaks_corrected: A two-dimensional array containing the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, but only for the lipids that have been transformed. - array_corrective_factors: A three-dimensional numpy array equal to the ratio of 'arrays_after_transfo' and 'arrays_before_transfo' containing the corrective factor used for lipid (first dimension) and each pixel (second and third dimension). Parameters: Name Type Description Default t_index_path tuple(int, str A tuple containing the index of the slice (starting from 1) and the corresponding path for the raw data. required save bool If True, output arrays are saved in a npz file. Defaults to True. True return_result bool If True, output arrays are returned by the function. Defaults to False. False output_path str Path to save the output npz file. Defaults to \"/data/lipidatlas/data/app/data/temp/\". '/data/lipidatlas/data/app/data/temp/' load_from_file bool If True, loads the extracted data from npz file. Only option implemented for now. True Returns: Type Description Depending on 'return result', returns either nothing, either several np.ndarrays, described above. Source code in modules/tools/maldi_conversion.py 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 def process_raw_data ( t_index_path , save = True , return_result = False , output_path = \"/data/lipidatlas/data/app/data/temp/\" , load_from_file = True , ): \"\"\"This function has been implemented to allow the parallelization of slice processing. It turns the MALDI data into several numpy arrays and lookup tables: - array_pixel_indexes_high_res: A numpy array of shape (n,2), it maps each pixel to two array_spectra_high_res indices, delimiting the corresponding spectrum. - array_spectra_high_res: A numpy array of shape (2,m), it contains the concatenated spectra of each pixel. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_low_res: A numpy array of shape (2, k), it contains the low-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_high_res: Same as array_averaged_mz_intensity_low_res, but in higher resolution, with, therefore, a different shape. - array_averaged_mz_intensity_high_res_after_standardization: Same as array_averaged_mz_intensity_high_res, but before applying MAIA standardization. - image_shape: a tuple of integers, indicating the vertical and horizontal sizes of the corresponding slice. - array_peaks_corrected: A two-dimensional array containing the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, but only for the lipids that have been transformed. - array_corrective_factors: A three-dimensional numpy array equal to the ratio of 'arrays_after_transfo' and 'arrays_before_transfo' containing the corrective factor used for lipid (first dimension) and each pixel (second and third dimension). Args: t_index_path (tuple(int, str)): A tuple containing the index of the slice (starting from 1) and the corresponding path for the raw data. save (bool, optional): If True, output arrays are saved in a npz file. Defaults to True. return_result (bool, optional): If True, output arrays are returned by the function. Defaults to False. output_path (str, optional): Path to save the output npz file. Defaults to \"/data/lipidatlas/data/app/data/temp/\". load_from_file (bool, optional): If True, loads the extracted data from npz file. Only option implemented for now. Returns: Depending on 'return result', returns either nothing, either several np.ndarrays, described above. \"\"\" if load_from_file : # Get slice path slice_index = t_index_path [ 0 ] name = t_index_path [ 1 ] # Correct output path if \"MouseBrain2\" in name : output_path += \"brain_2/\" brain_1 = False else : output_path += \"brain_1/\" brain_1 = True path = output_path + \"slice_\" + str ( slice_index ) + \"raw.npz\" npzfile = np . load ( path ) # Load individual arrays array_high_res = npzfile [ \"array_high_res\" ] image_shape = npzfile [ \"image_shape\" ] else : raise Exception ( \"Loading from arguments is not implemented yet\" ) print ( \"Compute and normalize pixels values according to TIC\" ) # Get the TIC per pixel for normalization (must be done before filtering out peaks) array_TIC = compute_TIC_per_pixel ( array_high_res , image_shape [ 0 ] * image_shape [ 1 ]) array_high_res = normalize_per_TIC_per_pixel ( array_high_res , array_TIC ) # Filter out the non-requested peaks and convert to array print ( \"Filtering out noise and matrix peaks\" ) # Get the peak annotation file array_peaks = load_peak_file ( name ) # Get the list of m/z values to keep for visualization array_mz_lipids = load_lipid_file ( slice_index - 10 if not brain_1 else slice_index , path = \"data/annotations/df_match_brain_2.csv\" if not brain_1 else \"data/annotations/df_match_brain_1.csv\" , ) # Get the arrays to standardize data with MAIA ( l_lipids_str , l_lipids_float , arrays_before_transfo , arrays_after_transfo , ) = get_standardized_values ( slice_index - 10 if not brain_1 else slice_index , path_array_data = \"/data/lipidatlas/data/processed/brain1/BRAIN1\" if brain_1 else \"/data/lipidatlas/data/processed/brain2/BRAIN2\" , path_array_transformed_data = \"/data/lipidatlas/data/processed/brain1/BRAIN1_normalized\" if brain_1 else \"/data/lipidatlas/data/processed/brain2/BRAIN2_normalized\" , ) if SAMPLE_APP : l_lipids_str = l_lipids_str [: N_SAMPLES ] l_lipids_float = l_lipids_float [: N_SAMPLES ] arrays_before_transfo = arrays_before_transfo [: N_SAMPLES ] arrays_after_transfo = arrays_after_transfo [: N_SAMPLES ] # Get the array of MAIA-transformed lipids array_peaks_MAIA = get_array_peaks_to_correct ( l_lipids_float , array_mz_lipids , array_peaks , slice_index = slice_index - 10 ) # Filter out all the undesired values l_to_keep_high_res , l_mz_lipids_kept = filter_peaks ( array_high_res , array_peaks_MAIA if SAMPLE_APP else array_peaks , array_mz_lipids [:, 0 ] ) # Keep only the requested peaks array_high_res = array_high_res [ l_to_keep_high_res ] print ( \"Prepare data for standardization\" ) # Double sort by pixel and mz array_high_res = array_high_res [ np . lexsort (( array_high_res [:, 1 ], array_high_res [:, 0 ]), axis = 0 ) ] # Get arrays spectra and corresponding array_pixel_index tables for the high res array_pixel_high_res = array_high_res [:, 0 ] . T . astype ( np . int32 ) array_pixel_indexes_high_res = return_array_pixel_indexes ( array_pixel_high_res , image_shape [ 0 ] * image_shape [ 1 ] ) print ( \"Standardize data\" ) # Standardize a copy of a the data ( array_high_res_standardized , array_peaks_corrected , array_corrective_factors , ) = standardize_values ( array_high_res . copy (), array_pixel_indexes_high_res , array_peaks , array_mz_lipids , l_lipids_float , arrays_before_transfo , arrays_after_transfo , array_peaks_MAIA , ignore_standardization = False if len ( l_lipids_str ) > 0 else True , ) # Sort according to mz for averaging print ( \"Sorting by m/z value for averaging\" ) array_high_res = array_high_res [ np . lexsort (( array_high_res [:, 1 ],), axis = 0 )] # Average low/high resolution arrays over identical mz across pixels print ( \"Getting spectrums array averaged accross pixels\" ) array_averaged_mz_intensity_high_res = return_averaged_spectra_array ( array_high_res ) print ( \"Build the low-resolution averaged array from the high resolution averaged array\" ) array_averaged_mz_intensity_low_res = reduce_resolution_sorted_array_spectra ( array_averaged_mz_intensity_high_res , resolution = 10 **- 2 ) # Same with the standardized data print ( \"Sorting by m/z value for averaging after standardization\" ) array_high_res_standardized = array_high_res_standardized [ np . lexsort (( array_high_res_standardized [:, 1 ],), axis = 0 ) ] # Average low/high resolution arrays over identical mz across pixels print ( \"Getting spectrums array averaged accross pixels\" ) array_averaged_mz_intensity_high_res_after_standardization = return_averaged_spectra_array ( array_high_res_standardized ) # Process more high-resolution data print ( \"Double sorting according to pixel and mz high-res array\" ) array_high_res = array_high_res [ np . lexsort (( array_high_res [:, 1 ], array_high_res [:, 0 ]), axis = 0 ) ] # Get arrays spectra and corresponding array_pixel_index tables for the high resolution print ( \"Getting corresponding spectra arrays\" ) array_pixel_high_res = array_high_res [:, 0 ] . T . astype ( np . int32 ) array_spectra_high_res = array_high_res [:, 1 :] . T . astype ( np . float32 ) array_pixel_indexes_high_res = return_array_pixel_indexes ( array_pixel_high_res , image_shape [ 0 ] * image_shape [ 1 ] ) # Save all array as a npz file as a temporary backup if save : print ( \"Saving : \" + name ) np . savez ( output_path + \"slice_\" + str ( slice_index ) + \".npz\" , array_pixel_indexes_high_res = array_pixel_indexes_high_res , array_spectra_high_res = array_spectra_high_res , array_averaged_mz_intensity_low_res = array_averaged_mz_intensity_low_res , array_averaged_mz_intensity_high_res = array_averaged_mz_intensity_high_res , array_averaged_mz_intensity_high_res_after_standardization = array_averaged_mz_intensity_high_res_after_standardization , image_shape = image_shape , array_peaks_corrected = array_peaks_corrected , array_corrective_factors = array_corrective_factors , ) # Returns all array if needed if return_result : return ( array_pixel_indexes_high_res , array_spectra_high_res , array_averaged_mz_intensity_low_res , array_averaged_mz_intensity_high_res , array_averaged_mz_intensity_high_res_after_standardization , image_shape , array_peaks_corrected , array_corrective_factors , ) process_sparse_matrix ( smz , sort = [ 'Pixel' , 'm/z' ], sample = False ) This function converts the space matrix into a dataframe sorted according to the 'sort' parameter. It is possible to work only on a tiny subset of the matrix with the 'sample' parameter for debugging purposes. Parameters: Name Type Description Default smz scipy . sparse The sparse matrix obtained from the MALDI imaging. required sort list A list of column names according to which the final dataframe should be sorted. Defaults to [\"Pixel\", \"m/z\"]. ['Pixel', 'm/z'] sample bool A boolean parameter to sample only a subset of the matrix. Defaults to False. False Returns: Type Description pandas . Dataframe A sorted dataframe with three columns: pixels index, m/z, and intensity value. Source code in modules/tools/maldi_conversion.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def process_sparse_matrix ( smz , sort = [ \"Pixel\" , \"m/z\" ], sample = False ): \"\"\"This function converts the space matrix into a dataframe sorted according to the 'sort' parameter. It is possible to work only on a tiny subset of the matrix with the 'sample' parameter for debugging purposes. Args: smz (scipy.sparse): The sparse matrix obtained from the MALDI imaging. sort (list, optional): A list of column names according to which the final dataframe should be sorted. Defaults to [\"Pixel\", \"m/z\"]. sample (bool, optional): A boolean parameter to sample only a subset of the matrix. Defaults to False. Returns: (pandas.Dataframe): A sorted dataframe with three columns: pixels index, m/z, and intensity value. \"\"\" # We're going to slice the matrix row by row, so it's faster to convert to csr rather than csc S_row = smz . S . tocsr () # Turn S into a dict for later conversion into a dataframe dic_spectra = { \"Pixel\" : [], \"m/z\" : [], \"Intensity\" : []} for i in range ( S_row . shape [ 0 ]): non_zero_indices = S_row [ i , :] . nonzero ()[ 1 ] dic_spectra [ \"Pixel\" ] . extend ([ i ] * len ( non_zero_indices )) dic_spectra [ \"m/z\" ] . extend ( smz . mz_vals [ non_zero_indices ]) dic_spectra [ \"Intensity\" ] . extend ( S_row [ i , non_zero_indices ] . toarray () . flatten ()) if sample and i == 10 : break # Turn dict into a df for easier manipulation df = pd . DataFrame . from_dict ( dic_spectra ) # Sort df = df . sort_values ( by = sort , axis = 0 ) # Store image size as metadata df . attrs [ \"image_shape\" ] = smz . img_shape return df return_array_pixel_indexes ( array_pixel , total_shape ) This function returns an array of pixel indexes: for each pixel (corresponding to the index of a given row of array_pixel_indexes), it returns the 2 boundaries in the corresponding array_spectra (upper boundarie is included). Parameters: Name Type Description Default array_pixel np . ndarray Array of length n containing the index of each pixel for each m/z value. required total_shape int Total number of pixels in the slice. required Returns: Type Description np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in the original spectra array. Source code in modules/tools/maldi_conversion.py 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 @njit def return_array_pixel_indexes ( array_pixel , total_shape ): \"\"\"This function returns an array of pixel indexes: for each pixel (corresponding to the index of a given row of array_pixel_indexes), it returns the 2 boundaries in the corresponding array_spectra (upper boundarie is included). Args: array_pixel (np.ndarray): Array of length n containing the index of each pixel for each m/z value. total_shape (int): Total number of pixels in the slice. Returns: (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in the original spectra array. \"\"\" array_pixel_indexes = np . empty (( total_shape , 2 ), dtype = np . int32 ) array_pixel_indexes . fill ( - 1 ) for i , p in enumerate ( array_pixel ): # First time pixel is encountered if array_pixel_indexes [ p , 0 ] == - 1 : array_pixel_indexes [ p , 0 ] = i # Last time pixel is encountered array_pixel_indexes [ p , 1 ] = i return array_pixel_indexes return_average_spectrum ( array_intensity , array_unique_counts ) Returns intensities averaged over all pixels, given the previously computed unique m/z value across all pixels. Parameters: Name Type Description Default array_intensity np . ndarray Array of length n containing the sorted intensities of all the pixels of a given acquisition. required array_unique_counts np . ndarray Array of length m containing the unique m/z values found across all spectra from all pixels. required Returns: Type Description np . ndarray Array of length m containing the summed intensities for the unique m/z values across all spectra from all pixels. Source code in modules/tools/maldi_conversion.py 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 @njit def return_average_spectrum ( array_intensity , array_unique_counts ): \"\"\"Returns intensities averaged over all pixels, given the previously computed unique m/z value across all pixels. Args: array_intensity (np.ndarray): Array of length n containing the sorted intensities of all the pixels of a given acquisition. array_unique_counts (np.ndarray)): Array of length m containing the unique m/z values found across all spectra from all pixels. Returns: (np.ndarray): Array of length m containing the summed intensities for the unique m/z values across all spectra from all pixels. \"\"\" array_unique_intensity = np . zeros ( array_unique_counts . shape [ 0 ], dtype = np . float32 ) j = 0 # For each unique m/z value, sum corresponding intensities for i , count in enumerate ( array_unique_counts ): array_unique_intensity [ i ] = np . sum ( array_intensity [ j : j + count ]) j += count return array_unique_intensity return_averaged_spectra_array ( array ) Returns full spectrum averaged over all pixels Parameters: Name Type Description Default array np . ndarray Array of shape (3,n) contaning pixel index, m/z values and intensities in each row. required Returns: Type Description np . ndarray Array of shape (2,n) containing intensities averaged over unique m/z values across all pixels. Source code in modules/tools/maldi_conversion.py 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 def return_averaged_spectra_array ( array ): \"\"\"Returns full spectrum averaged over all pixels Args: array (np.ndarray): Array of shape (3,n) contaning pixel index, m/z values and intensities in each row. Returns: (np.ndarray): Array of shape (2,n) containing intensities averaged over unique m/z values across all pixels. \"\"\" # Take the transpose for easier browsing array_spectra = array . T # Get length of spectrum (i.e. unique mz values) array_unique_mz , array_unique_counts = np . unique ( array_spectra [ 1 , :], return_counts = True ) # Get averaged array array_unique_intensity = return_average_spectrum ( array_spectra [ 2 , :], array_unique_counts ) return np . array ([ array_unique_mz , array_unique_intensity ], dtype = np . float32 ) standardize_values ( array_spectra , array_pixel_indexes , array_peaks , array_mz_lipids , l_lipids_float , arrays_before_transfo , arrays_after_transfo , array_peaks_to_correct , ignore_standardization = True ) This function rescale the intensity values of the lipids annotated with a Combat-like method as part of the MAIA pipeline, using pre-computed intensities values. Parameters: Name Type Description Default array_spectra np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity), sorted by pixel index and mz. required array_pixel_indexes np . ndarray A numpy array of shape (m,2) containing the boundary indices of each pixel in the original spectra array. required array_peaks np . ndarray A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), sorted by min_mz. required array_mz_lipids np . ndarray A 1-D numpy array containing the per-slice mz values of the lipids we want to visualize. required l_lipids_float list A list containing the estimated m/z values of the lipids we want to visualize. required arrays_before_transfo np . ndarray A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, before these intensities were transformed. required arrays_after_transfo np . ndarray A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, after these intensities were transformed. required array_peaks_to_correct np . ndarray A numpy array similar to 'array_peaks', but containing only the lipids that have been MAIA-transformed. required ignore_standardization bool If True, the standardization step is ignored. The function is not useless as it still returns 'array_peaks_to_correct' and 'array_corrective_factors'. True Returns: Type Description np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity), sorted by pixel index and mz, with lipids values transformed. np . ndarray A numpy array similar to 'array_peaks', but containing only the lipids that have been transformed. np . ndarray A numpy array equal to the ratio of 'arrays_after_transfo' and 'arrays_before_transfo' containing the corrective factor used for lipid and each pixel. Source code in modules/tools/maldi_conversion.py 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 def standardize_values ( array_spectra , array_pixel_indexes , array_peaks , array_mz_lipids , l_lipids_float , arrays_before_transfo , arrays_after_transfo , array_peaks_to_correct , ignore_standardization = True , ): \"\"\"This function rescale the intensity values of the lipids annotated with a Combat-like method as part of the MAIA pipeline, using pre-computed intensities values. Args: array_spectra (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity), sorted by pixel index and mz. array_pixel_indexes (np.ndarray): A numpy array of shape (m,2) containing the boundary indices of each pixel in the original spectra array. array_peaks (np.ndarray): A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), sorted by min_mz. array_mz_lipids (np.ndarray): A 1-D numpy array containing the per-slice mz values of the lipids we want to visualize. l_lipids_float (list): A list containing the estimated m/z values of the lipids we want to visualize. arrays_before_transfo (np.ndarray): A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, before these intensities were transformed. arrays_after_transfo (np.ndarray): A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, after these intensities were transformed. array_peaks_to_correct (np.ndarray): A numpy array similar to 'array_peaks', but containing only the lipids that have been MAIA-transformed. ignore_standardization (bool): If True, the standardization step is ignored. The function is not useless as it still returns 'array_peaks_to_correct' and 'array_corrective_factors'. Returns: (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity), sorted by pixel index and mz, with lipids values transformed. (np.ndarray): A numpy array similar to 'array_peaks', but containing only the lipids that have been transformed. (np.ndarray): A numpy array equal to the ratio of 'arrays_after_transfo' and 'arrays_before_transfo' containing the corrective factor used for lipid and each pixel. \"\"\" if not ignore_standardization : # Compute the transformed spectrum for each pixel n_pix_transformed = 0 sum_n_peaks_transformed = 0 for idx_pixel , [ idx_pixel_min , idx_pixel_max ] in enumerate ( array_pixel_indexes ): array_spectra_pixel = array_spectra [ idx_pixel_min : idx_pixel_max + 1 ] if len ( array_spectra_pixel ) > 1 : array_spectra_pixel , n_peaks_transformed = compute_standardization ( array_spectra_pixel , idx_pixel , array_peaks_to_correct , arrays_before_transfo , arrays_after_transfo , ) # Reattribute the corrected values to the intial spectrum array_spectra [ idx_pixel_min : idx_pixel_max + 1 ] = array_spectra_pixel n_pix_transformed += 1 sum_n_peaks_transformed += n_peaks_transformed print ( n_pix_transformed , \"have been transformed, with an average of \" , sum_n_peaks_transformed / n_pix_transformed , \"peaks transformed\" , ) # Delete the n_pix column (3rd column) in array_peaks array_peaks_to_correct = np . delete ( array_peaks_to_correct , 2 , 1 ) # Get the array of corrective factors (per lipid per pixel), removing zero values array_corrective_factors = np . array ( np . nan_to_num ( arrays_after_transfo / arrays_before_transfo , nan = 1.0 ), dtype = np . float16 ) # Correct for negative values array_corrective_factors = np . clip ( array_corrective_factors , 0 , None ) return array_spectra , array_peaks_to_correct , array_corrective_factors","title":"Maldi conversion"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.compute_TIC_per_pixel","text":"This function computes the Total Ion Content (TIC) per pixel of the raw data. Parameters: Name Type Description Default array_spectra np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity). required n_pixels int Number of pixels in the acquisition. required Returns: Type Description np . ndarray A numpy array of len n_pixels containing the TIC for each pixel. Source code in modules/tools/maldi_conversion.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 @njit def compute_TIC_per_pixel ( array_spectra , n_pixels ): \"\"\"This function computes the Total Ion Content (TIC) per pixel of the raw data. Args: array_spectra (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity). n_pixels (int): Number of pixels in the acquisition. Returns: (np.ndarray): A numpy array of len n_pixels containing the TIC for each pixel. \"\"\" array_TIC = np . zeros (( n_pixels ,), dtype = np . float32 ) for i in range ( array_spectra . shape [ 0 ]): pix_idx , mz , intensity = array_spectra [ i ] array_TIC [ int ( pix_idx )] += intensity return array_TIC","title":"compute_TIC_per_pixel()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.compute_standardization","text":"This function takes the spectrum data of a given pixel, along with the corresponding pixel index, and transforms the value of the lipids intensities annotated in 'array_peaks' according to the transformation made in 'arrays_before_transfo' and 'arrays_after_transfo'. Parameters: Name Type Description Default array_spectra_pixel np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity) of pixel 'idx_pixel', sorted by mz. required idx_pixel int Index of the current pixel whose spectrum is transformed. required array_peaks np . ndarray A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), filtered for the lipids who have preliminarily been transformed. Sorted by min_mz. required arrays_before_transfo np . ndarray A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, before these intensities were transformed. required arrays_after_transfo np . ndarray A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, after these intensities were transformed. required Raises: Type Description Exception description Returns: Type Description np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity), of pixel 'idx_pixel', sorted by mz, with lipids values transformed. Source code in modules/tools/maldi_conversion.py 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 @njit def compute_standardization ( array_spectra_pixel , idx_pixel , array_peaks , arrays_before_transfo , arrays_after_transfo ): \"\"\"This function takes the spectrum data of a given pixel, along with the corresponding pixel index, and transforms the value of the lipids intensities annotated in 'array_peaks' according to the transformation made in 'arrays_before_transfo' and 'arrays_after_transfo'. Args: array_spectra_pixel (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity) of pixel 'idx_pixel', sorted by mz. idx_pixel (int): Index of the current pixel whose spectrum is transformed. array_peaks (np.ndarray): A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), filtered for the lipids who have preliminarily been transformed. Sorted by min_mz. arrays_before_transfo (np.ndarray): A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, before these intensities were transformed. arrays_after_transfo (np.ndarray): A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, after these intensities were transformed. Raises: Exception: _description_ Returns: (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity), of pixel 'idx_pixel', sorted by mz, with lipids values transformed. \"\"\" # Define initial values idx_peak = 0 idx_mz = 0 n_peaks_transformed = 0 while idx_mz < array_spectra_pixel . shape [ 0 ] and idx_peak < array_peaks . shape [ 0 ]: idx_pix , mz , intensity = array_spectra_pixel [ idx_mz ] min_mz , max_mz , n_pix , mz_estimated = array_peaks [ idx_peak ] # New window has been discovered if mz >= min_mz and mz <= max_mz : idx_min_mz = idx_mz idx_max_mz = idx_mz for idx_mz in range ( idx_min_mz , array_spectra_pixel . shape [ 0 ]): idx_pix , mz , intensity = array_spectra_pixel [ idx_mz ] if mz > max_mz : idx_max_mz = idx_mz - 1 break # Most likely, the annotation doesn't exist, so skip it if np . abs ( idx_max_mz - idx_min_mz ) <= 0.9 : pass # Else compute a multiplicative factor else : # Get array of intensity before and after correction for current pixel intensity_before = arrays_before_transfo [ idx_peak ] . flatten ()[ idx_pixel ] intensity_after = arrays_after_transfo [ idx_peak ] . flatten ()[ idx_pixel ] # Compute sum of expression between limits integral = np . sum ( array_spectra_pixel [ idx_min_mz : idx_max_mz + 1 , 2 ]) # Assess that this sum is equal to the one precomputed with MAIA if np . abs ( integral - intensity_before ) > 10 **- 4 and ( idx_max_mz - idx_min_mz ) > 1 : print ( \"There seems to be a problem with the computation of the integral\" ) print ( integral , intensity_before ) print ( idx_min_mz , idx_max_mz ) else : # print(integral, intensity_before) # print(idx_min_mz, idx_max_mz) pass # To avoid division by 0 (altough it shouldn't happen) if intensity_before == 0 : intensity_before = 1 correction = intensity_after / intensity_before # Correct for negative values for very small corrections if correction < 0 : correction = 0 # Multiply all intensities in the window by the corrective coefficient array_spectra_pixel [ idx_min_mz : idx_max_mz + 1 , 2 ] *= correction n_peaks_transformed += 1 # Move on to the next peak idx_peak += 1 else : if mz > max_mz : idx_peak += 1 else : idx_mz += 1 return array_spectra_pixel , n_peaks_transformed","title":"compute_standardization()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.extract_raw_data","text":"This function loads the raw maldi data and turns it into a python friendly numpy array, along with a given shape for the acquisition. Parameters: Name Type Description Default t_index_path tuple(int, str A tuple containing the index of the slice (starting from 1)and the corresponding path for the raw data. required save bool If True, arrays for the extracted data are saved in a npz file. Defaults to True (only option implemented for now for the rest of the pipeline). True output_path str Path to save the output npz file. Defaults to \"/data/lipidatlas/data/app/data/temp/\". '/data/lipidatlas/data/app/data/temp/' Returns: Type Description np . ndarray , np . ndarray The first array, of shape (3,n), contains, for the current acquisition, the mz value (2nd column) and intensity (3rd column) for each pixel (first column). The second array contains two integers representing the acquisition shape. Source code in modules/tools/maldi_conversion.py 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 def extract_raw_data ( t_index_path , save = True , output_path = \"/data/lipidatlas/data/app/data/temp/\" , ): \"\"\"This function loads the raw maldi data and turns it into a python friendly numpy array, along with a given shape for the acquisition. Args: t_index_path (tuple(int, str)): A tuple containing the index of the slice (starting from 1)and the corresponding path for the raw data. save (bool, optional): If True, arrays for the extracted data are saved in a npz file. Defaults to True (only option implemented for now for the rest of the pipeline). output_path (str, optional): Path to save the output npz file. Defaults to \"/data/lipidatlas/data/app/data/temp/\". Returns: (np.ndarray, np.ndarray): The first array, of shape (3,n), contains, for the current acquisition, the mz value (2nd column) and intensity (3rd column) for each pixel (first column). The second array contains two integers representing the acquisition shape. \"\"\" try : # Get slice path slice_index = t_index_path [ 0 ] name = t_index_path [ 1 ] # Correct output path if \"MouseBrain2\" in name : output_path += \"brain_2/\" else : output_path += \"brain_1/\" # Load file in high and low resolution print ( \"Loading files : \" + name ) smz_high_res = load_file ( name , resolution = 1e-5 ) image_shape = smz_high_res . img_shape # Load df with different sortings (low_res will be averaged over m/z afterwards) print ( \"Creating and sorting dataframes\" ) df_high_res = process_sparse_matrix ( smz_high_res , sort = \"m/z\" ) # Convert df into arrays for easier manipulation with numba array_high_res = df_high_res . to_numpy () if save : np . savez ( output_path + \"slice_\" + str ( slice_index ) + \"raw.npz\" , array_high_res = array_high_res , image_shape = image_shape , ) return array_high_res , image_shape except : return None","title":"extract_raw_data()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.filter_peaks","text":"This function is used to filter out all the spectrum data in 'array_spectra' that has not been annotated as peak in 'array_peaks' and that do not belong to 'array_mz_lipids_per_slice'. Parameters: Name Type Description Default array_spectra np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity), sorted by mz (but not necessarily by pixel index). required array_peaks np . ndarray A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), sorted by min_mz. required array_mz_lipids_per_slice np . ndarray A 1-D numpy array containing the per-slice mz values of the lipids we want to visualize. required Returns: Type Description list m/z values corresponding to peaks that have been annotated and belong to lipids we want to visualize. list m/z values of the lipids the lipids we want to visualize that have been kept. Source code in modules/tools/maldi_conversion.py 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 @njit def filter_peaks ( array_spectra , array_peaks , array_mz_lipids_per_slice ): \"\"\"This function is used to filter out all the spectrum data in 'array_spectra' that has not been annotated as peak in 'array_peaks' and that do not belong to 'array_mz_lipids_per_slice'. Args: array_spectra (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity), sorted by mz (but not necessarily by pixel index). array_peaks (np.ndarray): A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), sorted by min_mz. array_mz_lipids_per_slice (np.ndarray): A 1-D numpy array containing the per-slice mz values of the lipids we want to visualize. Returns: (list): m/z values corresponding to peaks that have been annotated and belong to lipids we want to visualize. (list): m/z values of the lipids the lipids we want to visualize that have been kept. \"\"\" # Define initial values l_to_keep = [] idx_peak = 0 idx_curr_mz = 0 idx_lipid = 0 l_n_pix = [] mz_lipid = array_mz_lipids_per_slice [ idx_lipid ] l_mz_lipids_kept = [] # Need to initialize the set with an int inside and then delete it because numba is retarded set_pix = { 0 } set_pix . remove ( 0 ) while idx_curr_mz < array_spectra . shape [ 0 ] and idx_peak < array_peaks . shape [ 0 ]: idx_pix , mz , intensity = array_spectra [ idx_curr_mz ] min_mz , max_mz , n_pix , mz_estimated = array_peaks [ idx_peak ] # Either we are before the current window if mz <= min_mz : idx_curr_mz += 1 # Either current mz is in the current window elif mz >= min_mz and mz <= max_mz : # Adapt the index of the current lipid while mz_lipid < min_mz and idx_lipid < array_mz_lipids_per_slice . shape [ 0 ]: idx_lipid += 1 mz_lipid = array_mz_lipids_per_slice [ idx_lipid ] # If we've explored all lipids already, exit the loop if idx_lipid == array_mz_lipids_per_slice . shape [ 0 ]: break # If mz lipid is not in the current peak, move on to the next if mz_lipid > max_mz or np . abs ( mz_estimated - mz_lipid ) > 2 * 10 **- 4 : idx_peak += 1 l_n_pix . append ( len ( set_pix )) set_pix . clear () else : # mz belong to a lipid we want to visualize l_to_keep . append ( idx_curr_mz ) set_pix . add ( idx_pix ) idx_curr_mz += 1 if len ( l_mz_lipids_kept ) == 0 : l_mz_lipids_kept . append ( mz_lipid ) elif mz_lipid != l_mz_lipids_kept [ - 1 ]: l_mz_lipids_kept . append ( mz_lipid ) # Either we're beyond, in which cas we move the window, and record the number of unique # pixels in the window for later check else : idx_peak += 1 l_n_pix . append ( len ( set_pix )) set_pix . clear () # * This piece of code is commented because it is not usable as such since the introduction of # * array_mz_lipids_per_slice as argument in the function, but it should still work if molecules # * not belonging to array_mz_lipids_per_slice are not excluded # if verbose: # # Check that the pixel recorded are identical to the expected number of pixels recorded # print( # \"Difference between number of recorded pixels\", # np.sum(np.array(l_n_pix) - array_peaks[:, 2]), # ) # print(np.array(l_n_pix)[-10:]) # print(array_peaks[-10:, 2]) return l_to_keep , l_mz_lipids_kept","title":"filter_peaks()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.get_array_peaks_to_correct","text":"This function computes an array similar to 'array_peaks', but containing only the lipids that have been MAIA-transformed. Parameters: Name Type Description Default l_lipids_float list A list containing the estimated m/z values of the lipids we want to visualize. required array_mz_lipids np . ndarray A 1-D numpy array containing the per-slice mz values of the lipids we want to visualize. required array_peaks np . ndarray A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), sorted by min_mz. required Returns: Type Description np . ndarray A numpy array similar to 'array_peaks', but containing only the lipids that have been MAIA-transformed. Source code in modules/tools/maldi_conversion.py 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 def get_array_peaks_to_correct ( l_lipids_float , array_mz_lipids , array_peaks , slice_index = None ): \"\"\"This function computes an array similar to 'array_peaks', but containing only the lipids that have been MAIA-transformed. Args: l_lipids_float (list): A list containing the estimated m/z values of the lipids we want to visualize. array_mz_lipids (np.ndarray): A 1-D numpy array containing the per-slice mz values of the lipids we want to visualize. array_peaks (np.ndarray): A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), sorted by min_mz. Returns: (np.ndarray): A numpy array similar to 'array_peaks', but containing only the lipids that have been MAIA-transformed. \"\"\" # Low precision as the reference can be quite different from the actual m/z value estimated precision = 5 * 10 **- 3 # First get the list of mz of the current slice l_lipids_float_correct = [] for mz_lipid in l_lipids_float : found = False # Find the closest value in the whole array of annotations idx_closest_value = ( np . abs ( array_mz_lipids [:, 1 ] - mz_lipid )) . argmin () mz_per_slice , mz_avg = array_mz_lipids [ idx_closest_value ] diff = np . abs ( mz_avg - mz_lipid ) if diff <= precision : l_lipids_float_correct . append ( mz_per_slice ) found = True if not found : print ( \"Could not find the annotation of the lipid {} in df_match.csv\" . format ( mz_lipid )) print ( \"Closest mz value found was {} \" . format ( mz_avg )) if slice_index is not None : print ( \"Slice index was {} \" . format ( slice_index - 1 )) raise Exception # for mz_per_slice, mz_avg in array_mz_lipids: # if np.abs(mz_avg - mz_lipid) <= precision: # found = True # l_lipids_float_correct.append(mz_per_slice) # break # if not found: # raise Exception(\"No lipid could be found for foldername with mz = \" + str(mz_lipid)) # keep only the peak annotation that correspond to the lipids which have been transformed rows_to_keep = [] # Take higher precision as values should be perfectly identical here precision = 10 **- 4 for mz_lipid in l_lipids_float_correct : found = False for idx , [ mini , maxi , npix , mz_est ] in enumerate ( array_peaks ): if np . abs ( mz_est - mz_lipid ) <= precision : found = True rows_to_keep . append ( idx ) break if not found : print ( \"Lipid with foldername with mz = \" + str ( mz_lipid ) + \" was in df_match.csv but not in ranges.csv\" ) if slice_index is not None : print ( \"Slice index was {} \" . format ( slice_index - 1 )) raise Exception array_peaks_to_correct = array_peaks [ rows_to_keep ] return array_peaks_to_correct","title":"get_array_peaks_to_correct()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.get_standardized_values","text":"This function loads the values of the intensities of the the lipids whose expression have been previously corrected using MAIA. Parameters: Name Type Description Default slice_index int Index of the current acquisition. required path_array_data str Path of the lipid intensities before transformation. Defaults to \"/data/lipidatlas/data/processed/BRAIN1\". required path_array_transformed_data str Path of the lipid intensities after transformation. Defaults to \"/data/lipidatlas/data/processed/BRAIN1_normalized\". required Raises: Type Description ValueError Some lipids have been transformed but the initial (untransformed) expression data is missing. Returns: Type Description list , list , np . array , np . array 2 lists and 2 arrays containing respectively: - The name of the folders containing the transformed lipid expression. The name is a string representing the mz value itself. - The corresponding mz values as floats. - The array of expression before transformation (having the same shape as the original acquisition). - The array of expression after transformation (having the same shape as the original acquisition). Source code in modules/tools/maldi_conversion.py 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 def get_standardized_values ( slice_index , path_array_data , path_array_transformed_data , remove_non_existing = True , ): \"\"\"This function loads the values of the intensities of the the lipids whose expression have been previously corrected using MAIA. Args: slice_index (int): Index of the current acquisition. path_array_data (str, optional): Path of the lipid intensities before transformation. Defaults to \"/data/lipidatlas/data/processed/BRAIN1\". path_array_transformed_data (str, optional): Path of the lipid intensities after transformation. Defaults to \"/data/lipidatlas/data/processed/BRAIN1_normalized\". Raises: ValueError: Some lipids have been transformed but the initial (untransformed) expression data is missing. Returns: (list, list, np.array, np.array): 2 lists and 2 arrays containing respectively: - The name of the folders containing the transformed lipid expression. The name is a string representing the mz value itself. - The corresponding mz values as floats. - The array of expression before transformation (having the same shape as the original acquisition). - The array of expression after transformation (having the same shape as the original acquisition). \"\"\" # First get list of lipids for which a transformation has been applied l_lipids_str = os . listdir ( path_array_data ) l_lipids_str_transformed = os . listdir ( path_array_transformed_data ) # Return empty lists if no MALDI files exist yet if len ( l_lipids_str ) == 0 and len ( l_lipids_str_transformed ) == 0 : return [], [], np . array ([], dtype = np . float32 ), np . array ([], dtype = np . float32 ) # Keep only lipid that have been transformed l_lipids_str = [ x for x in l_lipids_str if x in l_lipids_str_transformed ] # Assess that the two lists are identical if l_lipids_str != l_lipids_str_transformed : raise ValueError ( \"The lipids before and after transformation are not the same\" ) # Convert filename to float mz value l_lipids_float = [ float ( x ) for x in l_lipids_str ] # Sort the two lists by increasing m/z l_lipids_str , l_lipids_float = zip ( * sorted ( zip ( l_lipids_str , l_lipids_float ))) # Get the corresponding numpy arrays l_arrays_before_transfo = [] l_arrays_after_transfo = [] set_idx_to_keep = set ([]) for idx , lipid_str in enumerate ( l_lipids_str ): array_after_transfo = np . load ( path_array_transformed_data + \"/\" + lipid_str + \"/\" + str ( slice_index - 1 ) + \".npy\" ) if remove_non_existing : try : array_before_transfo = np . load ( path_array_data + \"/\" + lipid_str + \"/\" + str ( slice_index - 1 ) + \".npy\" ) except : # If the array doesn't exist, it means that the lipid doesn't exist for the current slice continue # Create an array of zeros instead else : try : array_before_transfo = np . load ( path_array_data + \"/\" + lipid_str + \"/\" + str ( slice_index - 1 ) + \".npy\" ) except : array_before_transfo = np . zeros_like ( array_after_transfo ) l_arrays_before_transfo . append ( array_before_transfo ) l_arrays_after_transfo . append ( array_after_transfo ) set_idx_to_keep . add ( idx ) return ( [ x for idx , x in enumerate ( l_lipids_str ) if idx in set_idx_to_keep ], [ x for idx , x in enumerate ( l_lipids_float ) if idx in set_idx_to_keep ], np . array ( l_arrays_before_transfo , dtype = np . float32 ), np . array ( l_arrays_after_transfo , dtype = np . float32 ), )","title":"get_standardized_values()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.load_file","text":"This function loads the specified MALDI file from the raw data format (.mzML and .UDP) with the given resolution, and turns it into a scipy sparse matrix. Parameters: Name Type Description Default path string The path of the file to load. required resolution float The resolution of the file to load. Defaults to 1e-5. 1e-05 Returns: Type Description scipy . sparse A sparse matrix containing the intensity for each m/z value. Source code in modules/tools/maldi_conversion.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def load_file ( path , resolution = 1e-5 ): \"\"\"This function loads the specified MALDI file from the raw data format (.mzML and .UDP) with the given resolution, and turns it into a scipy sparse matrix. Args: path (string): The path of the file to load. resolution (float, optional): The resolution of the file to load. Defaults to 1e-5. Returns: (scipy.sparse): A sparse matrix containing the intensity for each m/z value. \"\"\" # Check if imzML exists and load if possible if os . path . exists ( path + \".imzML\" ): smz = SmzMLobj ( path + \".ibd\" , path + \".imzML\" , mz_resolution = resolution ) smz . load ( load_unique_mz = True ) else : # Load object from SmzMLobj smz = SmzMLobj ( path + \".mzML\" , path + \".UDP\" , mz_resolution = resolution ) smz . load ( load_unique_mz = True ) # Compute shape of the spectra matrix to preload matrix smz . S . shape return smz","title":"load_file()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.load_lipid_file","text":"This function loads a set of specific lipid annotations containing a molecule ID, the average mz for the molecule, the section index and potentially other information, from a csv file located at the provided path. It returns an array of mz values corresponding to the lipids we want to keep for further visualization. Parameters: Name Type Description Default section_index int The index of the current acquisition (first slice having index 1). required path string The path of the csv file containing the lipids annotations. required Returns: Type Description np . ndarray A two-dimensional array of m/z values corrsponding to the lipids that we want to keep for further visualization (first column is per-slice value, second column is averaged value). Sorted by individual slice value in the end. Source code in modules/tools/maldi_conversion.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 def load_lipid_file ( section_index , path ): \"\"\"This function loads a set of specific lipid annotations containing a molecule ID, the average mz for the molecule, the section index and potentially other information, from a csv file located at the provided path. It returns an array of mz values corresponding to the lipids we want to keep for further visualization. Args: section_index (int): The index of the current acquisition (first slice having index 1). path (string): The path of the csv file containing the lipids annotations. Returns: (np.ndarray): A two-dimensional array of m/z values corrsponding to the lipids that we want to keep for further visualization (first column is per-slice value, second column is averaged value). Sorted by individual slice value in the end. \"\"\" # Load the peaks annotations using the last definition used for the csv file df = pd . read_csv ( path , sep = \",\" ) # Drop the columns that we won't use afterwards df = df . drop ( [ \"molecule_ID\" , \"concentration\" , ], axis = 1 , ) # Keep only the current section df = df [ df [ \"section_ix\" ] == section_index - 1 ] # Return a numpy array of mz values sorted by first column array_mz_lipids = np . array ( df [[ \"mz_estimated\" , \"mz_estimated_total\" ]], dtype = np . float32 ) return array_mz_lipids [ np . argsort ( array_mz_lipids [:, 0 ])]","title":"load_lipid_file()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.load_peak_file","text":"This function loads the peaks annotations (including matrix peaks) from a csv file located at the provided path. It returns a numpy array sorted by min peak value (m/z) annotation. Parameters: Name Type Description Default path string The path of the csv file containing the peaks annotations. required Returns: Type Description np . ndarray The sorted dataframe containing the annotations (min peak, max peak, number of pixels containing the current molecule, estimated mz of the current molecule). Source code in modules/tools/maldi_conversion.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 def load_peak_file ( path , array = True ): \"\"\"This function loads the peaks annotations (including matrix peaks) from a csv file located at the provided path. It returns a numpy array sorted by min peak value (m/z) annotation. Args: path (string): The path of the csv file containing the peaks annotations. Returns: (np.ndarray): The sorted dataframe containing the annotations (min peak, max peak, number of pixels containing the current molecule, estimated mz of the current molecule). \"\"\" # Load the peaks annotations using the last definition used for the csv file path = \"/\" . join ( path . split ( \"/\" )[: - 1 ]) + \"/ranges\" df = pd . read_csv ( path + \".csv\" , sep = \",\" ) # Drop the columns that we won't use afterwards df = df . drop ( [ \"Unnamed: 0\" , \"pixel_max_hits\" , \"percent_1_hit\" , \"concentration\" , \"median_intensity\" , \"difference\" , ], axis = 1 , ) # Sort by increasing m/z annotation for the peaks df = df . sort_values ( by = \"min\" , axis = 0 ) if array : return df . to_numpy () else : return df","title":"load_peak_file()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.normalize_per_TIC_per_pixel","text":"This function normalize each intensity value according to its (TIC), per pixel. Parameters: Name Type Description Default array_spectra np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity). required array_TIC np . ndarray A numpy array of len n_pixels containing the TIC for each pixel. required Returns: Type Description np . ndarray A numpy array containing TIC-normalized spectrum data (pixel index, m/z and intensity). Source code in modules/tools/maldi_conversion.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 @njit def normalize_per_TIC_per_pixel ( array_spectra , array_TIC ): \"\"\"This function normalize each intensity value according to its (TIC), per pixel. Args: array_spectra (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity). array_TIC (np.ndarray): A numpy array of len n_pixels containing the TIC for each pixel. Returns: (np.ndarray): A numpy array containing TIC-normalized spectrum data (pixel index, m/z and intensity). \"\"\" for i in range ( array_spectra . shape [ 0 ]): pix_idx , mz , intensity = array_spectra [ i ] array_spectra [ i , 2 ] /= array_TIC [ int ( pix_idx )] return array_spectra","title":"normalize_per_TIC_per_pixel()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.process_raw_data","text":"This function has been implemented to allow the parallelization of slice processing. It turns the MALDI data into several numpy arrays and lookup tables: - array_pixel_indexes_high_res: A numpy array of shape (n,2), it maps each pixel to two array_spectra_high_res indices, delimiting the corresponding spectrum. - array_spectra_high_res: A numpy array of shape (2,m), it contains the concatenated spectra of each pixel. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_low_res: A numpy array of shape (2, k), it contains the low-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_high_res: Same as array_averaged_mz_intensity_low_res, but in higher resolution, with, therefore, a different shape. - array_averaged_mz_intensity_high_res_after_standardization: Same as array_averaged_mz_intensity_high_res, but before applying MAIA standardization. - image_shape: a tuple of integers, indicating the vertical and horizontal sizes of the corresponding slice. - array_peaks_corrected: A two-dimensional array containing the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, but only for the lipids that have been transformed. - array_corrective_factors: A three-dimensional numpy array equal to the ratio of 'arrays_after_transfo' and 'arrays_before_transfo' containing the corrective factor used for lipid (first dimension) and each pixel (second and third dimension). Parameters: Name Type Description Default t_index_path tuple(int, str A tuple containing the index of the slice (starting from 1) and the corresponding path for the raw data. required save bool If True, output arrays are saved in a npz file. Defaults to True. True return_result bool If True, output arrays are returned by the function. Defaults to False. False output_path str Path to save the output npz file. Defaults to \"/data/lipidatlas/data/app/data/temp/\". '/data/lipidatlas/data/app/data/temp/' load_from_file bool If True, loads the extracted data from npz file. Only option implemented for now. True Returns: Type Description Depending on 'return result', returns either nothing, either several np.ndarrays, described above. Source code in modules/tools/maldi_conversion.py 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 def process_raw_data ( t_index_path , save = True , return_result = False , output_path = \"/data/lipidatlas/data/app/data/temp/\" , load_from_file = True , ): \"\"\"This function has been implemented to allow the parallelization of slice processing. It turns the MALDI data into several numpy arrays and lookup tables: - array_pixel_indexes_high_res: A numpy array of shape (n,2), it maps each pixel to two array_spectra_high_res indices, delimiting the corresponding spectrum. - array_spectra_high_res: A numpy array of shape (2,m), it contains the concatenated spectra of each pixel. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_low_res: A numpy array of shape (2, k), it contains the low-resolution spectrum averaged over all pixels. First row contains the m/z values, while second row contains the corresponding intensities. - array_averaged_mz_intensity_high_res: Same as array_averaged_mz_intensity_low_res, but in higher resolution, with, therefore, a different shape. - array_averaged_mz_intensity_high_res_after_standardization: Same as array_averaged_mz_intensity_high_res, but before applying MAIA standardization. - image_shape: a tuple of integers, indicating the vertical and horizontal sizes of the corresponding slice. - array_peaks_corrected: A two-dimensional array containing the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, but only for the lipids that have been transformed. - array_corrective_factors: A three-dimensional numpy array equal to the ratio of 'arrays_after_transfo' and 'arrays_before_transfo' containing the corrective factor used for lipid (first dimension) and each pixel (second and third dimension). Args: t_index_path (tuple(int, str)): A tuple containing the index of the slice (starting from 1) and the corresponding path for the raw data. save (bool, optional): If True, output arrays are saved in a npz file. Defaults to True. return_result (bool, optional): If True, output arrays are returned by the function. Defaults to False. output_path (str, optional): Path to save the output npz file. Defaults to \"/data/lipidatlas/data/app/data/temp/\". load_from_file (bool, optional): If True, loads the extracted data from npz file. Only option implemented for now. Returns: Depending on 'return result', returns either nothing, either several np.ndarrays, described above. \"\"\" if load_from_file : # Get slice path slice_index = t_index_path [ 0 ] name = t_index_path [ 1 ] # Correct output path if \"MouseBrain2\" in name : output_path += \"brain_2/\" brain_1 = False else : output_path += \"brain_1/\" brain_1 = True path = output_path + \"slice_\" + str ( slice_index ) + \"raw.npz\" npzfile = np . load ( path ) # Load individual arrays array_high_res = npzfile [ \"array_high_res\" ] image_shape = npzfile [ \"image_shape\" ] else : raise Exception ( \"Loading from arguments is not implemented yet\" ) print ( \"Compute and normalize pixels values according to TIC\" ) # Get the TIC per pixel for normalization (must be done before filtering out peaks) array_TIC = compute_TIC_per_pixel ( array_high_res , image_shape [ 0 ] * image_shape [ 1 ]) array_high_res = normalize_per_TIC_per_pixel ( array_high_res , array_TIC ) # Filter out the non-requested peaks and convert to array print ( \"Filtering out noise and matrix peaks\" ) # Get the peak annotation file array_peaks = load_peak_file ( name ) # Get the list of m/z values to keep for visualization array_mz_lipids = load_lipid_file ( slice_index - 10 if not brain_1 else slice_index , path = \"data/annotations/df_match_brain_2.csv\" if not brain_1 else \"data/annotations/df_match_brain_1.csv\" , ) # Get the arrays to standardize data with MAIA ( l_lipids_str , l_lipids_float , arrays_before_transfo , arrays_after_transfo , ) = get_standardized_values ( slice_index - 10 if not brain_1 else slice_index , path_array_data = \"/data/lipidatlas/data/processed/brain1/BRAIN1\" if brain_1 else \"/data/lipidatlas/data/processed/brain2/BRAIN2\" , path_array_transformed_data = \"/data/lipidatlas/data/processed/brain1/BRAIN1_normalized\" if brain_1 else \"/data/lipidatlas/data/processed/brain2/BRAIN2_normalized\" , ) if SAMPLE_APP : l_lipids_str = l_lipids_str [: N_SAMPLES ] l_lipids_float = l_lipids_float [: N_SAMPLES ] arrays_before_transfo = arrays_before_transfo [: N_SAMPLES ] arrays_after_transfo = arrays_after_transfo [: N_SAMPLES ] # Get the array of MAIA-transformed lipids array_peaks_MAIA = get_array_peaks_to_correct ( l_lipids_float , array_mz_lipids , array_peaks , slice_index = slice_index - 10 ) # Filter out all the undesired values l_to_keep_high_res , l_mz_lipids_kept = filter_peaks ( array_high_res , array_peaks_MAIA if SAMPLE_APP else array_peaks , array_mz_lipids [:, 0 ] ) # Keep only the requested peaks array_high_res = array_high_res [ l_to_keep_high_res ] print ( \"Prepare data for standardization\" ) # Double sort by pixel and mz array_high_res = array_high_res [ np . lexsort (( array_high_res [:, 1 ], array_high_res [:, 0 ]), axis = 0 ) ] # Get arrays spectra and corresponding array_pixel_index tables for the high res array_pixel_high_res = array_high_res [:, 0 ] . T . astype ( np . int32 ) array_pixel_indexes_high_res = return_array_pixel_indexes ( array_pixel_high_res , image_shape [ 0 ] * image_shape [ 1 ] ) print ( \"Standardize data\" ) # Standardize a copy of a the data ( array_high_res_standardized , array_peaks_corrected , array_corrective_factors , ) = standardize_values ( array_high_res . copy (), array_pixel_indexes_high_res , array_peaks , array_mz_lipids , l_lipids_float , arrays_before_transfo , arrays_after_transfo , array_peaks_MAIA , ignore_standardization = False if len ( l_lipids_str ) > 0 else True , ) # Sort according to mz for averaging print ( \"Sorting by m/z value for averaging\" ) array_high_res = array_high_res [ np . lexsort (( array_high_res [:, 1 ],), axis = 0 )] # Average low/high resolution arrays over identical mz across pixels print ( \"Getting spectrums array averaged accross pixels\" ) array_averaged_mz_intensity_high_res = return_averaged_spectra_array ( array_high_res ) print ( \"Build the low-resolution averaged array from the high resolution averaged array\" ) array_averaged_mz_intensity_low_res = reduce_resolution_sorted_array_spectra ( array_averaged_mz_intensity_high_res , resolution = 10 **- 2 ) # Same with the standardized data print ( \"Sorting by m/z value for averaging after standardization\" ) array_high_res_standardized = array_high_res_standardized [ np . lexsort (( array_high_res_standardized [:, 1 ],), axis = 0 ) ] # Average low/high resolution arrays over identical mz across pixels print ( \"Getting spectrums array averaged accross pixels\" ) array_averaged_mz_intensity_high_res_after_standardization = return_averaged_spectra_array ( array_high_res_standardized ) # Process more high-resolution data print ( \"Double sorting according to pixel and mz high-res array\" ) array_high_res = array_high_res [ np . lexsort (( array_high_res [:, 1 ], array_high_res [:, 0 ]), axis = 0 ) ] # Get arrays spectra and corresponding array_pixel_index tables for the high resolution print ( \"Getting corresponding spectra arrays\" ) array_pixel_high_res = array_high_res [:, 0 ] . T . astype ( np . int32 ) array_spectra_high_res = array_high_res [:, 1 :] . T . astype ( np . float32 ) array_pixel_indexes_high_res = return_array_pixel_indexes ( array_pixel_high_res , image_shape [ 0 ] * image_shape [ 1 ] ) # Save all array as a npz file as a temporary backup if save : print ( \"Saving : \" + name ) np . savez ( output_path + \"slice_\" + str ( slice_index ) + \".npz\" , array_pixel_indexes_high_res = array_pixel_indexes_high_res , array_spectra_high_res = array_spectra_high_res , array_averaged_mz_intensity_low_res = array_averaged_mz_intensity_low_res , array_averaged_mz_intensity_high_res = array_averaged_mz_intensity_high_res , array_averaged_mz_intensity_high_res_after_standardization = array_averaged_mz_intensity_high_res_after_standardization , image_shape = image_shape , array_peaks_corrected = array_peaks_corrected , array_corrective_factors = array_corrective_factors , ) # Returns all array if needed if return_result : return ( array_pixel_indexes_high_res , array_spectra_high_res , array_averaged_mz_intensity_low_res , array_averaged_mz_intensity_high_res , array_averaged_mz_intensity_high_res_after_standardization , image_shape , array_peaks_corrected , array_corrective_factors , )","title":"process_raw_data()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.process_sparse_matrix","text":"This function converts the space matrix into a dataframe sorted according to the 'sort' parameter. It is possible to work only on a tiny subset of the matrix with the 'sample' parameter for debugging purposes. Parameters: Name Type Description Default smz scipy . sparse The sparse matrix obtained from the MALDI imaging. required sort list A list of column names according to which the final dataframe should be sorted. Defaults to [\"Pixel\", \"m/z\"]. ['Pixel', 'm/z'] sample bool A boolean parameter to sample only a subset of the matrix. Defaults to False. False Returns: Type Description pandas . Dataframe A sorted dataframe with three columns: pixels index, m/z, and intensity value. Source code in modules/tools/maldi_conversion.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def process_sparse_matrix ( smz , sort = [ \"Pixel\" , \"m/z\" ], sample = False ): \"\"\"This function converts the space matrix into a dataframe sorted according to the 'sort' parameter. It is possible to work only on a tiny subset of the matrix with the 'sample' parameter for debugging purposes. Args: smz (scipy.sparse): The sparse matrix obtained from the MALDI imaging. sort (list, optional): A list of column names according to which the final dataframe should be sorted. Defaults to [\"Pixel\", \"m/z\"]. sample (bool, optional): A boolean parameter to sample only a subset of the matrix. Defaults to False. Returns: (pandas.Dataframe): A sorted dataframe with three columns: pixels index, m/z, and intensity value. \"\"\" # We're going to slice the matrix row by row, so it's faster to convert to csr rather than csc S_row = smz . S . tocsr () # Turn S into a dict for later conversion into a dataframe dic_spectra = { \"Pixel\" : [], \"m/z\" : [], \"Intensity\" : []} for i in range ( S_row . shape [ 0 ]): non_zero_indices = S_row [ i , :] . nonzero ()[ 1 ] dic_spectra [ \"Pixel\" ] . extend ([ i ] * len ( non_zero_indices )) dic_spectra [ \"m/z\" ] . extend ( smz . mz_vals [ non_zero_indices ]) dic_spectra [ \"Intensity\" ] . extend ( S_row [ i , non_zero_indices ] . toarray () . flatten ()) if sample and i == 10 : break # Turn dict into a df for easier manipulation df = pd . DataFrame . from_dict ( dic_spectra ) # Sort df = df . sort_values ( by = sort , axis = 0 ) # Store image size as metadata df . attrs [ \"image_shape\" ] = smz . img_shape return df","title":"process_sparse_matrix()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.return_array_pixel_indexes","text":"This function returns an array of pixel indexes: for each pixel (corresponding to the index of a given row of array_pixel_indexes), it returns the 2 boundaries in the corresponding array_spectra (upper boundarie is included). Parameters: Name Type Description Default array_pixel np . ndarray Array of length n containing the index of each pixel for each m/z value. required total_shape int Total number of pixels in the slice. required Returns: Type Description np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in the original spectra array. Source code in modules/tools/maldi_conversion.py 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 @njit def return_array_pixel_indexes ( array_pixel , total_shape ): \"\"\"This function returns an array of pixel indexes: for each pixel (corresponding to the index of a given row of array_pixel_indexes), it returns the 2 boundaries in the corresponding array_spectra (upper boundarie is included). Args: array_pixel (np.ndarray): Array of length n containing the index of each pixel for each m/z value. total_shape (int): Total number of pixels in the slice. Returns: (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in the original spectra array. \"\"\" array_pixel_indexes = np . empty (( total_shape , 2 ), dtype = np . int32 ) array_pixel_indexes . fill ( - 1 ) for i , p in enumerate ( array_pixel ): # First time pixel is encountered if array_pixel_indexes [ p , 0 ] == - 1 : array_pixel_indexes [ p , 0 ] = i # Last time pixel is encountered array_pixel_indexes [ p , 1 ] = i return array_pixel_indexes","title":"return_array_pixel_indexes()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.return_average_spectrum","text":"Returns intensities averaged over all pixels, given the previously computed unique m/z value across all pixels. Parameters: Name Type Description Default array_intensity np . ndarray Array of length n containing the sorted intensities of all the pixels of a given acquisition. required array_unique_counts np . ndarray Array of length m containing the unique m/z values found across all spectra from all pixels. required Returns: Type Description np . ndarray Array of length m containing the summed intensities for the unique m/z values across all spectra from all pixels. Source code in modules/tools/maldi_conversion.py 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 @njit def return_average_spectrum ( array_intensity , array_unique_counts ): \"\"\"Returns intensities averaged over all pixels, given the previously computed unique m/z value across all pixels. Args: array_intensity (np.ndarray): Array of length n containing the sorted intensities of all the pixels of a given acquisition. array_unique_counts (np.ndarray)): Array of length m containing the unique m/z values found across all spectra from all pixels. Returns: (np.ndarray): Array of length m containing the summed intensities for the unique m/z values across all spectra from all pixels. \"\"\" array_unique_intensity = np . zeros ( array_unique_counts . shape [ 0 ], dtype = np . float32 ) j = 0 # For each unique m/z value, sum corresponding intensities for i , count in enumerate ( array_unique_counts ): array_unique_intensity [ i ] = np . sum ( array_intensity [ j : j + count ]) j += count return array_unique_intensity","title":"return_average_spectrum()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.return_averaged_spectra_array","text":"Returns full spectrum averaged over all pixels Parameters: Name Type Description Default array np . ndarray Array of shape (3,n) contaning pixel index, m/z values and intensities in each row. required Returns: Type Description np . ndarray Array of shape (2,n) containing intensities averaged over unique m/z values across all pixels. Source code in modules/tools/maldi_conversion.py 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 def return_averaged_spectra_array ( array ): \"\"\"Returns full spectrum averaged over all pixels Args: array (np.ndarray): Array of shape (3,n) contaning pixel index, m/z values and intensities in each row. Returns: (np.ndarray): Array of shape (2,n) containing intensities averaged over unique m/z values across all pixels. \"\"\" # Take the transpose for easier browsing array_spectra = array . T # Get length of spectrum (i.e. unique mz values) array_unique_mz , array_unique_counts = np . unique ( array_spectra [ 1 , :], return_counts = True ) # Get averaged array array_unique_intensity = return_average_spectrum ( array_spectra [ 2 , :], array_unique_counts ) return np . array ([ array_unique_mz , array_unique_intensity ], dtype = np . float32 )","title":"return_averaged_spectra_array()"},{"location":"modules/tools/maldi_conversion/#modules.tools.maldi_conversion.standardize_values","text":"This function rescale the intensity values of the lipids annotated with a Combat-like method as part of the MAIA pipeline, using pre-computed intensities values. Parameters: Name Type Description Default array_spectra np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity), sorted by pixel index and mz. required array_pixel_indexes np . ndarray A numpy array of shape (m,2) containing the boundary indices of each pixel in the original spectra array. required array_peaks np . ndarray A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), sorted by min_mz. required array_mz_lipids np . ndarray A 1-D numpy array containing the per-slice mz values of the lipids we want to visualize. required l_lipids_float list A list containing the estimated m/z values of the lipids we want to visualize. required arrays_before_transfo np . ndarray A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, before these intensities were transformed. required arrays_after_transfo np . ndarray A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, after these intensities were transformed. required array_peaks_to_correct np . ndarray A numpy array similar to 'array_peaks', but containing only the lipids that have been MAIA-transformed. required ignore_standardization bool If True, the standardization step is ignored. The function is not useless as it still returns 'array_peaks_to_correct' and 'array_corrective_factors'. True Returns: Type Description np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity), sorted by pixel index and mz, with lipids values transformed. np . ndarray A numpy array similar to 'array_peaks', but containing only the lipids that have been transformed. np . ndarray A numpy array equal to the ratio of 'arrays_after_transfo' and 'arrays_before_transfo' containing the corrective factor used for lipid and each pixel. Source code in modules/tools/maldi_conversion.py 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 def standardize_values ( array_spectra , array_pixel_indexes , array_peaks , array_mz_lipids , l_lipids_float , arrays_before_transfo , arrays_after_transfo , array_peaks_to_correct , ignore_standardization = True , ): \"\"\"This function rescale the intensity values of the lipids annotated with a Combat-like method as part of the MAIA pipeline, using pre-computed intensities values. Args: array_spectra (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity), sorted by pixel index and mz. array_pixel_indexes (np.ndarray): A numpy array of shape (m,2) containing the boundary indices of each pixel in the original spectra array. array_peaks (np.ndarray): A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), sorted by min_mz. array_mz_lipids (np.ndarray): A 1-D numpy array containing the per-slice mz values of the lipids we want to visualize. l_lipids_float (list): A list containing the estimated m/z values of the lipids we want to visualize. arrays_before_transfo (np.ndarray): A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, before these intensities were transformed. arrays_after_transfo (np.ndarray): A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the cumulated intensities (summed over all bins) of the lipids we want to visualize, for each pixel, after these intensities were transformed. array_peaks_to_correct (np.ndarray): A numpy array similar to 'array_peaks', but containing only the lipids that have been MAIA-transformed. ignore_standardization (bool): If True, the standardization step is ignored. The function is not useless as it still returns 'array_peaks_to_correct' and 'array_corrective_factors'. Returns: (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity), sorted by pixel index and mz, with lipids values transformed. (np.ndarray): A numpy array similar to 'array_peaks', but containing only the lipids that have been transformed. (np.ndarray): A numpy array equal to the ratio of 'arrays_after_transfo' and 'arrays_before_transfo' containing the corrective factor used for lipid and each pixel. \"\"\" if not ignore_standardization : # Compute the transformed spectrum for each pixel n_pix_transformed = 0 sum_n_peaks_transformed = 0 for idx_pixel , [ idx_pixel_min , idx_pixel_max ] in enumerate ( array_pixel_indexes ): array_spectra_pixel = array_spectra [ idx_pixel_min : idx_pixel_max + 1 ] if len ( array_spectra_pixel ) > 1 : array_spectra_pixel , n_peaks_transformed = compute_standardization ( array_spectra_pixel , idx_pixel , array_peaks_to_correct , arrays_before_transfo , arrays_after_transfo , ) # Reattribute the corrected values to the intial spectrum array_spectra [ idx_pixel_min : idx_pixel_max + 1 ] = array_spectra_pixel n_pix_transformed += 1 sum_n_peaks_transformed += n_peaks_transformed print ( n_pix_transformed , \"have been transformed, with an average of \" , sum_n_peaks_transformed / n_pix_transformed , \"peaks transformed\" , ) # Delete the n_pix column (3rd column) in array_peaks array_peaks_to_correct = np . delete ( array_peaks_to_correct , 2 , 1 ) # Get the array of corrective factors (per lipid per pixel), removing zero values array_corrective_factors = np . array ( np . nan_to_num ( arrays_after_transfo / arrays_before_transfo , nan = 1.0 ), dtype = np . float16 ) # Correct for negative values array_corrective_factors = np . clip ( array_corrective_factors , 0 , None ) return array_spectra , array_peaks_to_correct , array_corrective_factors","title":"standardize_values()"},{"location":"modules/tools/misc/","text":"This file contains various functions which would not belong to any other class. delete_all_files_in_folder ( input_folder ) This function deletes all files and folder preset in the directory input_folder Parameters: Name Type Description Default input_folder str Path of the input folder to clean. required Source code in modules/tools/misc.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def delete_all_files_in_folder ( input_folder ): \"\"\"This function deletes all files and folder preset in the directory input_folder Args: input_folder (str): Path of the input folder to clean. \"\"\" for filename in os . listdir ( input_folder ): file_path = os . path . join ( input_folder , filename ) try : # Delete wether directory or file if os . path . isfile ( file_path ) or os . path . islink ( file_path ): os . unlink ( file_path ) elif os . path . isdir ( file_path ): shutil . rmtree ( file_path ) except Exception as e : print ( \"Failed to delete %s . Reason: %s \" % ( file_path , e )) logmem () This function returns a string representing the current amount of memory used by the program. It is almost instantaneous as it takes about 0.5ms to run. Returns: Type Description str Amount of memory used by the program. Source code in modules/tools/misc.py 20 21 22 23 24 25 26 27 28 29 def logmem (): \"\"\"This function returns a string representing the current amount of memory used by the program. It is almost instantaneous as it takes about 0.5ms to run. Returns: (str): Amount of memory used by the program. \"\"\" memory = psutil . Process ( os . getpid ()) . memory_info () . rss / ( 1024 * 1024 ) memory_string = \"MemTotal: \" + str ( memory ) return \" \\t \" + memory_string","title":"Misc"},{"location":"modules/tools/misc/#modules.tools.misc.delete_all_files_in_folder","text":"This function deletes all files and folder preset in the directory input_folder Parameters: Name Type Description Default input_folder str Path of the input folder to clean. required Source code in modules/tools/misc.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def delete_all_files_in_folder ( input_folder ): \"\"\"This function deletes all files and folder preset in the directory input_folder Args: input_folder (str): Path of the input folder to clean. \"\"\" for filename in os . listdir ( input_folder ): file_path = os . path . join ( input_folder , filename ) try : # Delete wether directory or file if os . path . isfile ( file_path ) or os . path . islink ( file_path ): os . unlink ( file_path ) elif os . path . isdir ( file_path ): shutil . rmtree ( file_path ) except Exception as e : print ( \"Failed to delete %s . Reason: %s \" % ( file_path , e ))","title":"delete_all_files_in_folder()"},{"location":"modules/tools/misc/#modules.tools.misc.logmem","text":"This function returns a string representing the current amount of memory used by the program. It is almost instantaneous as it takes about 0.5ms to run. Returns: Type Description str Amount of memory used by the program. Source code in modules/tools/misc.py 20 21 22 23 24 25 26 27 28 29 def logmem (): \"\"\"This function returns a string representing the current amount of memory used by the program. It is almost instantaneous as it takes about 0.5ms to run. Returns: (str): Amount of memory used by the program. \"\"\" memory = psutil . Process ( os . getpid ()) . memory_info () . rss / ( 1024 * 1024 ) memory_string = \"MemTotal: \" + str ( memory ) return \" \\t \" + memory_string","title":"logmem()"},{"location":"modules/tools/spectra/","text":"In this module, functions used to handle the MALDI data (e.g. get all pixels values for a given lipid annotation, for of a given slice) are defined. add_zeros_to_spectrum ( array_spectra , pad_individual_peaks = True , padding = 10 ** - 4 ) This function adds zeros in-between the peaks of the spectra contained in array_spectra (e.g. to be able to plot them as scatterplotgl). Parameters: Name Type Description Default array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required pad_individual_peaks bool If true, pads the peaks individually, with a given threshold distance between two m/z values to consider them as belonging to the same peak. Else, it pads all single value in the spectrum with zeros. Defaults to False. True padding float The m/z distance between a peak value and a zero for the padding. Default to 10**-4. 10 ** -4 Returns: Type Description np . ndarray , np . ndarray An array of shape (2,m) containing the padded spectrum data (m/z and intensity) and an array of shape (k,) containing the number of zeros added at each index of array_spectra. Source code in modules/tools/spectra.py 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 @njit def add_zeros_to_spectrum ( array_spectra , pad_individual_peaks = True , padding = 10 **- 4 ): \"\"\"This function adds zeros in-between the peaks of the spectra contained in array_spectra (e.g. to be able to plot them as scatterplotgl). Args: array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. pad_individual_peaks (bool, optional): If true, pads the peaks individually, with a given threshold distance between two m/z values to consider them as belonging to the same peak. Else, it pads all single value in the spectrum with zeros. Defaults to False. padding (float, optional): The m/z distance between a peak value and a zero for the padding. Default to 10**-4. Returns: (np.ndarray, np.ndarray): An array of shape (2,m) containing the padded spectrum data (m/z and intensity) and an array of shape (k,) containing the number of zeros added at each index of array_spectra. \"\"\" # For speed, allocate array of maximum size new_array_spectra = np . zeros ( ( array_spectra . shape [ 0 ], array_spectra . shape [ 1 ] * 3 ), dtype = np . float32 ) array_index_padding = np . zeros (( array_spectra . shape [ 1 ]), dtype = np . int32 ) # Either pad each peak individually if pad_individual_peaks : pad = 0 # Loop over m/z values for i in range ( array_spectra . shape [ 1 ] - 1 ): # If there's a discontinuity between two peaks, pad with zeros if array_spectra [ 0 , i + 1 ] - array_spectra [ 0 , i ] >= 2 * 10 **- 4 : # Add left peak new_array_spectra [ 0 , i + pad ] = array_spectra [ 0 , i ] new_array_spectra [ 1 , i + pad ] = array_spectra [ 1 , i ] # Add zero to the right of left peak pad += 1 new_array_spectra [ 0 , i + pad ] = array_spectra [ 0 , i ] + padding new_array_spectra [ 1 , i + pad ] = 0 # Add zero to the left of right peak pad += 1 new_array_spectra [ 0 , i + pad ] = array_spectra [ 0 , i + 1 ] - padding new_array_spectra [ 1 , i + pad ] = 0 # Record that 2 zeros have been added between idx i and i+1 array_index_padding [ i ] = 2 # Right peak added in the next loop iteration # Else, just store the values of array_spectra without padding else : # logging.info(\"two near peaks\") new_array_spectra [ 0 , i + pad ] = array_spectra [ 0 , i ] new_array_spectra [ 1 , i + pad ] = array_spectra [ 1 , i ] # Add the last value of array_spectra new_array_spectra [ 0 , array_spectra . shape [ 1 ] + pad - 1 ] = array_spectra [ 0 , - 1 ] new_array_spectra [ 1 , array_spectra . shape [ 1 ] + pad - 1 ] = array_spectra [ 1 , - 1 ] return new_array_spectra [:, : array_spectra . shape [ 1 ] + pad ], array_index_padding # Or pad each m/z value individually else : # Loop over m/z values for i in range ( array_spectra . shape [ 1 ]): # Store old array in a regular grid in the extended array new_array_spectra [ 0 , 3 * i + 1 ] = array_spectra [ 0 , i ] new_array_spectra [ 1 , 3 * i + 1 ] = array_spectra [ 1 , i ] # Add zeros in the remaining slots new_array_spectra [ 0 , 3 * i ] = array_spectra [ 0 , i ] - padding new_array_spectra [ 0 , 3 * i + 2 ] = array_spectra [ 0 , i ] + padding # Record that 2 zeros have been added between idx i and i+1 array_index_padding [ i ] = 2 return new_array_spectra , array_index_padding compute_avg_intensity_per_lipid ( l_intensity_with_lipids , l_idx_labels ) This function computes the average intensity of each annotated lipid (summing over peaks coming from the same lipid) from a given spectrum. Parameters: Name Type Description Default l_intensity_with_lipids list(float A list of peak intensities (where one lipid can correspond to several peaks, but one peak always correspond to one lipid). required l_idx_labels list(int A list of lipid annotation, each lipid being annotated with a unique integer. required Returns: Type Description list ( int ), list ( float ) The first list provides the lipid indices, while the second provide the lipid average intensities. Peaks corresponding to identical lipid have been averaged. Source code in modules/tools/spectra.py 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 @njit def compute_avg_intensity_per_lipid ( l_intensity_with_lipids , l_idx_labels ): \"\"\"This function computes the average intensity of each annotated lipid (summing over peaks coming from the same lipid) from a given spectrum. Args: l_intensity_with_lipids (list(float)): A list of peak intensities (where one lipid can correspond to several peaks, but one peak always correspond to one lipid). l_idx_labels (list(int)): A list of lipid annotation, each lipid being annotated with a unique integer. Returns: (list(int), list(float)): The first list provides the lipid indices, while the second provide the lipid average intensities. Peaks corresponding to identical lipid have been averaged. \"\"\" # Define empty lists for the lipid indices and intensities l_unique_idx_labels = [] l_avg_intensity = [] idx_label_temp = - 1 # Loop over the lipid indices (i.e. m/z values) for i , idx_label in enumerate ( l_idx_labels ): # Actual lipid and not just a placeholder if idx_label >= 0 : # New lipid is discovered if idx_label != idx_label_temp : idx_label_temp = l_idx_labels [ i ] l_avg_intensity . append ( l_intensity_with_lipids [ i ]) l_unique_idx_labels . append ( idx_label ) # Continuity of the previous lipid else : l_avg_intensity [ - 1 ] += l_intensity_with_lipids [ i ] return l_unique_idx_labels , l_avg_intensity compute_image_using_index_and_image_lookup ( low_bound , high_bound , array_spectra , array_pixel_indexes , img_shape , lookup_table_spectra , lookup_table_image , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform = False ) This function is very much similar to compute_image_using_index_lookup, except that it uses a different lookup table: lookup_table_image. This lookup table contains the cumulated intensities above the current lookup (instead of the sheer intensities). Therefore, any image corresponding to the integral of all pixel spectra between two bounds can be approximated by the difference of the lookups closest to these bounds. The integral can then be corrected a posteriori to obtain the exact value. If the m/z distance between the two bounds is low, it calls compute_image_using_index_lookup() as the optimization is not worth it. It wraps the internal functions _compute_image_using_index_and_image_lookup_full() and _compute_image_using_index_and_image_lookup_partial() to ensure that the proper array type is used with numba. Parameters: Name Type Description Default low_bound float Lower m/z value for the annotation. required high_bound float Higher m/z value for the annotation. required array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required img_shape tuple(int A tuple with the two integer values corresponding to height and width of the current slice acquisition. required lookup_table_spectra np . ndarray An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_spectra[i,j] contains the first m/z index of pixel j such that m/z >= i * divider_lookup. required lookup_table_image np . ndarray An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_image[i,j] contains, for the pixel of index j, the cumulated intensities from the lowest possible m/z until the first m/z such that m/z >= i * divider_lookup. required divider_lookup int Integer used to set the resolution when building the lookup table. required array_peaks_transformed_lipids np . ndarray A two-dimensional numpy array, which contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. required array_corrective_factors np . ndarray A three-dimensional numpy array, which contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). required apply_transform bool If True, the MAIA correction for pixel intensity is applied. Defaults to False. False Returns: Type Description np . ndarray An array of shape img_shape (reprensenting an image) containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. Source code in modules/tools/spectra.py 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 def compute_image_using_index_and_image_lookup ( low_bound , high_bound , array_spectra , array_pixel_indexes , img_shape , lookup_table_spectra , lookup_table_image , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform = False , ): \"\"\"This function is very much similar to compute_image_using_index_lookup, except that it uses a different lookup table: lookup_table_image. This lookup table contains the cumulated intensities above the current lookup (instead of the sheer intensities). Therefore, any image corresponding to the integral of all pixel spectra between two bounds can be approximated by the difference of the lookups closest to these bounds. The integral can then be corrected a posteriori to obtain the exact value. If the m/z distance between the two bounds is low, it calls compute_image_using_index_lookup() as the optimization is not worth it. It wraps the internal functions _compute_image_using_index_and_image_lookup_full() and _compute_image_using_index_and_image_lookup_partial() to ensure that the proper array type is used with numba. Args: low_bound (float): Lower m/z value for the annotation. high_bound (float): Higher m/z value for the annotation. array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. img_shape (tuple(int)): A tuple with the two integer values corresponding to height and width of the current slice acquisition. lookup_table_spectra (np.ndarray): An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_spectra[i,j] contains the first m/z index of pixel j such that m/z >= i * divider_lookup. lookup_table_image (np.ndarray): An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_image[i,j] contains, for the pixel of index j, the cumulated intensities from the lowest possible m/z until the first m/z such that m/z >= i * divider_lookup. divider_lookup (int): Integer used to set the resolution when building the lookup table. array_peaks_transformed_lipids (np.ndarray): A two-dimensional numpy array, which contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. array_corrective_factors (np.ndarray): A three-dimensional numpy array, which contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). apply_transform (bool): If True, the MAIA correction for pixel intensity is applied. Defaults to False. Returns: (np.ndarray): An array of shape img_shape (reprensenting an image) containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. \"\"\" # Image lookup table is not worth it for small differences between the bounds # And image lookup can't be used if the transformation should not be applied if ( high_bound - low_bound ) < 5 or apply_transform : return compute_image_using_index_lookup ( low_bound , high_bound , array_spectra , array_pixel_indexes , img_shape , lookup_table_spectra , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform , ) else : return _compute_image_using_index_and_image_lookup_partial ( low_bound , high_bound , array_spectra , array_pixel_indexes , img_shape , lookup_table_spectra , lookup_table_image , divider_lookup , ) compute_image_using_index_lookup ( low_bound , high_bound , array_spectra , array_pixel_indexes , img_shape , lookup_table_spectra , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform ) For each pixel, this function extracts from array_spectra the intensity of a given m/z selection (normally corresponding to a lipid annotation) defined by a lower and a higher bound. For faster computation, it uses lookup_table_spectra to map m/z values to given indices. It then assigns the pixel intensity to an array of shape img_shape, therefore producing an image representing the requested lipid distribution. Parameters: Name Type Description Default low_bound float Lower m/z value for the annotation. required high_bound float Higher m/z value for the annotation. required array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required img_shape tuple(int A tuple with the two integer values corresponding to height and width of the current slice acquisition. required lookup_table_spectra np . ndarray An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_spectra[i,j] contains the first m/z index of pixel j such that m/z >= i * divider_lookup. required divider_lookup int Integer used to set the resolution when building the lookup table. required array_peaks_transformed_lipids np . ndarray A two-dimensional numpy array, which contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. required array_corrective_factors np . ndarray A three-dimensional numpy array, which contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). required apply_transform bool If True, the MAIA correction for pixel intensity is reverted. required Returns: Type Description np . ndarray An array of shape img_shape (reprensenting an image) containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. Source code in modules/tools/spectra.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 @njit def compute_image_using_index_lookup ( low_bound , high_bound , array_spectra , array_pixel_indexes , img_shape , lookup_table_spectra , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform , ): \"\"\"For each pixel, this function extracts from array_spectra the intensity of a given m/z selection (normally corresponding to a lipid annotation) defined by a lower and a higher bound. For faster computation, it uses lookup_table_spectra to map m/z values to given indices. It then assigns the pixel intensity to an array of shape img_shape, therefore producing an image representing the requested lipid distribution. Args: low_bound (float): Lower m/z value for the annotation. high_bound (float): Higher m/z value for the annotation. array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. img_shape (tuple(int)): A tuple with the two integer values corresponding to height and width of the current slice acquisition. lookup_table_spectra (np.ndarray): An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_spectra[i,j] contains the first m/z index of pixel j such that m/z >= i * divider_lookup. divider_lookup (int): Integer used to set the resolution when building the lookup table. array_peaks_transformed_lipids (np.ndarray): A two-dimensional numpy array, which contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. array_corrective_factors (np.ndarray): A three-dimensional numpy array, which contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). apply_transform (bool): If True, the MAIA correction for pixel intensity is reverted. Returns: (np.ndarray): An array of shape img_shape (reprensenting an image) containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. \"\"\" # Build empty image image = np . zeros (( img_shape [ 0 ], img_shape [ 1 ]), dtype = np . float32 ) # Build an array of ones for the correction (i.e. default is no correction) array_corrective_factors_lipid = np . ones (( img_shape [ 0 ] * img_shape [ 1 ],), np . float32 ) if apply_transform : # Check if the m/z region must transformed, i.e. low and high bound are inside annotation idx_lipid_right = - 1 for idx_lipid , ( min_mz , max_mz , avg_mz ) in enumerate ( array_peaks_transformed_lipids ): # Take 10**-4 for precision if ( low_bound + 10 **- 4 ) >= min_mz and ( high_bound - 10 **- 4 ) <= max_mz : idx_lipid_right = idx_lipid break # If the current region corresponds to a transformed lipid: if idx_lipid_right != - 1 : array_corrective_factors_lipid [:] = array_corrective_factors [ idx_lipid_right ] . flatten () # Find lower bound and add from there for idx_pix in range ( array_pixel_indexes . shape [ 0 ]): # If pixel contains no peak, skip it if array_pixel_indexes [ idx_pix , 0 ] == - 1 : continue # Compute range in which values must be summed and extract corresponding part of spectrum lower_bound = lookup_table_spectra [ int ( low_bound / divider_lookup )][ idx_pix ] higher_bound = lookup_table_spectra [ int ( np . ceil ( high_bound / divider_lookup ))][ idx_pix ] array_to_sum = array_spectra [:, lower_bound : higher_bound + 1 ] # Apply MAIA correction if array_corrective_factors_lipid [ idx_pix ] == 0 : correction = 1.0 else : correction = array_corrective_factors_lipid [ idx_pix ] # Sum the m/z values over the requested range image = _fill_image ( image , idx_pix , img_shape , array_to_sum , lower_bound , higher_bound , low_bound , high_bound , correction , ) return image compute_index_boundaries ( low_bound , high_bound , array_spectra_avg , lookup_table ) This function is very much similar to compute_index_boundaries_nolookup(), except that it uses lookup_table to find the low and high bounds indices faster. As in compute_index_boundaries_nolookup(), it computes, from array_spectra_avg, the first existing indices corresponding to m/z values above the provided lower and higher bounds. If high_bound and/or low_bound are above the highest possible value for the required lookup, it returns the index of the highest existing value. Note that array_spectra_avg normally corresponds to the high-resolution spectrum averaged across all pixels, but in can be any spectrum so long as it is not subdivided in pixels. Also note that there are no partial full versions of this function depending if the dataset is stored in RAM or HDF5, since the two versions would have been almost identical (there's no loop over pixels, contrarily to e.g. compute_image_using_index_lookup(), and a view/copy of the partial spectra in the selection is made as a first step, turning an in a np.ndarray). It wraps the internal numba-ized function _compute_index_boundaries_nolookup(). Parameters: Name Type Description Default low_bound float Lower m/z value for the annotation. required high_bound float Higher m/z value for the annotation. required array_spectra_avg np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity). required lookup_table np . ndarray A 1-dimensional array of length m providing, for each index (i.e. lookup), the index of the first m/z value in the averaged array_spectra superior or equal to the lookup. required Returns: Type Description tuple ( int ) A tuple of integer representing the best guess for the indices of low_bound and high_bound in array_spectra_avg. Source code in modules/tools/spectra.py 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 @njit def compute_index_boundaries ( low_bound , high_bound , array_spectra_avg , lookup_table ): \"\"\"This function is very much similar to compute_index_boundaries_nolookup(), except that it uses lookup_table to find the low and high bounds indices faster. As in compute_index_boundaries_nolookup(), it computes, from array_spectra_avg, the first existing indices corresponding to m/z values above the provided lower and higher bounds. If high_bound and/or low_bound are above the highest possible value for the required lookup, it returns the index of the highest existing value. Note that array_spectra_avg normally corresponds to the high-resolution spectrum averaged across all pixels, but in can be any spectrum so long as it is not subdivided in pixels. Also note that there are no partial full versions of this function depending if the dataset is stored in RAM or HDF5, since the two versions would have been almost identical (there's no loop over pixels, contrarily to e.g. compute_image_using_index_lookup(), and a view/copy of the partial spectra in the selection is made as a first step, turning an in a np.ndarray). It wraps the internal numba-ized function _compute_index_boundaries_nolookup(). Args: low_bound (float): Lower m/z value for the annotation. high_bound (float): Higher m/z value for the annotation. array_spectra_avg (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity). lookup_table (np.ndarray): A 1-dimensional array of length m providing, for each index (i.e. lookup), the index of the first m/z value in the averaged array_spectra superior or equal to the lookup. Returns: (tuple(int)): A tuple of integer representing the best guess for the indices of low_bound and high_bound in array_spectra_avg. \"\"\" # Extract the arrays provided by the lookup table as first guess for the low and high bounds array_to_sum_lb = array_spectra_avg [ 0 , lookup_table [ int ( low_bound )] : lookup_table [ int ( np . ceil ( low_bound ))] + 1 ] array_to_sum_hb = array_spectra_avg [ 0 , lookup_table [ int ( high_bound )] : lookup_table [ int ( np . ceil ( high_bound ))] + 1 ] # Correct the lookup indices with these arrays return _loop_compute_index_boundaries ( array_to_sum_lb , array_to_sum_hb , low_bound , high_bound , lookup_table ) compute_index_boundaries_nolookup ( low_bound , high_bound , array_spectra_avg ) This function computes, from array_spectra_avg, the first existing indices corresponding to m/z values above the provided lower and higher bounds, without using any lookup. If high_bound and/or low_bound are above the highest possible value for the required lookup, it returns the index of the highest existing value. Note that array_spectra_avg normally corresponds to the high-resolution spectrum averaged across all pixels, but in can be any spectrum so long as it is not subdivided in pixels. Parameters: Name Type Description Default low_bound float Lower m/z value for the annotation. required high_bound float Higher m/z value for the annotation. required array_spectra_avg np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity). required Returns: Type Description tuple ( int ) A tuple of integer representing the best guess for the indices of low_bound and high_bound in array_spectra_avg. Source code in modules/tools/spectra.py 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 @njit def compute_index_boundaries_nolookup ( low_bound , high_bound , array_spectra_avg ): \"\"\"This function computes, from array_spectra_avg, the first existing indices corresponding to m/z values above the provided lower and higher bounds, without using any lookup. If high_bound and/or low_bound are above the highest possible value for the required lookup, it returns the index of the highest existing value. Note that array_spectra_avg normally corresponds to the high-resolution spectrum averaged across all pixels, but in can be any spectrum so long as it is not subdivided in pixels. Args: low_bound (float): Lower m/z value for the annotation. high_bound (float): Higher m/z value for the annotation. array_spectra_avg (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity). Returns: (tuple(int)): A tuple of integer representing the best guess for the indices of low_bound and high_bound in array_spectra_avg. \"\"\" # Extract the mz values for array_spectra_avg array_mz = array_spectra_avg [ 0 , :] # Define intial guess for the low and high bounds indices index_low_bound = 0 index_high_bound = array_mz . shape [ 0 ] - 1 # Browse array_mz until low bound is crossed for i , mz in enumerate ( array_mz ): index_low_bound = i if mz >= low_bound : break # Start from the low bound index, and browse array_mz until high bound is crossed for i , mz in enumerate ( array_mz [ index_low_bound :]): index_high_bound = i + index_low_bound if mz >= high_bound : break return index_low_bound , index_high_bound compute_normalized_image_per_lipid ( lb_mz , hb_mz , array_spectra , array_pixel_indexes , image_shape , lookup_table_spectra , cumulated_image_lookup_table , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform = False , percentile_normalization = 99 , RGB_channel_format = True ) This function is mostly a wrapper for compute_image_using_index_and_image_lookup, that is, it computes an image containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. In addition, it adds a step of normalization, such that the output is more visually pleasing and comparable across selections. The output can also be provided in 8 bits, that is, the format of a single channel in an RGB image. Parameters: Name Type Description Default lb_mz float Lower m/z value for the annotation. required hb_mz float Higher m/z value for the annotation. required array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required image_shape tuple(int A tuple with the two integer values corresponding to height and width of the current slice acquisition. required lookup_table_spectra np . ndarray An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_spectra[i,j] contains the first m/z index of pixel j such that m/z >= i * divider_lookup. required cumulated_image_lookup_table np . ndarray An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_image[i,j] contains, for the pixel of index j, the cumulated intensities from the lowest possible m/z until the first m/z such that m/z >= i * divider_lookup. required divider_lookup int Integer used to set the resolution when building the lookup table. required array_peaks_transformed_lipids np . ndarray A two-dimensional numpy array, which contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. required array_corrective_factors np . ndarray A three-dimensional numpy array, which contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). required apply_transform bool If True, the MAIA correction for pixel intensity is applied. Defaults to False. False percentile_normalization int Integer used to re-normalize the data, such that the maximum value correspond to the given percentile. 99 RGB_channel_format bool If False, the output image is provided as an array with values between 0 and 1. Else, the values are between 0 and 255. True Returns: Type Description np . ndarray An array of shape img_shape (reprensenting an image) containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. This image is normalized according to percentile_normalized. Output values are between 0 and 1 (255) depending if RGB_channel_format is False (True). Source code in modules/tools/spectra.py 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 def compute_normalized_image_per_lipid ( lb_mz , hb_mz , array_spectra , array_pixel_indexes , image_shape , lookup_table_spectra , cumulated_image_lookup_table , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform = False , percentile_normalization = 99 , RGB_channel_format = True , ): \"\"\"This function is mostly a wrapper for compute_image_using_index_and_image_lookup, that is, it computes an image containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. In addition, it adds a step of normalization, such that the output is more visually pleasing and comparable across selections. The output can also be provided in 8 bits, that is, the format of a single channel in an RGB image. Args: lb_mz (float): Lower m/z value for the annotation. hb_mz (float): Higher m/z value for the annotation. array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. image_shape (tuple(int)): A tuple with the two integer values corresponding to height and width of the current slice acquisition. lookup_table_spectra (np.ndarray): An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_spectra[i,j] contains the first m/z index of pixel j such that m/z >= i * divider_lookup. cumulated_image_lookup_table (np.ndarray): An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_image[i,j] contains, for the pixel of index j, the cumulated intensities from the lowest possible m/z until the first m/z such that m/z >= i * divider_lookup. divider_lookup (int): Integer used to set the resolution when building the lookup table. array_peaks_transformed_lipids (np.ndarray): A two-dimensional numpy array, which contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. array_corrective_factors (np.ndarray): A three-dimensional numpy array, which contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). apply_transform (bool): If True, the MAIA correction for pixel intensity is applied. Defaults to False. percentile_normalization (int): Integer used to re-normalize the data, such that the maximum value correspond to the given percentile. RGB_channel_format (bool): If False, the output image is provided as an array with values between 0 and 1. Else, the values are between 0 and 255. Returns: (np.ndarray): An array of shape img_shape (reprensenting an image) containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. This image is normalized according to percentile_normalized. Output values are between 0 and 1 (255) depending if RGB_channel_format is False (True). \"\"\" # Get image from raw mass spec data image = compute_image_using_index_and_image_lookup ( lb_mz , hb_mz , array_spectra , array_pixel_indexes , image_shape , lookup_table_spectra , cumulated_image_lookup_table , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform , ) # Normalize by percentile image = image / np . percentile ( image , percentile_normalization ) * 1 image = np . clip ( 0 , 1 , image ) # Convert image to have values between 0 and 255 if RGB_channel_format : image *= 255 return image compute_normalized_spectra ( array_spectra , array_pixel_indexes ) This function takes an array of spectra and returns it normalized (per pixel). In pratice, each pixel spectrum is converted into a uncompressed version, and divided by the sum of all spectra. This might a problematic approach as there seems to be small shifts between spectra across pixels, leading to a noise amplification after normalization. Parameters: Name Type Description Default array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required Returns: Type Description np . ndarray An array of shape (2,m) containing the normalized spectrum data (m/z and intensity). Source code in modules/tools/spectra.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 @njit def compute_normalized_spectra ( array_spectra , array_pixel_indexes ): \"\"\"This function takes an array of spectra and returns it normalized (per pixel). In pratice, each pixel spectrum is converted into a uncompressed version, and divided by the sum of all spectra. This might a problematic approach as there seems to be small shifts between spectra across pixels, leading to a noise amplification after normalization. Args: array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. Returns: (np.ndarray): An array of shape (2,m) containing the normalized spectrum data (m/z and intensity). \"\"\" # Start by converting array_spectra into a very fine-grained version spectrum_sum = convert_array_to_fine_grained ( array_spectra , 10 **- 3 , lb = 350 , hb = 1250 ) + 1 array_spectra_normalized = np . zeros ( array_spectra . shape , dtype = np . float32 ) # Loop over the spectrum of each pixel for idx_pix in range ( array_pixel_indexes . shape [ 0 ]): logging . info ( \"_compute_normalized_spectra:\" + str ( idx_pix / array_pixel_indexes . shape [ 0 ] * 100 ) + \" done\" ) # If pixel contains no peak, skip it if array_pixel_indexes [ idx_pix , 0 ] == - 1 : continue # Get the spectrum of current pixel spectrum = array_spectra [ :, array_pixel_indexes [ idx_pix , 0 ] : array_pixel_indexes [ idx_pix , 1 ] + 1 ] # Out of safety, normalize the spectrum of current pixel with respect to its own sum # Might be useless since array_spectra is normally already normalized by pixel spectrum [ 1 , :] /= np . sum ( spectrum [ 1 , :]) # Then move spectrum to uncompressed version spectrum = convert_array_to_fine_grained ( spectrum , 10 **- 3 , lb = 350 , hb = 1250 ) # Then normalize with respect to all pixels spectrum [ 1 , :] /= spectrum_sum [ 1 , :] # Then back to original space spectrum = strip_zeros ( spectrum ) # Store back the spectrum if ( spectrum . shape [ 1 ] == array_pixel_indexes [ idx_pix , 1 ] + 1 - array_pixel_indexes [ idx_pix , 0 ] ): array_spectra_normalized [ :, array_pixel_indexes [ idx_pix , 0 ] : array_pixel_indexes [ idx_pix , 1 ] + 1 ] = spectrum else : # Store shorter-sized spectrum in array_spectra_normalized, rest will be zeros array_spectra_normalized [ :, array_pixel_indexes [ idx_pix , 0 ] : array_pixel_indexes [ idx_pix , 0 ] + len ( spectrum ) + 1 , ] return array_spectra_normalized compute_spectrum_per_row_selection ( list_index_bound_rows , list_index_bound_column_per_row , array_spectra , array_pixel_indexes , image_shape , array_peaks_transformed_lipids , array_corrective_factors , zeros_extend = True , apply_correction = False ) This function computes the average spectrum from a manual selection of rows of pixel (each containing a spectrum). The resulting average array can be zero-padded. Parameters: Name Type Description Default list_index_bound_rows list(tuple A list of lower and upper indices delimiting the range of rows belonging to the current selection. required list_index_bound_column_per_row list(list For each row (outer list), provides the index of the columns delimiting the current selection (inner list). required array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required image_shape int , int A tuple of integers, indicating the vertical and horizontal sizes of the current slice. required array_peaks_transformed_lipids np . ndarray A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), filtered for the lipids who have preliminarily been transformed. Sorted by min_mz. required array_corrective_factors np . ndarray A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the corrective factors for the lipids we want to visualize, for each pixel. required zeros_extend bool If True, the resulting spectrum will be zero-padded. Defaults to True. True apply_correction bool If True, MAIA transformation is applied to the lipids belonging to array_peaks_transformed_lipids, for each pixel. This option makes the computation very slow, so it shouldn't be selected if the computations must be done on the fly. Defaults to False. False Returns: Type Description np . ndarray Spectrum averaged from a manual selection of rows of pixel, containing m/z values in the first row, and intensities in the second row. Source code in modules/tools/spectra.py 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 @njit def compute_spectrum_per_row_selection ( list_index_bound_rows , list_index_bound_column_per_row , array_spectra , array_pixel_indexes , image_shape , array_peaks_transformed_lipids , array_corrective_factors , zeros_extend = True , apply_correction = False , ): \"\"\"This function computes the average spectrum from a manual selection of rows of pixel (each containing a spectrum). The resulting average array can be zero-padded. Args: list_index_bound_rows (list(tuple)): A list of lower and upper indices delimiting the range of rows belonging to the current selection. list_index_bound_column_per_row (list(list)): For each row (outer list), provides the index of the columns delimiting the current selection (inner list). array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. image_shape (int, int): A tuple of integers, indicating the vertical and horizontal sizes of the current slice. array_peaks_transformed_lipids (np.ndarray): A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), filtered for the lipids who have preliminarily been transformed. Sorted by min_mz. array_corrective_factors (np.ndarray): A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the corrective factors for the lipids we want to visualize, for each pixel. zeros_extend (bool, optional): If True, the resulting spectrum will be zero-padded. Defaults to True. apply_correction (bool, optional): If True, MAIA transformation is applied to the lipids belonging to array_peaks_transformed_lipids, for each pixel. This option makes the computation very slow, so it shouldn't be selected if the computations must be done on the fly. Defaults to False. Returns: (np.ndarray): Spectrum averaged from a manual selection of rows of pixel, containing m/z values in the first row, and intensities in the second row. \"\"\" # Get list of row indexes for the current selection ll_idx , size_array , ll_idx_pix = get_list_row_indexes ( list_index_bound_rows , list_index_bound_column_per_row , array_pixel_indexes , image_shape ) # Init array selection of size size_array array_spectra_selection = np . zeros (( 2 , size_array ), dtype = np . float32 ) pad = 0 # Fill array line by line for i , x in enumerate ( range ( list_index_bound_rows [ 0 ], list_index_bound_rows [ 1 ] + 1 )): for idx_1 , idx_2 , idx_pix_1 , idx_pix_2 in zip ( ll_idx [ i ][ 0 : - 1 : 2 ], ll_idx [ i ][ 1 :: 2 ], ll_idx_pix [ i ][ 0 : - 1 : 2 ], ll_idx_pix [ i ][ 1 :: 2 ] ): if apply_correction : for idx_pix in range ( idx_pix_1 , idx_pix_2 + 1 ): idx_mz_1 , idx_mz_2 = array_pixel_indexes [ idx_pix ] # If the pixel is not empty if idx_mz_2 - idx_mz_1 > 0 : array_spectra_pix_to_correct = array_spectra [ :, idx_mz_1 : idx_mz_2 + 1 ] . copy () array_spectra_pix_corrected , n_peaks_transformed = compute_standardization ( array_spectra_pix_to_correct . T , idx_pix , array_peaks_transformed_lipids , array_corrective_factors , ) array_spectra_selection [ :, pad : pad + idx_mz_2 + 1 - idx_mz_1 ] = array_spectra_pix_corrected . T pad += idx_mz_2 + 1 - idx_mz_1 else : array_spectra_selection [:, pad : pad + idx_2 + 1 - idx_1 ] = array_spectra [ :, idx_1 : idx_2 + 1 ] pad += idx_2 + 1 - idx_1 # Sort array array_spectra_selection = array_spectra_selection [:, array_spectra_selection [ 0 ] . argsort ()] # Remove the values that have been zeroed-out if apply_correction : array_spectra_selection = strip_zeros ( array_spectra_selection ) # Sum the arrays (similar m/z values are added) array_spectra_selection = reduce_resolution_sorted_array_spectra ( array_spectra_selection , resolution = 10 **- 4 ) # Pad with zeros if asked if zeros_extend : array_spectra_selection , array_index_padding = add_zeros_to_spectrum ( array_spectra_selection ) return array_spectra_selection compute_standardization ( array_spectra_pixel , idx_pixel , array_peaks , array_corrective_factors ) This function takes the spectrum data of a given pixel, along with the corresponding pixel index, and transforms the value of the lipids intensities annotated in 'array_peaks' according to the transformation registered in 'array_corrective_factors'. Parameters: Name Type Description Default array_spectra_pixel np . ndarray A numpy array containing spectrum data (m/z and intensity) of pixel 'idx_pixel', sorted by mz. required idx_pixel int Index of the current pixel whose spectrum is transformed. required array_peaks np . ndarray A numpy array containing the peak annotations (min peak, max peak, average value of the peak), filtered for the lipids who have preliminarily been transformed. Sorted by min_mz. required array_corrective_factors np . ndarray A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the corrective factors for the lipids we want to visualize, for each pixel. required Returns: Type Description np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity), of pixel 'idx_pixel', sorted by mz, with lipids values transformed. Source code in modules/tools/spectra.py 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 @njit def compute_standardization ( array_spectra_pixel , idx_pixel , array_peaks , array_corrective_factors ): \"\"\"This function takes the spectrum data of a given pixel, along with the corresponding pixel index, and transforms the value of the lipids intensities annotated in 'array_peaks' according to the transformation registered in 'array_corrective_factors'. Args: array_spectra_pixel (np.ndarray): A numpy array containing spectrum data (m/z and intensity) of pixel 'idx_pixel', sorted by mz. idx_pixel (int): Index of the current pixel whose spectrum is transformed. array_peaks (np.ndarray): A numpy array containing the peak annotations (min peak, max peak, average value of the peak), filtered for the lipids who have preliminarily been transformed. Sorted by min_mz. array_corrective_factors (np.ndarray): A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the corrective factors for the lipids we want to visualize, for each pixel. Returns: (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity), of pixel 'idx_pixel', sorted by mz, with lipids values transformed. \"\"\" # Define initial values idx_peak = 0 idx_mz = 0 n_peaks_transformed = 0 while idx_mz < array_spectra_pixel . shape [ 0 ] and idx_peak < array_peaks . shape [ 0 ]: mz , intensity = array_spectra_pixel [ idx_mz ] min_mz , max_mz , mz_estimated = array_peaks [ idx_peak ] # New window has been discovered if mz >= min_mz and mz <= max_mz : idx_min_mz = idx_mz idx_max_mz = idx_mz for idx_mz in range ( idx_min_mz , array_spectra_pixel . shape [ 0 ]): mz , intensity = array_spectra_pixel [ idx_mz ] if mz > max_mz : idx_max_mz = idx_mz - 1 break # Most likely, the annotation doesn't exist, so skip it if np . abs ( idx_max_mz - idx_min_mz ) <= 0.9 : # Zero-out value that do not belong to the MAIA-transformed regions array_spectra_pixel [ idx_mz , 1 ] = 0 # Else compute a multiplicative factor else : # Get array of intensity before and after correction for current pixel correction = array_corrective_factors [ idx_peak ] . flatten ()[ idx_pixel ] # Multiply all intensities in the window by the corrective coefficient array_spectra_pixel [ idx_min_mz : idx_max_mz + 1 , 1 ] *= correction n_peaks_transformed += 1 # Move on to the next peak idx_peak += 1 else : if mz > max_mz : idx_peak += 1 else : # zero-out value that do not belong to the MAIA-transformed regions array_spectra_pixel [ idx_mz , 1 ] = 0 idx_mz += 1 return array_spectra_pixel , n_peaks_transformed compute_thread_safe_function ( compute_function , cache , data , slice_index , * args_compute_function , ** kwargs_compute_function ) This function is a wrapper for safe multithreading and multiprocessing execution of compute_function. This is needed due to the regular cleansing of memory-mapped object. Parameters: Name Type Description Default compute_function func The function/method whose result must be loaded/saved. required cache flask_caching . Cache A caching object, used to check if the reading of memory-mapped data is safe required *args_compute_function Arguments of compute_function. () **kwargs_compute_function Named arguments of compute_function. {} Returns: Type Description The result of compute_function. Type may vary depending on compute_function. Source code in modules/tools/spectra.py 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 def compute_thread_safe_function ( compute_function , cache , data , slice_index , * args_compute_function , ** kwargs_compute_function ): \"\"\"This function is a wrapper for safe multithreading and multiprocessing execution of compute_function. This is needed due to the regular cleansing of memory-mapped object. Args: compute_function (func): The function/method whose result must be loaded/saved. cache (flask_caching.Cache): A caching object, used to check if the reading of memory-mapped data is safe *args_compute_function: Arguments of compute_function. **kwargs_compute_function: Named arguments of compute_function. Returns: The result of compute_function. Type may vary depending on compute_function. \"\"\" logging . info ( \"Trying to compute the thread-safe version of \" + str ( compute_function ) . split ( \"<\" )[ 1 ] . split ( \"at\" )[ 0 ] ) if cache is not None : # Wait for the data to be safe for reading while cache . get ( \"locked-cleaning\" ): time . sleep ( 0.05 ) # Lock it while while it's being read cache . set ( \"locked-reading\" , True ) else : logging . warning ( \"No cache provided, the thread unsafe version of the function will be run\" ) # Run the actual function try : result = compute_function ( * args_compute_function , ** kwargs_compute_function ) except : logging . warning ( 'The function \" %s \" failed to run' % str ( compute_function )) result = None if cache is not None : # Unlock the data cache . set ( \"locked-reading\" , False ) if data is not None : # Clean the memory-mapped data data . clean_memory ( slice_index = slice_index , cache = cache ) # Return result return result compute_zeros_extended_spectrum_per_pixel ( idx_pix , array_spectra , array_pixel_indexes ) This function computes a zero-extended version of the spectrum of pixel indexed by idx_pix. Parameters: Name Type Description Default idx_pix int Index of the pixel to return. required array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required Returns: Type Description np . ndarray An array of shape (2,m) containing the zero-padded spectrum data (m/z and intensity) for the requested pixel. Source code in modules/tools/spectra.py 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 @njit def compute_zeros_extended_spectrum_per_pixel ( idx_pix , array_spectra , array_pixel_indexes ): \"\"\"This function computes a zero-extended version of the spectrum of pixel indexed by idx_pix. Args: idx_pix (int): Index of the pixel to return. array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. Returns: (np.ndarray): An array of shape (2,m) containing the zero-padded spectrum data (m/z and intensity) for the requested pixel. \"\"\" array_spectra = return_spectrum_per_pixel ( idx_pix , array_spectra , array_pixel_indexes ) new_array_spectra , array_index_padding = add_zeros_to_spectrum ( array_spectra ) return new_array_spectra convert_array_to_fine_grained ( array , resolution , lb = 350 , hb = 1250 ) This function converts an array to a fine-grained version, which is common to all pixels, allowing for easier computations. If several values of the compressed version map to the same value of the uncompressed one, they are summed. Therefore, when ran on the spectrum of a whole image, it adds the spectra of all pixels. Parameters: Name Type Description Default array np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity). required resolution float The resolution used for finer-graining. required lb int Lower bound for the fine-grained array. Defaults to 350. 350 hb int Higher bound for the fine-grained array. Defaults to 1250. 1250 Returns: Type Description np . ndarray A sparse, fine-grained array of shape (2,m) containing spectrum data (m/z and intensity). Source code in modules/tools/spectra.py 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 @njit def convert_array_to_fine_grained ( array , resolution , lb = 350 , hb = 1250 ): \"\"\"This function converts an array to a fine-grained version, which is common to all pixels, allowing for easier computations. If several values of the compressed version map to the same value of the uncompressed one, they are summed. Therefore, when ran on the spectrum of a whole image, it adds the spectra of all pixels. Args: array (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity). resolution (float): The resolution used for finer-graining. lb (int, optional): Lower bound for the fine-grained array. Defaults to 350. hb (int, optional): Higher bound for the fine-grained array. Defaults to 1250. Returns: (np.ndarray): A sparse, fine-grained array of shape (2,m) containing spectrum data (m/z and intensity). \"\"\" # Build an empty (zeroed) array with the requested uncompressed size new_array = np . linspace ( lb , hb , int ( round (( hb - lb ) / resolution ))) new_array = np . vstack (( new_array , np . zeros ( new_array . shape , dtype = np . float32 ))) # Fill it with the values from the compressed array for mz , intensity in array . T : new_array [ 1 , int ( round (( mz - lb ) * ( 1 / resolution )))] += intensity return new_array convert_coor_to_spectrum_idx ( coordinate , shape ) This function takes a tuple of integers representing the coordinates of the pixel in the current slice and converts it into an index in a flattened version of the image. Parameters: Name Type Description Default coordinate tuple(int Coordinate in the original image. required shape tuple(int Shape of the MALDI acquisition of the corresponding slice. required Returns: Type Description int Pixel index in a flattened version of the slice image. Source code in modules/tools/spectra.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @njit def convert_coor_to_spectrum_idx ( coordinate , shape ): \"\"\"This function takes a tuple of integers representing the coordinates of the pixel in the current slice and converts it into an index in a flattened version of the image. Args: coordinate tuple(int): Coordinate in the original image. shape (tuple(int)): Shape of the MALDI acquisition of the corresponding slice. Returns: (int): Pixel index in a flattened version of the slice image. \"\"\" ind = coordinate [ 0 ] * shape [ 1 ] + coordinate [ 1 ] if ind >= shape [ 0 ] * shape [ 1 ]: # logging.warning(\"Index not allowed.\") return - 1 return ind convert_spectrum_idx_to_coor ( index , shape ) This function takes a pixel index and converts it into a tuple of integers representing the coordinates of the pixel in the current slice. Parameters: Name Type Description Default index int Pixel index in a flattened version of the slice image. required shape tuple(int Shape of the MALDI acquisition of the corresponding slice. required Returns: Type Description tuple ( int ) Corresponding coordinate in the original image. Source code in modules/tools/spectra.py 24 25 26 27 28 29 30 31 32 33 34 35 36 @njit def convert_spectrum_idx_to_coor ( index , shape ): \"\"\"This function takes a pixel index and converts it into a tuple of integers representing the coordinates of the pixel in the current slice. Args: index (int): Pixel index in a flattened version of the slice image. shape (tuple(int)): Shape of the MALDI acquisition of the corresponding slice. Returns: (tuple(int)): Corresponding coordinate in the original image. \"\"\" return int ( index / shape [ 1 ]), int ( index % shape [ 1 ]) get_list_row_indexes ( list_index_bound_rows , list_index_bound_column_per_row , array_pixel_indexes , image_shape ) This function turns a selection of rows (bounds in list_index_bound_rows) and corresponding columns (bounds in list_index_bound_column_per_row) into an optimized list of pixel indices in array_spectra. It takes advantage of the fact that pixels that are neighbours in a given rows also have contiguous spectra in array_spectra, allowing for faster query. Parameters: Name Type Description Default list_index_bound_rows list(tuple A list of lower and upper indices delimiting the range of rows belonging to the current selection. required list_index_bound_column_per_row list(list For each row (outer list), provides the index of the columns delimiting the current selection (inner list). required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required image_shape int , int A tuple of integers, indicating the vertical and horizontal sizes of the current slice. required Returns: Type Description list ( list ) List of 2-elements lists which contains the mz indices (inner list) in array_spectra of the extrema pixel for each row (outer list). int Total size of the concatenated spectra indexed list ( list ) List of 2-elements lists which contains pixels indices (inner list) in array_spectra of the extrema pixel for each row (outer list). Source code in modules/tools/spectra.py 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 @njit def get_list_row_indexes ( list_index_bound_rows , list_index_bound_column_per_row , array_pixel_indexes , image_shape ): \"\"\"This function turns a selection of rows (bounds in list_index_bound_rows) and corresponding columns (bounds in list_index_bound_column_per_row) into an optimized list of pixel indices in array_spectra. It takes advantage of the fact that pixels that are neighbours in a given rows also have contiguous spectra in array_spectra, allowing for faster query. Args: list_index_bound_rows (list(tuple)): A list of lower and upper indices delimiting the range of rows belonging to the current selection. list_index_bound_column_per_row (list(list)): For each row (outer list), provides the index of the columns delimiting the current selection (inner list). array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. image_shape (int, int): A tuple of integers, indicating the vertical and horizontal sizes of the current slice. Returns: (list(list)): List of 2-elements lists which contains the mz indices (inner list) in array_spectra of the extrema pixel for each row (outer list). (int): Total size of the concatenated spectra indexed (list(list)): List of 2-elements lists which contains pixels indices (inner list) in array_spectra of the extrema pixel for each row (outer list). \"\"\" # Compute size array size_array = 0 ll_idx = [] ll_idx_pix = [] # Loop over rows in the selection for i , x in enumerate ( range ( list_index_bound_rows [ 0 ], list_index_bound_rows [ 1 ] + 1 )): # Careful: list_index_bound_column_per_row l_idx = [] l_idx_pix = [] for j in range ( 0 , len ( list_index_bound_column_per_row [ i ]), 2 ): # Check if we're not just looping over zero padding if ( list_index_bound_column_per_row [ i ][ j ] == 0 and list_index_bound_column_per_row [ i ][ j + 1 ] == 0 ): continue # Get the outer indexes of the (concatenated) spectra of the current row belonging to # the selection idx_pix_1 = convert_coor_to_spectrum_idx ( ( x , list_index_bound_column_per_row [ i ][ j ]), image_shape ) idx_1 = array_pixel_indexes [ idx_pix_1 , 0 ] idx_pix_2 = convert_coor_to_spectrum_idx ( ( x , list_index_bound_column_per_row [ i ][ j + 1 ]), image_shape ) idx_2 = array_pixel_indexes [ idx_pix_2 , 1 ] # Case we started or finished with empty pixel if idx_1 == - 1 or idx_2 == - 1 : # Move forward until a non-empty pixel is found for idx_1 j = 1 while idx_1 == - 1 : idx_1 = array_pixel_indexes [ idx_pix_1 + j , 0 ] j += 1 idx_pix_1 = idx_pix_1 + j - 1 # Move backward until a non-empty pixel is found for idx_2 j = 1 while idx_2 == - 1 : idx_2 = array_pixel_indexes [ idx_pix_2 - j , 1 ] j += 1 idx_pix_2 = idx_pix_2 + j - 1 # Check that we still have idx_2>=idx_1 if idx_1 > idx_2 : pass else : size_array += idx_2 + 1 - idx_1 l_idx . extend ([ idx_1 , idx_2 ]) l_idx_pix . extend ([ idx_pix_1 , idx_pix_2 ]) # Add the couple of spectra indexes to the list ll_idx . append ( l_idx ) ll_idx_pix . append ( l_idx_pix ) return ll_idx , size_array , ll_idx_pix global_lipid_index_store ( data , slice_index , l_spectra ) This function is used to extract the lipid label indexes for a given list of spectra, coming from a given slice (slice_index). Parameters: Name Type Description Default data MaldiData The object used to access the MALDI data. required slice_index int Index of the current slice. required l_spectra list(np.ndarray A list of spectra (two dimensional numpy arrays), coming from the slice having index slice_index. required Returns: Type Description list ( list ( str )) A list of list of lipid labels, one list per spectrum. Source code in modules/tools/spectra.py 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 def global_lipid_index_store ( data , slice_index , l_spectra ): \"\"\"This function is used to extract the lipid label indexes for a given list of spectra, coming from a given slice (slice_index). Args: data (MaldiData): The object used to access the MALDI data. slice_index (int): Index of the current slice. l_spectra (list(np.ndarray)): A list of spectra (two dimensional numpy arrays), coming from the slice having index slice_index. Returns: (list(list(str))): A list of list of lipid labels, one list per spectrum. \"\"\" logging . info ( \"Starting computing ll_idx_labels\" ) ll_idx_labels = [] for spectrum in l_spectra : if spectrum is not None : # Get the average spectrum and add it to m/z plot grah_scattergl_data = np . array ( spectrum , dtype = np . float32 ) # Get df for current slice df_names = data . get_annotations ()[ data . get_annotations ()[ \"slice\" ] == slice_index ] # Extract lipid names l_idx_labels = return_index_labels ( df_names [ \"min\" ] . to_numpy (), df_names [ \"max\" ] . to_numpy (), grah_scattergl_data [ 0 , :], ) else : l_idx_labels = None # Save in a list of lists ll_idx_labels . append ( l_idx_labels ) logging . info ( \"Returning ll_idx_labels\" ) return ll_idx_labels reduce_resolution_sorted ( mz , intensity , resolution , max_intensity = True ) This function function has been imported from the mspec module. Please consult the corresponding module to get the docstring. Source code in modules/tools/spectra.py 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 @njit def reduce_resolution_sorted ( mz : np . ndarray , intensity : np . ndarray , resolution : float , max_intensity = True ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"This function function has been imported from the mspec module. Please consult the corresponding module to get the docstring. \"\"\" # First just count the unique values and store them to avoid recalc current_mz = - 1.0 cnt = 0 approx_mz = np . empty ( mz . shape , dtype = np . double ) for i in range ( len ( mz )): approx_mz [ i ] = np . floor ( mz [ i ] / resolution ) * resolution if approx_mz [ i ] != current_mz : cnt += 1 current_mz = approx_mz [ i ] new_mz = np . empty ( cnt , dtype = np . double ) new_intensity = np . empty ( cnt , dtype = np . double ) current_mz = - 1.0 rix = - 1 for i in range ( len ( mz )): if approx_mz [ i ] != current_mz : rix += 1 new_mz [ rix ] = approx_mz [ i ] new_intensity [ rix ] = intensity [ i ] current_mz = approx_mz [ i ] else : # retrieve the maximum intensity value within the new bin if max_intensity : # check that the new intensity is greater than what is already there if intensity [ i ] > new_intensity [ rix ]: new_intensity [ rix ] = intensity [ i ] # sum the intensity values within the new bin else : new_intensity [ rix ] += intensity [ i ] return new_mz , new_intensity reduce_resolution_sorted_array_spectra ( array_spectra , resolution = 10 ** - 3 ) Recompute a sparce representation of the spectrum at a lower (fixed) resolution, summing over the redundant bins. Resolution should be <=10**-4 as it's about the maximum precision allowed by float32. Parameters: Name Type Description Default array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required resolution float The size of the bin used to merge intensities. Defaults to 10**-3. 10 ** -3 Returns: Type Description np . ndarray Array of shape=(2, m) similar to the input array but with a new sampling resolution. Source code in modules/tools/spectra.py 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 @njit def reduce_resolution_sorted_array_spectra ( array_spectra , resolution = 10 **- 3 ): \"\"\"Recompute a sparce representation of the spectrum at a lower (fixed) resolution, summing over the redundant bins. Resolution should be <=10**-4 as it's about the maximum precision allowed by float32. Args: array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. resolution (float, optional): The size of the bin used to merge intensities. Defaults to 10**-3. Returns: (np.ndarray): Array of shape=(2, m) similar to the input array but with a new sampling resolution. \"\"\" # Get the re-sampled m/z and intensities from mspec library, with max_intensity = False to sum # over redundant bins new_mz , new_intensity = reduce_resolution_sorted ( array_spectra [ 0 , :], array_spectra [ 1 , :], resolution , max_intensity = False ) # Build a new array as the stack of the two others new_array_spectra = np . empty (( 2 , new_mz . shape [ 0 ]), dtype = np . float32 ) new_array_spectra [ 0 , :] = new_mz new_array_spectra [ 1 , :] = new_intensity return new_array_spectra return_idx_inf ( l_idx_labels ) Returns the indices of the lipids that do not have an annotation Parameters: Name Type Description Default l_idx_labels np . ndarray A 1-dimensional array containing the indices of the lipid labels. required Returns: Type Description np . ndarray A list containing the indices of the lipids that do not have an annotation. Source code in modules/tools/spectra.py 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 @njit def return_idx_inf ( l_idx_labels ): \"\"\"Returns the indices of the lipids that do not have an annotation Args: l_idx_labels (np.ndarray): A 1-dimensional array containing the indices of the lipid labels. Returns: (np.ndarray): A list containing the indices of the lipids that do not have an annotation. \"\"\" return [ i for i , x in enumerate ( l_idx_labels ) if x < 0 ] return_idx_sup ( l_idx_labels ) Returns the indices of the lipids that have an annotation Parameters: Name Type Description Default l_idx_labels np . ndarray A 1-dimensional array containing the indices of the lipid labels. required Returns: Type Description np . ndarray A list containing the indices of the lipids that have an annotation. Source code in modules/tools/spectra.py 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 @njit def return_idx_sup ( l_idx_labels ): \"\"\"Returns the indices of the lipids that have an annotation Args: l_idx_labels (np.ndarray): A 1-dimensional array containing the indices of the lipid labels. Returns: (np.ndarray): A list containing the indices of the lipids that have an annotation. \"\"\" return [ i for i , x in enumerate ( l_idx_labels ) if x >= 0 ] return_index_labels ( l_min , l_max , l_mz , zero_padding_extra = 5 * 10 ** - 5 ) This function returns the corresponding lipid name indices from a list of m/z values. Note that the zero_padding_extra parameter is needed for both taking into account the zero-padding (this way zeros on the sides of the peak are also identified as the annotated lipid) but also because the annotation is very stringent in the first place, and sometimes border of the peaks are missing in the annotation. Parameters: Name Type Description Default l_min list(int This list provides the lower peak boundaries of the identified lipids. required l_max list(int This list provides the upper peak boundaries of the identified lipids. required l_mz list(float The list of m/z value which must be annotated with lipid names. required zero_padding_extra float Size of the zero-padding. Defaults to 5 10 *-5. 5 * 10 ** -5 Returns: Type Description np . ndarray A 1-dimensional array containing the indices of the lipid labels. Source code in modules/tools/spectra.py 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 @njit def return_index_labels ( l_min , l_max , l_mz , zero_padding_extra = 5 * 10 **- 5 ): \"\"\"This function returns the corresponding lipid name indices from a list of m/z values. Note that the zero_padding_extra parameter is needed for both taking into account the zero-padding (this way zeros on the sides of the peak are also identified as the annotated lipid) but also because the annotation is very stringent in the first place, and sometimes border of the peaks are missing in the annotation. Args: l_min (list(int)): This list provides the lower peak boundaries of the identified lipids. l_max (list(int)): This list provides the upper peak boundaries of the identified lipids. l_mz (list(float)): The list of m/z value which must be annotated with lipid names. zero_padding_extra (float, optional): Size of the zero-padding. Defaults to 5*10**-5. Returns: (np.ndarray): A 1-dimensional array containing the indices of the lipid labels. \"\"\" # Build empty array for lipid indexes array_indexes = np . empty (( len ( l_mz ),), dtype = np . int32 ) array_indexes . fill ( - 1 ) idx_lipid = 0 idx_mz = 0 while idx_lipid < len ( l_min ) and idx_mz < len ( l_mz ): # Case peak is in lipid boundaries if ( l_mz [ idx_mz ] >= l_min [ idx_lipid ] - zero_padding_extra and l_mz [ idx_mz ] <= l_max [ idx_lipid ] + zero_padding_extra ): array_indexes [ idx_mz ] = idx_lipid idx_mz += 1 # Case peak is before lipid boundaries elif l_mz [ idx_mz ] < l_min [ idx_lipid ] - zero_padding_extra : # array_indexes[idx_mz] = -1 idx_mz += 1 # Case peak is after lipid boundaries elif l_mz [ idx_mz ] > l_max [ idx_lipid ] + zero_padding_extra : idx_lipid += 1 return array_indexes return_spectrum_per_pixel ( idx_pix , array_spectra , array_pixel_indexes ) This function returns the spectrum of the pixel having index pixel_idx, using the lookup table array_pixel_indexes. Parameters: Name Type Description Default idx_pix int Index of the pixel to return. required array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required Returns: Type Description np . ndarray An array of shape (2,m) containing spectrum data (m/z and intensity) for the requested pixel. Source code in modules/tools/spectra.py 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 @njit def return_spectrum_per_pixel ( idx_pix , array_spectra , array_pixel_indexes ): \"\"\"This function returns the spectrum of the pixel having index pixel_idx, using the lookup table array_pixel_indexes. Args: idx_pix (int): Index of the pixel to return. array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. Returns: (np.ndarray): An array of shape (2,m) containing spectrum data (m/z and intensity) for the requested pixel. \"\"\" # Get the indices of the spectrum of the requested pixel idx_1 , idx_2 = array_pixel_indexes [ idx_pix ] if idx_1 == - 1 : idx_2 == - 2 # To return empty list in the end return array_spectra [:, idx_1 : idx_2 + 1 ] sample_rows_from_path ( path ) This function takes a path as input and returns the lower and upper indexes of the rows belonging to the current selection (i.e. indexed in the path), as well as the corresponding column boundaries for each row. Note that, although counter-intuitive given the kind of regression done in this function, x is the vertical axis (from top to bottom), and y the horizontal one. Parameters: Name Type Description Default path np . ndarray A two-dimensional array, containing, in each row, the row and column coordinates (x and y) of the current selection. required Returns: Type Description np . ndarray , np . ndarray The first array contains the lower and upper indexes of the rows belonging to the current selection. The second array contains, for each row, the corresponding column boundaries (there can be more than 2 for non-convex shapes). Source code in modules/tools/spectra.py 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 @njit def sample_rows_from_path ( path ): \"\"\"This function takes a path as input and returns the lower and upper indexes of the rows belonging to the current selection (i.e. indexed in the path), as well as the corresponding column boundaries for each row. Note that, although counter-intuitive given the kind of regression done in this function, x is the vertical axis (from top to bottom), and y the horizontal one. Args: path (np.ndarray): A two-dimensional array, containing, in each row, the row and column coordinates (x and y) of the current selection. Returns: (np.ndarray, np.ndarray): The first array contains the lower and upper indexes of the rows belonging to the current selection. The second array contains, for each row, the corresponding column boundaries (there can be more than 2 for non-convex shapes). \"\"\" # Find out the lower and upper rows x_min = path [:, 0 ] . min () x_max = path [:, 0 ] . max () # Numba won't accept a list of list, so I must use a list of np arrays for the column boundaries list_index_bound_column_per_row = [ np . arange ( 0 ) for x in range ( x_min , x_max + 1 )] # Also register the x-axis direction to correct the linear regression accordingly dir_prev = None # For each couple of points in the path, do a linear regression to find the corresponding y # (needed due to non constant sampling on the y-axis) for i in range ( path . shape [ 0 ] - 1 ): x1 , y1 = path [ i ] x2 , y2 = path [ i + 1 ] if x2 != x1 : slope = ( y2 - y1 ) / ( x2 - x1 ) intercept = y1 - slope * x1 # Compute if change of direction on the x-axis and correct accordingly if x2 >= x1 : dir = 1 else : dir = - 1 if dir_prev is None or dir == dir_prev : offset = 0 else : offset = dir dir_prev = dir # For each x, get the corresponding y (with non constant sampling on y axis) for x in range ( x1 + offset , x2 , dir ): list_index_bound_column_per_row [ x - x_min ] = np . append ( list_index_bound_column_per_row [ x - x_min ], round ( slope * x + intercept ) ) # Min x and max x often cover only zero or one pixel due to the way the sampling is done, we # just get rid of them if len ( list_index_bound_column_per_row [ 0 ]) < 2 : del list_index_bound_column_per_row [ 0 ] x_min += 1 if len ( list_index_bound_column_per_row [ - 1 ]) < 2 : del list_index_bound_column_per_row [ - 1 ] x_max -= 1 # Clean list l_to_del = [] for x in range ( x_min , x_max + 1 ): # If everything went fine, x should appear an even number of times if len ( list_index_bound_column_per_row [ x - x_min ]) % 2 == 0 : pass else : # logging.warning(\"Bug with list x\", x, list_index_bound_column_per_row[x - x_min]) # Try to correct the number of times x appear if ( len ( list_index_bound_column_per_row [ x - x_min ]) % 2 == 1 and len ( list_index_bound_column_per_row [ x - x_min ]) != 1 ): list_index_bound_column_per_row [ x - x_min ] = list_index_bound_column_per_row [ x - x_min ][: - 1 ] else : list_index_bound_column_per_row [ x - x_min ] = np . append ( list_index_bound_column_per_row [ x - x_min ], list_index_bound_column_per_row [ x - x_min ][ 0 ], ) list_index_bound_column_per_row [ x - x_min ] . sort () # Inplace sort to spare memory # Convert list of np.array to np array padded with zeros (for numba compatibility) max_len = max ([ len ( i ) for i in list_index_bound_column_per_row ]) array_index_bound_column_per_row = np . zeros ( ( len ( list_index_bound_column_per_row ), max_len ), dtype = np . int32 ) for i , arr in enumerate ( list_index_bound_column_per_row ): array_index_bound_column_per_row [ i , : len ( arr )] = arr return np . array ([ x_min , x_max ], dtype = np . int32 ), array_index_bound_column_per_row strip_zeros ( array ) This function strips a (potentially sparse) array (e.g. one that has been converted with convert_array_to_fine_grained) from its columns having intensity zero. Parameters: Name Type Description Default array np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity). required Returns: Type Description np . ndarray The same array stripped from its zero intensity values. Now of shape (2,m). Source code in modules/tools/spectra.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 @njit def strip_zeros ( array ): \"\"\"This function strips a (potentially sparse) array (e.g. one that has been converted with convert_array_to_fine_grained) from its columns having intensity zero. Args: array (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity). Returns: (np.ndarray): The same array stripped from its zero intensity values. Now of shape (2,m). \"\"\" # Look for the non-zero values and store them in l_to_keep l_to_keep = [ idx for idx , x in enumerate ( array [ 1 , :]) if x != 0 and not np . isnan ( x )] # Keep only the previsouly assigned non-zero values array_mz = array [ 0 , :] . take ( l_to_keep ) array_intensity = array [ 1 , :] . take ( l_to_keep ) return np . vstack (( array_mz , array_intensity ))","title":"Spectra"},{"location":"modules/tools/spectra/#modules.tools.spectra.add_zeros_to_spectrum","text":"This function adds zeros in-between the peaks of the spectra contained in array_spectra (e.g. to be able to plot them as scatterplotgl). Parameters: Name Type Description Default array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required pad_individual_peaks bool If true, pads the peaks individually, with a given threshold distance between two m/z values to consider them as belonging to the same peak. Else, it pads all single value in the spectrum with zeros. Defaults to False. True padding float The m/z distance between a peak value and a zero for the padding. Default to 10**-4. 10 ** -4 Returns: Type Description np . ndarray , np . ndarray An array of shape (2,m) containing the padded spectrum data (m/z and intensity) and an array of shape (k,) containing the number of zeros added at each index of array_spectra. Source code in modules/tools/spectra.py 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 @njit def add_zeros_to_spectrum ( array_spectra , pad_individual_peaks = True , padding = 10 **- 4 ): \"\"\"This function adds zeros in-between the peaks of the spectra contained in array_spectra (e.g. to be able to plot them as scatterplotgl). Args: array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. pad_individual_peaks (bool, optional): If true, pads the peaks individually, with a given threshold distance between two m/z values to consider them as belonging to the same peak. Else, it pads all single value in the spectrum with zeros. Defaults to False. padding (float, optional): The m/z distance between a peak value and a zero for the padding. Default to 10**-4. Returns: (np.ndarray, np.ndarray): An array of shape (2,m) containing the padded spectrum data (m/z and intensity) and an array of shape (k,) containing the number of zeros added at each index of array_spectra. \"\"\" # For speed, allocate array of maximum size new_array_spectra = np . zeros ( ( array_spectra . shape [ 0 ], array_spectra . shape [ 1 ] * 3 ), dtype = np . float32 ) array_index_padding = np . zeros (( array_spectra . shape [ 1 ]), dtype = np . int32 ) # Either pad each peak individually if pad_individual_peaks : pad = 0 # Loop over m/z values for i in range ( array_spectra . shape [ 1 ] - 1 ): # If there's a discontinuity between two peaks, pad with zeros if array_spectra [ 0 , i + 1 ] - array_spectra [ 0 , i ] >= 2 * 10 **- 4 : # Add left peak new_array_spectra [ 0 , i + pad ] = array_spectra [ 0 , i ] new_array_spectra [ 1 , i + pad ] = array_spectra [ 1 , i ] # Add zero to the right of left peak pad += 1 new_array_spectra [ 0 , i + pad ] = array_spectra [ 0 , i ] + padding new_array_spectra [ 1 , i + pad ] = 0 # Add zero to the left of right peak pad += 1 new_array_spectra [ 0 , i + pad ] = array_spectra [ 0 , i + 1 ] - padding new_array_spectra [ 1 , i + pad ] = 0 # Record that 2 zeros have been added between idx i and i+1 array_index_padding [ i ] = 2 # Right peak added in the next loop iteration # Else, just store the values of array_spectra without padding else : # logging.info(\"two near peaks\") new_array_spectra [ 0 , i + pad ] = array_spectra [ 0 , i ] new_array_spectra [ 1 , i + pad ] = array_spectra [ 1 , i ] # Add the last value of array_spectra new_array_spectra [ 0 , array_spectra . shape [ 1 ] + pad - 1 ] = array_spectra [ 0 , - 1 ] new_array_spectra [ 1 , array_spectra . shape [ 1 ] + pad - 1 ] = array_spectra [ 1 , - 1 ] return new_array_spectra [:, : array_spectra . shape [ 1 ] + pad ], array_index_padding # Or pad each m/z value individually else : # Loop over m/z values for i in range ( array_spectra . shape [ 1 ]): # Store old array in a regular grid in the extended array new_array_spectra [ 0 , 3 * i + 1 ] = array_spectra [ 0 , i ] new_array_spectra [ 1 , 3 * i + 1 ] = array_spectra [ 1 , i ] # Add zeros in the remaining slots new_array_spectra [ 0 , 3 * i ] = array_spectra [ 0 , i ] - padding new_array_spectra [ 0 , 3 * i + 2 ] = array_spectra [ 0 , i ] + padding # Record that 2 zeros have been added between idx i and i+1 array_index_padding [ i ] = 2 return new_array_spectra , array_index_padding","title":"add_zeros_to_spectrum()"},{"location":"modules/tools/spectra/#modules.tools.spectra.compute_avg_intensity_per_lipid","text":"This function computes the average intensity of each annotated lipid (summing over peaks coming from the same lipid) from a given spectrum. Parameters: Name Type Description Default l_intensity_with_lipids list(float A list of peak intensities (where one lipid can correspond to several peaks, but one peak always correspond to one lipid). required l_idx_labels list(int A list of lipid annotation, each lipid being annotated with a unique integer. required Returns: Type Description list ( int ), list ( float ) The first list provides the lipid indices, while the second provide the lipid average intensities. Peaks corresponding to identical lipid have been averaged. Source code in modules/tools/spectra.py 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 @njit def compute_avg_intensity_per_lipid ( l_intensity_with_lipids , l_idx_labels ): \"\"\"This function computes the average intensity of each annotated lipid (summing over peaks coming from the same lipid) from a given spectrum. Args: l_intensity_with_lipids (list(float)): A list of peak intensities (where one lipid can correspond to several peaks, but one peak always correspond to one lipid). l_idx_labels (list(int)): A list of lipid annotation, each lipid being annotated with a unique integer. Returns: (list(int), list(float)): The first list provides the lipid indices, while the second provide the lipid average intensities. Peaks corresponding to identical lipid have been averaged. \"\"\" # Define empty lists for the lipid indices and intensities l_unique_idx_labels = [] l_avg_intensity = [] idx_label_temp = - 1 # Loop over the lipid indices (i.e. m/z values) for i , idx_label in enumerate ( l_idx_labels ): # Actual lipid and not just a placeholder if idx_label >= 0 : # New lipid is discovered if idx_label != idx_label_temp : idx_label_temp = l_idx_labels [ i ] l_avg_intensity . append ( l_intensity_with_lipids [ i ]) l_unique_idx_labels . append ( idx_label ) # Continuity of the previous lipid else : l_avg_intensity [ - 1 ] += l_intensity_with_lipids [ i ] return l_unique_idx_labels , l_avg_intensity","title":"compute_avg_intensity_per_lipid()"},{"location":"modules/tools/spectra/#modules.tools.spectra.compute_image_using_index_and_image_lookup","text":"This function is very much similar to compute_image_using_index_lookup, except that it uses a different lookup table: lookup_table_image. This lookup table contains the cumulated intensities above the current lookup (instead of the sheer intensities). Therefore, any image corresponding to the integral of all pixel spectra between two bounds can be approximated by the difference of the lookups closest to these bounds. The integral can then be corrected a posteriori to obtain the exact value. If the m/z distance between the two bounds is low, it calls compute_image_using_index_lookup() as the optimization is not worth it. It wraps the internal functions _compute_image_using_index_and_image_lookup_full() and _compute_image_using_index_and_image_lookup_partial() to ensure that the proper array type is used with numba. Parameters: Name Type Description Default low_bound float Lower m/z value for the annotation. required high_bound float Higher m/z value for the annotation. required array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required img_shape tuple(int A tuple with the two integer values corresponding to height and width of the current slice acquisition. required lookup_table_spectra np . ndarray An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_spectra[i,j] contains the first m/z index of pixel j such that m/z >= i * divider_lookup. required lookup_table_image np . ndarray An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_image[i,j] contains, for the pixel of index j, the cumulated intensities from the lowest possible m/z until the first m/z such that m/z >= i * divider_lookup. required divider_lookup int Integer used to set the resolution when building the lookup table. required array_peaks_transformed_lipids np . ndarray A two-dimensional numpy array, which contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. required array_corrective_factors np . ndarray A three-dimensional numpy array, which contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). required apply_transform bool If True, the MAIA correction for pixel intensity is applied. Defaults to False. False Returns: Type Description np . ndarray An array of shape img_shape (reprensenting an image) containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. Source code in modules/tools/spectra.py 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 def compute_image_using_index_and_image_lookup ( low_bound , high_bound , array_spectra , array_pixel_indexes , img_shape , lookup_table_spectra , lookup_table_image , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform = False , ): \"\"\"This function is very much similar to compute_image_using_index_lookup, except that it uses a different lookup table: lookup_table_image. This lookup table contains the cumulated intensities above the current lookup (instead of the sheer intensities). Therefore, any image corresponding to the integral of all pixel spectra between two bounds can be approximated by the difference of the lookups closest to these bounds. The integral can then be corrected a posteriori to obtain the exact value. If the m/z distance between the two bounds is low, it calls compute_image_using_index_lookup() as the optimization is not worth it. It wraps the internal functions _compute_image_using_index_and_image_lookup_full() and _compute_image_using_index_and_image_lookup_partial() to ensure that the proper array type is used with numba. Args: low_bound (float): Lower m/z value for the annotation. high_bound (float): Higher m/z value for the annotation. array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. img_shape (tuple(int)): A tuple with the two integer values corresponding to height and width of the current slice acquisition. lookup_table_spectra (np.ndarray): An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_spectra[i,j] contains the first m/z index of pixel j such that m/z >= i * divider_lookup. lookup_table_image (np.ndarray): An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_image[i,j] contains, for the pixel of index j, the cumulated intensities from the lowest possible m/z until the first m/z such that m/z >= i * divider_lookup. divider_lookup (int): Integer used to set the resolution when building the lookup table. array_peaks_transformed_lipids (np.ndarray): A two-dimensional numpy array, which contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. array_corrective_factors (np.ndarray): A three-dimensional numpy array, which contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). apply_transform (bool): If True, the MAIA correction for pixel intensity is applied. Defaults to False. Returns: (np.ndarray): An array of shape img_shape (reprensenting an image) containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. \"\"\" # Image lookup table is not worth it for small differences between the bounds # And image lookup can't be used if the transformation should not be applied if ( high_bound - low_bound ) < 5 or apply_transform : return compute_image_using_index_lookup ( low_bound , high_bound , array_spectra , array_pixel_indexes , img_shape , lookup_table_spectra , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform , ) else : return _compute_image_using_index_and_image_lookup_partial ( low_bound , high_bound , array_spectra , array_pixel_indexes , img_shape , lookup_table_spectra , lookup_table_image , divider_lookup , )","title":"compute_image_using_index_and_image_lookup()"},{"location":"modules/tools/spectra/#modules.tools.spectra.compute_image_using_index_lookup","text":"For each pixel, this function extracts from array_spectra the intensity of a given m/z selection (normally corresponding to a lipid annotation) defined by a lower and a higher bound. For faster computation, it uses lookup_table_spectra to map m/z values to given indices. It then assigns the pixel intensity to an array of shape img_shape, therefore producing an image representing the requested lipid distribution. Parameters: Name Type Description Default low_bound float Lower m/z value for the annotation. required high_bound float Higher m/z value for the annotation. required array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required img_shape tuple(int A tuple with the two integer values corresponding to height and width of the current slice acquisition. required lookup_table_spectra np . ndarray An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_spectra[i,j] contains the first m/z index of pixel j such that m/z >= i * divider_lookup. required divider_lookup int Integer used to set the resolution when building the lookup table. required array_peaks_transformed_lipids np . ndarray A two-dimensional numpy array, which contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. required array_corrective_factors np . ndarray A three-dimensional numpy array, which contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). required apply_transform bool If True, the MAIA correction for pixel intensity is reverted. required Returns: Type Description np . ndarray An array of shape img_shape (reprensenting an image) containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. Source code in modules/tools/spectra.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 @njit def compute_image_using_index_lookup ( low_bound , high_bound , array_spectra , array_pixel_indexes , img_shape , lookup_table_spectra , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform , ): \"\"\"For each pixel, this function extracts from array_spectra the intensity of a given m/z selection (normally corresponding to a lipid annotation) defined by a lower and a higher bound. For faster computation, it uses lookup_table_spectra to map m/z values to given indices. It then assigns the pixel intensity to an array of shape img_shape, therefore producing an image representing the requested lipid distribution. Args: low_bound (float): Lower m/z value for the annotation. high_bound (float): Higher m/z value for the annotation. array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. img_shape (tuple(int)): A tuple with the two integer values corresponding to height and width of the current slice acquisition. lookup_table_spectra (np.ndarray): An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_spectra[i,j] contains the first m/z index of pixel j such that m/z >= i * divider_lookup. divider_lookup (int): Integer used to set the resolution when building the lookup table. array_peaks_transformed_lipids (np.ndarray): A two-dimensional numpy array, which contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. array_corrective_factors (np.ndarray): A three-dimensional numpy array, which contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). apply_transform (bool): If True, the MAIA correction for pixel intensity is reverted. Returns: (np.ndarray): An array of shape img_shape (reprensenting an image) containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. \"\"\" # Build empty image image = np . zeros (( img_shape [ 0 ], img_shape [ 1 ]), dtype = np . float32 ) # Build an array of ones for the correction (i.e. default is no correction) array_corrective_factors_lipid = np . ones (( img_shape [ 0 ] * img_shape [ 1 ],), np . float32 ) if apply_transform : # Check if the m/z region must transformed, i.e. low and high bound are inside annotation idx_lipid_right = - 1 for idx_lipid , ( min_mz , max_mz , avg_mz ) in enumerate ( array_peaks_transformed_lipids ): # Take 10**-4 for precision if ( low_bound + 10 **- 4 ) >= min_mz and ( high_bound - 10 **- 4 ) <= max_mz : idx_lipid_right = idx_lipid break # If the current region corresponds to a transformed lipid: if idx_lipid_right != - 1 : array_corrective_factors_lipid [:] = array_corrective_factors [ idx_lipid_right ] . flatten () # Find lower bound and add from there for idx_pix in range ( array_pixel_indexes . shape [ 0 ]): # If pixel contains no peak, skip it if array_pixel_indexes [ idx_pix , 0 ] == - 1 : continue # Compute range in which values must be summed and extract corresponding part of spectrum lower_bound = lookup_table_spectra [ int ( low_bound / divider_lookup )][ idx_pix ] higher_bound = lookup_table_spectra [ int ( np . ceil ( high_bound / divider_lookup ))][ idx_pix ] array_to_sum = array_spectra [:, lower_bound : higher_bound + 1 ] # Apply MAIA correction if array_corrective_factors_lipid [ idx_pix ] == 0 : correction = 1.0 else : correction = array_corrective_factors_lipid [ idx_pix ] # Sum the m/z values over the requested range image = _fill_image ( image , idx_pix , img_shape , array_to_sum , lower_bound , higher_bound , low_bound , high_bound , correction , ) return image","title":"compute_image_using_index_lookup()"},{"location":"modules/tools/spectra/#modules.tools.spectra.compute_index_boundaries","text":"This function is very much similar to compute_index_boundaries_nolookup(), except that it uses lookup_table to find the low and high bounds indices faster. As in compute_index_boundaries_nolookup(), it computes, from array_spectra_avg, the first existing indices corresponding to m/z values above the provided lower and higher bounds. If high_bound and/or low_bound are above the highest possible value for the required lookup, it returns the index of the highest existing value. Note that array_spectra_avg normally corresponds to the high-resolution spectrum averaged across all pixels, but in can be any spectrum so long as it is not subdivided in pixels. Also note that there are no partial full versions of this function depending if the dataset is stored in RAM or HDF5, since the two versions would have been almost identical (there's no loop over pixels, contrarily to e.g. compute_image_using_index_lookup(), and a view/copy of the partial spectra in the selection is made as a first step, turning an in a np.ndarray). It wraps the internal numba-ized function _compute_index_boundaries_nolookup(). Parameters: Name Type Description Default low_bound float Lower m/z value for the annotation. required high_bound float Higher m/z value for the annotation. required array_spectra_avg np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity). required lookup_table np . ndarray A 1-dimensional array of length m providing, for each index (i.e. lookup), the index of the first m/z value in the averaged array_spectra superior or equal to the lookup. required Returns: Type Description tuple ( int ) A tuple of integer representing the best guess for the indices of low_bound and high_bound in array_spectra_avg. Source code in modules/tools/spectra.py 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 @njit def compute_index_boundaries ( low_bound , high_bound , array_spectra_avg , lookup_table ): \"\"\"This function is very much similar to compute_index_boundaries_nolookup(), except that it uses lookup_table to find the low and high bounds indices faster. As in compute_index_boundaries_nolookup(), it computes, from array_spectra_avg, the first existing indices corresponding to m/z values above the provided lower and higher bounds. If high_bound and/or low_bound are above the highest possible value for the required lookup, it returns the index of the highest existing value. Note that array_spectra_avg normally corresponds to the high-resolution spectrum averaged across all pixels, but in can be any spectrum so long as it is not subdivided in pixels. Also note that there are no partial full versions of this function depending if the dataset is stored in RAM or HDF5, since the two versions would have been almost identical (there's no loop over pixels, contrarily to e.g. compute_image_using_index_lookup(), and a view/copy of the partial spectra in the selection is made as a first step, turning an in a np.ndarray). It wraps the internal numba-ized function _compute_index_boundaries_nolookup(). Args: low_bound (float): Lower m/z value for the annotation. high_bound (float): Higher m/z value for the annotation. array_spectra_avg (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity). lookup_table (np.ndarray): A 1-dimensional array of length m providing, for each index (i.e. lookup), the index of the first m/z value in the averaged array_spectra superior or equal to the lookup. Returns: (tuple(int)): A tuple of integer representing the best guess for the indices of low_bound and high_bound in array_spectra_avg. \"\"\" # Extract the arrays provided by the lookup table as first guess for the low and high bounds array_to_sum_lb = array_spectra_avg [ 0 , lookup_table [ int ( low_bound )] : lookup_table [ int ( np . ceil ( low_bound ))] + 1 ] array_to_sum_hb = array_spectra_avg [ 0 , lookup_table [ int ( high_bound )] : lookup_table [ int ( np . ceil ( high_bound ))] + 1 ] # Correct the lookup indices with these arrays return _loop_compute_index_boundaries ( array_to_sum_lb , array_to_sum_hb , low_bound , high_bound , lookup_table )","title":"compute_index_boundaries()"},{"location":"modules/tools/spectra/#modules.tools.spectra.compute_index_boundaries_nolookup","text":"This function computes, from array_spectra_avg, the first existing indices corresponding to m/z values above the provided lower and higher bounds, without using any lookup. If high_bound and/or low_bound are above the highest possible value for the required lookup, it returns the index of the highest existing value. Note that array_spectra_avg normally corresponds to the high-resolution spectrum averaged across all pixels, but in can be any spectrum so long as it is not subdivided in pixels. Parameters: Name Type Description Default low_bound float Lower m/z value for the annotation. required high_bound float Higher m/z value for the annotation. required array_spectra_avg np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity). required Returns: Type Description tuple ( int ) A tuple of integer representing the best guess for the indices of low_bound and high_bound in array_spectra_avg. Source code in modules/tools/spectra.py 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 @njit def compute_index_boundaries_nolookup ( low_bound , high_bound , array_spectra_avg ): \"\"\"This function computes, from array_spectra_avg, the first existing indices corresponding to m/z values above the provided lower and higher bounds, without using any lookup. If high_bound and/or low_bound are above the highest possible value for the required lookup, it returns the index of the highest existing value. Note that array_spectra_avg normally corresponds to the high-resolution spectrum averaged across all pixels, but in can be any spectrum so long as it is not subdivided in pixels. Args: low_bound (float): Lower m/z value for the annotation. high_bound (float): Higher m/z value for the annotation. array_spectra_avg (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity). Returns: (tuple(int)): A tuple of integer representing the best guess for the indices of low_bound and high_bound in array_spectra_avg. \"\"\" # Extract the mz values for array_spectra_avg array_mz = array_spectra_avg [ 0 , :] # Define intial guess for the low and high bounds indices index_low_bound = 0 index_high_bound = array_mz . shape [ 0 ] - 1 # Browse array_mz until low bound is crossed for i , mz in enumerate ( array_mz ): index_low_bound = i if mz >= low_bound : break # Start from the low bound index, and browse array_mz until high bound is crossed for i , mz in enumerate ( array_mz [ index_low_bound :]): index_high_bound = i + index_low_bound if mz >= high_bound : break return index_low_bound , index_high_bound","title":"compute_index_boundaries_nolookup()"},{"location":"modules/tools/spectra/#modules.tools.spectra.compute_normalized_image_per_lipid","text":"This function is mostly a wrapper for compute_image_using_index_and_image_lookup, that is, it computes an image containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. In addition, it adds a step of normalization, such that the output is more visually pleasing and comparable across selections. The output can also be provided in 8 bits, that is, the format of a single channel in an RGB image. Parameters: Name Type Description Default lb_mz float Lower m/z value for the annotation. required hb_mz float Higher m/z value for the annotation. required array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required image_shape tuple(int A tuple with the two integer values corresponding to height and width of the current slice acquisition. required lookup_table_spectra np . ndarray An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_spectra[i,j] contains the first m/z index of pixel j such that m/z >= i * divider_lookup. required cumulated_image_lookup_table np . ndarray An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_image[i,j] contains, for the pixel of index j, the cumulated intensities from the lowest possible m/z until the first m/z such that m/z >= i * divider_lookup. required divider_lookup int Integer used to set the resolution when building the lookup table. required array_peaks_transformed_lipids np . ndarray A two-dimensional numpy array, which contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. required array_corrective_factors np . ndarray A three-dimensional numpy array, which contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). required apply_transform bool If True, the MAIA correction for pixel intensity is applied. Defaults to False. False percentile_normalization int Integer used to re-normalize the data, such that the maximum value correspond to the given percentile. 99 RGB_channel_format bool If False, the output image is provided as an array with values between 0 and 1. Else, the values are between 0 and 255. True Returns: Type Description np . ndarray An array of shape img_shape (reprensenting an image) containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. This image is normalized according to percentile_normalized. Output values are between 0 and 1 (255) depending if RGB_channel_format is False (True). Source code in modules/tools/spectra.py 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 def compute_normalized_image_per_lipid ( lb_mz , hb_mz , array_spectra , array_pixel_indexes , image_shape , lookup_table_spectra , cumulated_image_lookup_table , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform = False , percentile_normalization = 99 , RGB_channel_format = True , ): \"\"\"This function is mostly a wrapper for compute_image_using_index_and_image_lookup, that is, it computes an image containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. In addition, it adds a step of normalization, such that the output is more visually pleasing and comparable across selections. The output can also be provided in 8 bits, that is, the format of a single channel in an RGB image. Args: lb_mz (float): Lower m/z value for the annotation. hb_mz (float): Higher m/z value for the annotation. array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. image_shape (tuple(int)): A tuple with the two integer values corresponding to height and width of the current slice acquisition. lookup_table_spectra (np.ndarray): An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_spectra[i,j] contains the first m/z index of pixel j such that m/z >= i * divider_lookup. cumulated_image_lookup_table (np.ndarray): An array of shape (k,m) representing a lookup table with the following mapping: lookup_table_image[i,j] contains, for the pixel of index j, the cumulated intensities from the lowest possible m/z until the first m/z such that m/z >= i * divider_lookup. divider_lookup (int): Integer used to set the resolution when building the lookup table. array_peaks_transformed_lipids (np.ndarray): A two-dimensional numpy array, which contains the peak annotations (min peak, max peak, average value of the peak), sorted by min_mz, for the lipids that have been transformed. array_corrective_factors (np.ndarray): A three-dimensional numpy array, which contains the MAIA corrective factor used for lipid (first dimension) and each pixel (second and third dimension). apply_transform (bool): If True, the MAIA correction for pixel intensity is applied. Defaults to False. percentile_normalization (int): Integer used to re-normalize the data, such that the maximum value correspond to the given percentile. RGB_channel_format (bool): If False, the output image is provided as an array with values between 0 and 1. Else, the values are between 0 and 255. Returns: (np.ndarray): An array of shape img_shape (reprensenting an image) containing the cumulated intensity of the spectra between low_bound and high_bound, for each pixel. This image is normalized according to percentile_normalized. Output values are between 0 and 1 (255) depending if RGB_channel_format is False (True). \"\"\" # Get image from raw mass spec data image = compute_image_using_index_and_image_lookup ( lb_mz , hb_mz , array_spectra , array_pixel_indexes , image_shape , lookup_table_spectra , cumulated_image_lookup_table , divider_lookup , array_peaks_transformed_lipids , array_corrective_factors , apply_transform , ) # Normalize by percentile image = image / np . percentile ( image , percentile_normalization ) * 1 image = np . clip ( 0 , 1 , image ) # Convert image to have values between 0 and 255 if RGB_channel_format : image *= 255 return image","title":"compute_normalized_image_per_lipid()"},{"location":"modules/tools/spectra/#modules.tools.spectra.compute_normalized_spectra","text":"This function takes an array of spectra and returns it normalized (per pixel). In pratice, each pixel spectrum is converted into a uncompressed version, and divided by the sum of all spectra. This might a problematic approach as there seems to be small shifts between spectra across pixels, leading to a noise amplification after normalization. Parameters: Name Type Description Default array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required Returns: Type Description np . ndarray An array of shape (2,m) containing the normalized spectrum data (m/z and intensity). Source code in modules/tools/spectra.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 @njit def compute_normalized_spectra ( array_spectra , array_pixel_indexes ): \"\"\"This function takes an array of spectra and returns it normalized (per pixel). In pratice, each pixel spectrum is converted into a uncompressed version, and divided by the sum of all spectra. This might a problematic approach as there seems to be small shifts between spectra across pixels, leading to a noise amplification after normalization. Args: array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. Returns: (np.ndarray): An array of shape (2,m) containing the normalized spectrum data (m/z and intensity). \"\"\" # Start by converting array_spectra into a very fine-grained version spectrum_sum = convert_array_to_fine_grained ( array_spectra , 10 **- 3 , lb = 350 , hb = 1250 ) + 1 array_spectra_normalized = np . zeros ( array_spectra . shape , dtype = np . float32 ) # Loop over the spectrum of each pixel for idx_pix in range ( array_pixel_indexes . shape [ 0 ]): logging . info ( \"_compute_normalized_spectra:\" + str ( idx_pix / array_pixel_indexes . shape [ 0 ] * 100 ) + \" done\" ) # If pixel contains no peak, skip it if array_pixel_indexes [ idx_pix , 0 ] == - 1 : continue # Get the spectrum of current pixel spectrum = array_spectra [ :, array_pixel_indexes [ idx_pix , 0 ] : array_pixel_indexes [ idx_pix , 1 ] + 1 ] # Out of safety, normalize the spectrum of current pixel with respect to its own sum # Might be useless since array_spectra is normally already normalized by pixel spectrum [ 1 , :] /= np . sum ( spectrum [ 1 , :]) # Then move spectrum to uncompressed version spectrum = convert_array_to_fine_grained ( spectrum , 10 **- 3 , lb = 350 , hb = 1250 ) # Then normalize with respect to all pixels spectrum [ 1 , :] /= spectrum_sum [ 1 , :] # Then back to original space spectrum = strip_zeros ( spectrum ) # Store back the spectrum if ( spectrum . shape [ 1 ] == array_pixel_indexes [ idx_pix , 1 ] + 1 - array_pixel_indexes [ idx_pix , 0 ] ): array_spectra_normalized [ :, array_pixel_indexes [ idx_pix , 0 ] : array_pixel_indexes [ idx_pix , 1 ] + 1 ] = spectrum else : # Store shorter-sized spectrum in array_spectra_normalized, rest will be zeros array_spectra_normalized [ :, array_pixel_indexes [ idx_pix , 0 ] : array_pixel_indexes [ idx_pix , 0 ] + len ( spectrum ) + 1 , ] return array_spectra_normalized","title":"compute_normalized_spectra()"},{"location":"modules/tools/spectra/#modules.tools.spectra.compute_spectrum_per_row_selection","text":"This function computes the average spectrum from a manual selection of rows of pixel (each containing a spectrum). The resulting average array can be zero-padded. Parameters: Name Type Description Default list_index_bound_rows list(tuple A list of lower and upper indices delimiting the range of rows belonging to the current selection. required list_index_bound_column_per_row list(list For each row (outer list), provides the index of the columns delimiting the current selection (inner list). required array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required image_shape int , int A tuple of integers, indicating the vertical and horizontal sizes of the current slice. required array_peaks_transformed_lipids np . ndarray A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), filtered for the lipids who have preliminarily been transformed. Sorted by min_mz. required array_corrective_factors np . ndarray A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the corrective factors for the lipids we want to visualize, for each pixel. required zeros_extend bool If True, the resulting spectrum will be zero-padded. Defaults to True. True apply_correction bool If True, MAIA transformation is applied to the lipids belonging to array_peaks_transformed_lipids, for each pixel. This option makes the computation very slow, so it shouldn't be selected if the computations must be done on the fly. Defaults to False. False Returns: Type Description np . ndarray Spectrum averaged from a manual selection of rows of pixel, containing m/z values in the first row, and intensities in the second row. Source code in modules/tools/spectra.py 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 @njit def compute_spectrum_per_row_selection ( list_index_bound_rows , list_index_bound_column_per_row , array_spectra , array_pixel_indexes , image_shape , array_peaks_transformed_lipids , array_corrective_factors , zeros_extend = True , apply_correction = False , ): \"\"\"This function computes the average spectrum from a manual selection of rows of pixel (each containing a spectrum). The resulting average array can be zero-padded. Args: list_index_bound_rows (list(tuple)): A list of lower and upper indices delimiting the range of rows belonging to the current selection. list_index_bound_column_per_row (list(list)): For each row (outer list), provides the index of the columns delimiting the current selection (inner list). array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. image_shape (int, int): A tuple of integers, indicating the vertical and horizontal sizes of the current slice. array_peaks_transformed_lipids (np.ndarray): A numpy array containing the peak annotations (min peak, max peak, number of pixels containing the peak, average value of the peak), filtered for the lipids who have preliminarily been transformed. Sorted by min_mz. array_corrective_factors (np.ndarray): A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the corrective factors for the lipids we want to visualize, for each pixel. zeros_extend (bool, optional): If True, the resulting spectrum will be zero-padded. Defaults to True. apply_correction (bool, optional): If True, MAIA transformation is applied to the lipids belonging to array_peaks_transformed_lipids, for each pixel. This option makes the computation very slow, so it shouldn't be selected if the computations must be done on the fly. Defaults to False. Returns: (np.ndarray): Spectrum averaged from a manual selection of rows of pixel, containing m/z values in the first row, and intensities in the second row. \"\"\" # Get list of row indexes for the current selection ll_idx , size_array , ll_idx_pix = get_list_row_indexes ( list_index_bound_rows , list_index_bound_column_per_row , array_pixel_indexes , image_shape ) # Init array selection of size size_array array_spectra_selection = np . zeros (( 2 , size_array ), dtype = np . float32 ) pad = 0 # Fill array line by line for i , x in enumerate ( range ( list_index_bound_rows [ 0 ], list_index_bound_rows [ 1 ] + 1 )): for idx_1 , idx_2 , idx_pix_1 , idx_pix_2 in zip ( ll_idx [ i ][ 0 : - 1 : 2 ], ll_idx [ i ][ 1 :: 2 ], ll_idx_pix [ i ][ 0 : - 1 : 2 ], ll_idx_pix [ i ][ 1 :: 2 ] ): if apply_correction : for idx_pix in range ( idx_pix_1 , idx_pix_2 + 1 ): idx_mz_1 , idx_mz_2 = array_pixel_indexes [ idx_pix ] # If the pixel is not empty if idx_mz_2 - idx_mz_1 > 0 : array_spectra_pix_to_correct = array_spectra [ :, idx_mz_1 : idx_mz_2 + 1 ] . copy () array_spectra_pix_corrected , n_peaks_transformed = compute_standardization ( array_spectra_pix_to_correct . T , idx_pix , array_peaks_transformed_lipids , array_corrective_factors , ) array_spectra_selection [ :, pad : pad + idx_mz_2 + 1 - idx_mz_1 ] = array_spectra_pix_corrected . T pad += idx_mz_2 + 1 - idx_mz_1 else : array_spectra_selection [:, pad : pad + idx_2 + 1 - idx_1 ] = array_spectra [ :, idx_1 : idx_2 + 1 ] pad += idx_2 + 1 - idx_1 # Sort array array_spectra_selection = array_spectra_selection [:, array_spectra_selection [ 0 ] . argsort ()] # Remove the values that have been zeroed-out if apply_correction : array_spectra_selection = strip_zeros ( array_spectra_selection ) # Sum the arrays (similar m/z values are added) array_spectra_selection = reduce_resolution_sorted_array_spectra ( array_spectra_selection , resolution = 10 **- 4 ) # Pad with zeros if asked if zeros_extend : array_spectra_selection , array_index_padding = add_zeros_to_spectrum ( array_spectra_selection ) return array_spectra_selection","title":"compute_spectrum_per_row_selection()"},{"location":"modules/tools/spectra/#modules.tools.spectra.compute_standardization","text":"This function takes the spectrum data of a given pixel, along with the corresponding pixel index, and transforms the value of the lipids intensities annotated in 'array_peaks' according to the transformation registered in 'array_corrective_factors'. Parameters: Name Type Description Default array_spectra_pixel np . ndarray A numpy array containing spectrum data (m/z and intensity) of pixel 'idx_pixel', sorted by mz. required idx_pixel int Index of the current pixel whose spectrum is transformed. required array_peaks np . ndarray A numpy array containing the peak annotations (min peak, max peak, average value of the peak), filtered for the lipids who have preliminarily been transformed. Sorted by min_mz. required array_corrective_factors np . ndarray A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the corrective factors for the lipids we want to visualize, for each pixel. required Returns: Type Description np . ndarray A numpy array containing spectrum data (pixel index, m/z and intensity), of pixel 'idx_pixel', sorted by mz, with lipids values transformed. Source code in modules/tools/spectra.py 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 @njit def compute_standardization ( array_spectra_pixel , idx_pixel , array_peaks , array_corrective_factors ): \"\"\"This function takes the spectrum data of a given pixel, along with the corresponding pixel index, and transforms the value of the lipids intensities annotated in 'array_peaks' according to the transformation registered in 'array_corrective_factors'. Args: array_spectra_pixel (np.ndarray): A numpy array containing spectrum data (m/z and intensity) of pixel 'idx_pixel', sorted by mz. idx_pixel (int): Index of the current pixel whose spectrum is transformed. array_peaks (np.ndarray): A numpy array containing the peak annotations (min peak, max peak, average value of the peak), filtered for the lipids who have preliminarily been transformed. Sorted by min_mz. array_corrective_factors (np.ndarray): A numpy array of shape (n_lipids, image_shape[0], image_shape[1]) containing the corrective factors for the lipids we want to visualize, for each pixel. Returns: (np.ndarray): A numpy array containing spectrum data (pixel index, m/z and intensity), of pixel 'idx_pixel', sorted by mz, with lipids values transformed. \"\"\" # Define initial values idx_peak = 0 idx_mz = 0 n_peaks_transformed = 0 while idx_mz < array_spectra_pixel . shape [ 0 ] and idx_peak < array_peaks . shape [ 0 ]: mz , intensity = array_spectra_pixel [ idx_mz ] min_mz , max_mz , mz_estimated = array_peaks [ idx_peak ] # New window has been discovered if mz >= min_mz and mz <= max_mz : idx_min_mz = idx_mz idx_max_mz = idx_mz for idx_mz in range ( idx_min_mz , array_spectra_pixel . shape [ 0 ]): mz , intensity = array_spectra_pixel [ idx_mz ] if mz > max_mz : idx_max_mz = idx_mz - 1 break # Most likely, the annotation doesn't exist, so skip it if np . abs ( idx_max_mz - idx_min_mz ) <= 0.9 : # Zero-out value that do not belong to the MAIA-transformed regions array_spectra_pixel [ idx_mz , 1 ] = 0 # Else compute a multiplicative factor else : # Get array of intensity before and after correction for current pixel correction = array_corrective_factors [ idx_peak ] . flatten ()[ idx_pixel ] # Multiply all intensities in the window by the corrective coefficient array_spectra_pixel [ idx_min_mz : idx_max_mz + 1 , 1 ] *= correction n_peaks_transformed += 1 # Move on to the next peak idx_peak += 1 else : if mz > max_mz : idx_peak += 1 else : # zero-out value that do not belong to the MAIA-transformed regions array_spectra_pixel [ idx_mz , 1 ] = 0 idx_mz += 1 return array_spectra_pixel , n_peaks_transformed","title":"compute_standardization()"},{"location":"modules/tools/spectra/#modules.tools.spectra.compute_thread_safe_function","text":"This function is a wrapper for safe multithreading and multiprocessing execution of compute_function. This is needed due to the regular cleansing of memory-mapped object. Parameters: Name Type Description Default compute_function func The function/method whose result must be loaded/saved. required cache flask_caching . Cache A caching object, used to check if the reading of memory-mapped data is safe required *args_compute_function Arguments of compute_function. () **kwargs_compute_function Named arguments of compute_function. {} Returns: Type Description The result of compute_function. Type may vary depending on compute_function. Source code in modules/tools/spectra.py 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 def compute_thread_safe_function ( compute_function , cache , data , slice_index , * args_compute_function , ** kwargs_compute_function ): \"\"\"This function is a wrapper for safe multithreading and multiprocessing execution of compute_function. This is needed due to the regular cleansing of memory-mapped object. Args: compute_function (func): The function/method whose result must be loaded/saved. cache (flask_caching.Cache): A caching object, used to check if the reading of memory-mapped data is safe *args_compute_function: Arguments of compute_function. **kwargs_compute_function: Named arguments of compute_function. Returns: The result of compute_function. Type may vary depending on compute_function. \"\"\" logging . info ( \"Trying to compute the thread-safe version of \" + str ( compute_function ) . split ( \"<\" )[ 1 ] . split ( \"at\" )[ 0 ] ) if cache is not None : # Wait for the data to be safe for reading while cache . get ( \"locked-cleaning\" ): time . sleep ( 0.05 ) # Lock it while while it's being read cache . set ( \"locked-reading\" , True ) else : logging . warning ( \"No cache provided, the thread unsafe version of the function will be run\" ) # Run the actual function try : result = compute_function ( * args_compute_function , ** kwargs_compute_function ) except : logging . warning ( 'The function \" %s \" failed to run' % str ( compute_function )) result = None if cache is not None : # Unlock the data cache . set ( \"locked-reading\" , False ) if data is not None : # Clean the memory-mapped data data . clean_memory ( slice_index = slice_index , cache = cache ) # Return result return result","title":"compute_thread_safe_function()"},{"location":"modules/tools/spectra/#modules.tools.spectra.compute_zeros_extended_spectrum_per_pixel","text":"This function computes a zero-extended version of the spectrum of pixel indexed by idx_pix. Parameters: Name Type Description Default idx_pix int Index of the pixel to return. required array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required Returns: Type Description np . ndarray An array of shape (2,m) containing the zero-padded spectrum data (m/z and intensity) for the requested pixel. Source code in modules/tools/spectra.py 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 @njit def compute_zeros_extended_spectrum_per_pixel ( idx_pix , array_spectra , array_pixel_indexes ): \"\"\"This function computes a zero-extended version of the spectrum of pixel indexed by idx_pix. Args: idx_pix (int): Index of the pixel to return. array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. Returns: (np.ndarray): An array of shape (2,m) containing the zero-padded spectrum data (m/z and intensity) for the requested pixel. \"\"\" array_spectra = return_spectrum_per_pixel ( idx_pix , array_spectra , array_pixel_indexes ) new_array_spectra , array_index_padding = add_zeros_to_spectrum ( array_spectra ) return new_array_spectra","title":"compute_zeros_extended_spectrum_per_pixel()"},{"location":"modules/tools/spectra/#modules.tools.spectra.convert_array_to_fine_grained","text":"This function converts an array to a fine-grained version, which is common to all pixels, allowing for easier computations. If several values of the compressed version map to the same value of the uncompressed one, they are summed. Therefore, when ran on the spectrum of a whole image, it adds the spectra of all pixels. Parameters: Name Type Description Default array np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity). required resolution float The resolution used for finer-graining. required lb int Lower bound for the fine-grained array. Defaults to 350. 350 hb int Higher bound for the fine-grained array. Defaults to 1250. 1250 Returns: Type Description np . ndarray A sparse, fine-grained array of shape (2,m) containing spectrum data (m/z and intensity). Source code in modules/tools/spectra.py 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 @njit def convert_array_to_fine_grained ( array , resolution , lb = 350 , hb = 1250 ): \"\"\"This function converts an array to a fine-grained version, which is common to all pixels, allowing for easier computations. If several values of the compressed version map to the same value of the uncompressed one, they are summed. Therefore, when ran on the spectrum of a whole image, it adds the spectra of all pixels. Args: array (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity). resolution (float): The resolution used for finer-graining. lb (int, optional): Lower bound for the fine-grained array. Defaults to 350. hb (int, optional): Higher bound for the fine-grained array. Defaults to 1250. Returns: (np.ndarray): A sparse, fine-grained array of shape (2,m) containing spectrum data (m/z and intensity). \"\"\" # Build an empty (zeroed) array with the requested uncompressed size new_array = np . linspace ( lb , hb , int ( round (( hb - lb ) / resolution ))) new_array = np . vstack (( new_array , np . zeros ( new_array . shape , dtype = np . float32 ))) # Fill it with the values from the compressed array for mz , intensity in array . T : new_array [ 1 , int ( round (( mz - lb ) * ( 1 / resolution )))] += intensity return new_array","title":"convert_array_to_fine_grained()"},{"location":"modules/tools/spectra/#modules.tools.spectra.convert_coor_to_spectrum_idx","text":"This function takes a tuple of integers representing the coordinates of the pixel in the current slice and converts it into an index in a flattened version of the image. Parameters: Name Type Description Default coordinate tuple(int Coordinate in the original image. required shape tuple(int Shape of the MALDI acquisition of the corresponding slice. required Returns: Type Description int Pixel index in a flattened version of the slice image. Source code in modules/tools/spectra.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @njit def convert_coor_to_spectrum_idx ( coordinate , shape ): \"\"\"This function takes a tuple of integers representing the coordinates of the pixel in the current slice and converts it into an index in a flattened version of the image. Args: coordinate tuple(int): Coordinate in the original image. shape (tuple(int)): Shape of the MALDI acquisition of the corresponding slice. Returns: (int): Pixel index in a flattened version of the slice image. \"\"\" ind = coordinate [ 0 ] * shape [ 1 ] + coordinate [ 1 ] if ind >= shape [ 0 ] * shape [ 1 ]: # logging.warning(\"Index not allowed.\") return - 1 return ind","title":"convert_coor_to_spectrum_idx()"},{"location":"modules/tools/spectra/#modules.tools.spectra.convert_spectrum_idx_to_coor","text":"This function takes a pixel index and converts it into a tuple of integers representing the coordinates of the pixel in the current slice. Parameters: Name Type Description Default index int Pixel index in a flattened version of the slice image. required shape tuple(int Shape of the MALDI acquisition of the corresponding slice. required Returns: Type Description tuple ( int ) Corresponding coordinate in the original image. Source code in modules/tools/spectra.py 24 25 26 27 28 29 30 31 32 33 34 35 36 @njit def convert_spectrum_idx_to_coor ( index , shape ): \"\"\"This function takes a pixel index and converts it into a tuple of integers representing the coordinates of the pixel in the current slice. Args: index (int): Pixel index in a flattened version of the slice image. shape (tuple(int)): Shape of the MALDI acquisition of the corresponding slice. Returns: (tuple(int)): Corresponding coordinate in the original image. \"\"\" return int ( index / shape [ 1 ]), int ( index % shape [ 1 ])","title":"convert_spectrum_idx_to_coor()"},{"location":"modules/tools/spectra/#modules.tools.spectra.get_list_row_indexes","text":"This function turns a selection of rows (bounds in list_index_bound_rows) and corresponding columns (bounds in list_index_bound_column_per_row) into an optimized list of pixel indices in array_spectra. It takes advantage of the fact that pixels that are neighbours in a given rows also have contiguous spectra in array_spectra, allowing for faster query. Parameters: Name Type Description Default list_index_bound_rows list(tuple A list of lower and upper indices delimiting the range of rows belonging to the current selection. required list_index_bound_column_per_row list(list For each row (outer list), provides the index of the columns delimiting the current selection (inner list). required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required image_shape int , int A tuple of integers, indicating the vertical and horizontal sizes of the current slice. required Returns: Type Description list ( list ) List of 2-elements lists which contains the mz indices (inner list) in array_spectra of the extrema pixel for each row (outer list). int Total size of the concatenated spectra indexed list ( list ) List of 2-elements lists which contains pixels indices (inner list) in array_spectra of the extrema pixel for each row (outer list). Source code in modules/tools/spectra.py 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 @njit def get_list_row_indexes ( list_index_bound_rows , list_index_bound_column_per_row , array_pixel_indexes , image_shape ): \"\"\"This function turns a selection of rows (bounds in list_index_bound_rows) and corresponding columns (bounds in list_index_bound_column_per_row) into an optimized list of pixel indices in array_spectra. It takes advantage of the fact that pixels that are neighbours in a given rows also have contiguous spectra in array_spectra, allowing for faster query. Args: list_index_bound_rows (list(tuple)): A list of lower and upper indices delimiting the range of rows belonging to the current selection. list_index_bound_column_per_row (list(list)): For each row (outer list), provides the index of the columns delimiting the current selection (inner list). array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. image_shape (int, int): A tuple of integers, indicating the vertical and horizontal sizes of the current slice. Returns: (list(list)): List of 2-elements lists which contains the mz indices (inner list) in array_spectra of the extrema pixel for each row (outer list). (int): Total size of the concatenated spectra indexed (list(list)): List of 2-elements lists which contains pixels indices (inner list) in array_spectra of the extrema pixel for each row (outer list). \"\"\" # Compute size array size_array = 0 ll_idx = [] ll_idx_pix = [] # Loop over rows in the selection for i , x in enumerate ( range ( list_index_bound_rows [ 0 ], list_index_bound_rows [ 1 ] + 1 )): # Careful: list_index_bound_column_per_row l_idx = [] l_idx_pix = [] for j in range ( 0 , len ( list_index_bound_column_per_row [ i ]), 2 ): # Check if we're not just looping over zero padding if ( list_index_bound_column_per_row [ i ][ j ] == 0 and list_index_bound_column_per_row [ i ][ j + 1 ] == 0 ): continue # Get the outer indexes of the (concatenated) spectra of the current row belonging to # the selection idx_pix_1 = convert_coor_to_spectrum_idx ( ( x , list_index_bound_column_per_row [ i ][ j ]), image_shape ) idx_1 = array_pixel_indexes [ idx_pix_1 , 0 ] idx_pix_2 = convert_coor_to_spectrum_idx ( ( x , list_index_bound_column_per_row [ i ][ j + 1 ]), image_shape ) idx_2 = array_pixel_indexes [ idx_pix_2 , 1 ] # Case we started or finished with empty pixel if idx_1 == - 1 or idx_2 == - 1 : # Move forward until a non-empty pixel is found for idx_1 j = 1 while idx_1 == - 1 : idx_1 = array_pixel_indexes [ idx_pix_1 + j , 0 ] j += 1 idx_pix_1 = idx_pix_1 + j - 1 # Move backward until a non-empty pixel is found for idx_2 j = 1 while idx_2 == - 1 : idx_2 = array_pixel_indexes [ idx_pix_2 - j , 1 ] j += 1 idx_pix_2 = idx_pix_2 + j - 1 # Check that we still have idx_2>=idx_1 if idx_1 > idx_2 : pass else : size_array += idx_2 + 1 - idx_1 l_idx . extend ([ idx_1 , idx_2 ]) l_idx_pix . extend ([ idx_pix_1 , idx_pix_2 ]) # Add the couple of spectra indexes to the list ll_idx . append ( l_idx ) ll_idx_pix . append ( l_idx_pix ) return ll_idx , size_array , ll_idx_pix","title":"get_list_row_indexes()"},{"location":"modules/tools/spectra/#modules.tools.spectra.global_lipid_index_store","text":"This function is used to extract the lipid label indexes for a given list of spectra, coming from a given slice (slice_index). Parameters: Name Type Description Default data MaldiData The object used to access the MALDI data. required slice_index int Index of the current slice. required l_spectra list(np.ndarray A list of spectra (two dimensional numpy arrays), coming from the slice having index slice_index. required Returns: Type Description list ( list ( str )) A list of list of lipid labels, one list per spectrum. Source code in modules/tools/spectra.py 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 def global_lipid_index_store ( data , slice_index , l_spectra ): \"\"\"This function is used to extract the lipid label indexes for a given list of spectra, coming from a given slice (slice_index). Args: data (MaldiData): The object used to access the MALDI data. slice_index (int): Index of the current slice. l_spectra (list(np.ndarray)): A list of spectra (two dimensional numpy arrays), coming from the slice having index slice_index. Returns: (list(list(str))): A list of list of lipid labels, one list per spectrum. \"\"\" logging . info ( \"Starting computing ll_idx_labels\" ) ll_idx_labels = [] for spectrum in l_spectra : if spectrum is not None : # Get the average spectrum and add it to m/z plot grah_scattergl_data = np . array ( spectrum , dtype = np . float32 ) # Get df for current slice df_names = data . get_annotations ()[ data . get_annotations ()[ \"slice\" ] == slice_index ] # Extract lipid names l_idx_labels = return_index_labels ( df_names [ \"min\" ] . to_numpy (), df_names [ \"max\" ] . to_numpy (), grah_scattergl_data [ 0 , :], ) else : l_idx_labels = None # Save in a list of lists ll_idx_labels . append ( l_idx_labels ) logging . info ( \"Returning ll_idx_labels\" ) return ll_idx_labels","title":"global_lipid_index_store()"},{"location":"modules/tools/spectra/#modules.tools.spectra.reduce_resolution_sorted","text":"This function function has been imported from the mspec module. Please consult the corresponding module to get the docstring. Source code in modules/tools/spectra.py 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 @njit def reduce_resolution_sorted ( mz : np . ndarray , intensity : np . ndarray , resolution : float , max_intensity = True ) -> Tuple [ np . ndarray , np . ndarray ]: \"\"\"This function function has been imported from the mspec module. Please consult the corresponding module to get the docstring. \"\"\" # First just count the unique values and store them to avoid recalc current_mz = - 1.0 cnt = 0 approx_mz = np . empty ( mz . shape , dtype = np . double ) for i in range ( len ( mz )): approx_mz [ i ] = np . floor ( mz [ i ] / resolution ) * resolution if approx_mz [ i ] != current_mz : cnt += 1 current_mz = approx_mz [ i ] new_mz = np . empty ( cnt , dtype = np . double ) new_intensity = np . empty ( cnt , dtype = np . double ) current_mz = - 1.0 rix = - 1 for i in range ( len ( mz )): if approx_mz [ i ] != current_mz : rix += 1 new_mz [ rix ] = approx_mz [ i ] new_intensity [ rix ] = intensity [ i ] current_mz = approx_mz [ i ] else : # retrieve the maximum intensity value within the new bin if max_intensity : # check that the new intensity is greater than what is already there if intensity [ i ] > new_intensity [ rix ]: new_intensity [ rix ] = intensity [ i ] # sum the intensity values within the new bin else : new_intensity [ rix ] += intensity [ i ] return new_mz , new_intensity","title":"reduce_resolution_sorted()"},{"location":"modules/tools/spectra/#modules.tools.spectra.reduce_resolution_sorted_array_spectra","text":"Recompute a sparce representation of the spectrum at a lower (fixed) resolution, summing over the redundant bins. Resolution should be <=10**-4 as it's about the maximum precision allowed by float32. Parameters: Name Type Description Default array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required resolution float The size of the bin used to merge intensities. Defaults to 10**-3. 10 ** -3 Returns: Type Description np . ndarray Array of shape=(2, m) similar to the input array but with a new sampling resolution. Source code in modules/tools/spectra.py 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 @njit def reduce_resolution_sorted_array_spectra ( array_spectra , resolution = 10 **- 3 ): \"\"\"Recompute a sparce representation of the spectrum at a lower (fixed) resolution, summing over the redundant bins. Resolution should be <=10**-4 as it's about the maximum precision allowed by float32. Args: array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. resolution (float, optional): The size of the bin used to merge intensities. Defaults to 10**-3. Returns: (np.ndarray): Array of shape=(2, m) similar to the input array but with a new sampling resolution. \"\"\" # Get the re-sampled m/z and intensities from mspec library, with max_intensity = False to sum # over redundant bins new_mz , new_intensity = reduce_resolution_sorted ( array_spectra [ 0 , :], array_spectra [ 1 , :], resolution , max_intensity = False ) # Build a new array as the stack of the two others new_array_spectra = np . empty (( 2 , new_mz . shape [ 0 ]), dtype = np . float32 ) new_array_spectra [ 0 , :] = new_mz new_array_spectra [ 1 , :] = new_intensity return new_array_spectra","title":"reduce_resolution_sorted_array_spectra()"},{"location":"modules/tools/spectra/#modules.tools.spectra.return_idx_inf","text":"Returns the indices of the lipids that do not have an annotation Parameters: Name Type Description Default l_idx_labels np . ndarray A 1-dimensional array containing the indices of the lipid labels. required Returns: Type Description np . ndarray A list containing the indices of the lipids that do not have an annotation. Source code in modules/tools/spectra.py 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 @njit def return_idx_inf ( l_idx_labels ): \"\"\"Returns the indices of the lipids that do not have an annotation Args: l_idx_labels (np.ndarray): A 1-dimensional array containing the indices of the lipid labels. Returns: (np.ndarray): A list containing the indices of the lipids that do not have an annotation. \"\"\" return [ i for i , x in enumerate ( l_idx_labels ) if x < 0 ]","title":"return_idx_inf()"},{"location":"modules/tools/spectra/#modules.tools.spectra.return_idx_sup","text":"Returns the indices of the lipids that have an annotation Parameters: Name Type Description Default l_idx_labels np . ndarray A 1-dimensional array containing the indices of the lipid labels. required Returns: Type Description np . ndarray A list containing the indices of the lipids that have an annotation. Source code in modules/tools/spectra.py 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 @njit def return_idx_sup ( l_idx_labels ): \"\"\"Returns the indices of the lipids that have an annotation Args: l_idx_labels (np.ndarray): A 1-dimensional array containing the indices of the lipid labels. Returns: (np.ndarray): A list containing the indices of the lipids that have an annotation. \"\"\" return [ i for i , x in enumerate ( l_idx_labels ) if x >= 0 ]","title":"return_idx_sup()"},{"location":"modules/tools/spectra/#modules.tools.spectra.return_index_labels","text":"This function returns the corresponding lipid name indices from a list of m/z values. Note that the zero_padding_extra parameter is needed for both taking into account the zero-padding (this way zeros on the sides of the peak are also identified as the annotated lipid) but also because the annotation is very stringent in the first place, and sometimes border of the peaks are missing in the annotation. Parameters: Name Type Description Default l_min list(int This list provides the lower peak boundaries of the identified lipids. required l_max list(int This list provides the upper peak boundaries of the identified lipids. required l_mz list(float The list of m/z value which must be annotated with lipid names. required zero_padding_extra float Size of the zero-padding. Defaults to 5 10 *-5. 5 * 10 ** -5 Returns: Type Description np . ndarray A 1-dimensional array containing the indices of the lipid labels. Source code in modules/tools/spectra.py 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 @njit def return_index_labels ( l_min , l_max , l_mz , zero_padding_extra = 5 * 10 **- 5 ): \"\"\"This function returns the corresponding lipid name indices from a list of m/z values. Note that the zero_padding_extra parameter is needed for both taking into account the zero-padding (this way zeros on the sides of the peak are also identified as the annotated lipid) but also because the annotation is very stringent in the first place, and sometimes border of the peaks are missing in the annotation. Args: l_min (list(int)): This list provides the lower peak boundaries of the identified lipids. l_max (list(int)): This list provides the upper peak boundaries of the identified lipids. l_mz (list(float)): The list of m/z value which must be annotated with lipid names. zero_padding_extra (float, optional): Size of the zero-padding. Defaults to 5*10**-5. Returns: (np.ndarray): A 1-dimensional array containing the indices of the lipid labels. \"\"\" # Build empty array for lipid indexes array_indexes = np . empty (( len ( l_mz ),), dtype = np . int32 ) array_indexes . fill ( - 1 ) idx_lipid = 0 idx_mz = 0 while idx_lipid < len ( l_min ) and idx_mz < len ( l_mz ): # Case peak is in lipid boundaries if ( l_mz [ idx_mz ] >= l_min [ idx_lipid ] - zero_padding_extra and l_mz [ idx_mz ] <= l_max [ idx_lipid ] + zero_padding_extra ): array_indexes [ idx_mz ] = idx_lipid idx_mz += 1 # Case peak is before lipid boundaries elif l_mz [ idx_mz ] < l_min [ idx_lipid ] - zero_padding_extra : # array_indexes[idx_mz] = -1 idx_mz += 1 # Case peak is after lipid boundaries elif l_mz [ idx_mz ] > l_max [ idx_lipid ] + zero_padding_extra : idx_lipid += 1 return array_indexes","title":"return_index_labels()"},{"location":"modules/tools/spectra/#modules.tools.spectra.return_spectrum_per_pixel","text":"This function returns the spectrum of the pixel having index pixel_idx, using the lookup table array_pixel_indexes. Parameters: Name Type Description Default idx_pix int Index of the pixel to return. required array_spectra np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. required array_pixel_indexes np . ndarray An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. required Returns: Type Description np . ndarray An array of shape (2,m) containing spectrum data (m/z and intensity) for the requested pixel. Source code in modules/tools/spectra.py 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 @njit def return_spectrum_per_pixel ( idx_pix , array_spectra , array_pixel_indexes ): \"\"\"This function returns the spectrum of the pixel having index pixel_idx, using the lookup table array_pixel_indexes. Args: idx_pix (int): Index of the pixel to return. array_spectra (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity) for each pixel. array_pixel_indexes (np.ndarray): An array of shape (m,2) containing the boundary indices of each pixel in array_spectra. Returns: (np.ndarray): An array of shape (2,m) containing spectrum data (m/z and intensity) for the requested pixel. \"\"\" # Get the indices of the spectrum of the requested pixel idx_1 , idx_2 = array_pixel_indexes [ idx_pix ] if idx_1 == - 1 : idx_2 == - 2 # To return empty list in the end return array_spectra [:, idx_1 : idx_2 + 1 ]","title":"return_spectrum_per_pixel()"},{"location":"modules/tools/spectra/#modules.tools.spectra.sample_rows_from_path","text":"This function takes a path as input and returns the lower and upper indexes of the rows belonging to the current selection (i.e. indexed in the path), as well as the corresponding column boundaries for each row. Note that, although counter-intuitive given the kind of regression done in this function, x is the vertical axis (from top to bottom), and y the horizontal one. Parameters: Name Type Description Default path np . ndarray A two-dimensional array, containing, in each row, the row and column coordinates (x and y) of the current selection. required Returns: Type Description np . ndarray , np . ndarray The first array contains the lower and upper indexes of the rows belonging to the current selection. The second array contains, for each row, the corresponding column boundaries (there can be more than 2 for non-convex shapes). Source code in modules/tools/spectra.py 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 @njit def sample_rows_from_path ( path ): \"\"\"This function takes a path as input and returns the lower and upper indexes of the rows belonging to the current selection (i.e. indexed in the path), as well as the corresponding column boundaries for each row. Note that, although counter-intuitive given the kind of regression done in this function, x is the vertical axis (from top to bottom), and y the horizontal one. Args: path (np.ndarray): A two-dimensional array, containing, in each row, the row and column coordinates (x and y) of the current selection. Returns: (np.ndarray, np.ndarray): The first array contains the lower and upper indexes of the rows belonging to the current selection. The second array contains, for each row, the corresponding column boundaries (there can be more than 2 for non-convex shapes). \"\"\" # Find out the lower and upper rows x_min = path [:, 0 ] . min () x_max = path [:, 0 ] . max () # Numba won't accept a list of list, so I must use a list of np arrays for the column boundaries list_index_bound_column_per_row = [ np . arange ( 0 ) for x in range ( x_min , x_max + 1 )] # Also register the x-axis direction to correct the linear regression accordingly dir_prev = None # For each couple of points in the path, do a linear regression to find the corresponding y # (needed due to non constant sampling on the y-axis) for i in range ( path . shape [ 0 ] - 1 ): x1 , y1 = path [ i ] x2 , y2 = path [ i + 1 ] if x2 != x1 : slope = ( y2 - y1 ) / ( x2 - x1 ) intercept = y1 - slope * x1 # Compute if change of direction on the x-axis and correct accordingly if x2 >= x1 : dir = 1 else : dir = - 1 if dir_prev is None or dir == dir_prev : offset = 0 else : offset = dir dir_prev = dir # For each x, get the corresponding y (with non constant sampling on y axis) for x in range ( x1 + offset , x2 , dir ): list_index_bound_column_per_row [ x - x_min ] = np . append ( list_index_bound_column_per_row [ x - x_min ], round ( slope * x + intercept ) ) # Min x and max x often cover only zero or one pixel due to the way the sampling is done, we # just get rid of them if len ( list_index_bound_column_per_row [ 0 ]) < 2 : del list_index_bound_column_per_row [ 0 ] x_min += 1 if len ( list_index_bound_column_per_row [ - 1 ]) < 2 : del list_index_bound_column_per_row [ - 1 ] x_max -= 1 # Clean list l_to_del = [] for x in range ( x_min , x_max + 1 ): # If everything went fine, x should appear an even number of times if len ( list_index_bound_column_per_row [ x - x_min ]) % 2 == 0 : pass else : # logging.warning(\"Bug with list x\", x, list_index_bound_column_per_row[x - x_min]) # Try to correct the number of times x appear if ( len ( list_index_bound_column_per_row [ x - x_min ]) % 2 == 1 and len ( list_index_bound_column_per_row [ x - x_min ]) != 1 ): list_index_bound_column_per_row [ x - x_min ] = list_index_bound_column_per_row [ x - x_min ][: - 1 ] else : list_index_bound_column_per_row [ x - x_min ] = np . append ( list_index_bound_column_per_row [ x - x_min ], list_index_bound_column_per_row [ x - x_min ][ 0 ], ) list_index_bound_column_per_row [ x - x_min ] . sort () # Inplace sort to spare memory # Convert list of np.array to np array padded with zeros (for numba compatibility) max_len = max ([ len ( i ) for i in list_index_bound_column_per_row ]) array_index_bound_column_per_row = np . zeros ( ( len ( list_index_bound_column_per_row ), max_len ), dtype = np . int32 ) for i , arr in enumerate ( list_index_bound_column_per_row ): array_index_bound_column_per_row [ i , : len ( arr )] = arr return np . array ([ x_min , x_max ], dtype = np . int32 ), array_index_bound_column_per_row","title":"sample_rows_from_path()"},{"location":"modules/tools/spectra/#modules.tools.spectra.strip_zeros","text":"This function strips a (potentially sparse) array (e.g. one that has been converted with convert_array_to_fine_grained) from its columns having intensity zero. Parameters: Name Type Description Default array np . ndarray An array of shape (2,n) containing spectrum data (m/z and intensity). required Returns: Type Description np . ndarray The same array stripped from its zero intensity values. Now of shape (2,m). Source code in modules/tools/spectra.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 @njit def strip_zeros ( array ): \"\"\"This function strips a (potentially sparse) array (e.g. one that has been converted with convert_array_to_fine_grained) from its columns having intensity zero. Args: array (np.ndarray): An array of shape (2,n) containing spectrum data (m/z and intensity). Returns: (np.ndarray): The same array stripped from its zero intensity values. Now of shape (2,m). \"\"\" # Look for the non-zero values and store them in l_to_keep l_to_keep = [ idx for idx , x in enumerate ( array [ 1 , :]) if x != 0 and not np . isnan ( x )] # Keep only the previsouly assigned non-zero values array_mz = array [ 0 , :] . take ( l_to_keep ) array_intensity = array [ 1 , :] . take ( l_to_keep ) return np . vstack (( array_mz , array_intensity ))","title":"strip_zeros()"},{"location":"modules/tools/volume/","text":"In this module, functions used to handle 3D graphing (e.g. voxel filtering, interpolations, etc) are defined. crop_array ( array_annotation , list_id_regions ) Given an array of annotations containing regions as ids, and a list of ids, this functions crops the parts of the array that do not contain the regions inside of the list. Parameters: Name Type Description Default array_annotation np . ndarray A 3D numpy array containing the annotations of the brain as integers. required list_id_regions np . ndarray A flat array of integers containing the ids of the regions to keep. required Returns: Type Description int , int , int , int , int , int The min and max indices to keep for each dimension. Source code in modules/tools/volume.py 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 @njit def crop_array ( array_annotation , list_id_regions ): \"\"\"Given an array of annotations containing regions as ids, and a list of ids, this functions crops the parts of the array that do not contain the regions inside of the list. Args: array_annotation (np.ndarray): A 3D numpy array containing the annotations of the brain as integers. list_id_regions (np.ndarray): A flat array of integers containing the ids of the regions to keep. Returns: (int, int, int, int, int, int): The min and max indices to keep for each dimension. \"\"\" # Define min and max as image dimensions initially x_min , x_max , y_min , y_max , z_min , z_max = ( 0 , array_annotation . shape [ 0 ], 0 , array_annotation . shape [ 1 ], 0 , array_annotation . shape [ 2 ], ) # Crop unfilled parts to save space found = False for x in range ( 0 , array_annotation . shape [ 0 ]): for id_structure in list_id_regions : if id_structure in array_annotation [ x , :, :]: x_min = max ( x_min , x - 1 ) found = True if found : break found = False for x in range ( array_annotation . shape [ 0 ] - 1 , - 1 , - 1 ): for id_structure in list_id_regions : if id_structure in array_annotation [ x , :, :]: x_max = min ( x + 1 , x_max ) found = True if found : break found = False for y in range ( 0 , array_annotation . shape [ 1 ]): for id_structure in list_id_regions : if id_structure in array_annotation [:, y , :]: y_min = max ( y - 1 , y_min ) found = True if found : break found = False for y in range ( array_annotation . shape [ 1 ] - 1 , - 1 , - 1 ): for id_structure in list_id_regions : if id_structure in array_annotation [:, y , :]: y_max = min ( y + 1 , y_max ) found = True if found : break found = False for z in range ( 0 , array_annotation . shape [ 2 ]): for id_structure in list_id_regions : if id_structure in array_annotation [:, :, z ]: z_min = max ( z - 1 , z_min ) found = True if found : break found = False for z in range ( array_annotation . shape [ 2 ] - 1 , - 1 , - 1 ): for id_structure in list_id_regions : if id_structure in array_annotation [:, :, z ]: z_max = min ( z + 1 , z_max ) found = True if found : break # If the cropping went properly, return the extrema indices, else return None if x_min is None : return None else : return x_min , x_max , y_min , y_max , z_min , z_max fill_array_borders ( array_annotation , differentiate_borders = False , color_near_borders = False , keep_structure_id = None , annot_outside =- 2 , annot_border =- 0.1 , annot_inside =- 0.01 , annot_near_border = 0.2 , decrease_dimensionality_factor = None ) This function takes the Allen Brain atlas array of annotation and returns an array representing the borders of the atlas, to be used later for the volume plot. Values in the array are as follows by default: -2 is outside brain or selected structures -0.1 is border if differentiate_borders is True -0.01 is inside brain/structure 0.2 is near border if color_near_borders is True NB: the -0.01 values get changed after assignment to lipid expression, later on in fill_array_interpolation. Parameters: Name Type Description Default array_annotation np . ndarray Three-dimensional array of annotation coming from the Allen Brain Atlas. required differentiate_borders bool If True, represent the brain border with a different value. Defaults to False. False color_near_borders bool If True, the region surrounding the brain border is also filled. Defaults to False. False keep_structure_id np . ndarray Array containing the id of the brain regions whose border must be annotated. Defaults to None. None annot_outside float Value to be used for the areas outside of the brain. Defaults to -2. -2 annot_border float Value to be used for the border of the brain. Defaults to -0.1. -0.1 annot_inside float Value to be used for the inside of the brain. Defaults to -0.01. -0.01 annot_near_border float Value to be used for the color of the area near the border of the brain. Defaults to 0.2. 0.2 decrease_dimensionality_factor int Useless parameter, kept for ensuring that shelving is done properly, as array_annotation corresponds to a given decrease_dimensionality_factor. Defaults to None. None Returns: Type Description np . ndarray A numpy array representing the borders of the atlas. Source code in modules/tools/volume.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 @njit def fill_array_borders ( array_annotation , differentiate_borders = False , color_near_borders = False , keep_structure_id = None , annot_outside =- 2 , annot_border =- 0.1 , annot_inside =- 0.01 , annot_near_border = 0.2 , decrease_dimensionality_factor = None , ): \"\"\"This function takes the Allen Brain atlas array of annotation and returns an array representing the borders of the atlas, to be used later for the volume plot. Values in the array are as follows by default: -2 is outside brain or selected structures -0.1 is border if differentiate_borders is True -0.01 is inside brain/structure 0.2 is near border if color_near_borders is True NB: the -0.01 values get changed after assignment to lipid expression, later on in fill_array_interpolation. Args: array_annotation (np.ndarray): Three-dimensional array of annotation coming from the Allen Brain Atlas. differentiate_borders (bool, optional): If True, represent the brain border with a different value. Defaults to False. color_near_borders (bool, optional): If True, the region surrounding the brain border is also filled. Defaults to False. keep_structure_id (np.ndarray, optional): Array containing the id of the brain regions whose border must be annotated. Defaults to None. annot_outside (float, optional): Value to be used for the areas outside of the brain. Defaults to -2. annot_border (float, optional): Value to be used for the border of the brain. Defaults to -0.1. annot_inside (float, optional): Value to be used for the inside of the brain. Defaults to -0.01. annot_near_border (float, optional): Value to be used for the color of the area near the border of the brain. Defaults to 0.2. decrease_dimensionality_factor (int, optional): Useless parameter, kept for ensuring that shelving is done properly, as array_annotation corresponds to a given decrease_dimensionality_factor. Defaults to None. Returns: (np.ndarray): A numpy array representing the borders of the atlas. \"\"\" array_atlas_borders = np . full_like ( array_annotation , annot_outside , dtype = np . float32 ) for x in range ( 1 , array_annotation . shape [ 0 ] - 1 ): for y in range ( 1 , array_annotation . shape [ 1 ] - 1 ): for z in range ( 1 , array_annotation . shape [ 2 ] - 1 ): if array_annotation [ x , y , z ] > 0 : if keep_structure_id is not None : if array_annotation [ x , y , z ] not in keep_structure_id : continue # If we want to plot the brain border with a different shade if differentiate_borders : # check if border in a cube of size 2 found = False for xt in range ( x - 1 , x + 2 ): for yt in range ( y - 1 , y + 2 ): for zt in range ( z - 1 , z + 2 ): # two cases in which there's a border around, depending if # keep_structure_id is defined if keep_structure_id is None : if array_annotation [ xt , yt , zt ] == 0 : found = True else : if array_annotation [ xt , yt , zt ] not in keep_structure_id : found = True if found : array_atlas_borders [ x , y , z ] = annot_border # inside the brain/structure but not a border else : array_atlas_borders [ x , y , z ] = annot_inside else : array_atlas_borders [ x , y , z ] = annot_inside # Also color the region surrounding the border if color_near_borders : for x in range ( 1 , array_annotation . shape [ 0 ] - 1 ): for y in range ( 1 , array_annotation . shape [ 1 ] - 1 ): for z in range ( 1 , array_annotation . shape [ 2 ] - 1 ): if np . abs ( array_atlas_borders [ x , y , z ] - ( - 0.1 )) < 10 **- 4 : for xt in range ( x - 1 , x + 2 ): for yt in range ( y - 1 , y + 2 ): for zt in range ( z - 1 , z + 2 ): # not on the border if np . abs ( array_atlas_borders [ xt , yt , zt ] - ( - 0.1 )) > 10 **- 4 : array_atlas_borders [ xt , yt , zt ] = annot_near_border return array_atlas_borders fill_array_interpolation ( array_annotation , array_slices , divider_radius = 5 , annot_inside =- 0.01 , limit_value_inside =- 2 , structure_guided = True ) This function is used to fill the empty space (unassigned voxels) between the slices with interpolated values. Parameters: Name Type Description Default array_annotation np . ndarray Three-dimensional array of annotation coming from the Allen Brain Atlas. required array_slices np . ndarray Three-dimensional array containing the lipid intensity values from the MALDI experiments (with many unassigned voxels). required divider_radius int Divides the radius of the region used for interpolation (the bigger, the lower the number of voxels used). Defaults to 5. 5 annot_inside float Value used to denotate the inside of the brain. Defaults to -0.01. -0.01 limit_value_inside float Alternative to annot_inside. Values above limit_value_inside are considered inside the brain. Defaults to -2. -2 structure_guided bool If True, the interpolation is done using the annotated structures. If False, the interpolation is done blindly. True Returns: Type Description np . ndarray A three-dimensional array containing the interpolated lipid intensity values. Source code in modules/tools/volume.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 @njit def fill_array_interpolation ( array_annotation , array_slices , divider_radius = 5 , annot_inside =- 0.01 , limit_value_inside =- 2 , structure_guided = True , ): \"\"\"This function is used to fill the empty space (unassigned voxels) between the slices with interpolated values. Args: array_annotation (np.ndarray): Three-dimensional array of annotation coming from the Allen Brain Atlas. array_slices (np.ndarray): Three-dimensional array containing the lipid intensity values from the MALDI experiments (with many unassigned voxels). divider_radius (int, optional): Divides the radius of the region used for interpolation (the bigger, the lower the number of voxels used). Defaults to 5. annot_inside (float, optional): Value used to denotate the inside of the brain. Defaults to -0.01. limit_value_inside (float, optional): Alternative to annot_inside. Values above limit_value_inside are considered inside the brain. Defaults to -2. structure_guided (bool, optional): If True, the interpolation is done using the annotated structures. If False, the interpolation is done blindly. Returns: (np.ndarray): A three-dimensional array containing the interpolated lipid intensity values. \"\"\" array_interpolated = np . copy ( array_slices ) # Start from 8 as we don't have data before and the structure disposition makes it look # like a bug with the interpolation for x in range ( 8 , array_annotation . shape [ 0 ]): for y in range ( 0 , array_annotation . shape [ 1 ]): for z in range ( 0 , array_annotation . shape [ 2 ]): # If we are in a unfilled region of the brain or just inside the brain condition_fulfilled = False if array_slices [ x , y , z ] >= 0 : condition_fulfilled = True elif limit_value_inside is not None and not condition_fulfilled : if array_annotation [ x , y , z ] > limit_value_inside : condition_fulfilled = True elif ( np . abs ( array_slices [ x , y , z ] - annot_inside ) < 10 **- 4 ) and not condition_fulfilled : condition_fulfilled = True if condition_fulfilled : # Check all datapoints in the same structure, and do a distance-weighted average value_voxel = 0 sum_weights = 0 size_radius = int ( array_annotation . shape [ 0 ] / divider_radius ) for xt in range ( max ( 0 , x - size_radius ), min ( array_annotation . shape [ 0 ], x + size_radius + 1 ) ): for yt in range ( max ( 0 , y - size_radius ), min ( array_annotation . shape [ 1 ], y + size_radius + 1 ), ): for zt in range ( max ( 0 , z - size_radius ), min ( array_annotation . shape [ 2 ], z + size_radius + 1 ), ): # If we are inside of the shere of radius size_radius if ( np . sqrt (( x - xt ) ** 2 + ( y - yt ) ** 2 + ( z - zt ) ** 2 ) <= size_radius ): # The voxel has data if array_slices [ xt , yt , zt ] >= 0 : # The structure is identical if ( structure_guided and np . abs ( array_annotation [ x , y , z ] - array_annotation [ xt , yt , zt ] ) < 10 **- 4 ) or not structure_guided : d = np . sqrt ( ( x - xt ) ** 2 + ( y - yt ) ** 2 + ( z - zt ) ** 2 ) value_voxel += np . exp ( - d ) * array_slices [ xt , yt , zt ] sum_weights += np . exp ( - d ) if sum_weights == 0 : pass # print(\"No other voxel found for structure \", array_annotation[x, y, z]) else : # print('Voxel found for structure', array_annotation[x, y, z]) value_voxel = value_voxel / sum_weights array_interpolated [ x , y , z ] = value_voxel return array_interpolated fill_array_slices ( array_x , array_y , array_z , array_c , array_slices , array_for_avg , limit_value_inside =- 0.05 ) This function takes the arrays of expression in the slices and fills the 3D array of expression with them, inside of the regions annotated in the provided array_slices (which is initially a simple copy of array_atlas_borders). Parameters: Name Type Description Default array_x np . ndarray A flat array of x coordinates for the 3D graphing. required array_y np . ndarray A flat array of y coordinates for the 3D graphing. required array_z np . ndarray A flat array of z coordinates for the 3D graphing. required array_c np . ndarray A flat array of expression values (float) for the 3D graphing. required array_slices np . ndarray Initially, a 3D numpy array representing the borders of the atlas. It is then filled with lipid expression values (from array_c) in the slices. required array_for_avg np . ndarray A 3D numpy array used for keeping count of the number of times a cell has been assigned, for averaging the expression values later on. required limit_value_inside float The value above which the array must be filled, i.e. corresponds to an annotated region of the brain. Defaults to -0.05. -0.05 Returns: Type Description np . ndarray A 3D numpy array representing the expression of the lipids preliminarily stored in array_c, in the regions preliminarily annotated in array_slices. Source code in modules/tools/volume.py 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 @njit def fill_array_slices ( array_x , array_y , array_z , array_c , array_slices , array_for_avg , limit_value_inside =- 0.05 , ): \"\"\"This function takes the arrays of expression in the slices and fills the 3D array of expression with them, inside of the regions annotated in the provided array_slices (which is initially a simple copy of array_atlas_borders). Args: array_x (np.ndarray): A flat array of x coordinates for the 3D graphing. array_y (np.ndarray): A flat array of y coordinates for the 3D graphing. array_z (np.ndarray): A flat array of z coordinates for the 3D graphing. array_c (np.ndarray): A flat array of expression values (float) for the 3D graphing. array_slices (np.ndarray): Initially, a 3D numpy array representing the borders of the atlas. It is then filled with lipid expression values (from array_c) in the slices. array_for_avg (np.ndarray): A 3D numpy array used for keeping count of the number of times a cell has been assigned, for averaging the expression values later on. limit_value_inside (float, optional): The value above which the array must be filled, i.e. corresponds to an annotated region of the brain. Defaults to -0.05. Returns: (np.ndarray): A 3D numpy array representing the expression of the lipids preliminarily stored in array_c, in the regions preliminarily annotated in array_slices. \"\"\" for x , y , z , c in zip ( array_x , array_y , array_z , array_c ): # ! Coordinates need to be switched x_scaled = int ( round ( y )) y_scaled = int ( round ( z )) z_scaled = int ( round ( x )) # If inside the brain if array_slices [ x_scaled , y_scaled , z_scaled ] > limit_value_inside : # If inside the brain and not assigned before if array_slices [ x_scaled , y_scaled , z_scaled ] < 0 : array_slices [ x_scaled , y_scaled , z_scaled ] = c / 100 # Inside the brain but already assigned, in which case average else : array_slices [ x_scaled , y_scaled , z_scaled ] += c / 100 array_for_avg [ x_scaled , y_scaled , z_scaled ] += 1 array_slices = array_slices / array_for_avg return array_slices filter_voxels ( array_data_stripped , coordinates_stripped , array_annotations , percentile , array_x , array_y , array_z , array_c , total_index , reference_shape , resolution ) This function takes a given array of coordinates 'coordinates_stripped' and checks if it corresponds to a given annotation in the atlas. If so, the coordinates are added to the arrays 'array_x', 'array_y', 'array_z' to be used for the 3D graphing. Else, it's filtered out. Parameters: Name Type Description Default array_data_stripped np . ndarray A 2-dimensional array of voxel intensity for the current slice, stripped of zero values. required coordinates_stripped np . ndarray A 2-dimensional array of voxel coordinates for the current slice, stripped of zero values. required array_annotations np . ndarray The 3-dimensional array of annotation coming from the Allen Brain Atlas. required percentile float The value above which the voxels are considered for the graphing. required array_x np . ndarray A flat array of x coordinates for the 3D graphing. required array_y np . ndarray A flat array of y coordinates for the 3D graphing. required array_z np . ndarray A flat array of z coordinates for the 3D graphing. required array_c np . ndarray A flat array of color (expression) values (float) for the 3D graphing. required total_index int An integer used to keep track of the array indexing outside of this function. required reference_shape np . ndarray Array containing the reference atlas shape. required resolution int Integer representing the resolution of the atlas. required Returns: Type Description np . ndarray , np . ndarray , np . ndarray , np . ndarray , int The filled arrays of coordinates or color for the current slice, and the updated total_index. Source code in modules/tools/volume.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 @njit def filter_voxels ( array_data_stripped , coordinates_stripped , array_annotations , percentile , array_x , array_y , array_z , array_c , total_index , reference_shape , resolution , ): \"\"\"This function takes a given array of coordinates 'coordinates_stripped' and checks if it corresponds to a given annotation in the atlas. If so, the coordinates are added to the arrays 'array_x', 'array_y', 'array_z' to be used for the 3D graphing. Else, it's filtered out. Args: array_data_stripped (np.ndarray): A 2-dimensional array of voxel intensity for the current slice, stripped of zero values. coordinates_stripped (np.ndarray): A 2-dimensional array of voxel coordinates for the current slice, stripped of zero values. array_annotations (np.ndarray): The 3-dimensional array of annotation coming from the Allen Brain Atlas. percentile (float): The value above which the voxels are considered for the graphing. array_x (np.ndarray): A flat array of x coordinates for the 3D graphing. array_y (np.ndarray): A flat array of y coordinates for the 3D graphing. array_z (np.ndarray): A flat array of z coordinates for the 3D graphing. array_c (np.ndarray): A flat array of color (expression) values (float) for the 3D graphing. total_index (int): An integer used to keep track of the array indexing outside of this function. reference_shape (np.ndarray): Array containing the reference atlas shape. resolution (int): Integer representing the resolution of the atlas. Returns: (np.ndarray, np.ndarray, np.ndarray, np.ndarray, int): The filled arrays of coordinates or color for the current slice, and the updated total_index. \"\"\" # Keep track of the array indexing even outside of this function total_index_temp = 0 for i in range ( array_data_stripped . shape [ 0 ]): x_atlas , y_atlas , z_atlas = coordinates_stripped [ i ] / 1000 # Filter out voxels that are not in the atlas x_temp = int ( round ( x_atlas * 1000000 / resolution )) y_temp = int ( round ( y_atlas * 1000000 / resolution )) z_temp = int ( round ( z_atlas * 1000000 / resolution )) # Voxels not even in the atlas array if x_temp < 0 or x_temp >= reference_shape [ 0 ]: continue if y_temp < 0 or y_temp >= reference_shape [ 1 ]: continue if z_temp < 0 or z_temp >= reference_shape [ 2 ]: continue # Voxels in the atlas but which don't correspond to a structure if array_annotations [ x_temp , y_temp , z_temp ] == 0 : continue if array_data_stripped [ i ] >= percentile : # * careful, x,y,z are switched array_x [ total_index + total_index_temp ] = z_atlas array_y [ total_index + total_index_temp ] = x_atlas array_z [ total_index + total_index_temp ] = y_atlas array_c [ total_index + total_index_temp ] = array_data_stripped [ i ] total_index_temp += 1 total_index += total_index_temp return array_x , array_y , array_z , array_c , total_index","title":"Volume"},{"location":"modules/tools/volume/#modules.tools.volume.crop_array","text":"Given an array of annotations containing regions as ids, and a list of ids, this functions crops the parts of the array that do not contain the regions inside of the list. Parameters: Name Type Description Default array_annotation np . ndarray A 3D numpy array containing the annotations of the brain as integers. required list_id_regions np . ndarray A flat array of integers containing the ids of the regions to keep. required Returns: Type Description int , int , int , int , int , int The min and max indices to keep for each dimension. Source code in modules/tools/volume.py 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 @njit def crop_array ( array_annotation , list_id_regions ): \"\"\"Given an array of annotations containing regions as ids, and a list of ids, this functions crops the parts of the array that do not contain the regions inside of the list. Args: array_annotation (np.ndarray): A 3D numpy array containing the annotations of the brain as integers. list_id_regions (np.ndarray): A flat array of integers containing the ids of the regions to keep. Returns: (int, int, int, int, int, int): The min and max indices to keep for each dimension. \"\"\" # Define min and max as image dimensions initially x_min , x_max , y_min , y_max , z_min , z_max = ( 0 , array_annotation . shape [ 0 ], 0 , array_annotation . shape [ 1 ], 0 , array_annotation . shape [ 2 ], ) # Crop unfilled parts to save space found = False for x in range ( 0 , array_annotation . shape [ 0 ]): for id_structure in list_id_regions : if id_structure in array_annotation [ x , :, :]: x_min = max ( x_min , x - 1 ) found = True if found : break found = False for x in range ( array_annotation . shape [ 0 ] - 1 , - 1 , - 1 ): for id_structure in list_id_regions : if id_structure in array_annotation [ x , :, :]: x_max = min ( x + 1 , x_max ) found = True if found : break found = False for y in range ( 0 , array_annotation . shape [ 1 ]): for id_structure in list_id_regions : if id_structure in array_annotation [:, y , :]: y_min = max ( y - 1 , y_min ) found = True if found : break found = False for y in range ( array_annotation . shape [ 1 ] - 1 , - 1 , - 1 ): for id_structure in list_id_regions : if id_structure in array_annotation [:, y , :]: y_max = min ( y + 1 , y_max ) found = True if found : break found = False for z in range ( 0 , array_annotation . shape [ 2 ]): for id_structure in list_id_regions : if id_structure in array_annotation [:, :, z ]: z_min = max ( z - 1 , z_min ) found = True if found : break found = False for z in range ( array_annotation . shape [ 2 ] - 1 , - 1 , - 1 ): for id_structure in list_id_regions : if id_structure in array_annotation [:, :, z ]: z_max = min ( z + 1 , z_max ) found = True if found : break # If the cropping went properly, return the extrema indices, else return None if x_min is None : return None else : return x_min , x_max , y_min , y_max , z_min , z_max","title":"crop_array()"},{"location":"modules/tools/volume/#modules.tools.volume.fill_array_borders","text":"This function takes the Allen Brain atlas array of annotation and returns an array representing the borders of the atlas, to be used later for the volume plot. Values in the array are as follows by default: -2 is outside brain or selected structures -0.1 is border if differentiate_borders is True -0.01 is inside brain/structure 0.2 is near border if color_near_borders is True NB: the -0.01 values get changed after assignment to lipid expression, later on in fill_array_interpolation. Parameters: Name Type Description Default array_annotation np . ndarray Three-dimensional array of annotation coming from the Allen Brain Atlas. required differentiate_borders bool If True, represent the brain border with a different value. Defaults to False. False color_near_borders bool If True, the region surrounding the brain border is also filled. Defaults to False. False keep_structure_id np . ndarray Array containing the id of the brain regions whose border must be annotated. Defaults to None. None annot_outside float Value to be used for the areas outside of the brain. Defaults to -2. -2 annot_border float Value to be used for the border of the brain. Defaults to -0.1. -0.1 annot_inside float Value to be used for the inside of the brain. Defaults to -0.01. -0.01 annot_near_border float Value to be used for the color of the area near the border of the brain. Defaults to 0.2. 0.2 decrease_dimensionality_factor int Useless parameter, kept for ensuring that shelving is done properly, as array_annotation corresponds to a given decrease_dimensionality_factor. Defaults to None. None Returns: Type Description np . ndarray A numpy array representing the borders of the atlas. Source code in modules/tools/volume.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 @njit def fill_array_borders ( array_annotation , differentiate_borders = False , color_near_borders = False , keep_structure_id = None , annot_outside =- 2 , annot_border =- 0.1 , annot_inside =- 0.01 , annot_near_border = 0.2 , decrease_dimensionality_factor = None , ): \"\"\"This function takes the Allen Brain atlas array of annotation and returns an array representing the borders of the atlas, to be used later for the volume plot. Values in the array are as follows by default: -2 is outside brain or selected structures -0.1 is border if differentiate_borders is True -0.01 is inside brain/structure 0.2 is near border if color_near_borders is True NB: the -0.01 values get changed after assignment to lipid expression, later on in fill_array_interpolation. Args: array_annotation (np.ndarray): Three-dimensional array of annotation coming from the Allen Brain Atlas. differentiate_borders (bool, optional): If True, represent the brain border with a different value. Defaults to False. color_near_borders (bool, optional): If True, the region surrounding the brain border is also filled. Defaults to False. keep_structure_id (np.ndarray, optional): Array containing the id of the brain regions whose border must be annotated. Defaults to None. annot_outside (float, optional): Value to be used for the areas outside of the brain. Defaults to -2. annot_border (float, optional): Value to be used for the border of the brain. Defaults to -0.1. annot_inside (float, optional): Value to be used for the inside of the brain. Defaults to -0.01. annot_near_border (float, optional): Value to be used for the color of the area near the border of the brain. Defaults to 0.2. decrease_dimensionality_factor (int, optional): Useless parameter, kept for ensuring that shelving is done properly, as array_annotation corresponds to a given decrease_dimensionality_factor. Defaults to None. Returns: (np.ndarray): A numpy array representing the borders of the atlas. \"\"\" array_atlas_borders = np . full_like ( array_annotation , annot_outside , dtype = np . float32 ) for x in range ( 1 , array_annotation . shape [ 0 ] - 1 ): for y in range ( 1 , array_annotation . shape [ 1 ] - 1 ): for z in range ( 1 , array_annotation . shape [ 2 ] - 1 ): if array_annotation [ x , y , z ] > 0 : if keep_structure_id is not None : if array_annotation [ x , y , z ] not in keep_structure_id : continue # If we want to plot the brain border with a different shade if differentiate_borders : # check if border in a cube of size 2 found = False for xt in range ( x - 1 , x + 2 ): for yt in range ( y - 1 , y + 2 ): for zt in range ( z - 1 , z + 2 ): # two cases in which there's a border around, depending if # keep_structure_id is defined if keep_structure_id is None : if array_annotation [ xt , yt , zt ] == 0 : found = True else : if array_annotation [ xt , yt , zt ] not in keep_structure_id : found = True if found : array_atlas_borders [ x , y , z ] = annot_border # inside the brain/structure but not a border else : array_atlas_borders [ x , y , z ] = annot_inside else : array_atlas_borders [ x , y , z ] = annot_inside # Also color the region surrounding the border if color_near_borders : for x in range ( 1 , array_annotation . shape [ 0 ] - 1 ): for y in range ( 1 , array_annotation . shape [ 1 ] - 1 ): for z in range ( 1 , array_annotation . shape [ 2 ] - 1 ): if np . abs ( array_atlas_borders [ x , y , z ] - ( - 0.1 )) < 10 **- 4 : for xt in range ( x - 1 , x + 2 ): for yt in range ( y - 1 , y + 2 ): for zt in range ( z - 1 , z + 2 ): # not on the border if np . abs ( array_atlas_borders [ xt , yt , zt ] - ( - 0.1 )) > 10 **- 4 : array_atlas_borders [ xt , yt , zt ] = annot_near_border return array_atlas_borders","title":"fill_array_borders()"},{"location":"modules/tools/volume/#modules.tools.volume.fill_array_interpolation","text":"This function is used to fill the empty space (unassigned voxels) between the slices with interpolated values. Parameters: Name Type Description Default array_annotation np . ndarray Three-dimensional array of annotation coming from the Allen Brain Atlas. required array_slices np . ndarray Three-dimensional array containing the lipid intensity values from the MALDI experiments (with many unassigned voxels). required divider_radius int Divides the radius of the region used for interpolation (the bigger, the lower the number of voxels used). Defaults to 5. 5 annot_inside float Value used to denotate the inside of the brain. Defaults to -0.01. -0.01 limit_value_inside float Alternative to annot_inside. Values above limit_value_inside are considered inside the brain. Defaults to -2. -2 structure_guided bool If True, the interpolation is done using the annotated structures. If False, the interpolation is done blindly. True Returns: Type Description np . ndarray A three-dimensional array containing the interpolated lipid intensity values. Source code in modules/tools/volume.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 @njit def fill_array_interpolation ( array_annotation , array_slices , divider_radius = 5 , annot_inside =- 0.01 , limit_value_inside =- 2 , structure_guided = True , ): \"\"\"This function is used to fill the empty space (unassigned voxels) between the slices with interpolated values. Args: array_annotation (np.ndarray): Three-dimensional array of annotation coming from the Allen Brain Atlas. array_slices (np.ndarray): Three-dimensional array containing the lipid intensity values from the MALDI experiments (with many unassigned voxels). divider_radius (int, optional): Divides the radius of the region used for interpolation (the bigger, the lower the number of voxels used). Defaults to 5. annot_inside (float, optional): Value used to denotate the inside of the brain. Defaults to -0.01. limit_value_inside (float, optional): Alternative to annot_inside. Values above limit_value_inside are considered inside the brain. Defaults to -2. structure_guided (bool, optional): If True, the interpolation is done using the annotated structures. If False, the interpolation is done blindly. Returns: (np.ndarray): A three-dimensional array containing the interpolated lipid intensity values. \"\"\" array_interpolated = np . copy ( array_slices ) # Start from 8 as we don't have data before and the structure disposition makes it look # like a bug with the interpolation for x in range ( 8 , array_annotation . shape [ 0 ]): for y in range ( 0 , array_annotation . shape [ 1 ]): for z in range ( 0 , array_annotation . shape [ 2 ]): # If we are in a unfilled region of the brain or just inside the brain condition_fulfilled = False if array_slices [ x , y , z ] >= 0 : condition_fulfilled = True elif limit_value_inside is not None and not condition_fulfilled : if array_annotation [ x , y , z ] > limit_value_inside : condition_fulfilled = True elif ( np . abs ( array_slices [ x , y , z ] - annot_inside ) < 10 **- 4 ) and not condition_fulfilled : condition_fulfilled = True if condition_fulfilled : # Check all datapoints in the same structure, and do a distance-weighted average value_voxel = 0 sum_weights = 0 size_radius = int ( array_annotation . shape [ 0 ] / divider_radius ) for xt in range ( max ( 0 , x - size_radius ), min ( array_annotation . shape [ 0 ], x + size_radius + 1 ) ): for yt in range ( max ( 0 , y - size_radius ), min ( array_annotation . shape [ 1 ], y + size_radius + 1 ), ): for zt in range ( max ( 0 , z - size_radius ), min ( array_annotation . shape [ 2 ], z + size_radius + 1 ), ): # If we are inside of the shere of radius size_radius if ( np . sqrt (( x - xt ) ** 2 + ( y - yt ) ** 2 + ( z - zt ) ** 2 ) <= size_radius ): # The voxel has data if array_slices [ xt , yt , zt ] >= 0 : # The structure is identical if ( structure_guided and np . abs ( array_annotation [ x , y , z ] - array_annotation [ xt , yt , zt ] ) < 10 **- 4 ) or not structure_guided : d = np . sqrt ( ( x - xt ) ** 2 + ( y - yt ) ** 2 + ( z - zt ) ** 2 ) value_voxel += np . exp ( - d ) * array_slices [ xt , yt , zt ] sum_weights += np . exp ( - d ) if sum_weights == 0 : pass # print(\"No other voxel found for structure \", array_annotation[x, y, z]) else : # print('Voxel found for structure', array_annotation[x, y, z]) value_voxel = value_voxel / sum_weights array_interpolated [ x , y , z ] = value_voxel return array_interpolated","title":"fill_array_interpolation()"},{"location":"modules/tools/volume/#modules.tools.volume.fill_array_slices","text":"This function takes the arrays of expression in the slices and fills the 3D array of expression with them, inside of the regions annotated in the provided array_slices (which is initially a simple copy of array_atlas_borders). Parameters: Name Type Description Default array_x np . ndarray A flat array of x coordinates for the 3D graphing. required array_y np . ndarray A flat array of y coordinates for the 3D graphing. required array_z np . ndarray A flat array of z coordinates for the 3D graphing. required array_c np . ndarray A flat array of expression values (float) for the 3D graphing. required array_slices np . ndarray Initially, a 3D numpy array representing the borders of the atlas. It is then filled with lipid expression values (from array_c) in the slices. required array_for_avg np . ndarray A 3D numpy array used for keeping count of the number of times a cell has been assigned, for averaging the expression values later on. required limit_value_inside float The value above which the array must be filled, i.e. corresponds to an annotated region of the brain. Defaults to -0.05. -0.05 Returns: Type Description np . ndarray A 3D numpy array representing the expression of the lipids preliminarily stored in array_c, in the regions preliminarily annotated in array_slices. Source code in modules/tools/volume.py 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 @njit def fill_array_slices ( array_x , array_y , array_z , array_c , array_slices , array_for_avg , limit_value_inside =- 0.05 , ): \"\"\"This function takes the arrays of expression in the slices and fills the 3D array of expression with them, inside of the regions annotated in the provided array_slices (which is initially a simple copy of array_atlas_borders). Args: array_x (np.ndarray): A flat array of x coordinates for the 3D graphing. array_y (np.ndarray): A flat array of y coordinates for the 3D graphing. array_z (np.ndarray): A flat array of z coordinates for the 3D graphing. array_c (np.ndarray): A flat array of expression values (float) for the 3D graphing. array_slices (np.ndarray): Initially, a 3D numpy array representing the borders of the atlas. It is then filled with lipid expression values (from array_c) in the slices. array_for_avg (np.ndarray): A 3D numpy array used for keeping count of the number of times a cell has been assigned, for averaging the expression values later on. limit_value_inside (float, optional): The value above which the array must be filled, i.e. corresponds to an annotated region of the brain. Defaults to -0.05. Returns: (np.ndarray): A 3D numpy array representing the expression of the lipids preliminarily stored in array_c, in the regions preliminarily annotated in array_slices. \"\"\" for x , y , z , c in zip ( array_x , array_y , array_z , array_c ): # ! Coordinates need to be switched x_scaled = int ( round ( y )) y_scaled = int ( round ( z )) z_scaled = int ( round ( x )) # If inside the brain if array_slices [ x_scaled , y_scaled , z_scaled ] > limit_value_inside : # If inside the brain and not assigned before if array_slices [ x_scaled , y_scaled , z_scaled ] < 0 : array_slices [ x_scaled , y_scaled , z_scaled ] = c / 100 # Inside the brain but already assigned, in which case average else : array_slices [ x_scaled , y_scaled , z_scaled ] += c / 100 array_for_avg [ x_scaled , y_scaled , z_scaled ] += 1 array_slices = array_slices / array_for_avg return array_slices","title":"fill_array_slices()"},{"location":"modules/tools/volume/#modules.tools.volume.filter_voxels","text":"This function takes a given array of coordinates 'coordinates_stripped' and checks if it corresponds to a given annotation in the atlas. If so, the coordinates are added to the arrays 'array_x', 'array_y', 'array_z' to be used for the 3D graphing. Else, it's filtered out. Parameters: Name Type Description Default array_data_stripped np . ndarray A 2-dimensional array of voxel intensity for the current slice, stripped of zero values. required coordinates_stripped np . ndarray A 2-dimensional array of voxel coordinates for the current slice, stripped of zero values. required array_annotations np . ndarray The 3-dimensional array of annotation coming from the Allen Brain Atlas. required percentile float The value above which the voxels are considered for the graphing. required array_x np . ndarray A flat array of x coordinates for the 3D graphing. required array_y np . ndarray A flat array of y coordinates for the 3D graphing. required array_z np . ndarray A flat array of z coordinates for the 3D graphing. required array_c np . ndarray A flat array of color (expression) values (float) for the 3D graphing. required total_index int An integer used to keep track of the array indexing outside of this function. required reference_shape np . ndarray Array containing the reference atlas shape. required resolution int Integer representing the resolution of the atlas. required Returns: Type Description np . ndarray , np . ndarray , np . ndarray , np . ndarray , int The filled arrays of coordinates or color for the current slice, and the updated total_index. Source code in modules/tools/volume.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 @njit def filter_voxels ( array_data_stripped , coordinates_stripped , array_annotations , percentile , array_x , array_y , array_z , array_c , total_index , reference_shape , resolution , ): \"\"\"This function takes a given array of coordinates 'coordinates_stripped' and checks if it corresponds to a given annotation in the atlas. If so, the coordinates are added to the arrays 'array_x', 'array_y', 'array_z' to be used for the 3D graphing. Else, it's filtered out. Args: array_data_stripped (np.ndarray): A 2-dimensional array of voxel intensity for the current slice, stripped of zero values. coordinates_stripped (np.ndarray): A 2-dimensional array of voxel coordinates for the current slice, stripped of zero values. array_annotations (np.ndarray): The 3-dimensional array of annotation coming from the Allen Brain Atlas. percentile (float): The value above which the voxels are considered for the graphing. array_x (np.ndarray): A flat array of x coordinates for the 3D graphing. array_y (np.ndarray): A flat array of y coordinates for the 3D graphing. array_z (np.ndarray): A flat array of z coordinates for the 3D graphing. array_c (np.ndarray): A flat array of color (expression) values (float) for the 3D graphing. total_index (int): An integer used to keep track of the array indexing outside of this function. reference_shape (np.ndarray): Array containing the reference atlas shape. resolution (int): Integer representing the resolution of the atlas. Returns: (np.ndarray, np.ndarray, np.ndarray, np.ndarray, int): The filled arrays of coordinates or color for the current slice, and the updated total_index. \"\"\" # Keep track of the array indexing even outside of this function total_index_temp = 0 for i in range ( array_data_stripped . shape [ 0 ]): x_atlas , y_atlas , z_atlas = coordinates_stripped [ i ] / 1000 # Filter out voxels that are not in the atlas x_temp = int ( round ( x_atlas * 1000000 / resolution )) y_temp = int ( round ( y_atlas * 1000000 / resolution )) z_temp = int ( round ( z_atlas * 1000000 / resolution )) # Voxels not even in the atlas array if x_temp < 0 or x_temp >= reference_shape [ 0 ]: continue if y_temp < 0 or y_temp >= reference_shape [ 1 ]: continue if z_temp < 0 or z_temp >= reference_shape [ 2 ]: continue # Voxels in the atlas but which don't correspond to a structure if array_annotations [ x_temp , y_temp , z_temp ] == 0 : continue if array_data_stripped [ i ] >= percentile : # * careful, x,y,z are switched array_x [ total_index + total_index_temp ] = z_atlas array_y [ total_index + total_index_temp ] = x_atlas array_z [ total_index + total_index_temp ] = y_atlas array_c [ total_index + total_index_temp ] = array_data_stripped [ i ] total_index_temp += 1 total_index += total_index_temp return array_x , array_y , array_z , array_c , total_index","title":"filter_voxels()"},{"location":"pages/home/","text":"This file contains the home page of the app. display_rotating_brain ( x ) This callback loads some javascript code to display the rotating brain. Source code in pages/home.py 157 158 159 160 161 162 @app . long_callback ( output = Output ( \"javascript\" , \"run\" ), inputs = [ Input ( \"main-slider\" , \"data\" )]) def display_rotating_brain ( x ): \"\"\"This callback loads some javascript code to display the rotating brain.\"\"\" with open ( \"js/rotating-brain.js\" ) as f : js = f . read () return js toggle_collapse ( n , is_open ) This callback will trigger the drawer displaying the app documentation. Source code in pages/home.py 145 146 147 148 149 150 151 152 153 154 @app . callback ( Output ( \"documentation-offcanvas-home\" , \"opened\" ), [ Input ( \"page-0-collapse-doc-button\" , \"n_clicks\" )], [ State ( \"documentation-offcanvas-home\" , \"opened\" )], ) def toggle_collapse ( n , is_open ): \"\"\"This callback will trigger the drawer displaying the app documentation.\"\"\" if n : return not is_open return is_open","title":"home"},{"location":"pages/home/#pages.home.display_rotating_brain","text":"This callback loads some javascript code to display the rotating brain. Source code in pages/home.py 157 158 159 160 161 162 @app . long_callback ( output = Output ( \"javascript\" , \"run\" ), inputs = [ Input ( \"main-slider\" , \"data\" )]) def display_rotating_brain ( x ): \"\"\"This callback loads some javascript code to display the rotating brain.\"\"\" with open ( \"js/rotating-brain.js\" ) as f : js = f . read () return js","title":"display_rotating_brain()"},{"location":"pages/home/#pages.home.toggle_collapse","text":"This callback will trigger the drawer displaying the app documentation. Source code in pages/home.py 145 146 147 148 149 150 151 152 153 154 @app . callback ( Output ( \"documentation-offcanvas-home\" , \"opened\" ), [ Input ( \"page-0-collapse-doc-button\" , \"n_clicks\" )], [ State ( \"documentation-offcanvas-home\" , \"opened\" )], ) def toggle_collapse ( n , is_open ): \"\"\"This callback will trigger the drawer displaying the app documentation.\"\"\" if n : return not is_open return is_open","title":"toggle_collapse()"},{"location":"pages/lipid_selection/","text":"This file contains the page used to select and visualize lipids according to pre-existing annotations, or directly using m/z ranges. page_2_active_download ( lipid_1_index , lipid_2_index , lipid_3_index ) This callback is used to toggle on/off the display rgb and colormap buttons. Source code in pages/lipid_selection.py 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 @app . callback ( Output ( \"page-2-rgb-button\" , \"disabled\" ), Output ( \"page-2-colormap-button\" , \"disabled\" ), Input ( \"page-2-selected-lipid-1\" , \"data\" ), Input ( \"page-2-selected-lipid-2\" , \"data\" ), Input ( \"page-2-selected-lipid-3\" , \"data\" ), ) def page_2_active_download ( lipid_1_index , lipid_2_index , lipid_3_index ): \"\"\"This callback is used to toggle on/off the display rgb and colormap buttons.\"\"\" # Get the current lipid selection l_lipids_indexes = [ x for x in [ lipid_1_index , lipid_2_index , lipid_3_index ] if x is not None and x != - 1 ] # If lipids has been selected from the dropdown, activate button if len ( l_lipids_indexes ) > 0 : return False , False else : return True , True page_2_add_toast_selection ( l_lipid_names , class_name_badge_1 , class_name_badge_2 , class_name_badge_3 , slice_index , lipid_1_index , lipid_2_index , lipid_3_index , header_1 , header_2 , header_3 ) This callback adds the selected lipid to the selection. Source code in pages/lipid_selection.py 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 @app . callback ( Output ( \"page-2-badge-lipid-1\" , \"children\" ), Output ( \"page-2-badge-lipid-2\" , \"children\" ), Output ( \"page-2-badge-lipid-3\" , \"children\" ), Output ( \"page-2-selected-lipid-1\" , \"data\" ), Output ( \"page-2-selected-lipid-2\" , \"data\" ), Output ( \"page-2-selected-lipid-3\" , \"data\" ), Output ( \"page-2-badge-lipid-1\" , \"class_name\" ), Output ( \"page-2-badge-lipid-2\" , \"class_name\" ), Output ( \"page-2-badge-lipid-3\" , \"class_name\" ), Input ( \"page-2-dropdown-lipids\" , \"value\" ), Input ( \"page-2-badge-lipid-1\" , \"class_name\" ), Input ( \"page-2-badge-lipid-2\" , \"class_name\" ), Input ( \"page-2-badge-lipid-3\" , \"class_name\" ), Input ( \"main-slider\" , \"data\" ), State ( \"page-2-selected-lipid-1\" , \"data\" ), State ( \"page-2-selected-lipid-2\" , \"data\" ), State ( \"page-2-selected-lipid-3\" , \"data\" ), State ( \"page-2-badge-lipid-1\" , \"children\" ), State ( \"page-2-badge-lipid-2\" , \"children\" ), State ( \"page-2-badge-lipid-3\" , \"children\" ), ) def page_2_add_toast_selection ( l_lipid_names , class_name_badge_1 , class_name_badge_2 , class_name_badge_3 , slice_index , lipid_1_index , lipid_2_index , lipid_3_index , header_1 , header_2 , header_3 , ): \"\"\"This callback adds the selected lipid to the selection.\"\"\" logging . info ( \"Entering function to update lipid data\" ) # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # if page-2-dropdown-lipids is called while there's no lipid name defined, it means the page # just got loaded if len ( id_input ) == 0 or ( id_input == \"page-2-dropdown-lipids\" and l_lipid_names is None ): return \"\" , \"\" , \"\" , - 1 , - 1 , - 1 , \"d-none\" , \"d-none\" , \"d-none\" # , None # If one or several lipids have been deleted if l_lipid_names is not None : if len ( l_lipid_names ) < len ( [ x for x in [ lipid_1_index , lipid_2_index , lipid_3_index ] if x != - 1 ] ): logging . info ( \"One or several lipids have been deleter. Cleaning lipid badges now.\" ) for idx_header , header in enumerate ([ header_1 , header_2 , header_3 ]): found = False for lipid_name in l_lipid_names : if lipid_name == header : found = True if not found : if idx_header == 0 : header_1 = \"\" lipid_1_index = - 1 class_name_badge_1 = \"d-none\" if idx_header == 1 : header_2 = \"\" lipid_2_index = - 1 class_name_badge_2 = \"d-none\" if idx_header == 2 : header_3 = \"\" lipid_3_index = - 1 class_name_badge_3 = \"d-none\" return ( header_1 , header_2 , header_3 , lipid_1_index , lipid_2_index , lipid_3_index , class_name_badge_1 , class_name_badge_2 , class_name_badge_3 , ) # Otherwise, update selection or add lipid if ( id_input == \"page-2-dropdown-lipids\" and l_lipid_names is not None ) or id_input == \"main-slider\" : # If a new slice has been selected if id_input == \"main-slider\" : # for each lipid, get lipid name, structure and cation for header in [ header_1 , header_2 , header_3 ]: if len ( header ) > 2 : name , structure , cation = header . split ( \" \" ) # Find lipid location l_lipid_loc_temp = ( data . get_annotations () . index [ ( data . get_annotations ()[ \"name\" ] == name ) & ( data . get_annotations ()[ \"structure\" ] == structure ) & ( data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) l_lipid_loc = [ l_lipid_loc_temp [ i ] for i , x in enumerate ( data . get_annotations () . iloc [ l_lipid_loc_temp ][ \"slice\" ] == slice_index ) if x ] # Fill list with first annotation that exists if it can't find one for the # current slice if len ( l_lipid_loc ) == 0 : l_lipid_loc = l_lipid_loc_temp [: 1 ] # Record location and lipid name lipid_index = l_lipid_loc [ 0 ] # If lipid has already been selected before, replace the index if header_1 == header : lipid_1_index = lipid_index elif header_2 == header : lipid_2_index = lipid_index elif header_3 == header : lipid_3_index = lipid_index logging . info ( \"Returning updated lipid data\" ) return ( header_1 , header_2 , header_3 , lipid_1_index , lipid_2_index , lipid_3_index , class_name_badge_1 , class_name_badge_2 , class_name_badge_3 , ) # If lipids have been added from dropdown menu elif id_input == \"page-2-dropdown-lipids\" : # Get the lipid name and structure name , structure , cation = l_lipid_names [ - 1 ] . split ( \" \" ) # Find lipid location l_lipid_loc = ( data . get_annotations () . index [ ( data . get_annotations ()[ \"name\" ] == name ) & ( data . get_annotations ()[ \"structure\" ] == structure ) & ( data . get_annotations ()[ \"slice\" ] == slice_index ) & ( data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) > 1 : logging . warning ( \"More than one lipid corresponds to the selection\" ) l_lipid_loc = [ l_lipid_loc [ - 1 ]] if len ( l_lipid_loc ) < 1 : logging . warning ( \"No lipid annotation exist. Taking another slice annotation\" ) l_lipid_loc = ( data . get_annotations () . index [ ( data . get_annotations ()[ \"name\" ] == name ) & ( data . get_annotations ()[ \"structure\" ] == structure ) & ( data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () )[: 1 ] # return dash.no_update # Record location and lipid name lipid_index = l_lipid_loc [ 0 ] lipid_string = name + \" \" + structure + \" \" + cation change_made = False # If lipid has already been selected before, replace the index if header_1 == lipid_string : lipid_1_index = lipid_index change_made = True elif header_2 == lipid_string : lipid_2_index = lipid_index change_made = True elif header_3 == lipid_string : lipid_3_index = lipid_index change_made = True # If it's a new lipid selection, fill the first available header if lipid_string not in [ header_1 , header_2 , header_2 ]: # Check first slot available if class_name_badge_1 == \"d-none\" : header_1 = lipid_string lipid_1_index = lipid_index class_name_badge_1 = \"position-absolute\" elif class_name_badge_2 == \"d-none\" : header_2 = lipid_string lipid_2_index = lipid_index class_name_badge_2 = \"position-absolute\" elif class_name_badge_3 == \"d-none\" : header_3 = lipid_string lipid_3_index = lipid_index class_name_badge_3 = \"position-absolute\" else : logging . warning ( \"More than 3 lipids have been selected\" ) return dash . no_update change_made = True if change_made : logging . info ( \"Changes have been made to the lipid selection or indexation,\" + \" propagating callback.\" ) return ( header_1 , header_2 , header_3 , lipid_1_index , lipid_2_index , lipid_3_index , class_name_badge_1 , class_name_badge_2 , class_name_badge_3 , # None, ) else : return dash . no_update return dash . no_update page_2_button_window ( lb , hb ) This callaback is used to toggle on/off the display heatmap from bounds button. Source code in pages/lipid_selection.py 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 @app . callback ( Output ( \"page-2-button-bounds\" , \"disabled\" ), Input ( \"page-2-lower-bound\" , \"value\" ), Input ( \"page-2-upper-bound\" , \"value\" ), ) def page_2_button_window ( lb , hb ): \"\"\"This callaback is used to toggle on/off the display heatmap from bounds button.\"\"\" # Check that the user has inputted something if lb is not None and hb is not None : lb , hb = float ( lb ), float ( hb ) if lb >= 400 and hb <= 1600 and hb - lb > 0 and hb - lb < 10 : return False return True page_2_display_alert ( figure ) This callback is used to turn visible the alert regarding the high-res m/z plot. Source code in pages/lipid_selection.py 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 @app . callback ( Output ( \"page-2-alert\" , \"style\" ), Input ( \"page-2-graph-high-resolution-spectrum\" , \"figure\" ), ) def page_2_display_alert ( figure ): \"\"\"This callback is used to turn visible the alert regarding the high-res m/z plot.\"\"\" if figure is not None : if figure [ \"data\" ][ 0 ][ \"x\" ] != [[]]: return { \"display\" : \"none\" } return {} page_2_display_high_res_mz_plot ( figure ) This callback is used to turn visible the high-resolution m/z plot. Source code in pages/lipid_selection.py 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 @app . callback ( Output ( \"page-2-graph-high-resolution-spectrum\" , \"style\" ), Input ( \"page-2-graph-high-resolution-spectrum\" , \"figure\" ), ) def page_2_display_high_res_mz_plot ( figure ): \"\"\"This callback is used to turn visible the high-resolution m/z plot.\"\"\" if figure is not None : if figure [ \"data\" ][ 0 ][ \"x\" ] != [[]]: return { \"height\" : 280 } return { \"display\" : \"none\" } page_2_download ( n_clicks , lipid_1_index , lipid_2_index , lipid_3_index , slice_index , apply_transform , graph_input , bound_high_res , lb , hb ) This callback is used to generate and download the data in proper format. Source code in pages/lipid_selection.py 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 @app . callback ( Output ( \"page-2-download-data\" , \"data\" ), Input ( \"page-2-download-data-button\" , \"n_clicks\" ), State ( \"page-2-selected-lipid-1\" , \"data\" ), State ( \"page-2-selected-lipid-2\" , \"data\" ), State ( \"page-2-selected-lipid-3\" , \"data\" ), State ( \"main-slider\" , \"data\" ), State ( \"page-2-toggle-apply-transform\" , \"checked\" ), State ( \"page-2-badge-input\" , \"children\" ), State ( \"boundaries-low-resolution-mz-plot\" , \"data\" ), State ( \"page-2-lower-bound\" , \"value\" ), State ( \"page-2-upper-bound\" , \"value\" ), prevent_initial_call = True , ) def page_2_download ( n_clicks , lipid_1_index , lipid_2_index , lipid_3_index , slice_index , apply_transform , graph_input , bound_high_res , lb , hb , ): \"\"\"This callback is used to generate and download the data in proper format.\"\"\" # Current input is lipid selection if ( graph_input == \"Current input: \" + \"Lipid selection colormap\" or graph_input == \"Current input: \" + \"Lipid selection RGB\" ): l_lipids_indexes = [ x for x in [ lipid_1_index , lipid_2_index , lipid_3_index ] if x is not None and x != - 1 ] # If lipids has been selected from the dropdown, filter them in the df and download them if len ( l_lipids_indexes ) > 0 : def to_excel ( bytes_io ): xlsx_writer = pd . ExcelWriter ( bytes_io , engine = \"xlsxwriter\" ) data . get_annotations () . iloc [ l_lipids_indexes ] . to_excel ( xlsx_writer , index = False , sheet_name = \"Selected lipids\" ) for i , index in enumerate ( l_lipids_indexes ): name = ( data . get_annotations () . iloc [ index ][ \"name\" ] + \"_\" + data . get_annotations () . iloc [ index ][ \"structure\" ] + \"_\" + data . get_annotations () . iloc [ index ][ \"cation\" ] ) # Need to clean name to use it as a sheet name name = name . replace ( \":\" , \"\" ) . replace ( \"/\" , \"\" ) lb = float ( data . get_annotations () . iloc [ index ][ \"min\" ]) - 10 **- 2 hb = float ( data . get_annotations () . iloc [ index ][ \"max\" ]) + 10 **- 2 x , y = figures . compute_spectrum_high_res ( slice_index , lb , hb , plot = False , standardization = apply_transform , cache_flask = cache_flask , ) df = pd . DataFrame . from_dict ({ \"m/z\" : x , \"Intensity\" : y }) df . to_excel ( xlsx_writer , index = False , sheet_name = name [: 31 ]) xlsx_writer . save () return dcc . send_data_frame ( to_excel , \"my_lipid_selection.xlsx\" ) # Current input is manual boundaries selection from input box if graph_input == \"Current input: \" + \"m/z boundaries\" : lb , hb = float ( lb ), float ( hb ) if lb >= 400 and hb <= 1600 and hb - lb > 0 and hb - lb < 10 : def to_excel ( bytes_io ): # Get spectral data mz , intensity = figures . compute_spectrum_high_res ( slice_index , lb - 10 **- 2 , hb + 10 **- 2 , force_xlim = True , standardization = apply_transform , cache_flask = cache_flask , plot = False , ) # Turn to dataframe dataset = pd . DataFrame . from_dict ({ \"m/z\" : mz , \"Intensity\" : intensity }) # Export to excel xlsx_writer = pd . ExcelWriter ( bytes_io , engine = \"xlsxwriter\" ) dataset . to_excel ( xlsx_writer , index = False , sheet_name = \"mz selection\" ) xlsx_writer . save () return dcc . send_data_frame ( to_excel , \"my_boundaries_selection.xlsx\" ) # Current input is boundaries from the low-res m/z plot elif graph_input == \"Current input: \" + \"Selection from high-res m/z graph\" : if bound_high_res is not None : # Case the zoom is high enough if bound_high_res [ 1 ] - bound_high_res [ 0 ] <= 3 : def to_excel ( bytes_io ): # Get spectral data bound_high_res = json . loads ( bound_high_res ) mz , intensity = figures . compute_spectrum_high_res ( slice_index , bound_high_res [ 0 ], bound_high_res [ 1 ], standardization = apply_transform , cache_flask = cache_flask , plot = False , ) # Turn to dataframe dataset = pd . DataFrame . from_dict ({ \"m/z\" : mz , \"Intensity\" : intensity }) # Export to excel xlsx_writer = pd . ExcelWriter ( bytes_io , engine = \"xlsxwriter\" ) dataset . to_excel ( xlsx_writer , index = False , sheet_name = \"mz selection\" ) xlsx_writer . save () return dcc . send_data_frame ( to_excel , \"my_boundaries_selection.xlsx\" ) return dash . no_update page_2_plot_graph_heatmap_mz_selection ( slice_index , bound_high_res , bound_low_res , lipid_1_index , lipid_2_index , lipid_3_index , n_clicks_button_rgb , n_clicks_button_colormap , n_clicks_button_bounds , lb , hb , graph_input , apply_transform ) This callback plots the heatmap of the selected lipid(s) or m/z range. Source code in pages/lipid_selection.py 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 @app . callback ( Output ( \"page-2-graph-heatmap-mz-selection\" , \"figure\" ), Output ( \"page-2-badge-input\" , \"children\" ), Input ( \"main-slider\" , \"data\" ), Input ( \"boundaries-high-resolution-mz-plot\" , \"data\" ), Input ( \"boundaries-low-resolution-mz-plot\" , \"data\" ), Input ( \"page-2-selected-lipid-1\" , \"data\" ), Input ( \"page-2-selected-lipid-2\" , \"data\" ), Input ( \"page-2-selected-lipid-3\" , \"data\" ), Input ( \"page-2-rgb-button\" , \"n_clicks\" ), Input ( \"page-2-colormap-button\" , \"n_clicks\" ), Input ( \"page-2-button-bounds\" , \"n_clicks\" ), State ( \"page-2-lower-bound\" , \"value\" ), State ( \"page-2-upper-bound\" , \"value\" ), State ( \"page-2-badge-input\" , \"children\" ), Input ( \"page-2-toggle-apply-transform\" , \"checked\" ), ) def page_2_plot_graph_heatmap_mz_selection ( slice_index , bound_high_res , bound_low_res , lipid_1_index , lipid_2_index , lipid_3_index , n_clicks_button_rgb , n_clicks_button_colormap , n_clicks_button_bounds , lb , hb , graph_input , apply_transform , ): \"\"\"This callback plots the heatmap of the selected lipid(s) or m/z range.\"\"\" logging . info ( \"Entering function to plot heatmap or RGB depending on lipid selection\" ) # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # Case a two mz bounds values have been inputed if id_input == \"page-2-button-bounds\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"m/z boundaries\" ): if lb is not None and hb is not None : lb , hb = float ( lb ), float ( hb ) if lb >= 400 and hb <= 1600 and hb - lb > 0 and hb - lb < 10 : return ( figures . compute_heatmap_per_mz ( slice_index , lb , hb , cache_flask = cache_flask ), \"Current input: \" + \"m/z boundaries\" , ) return dash . no_update # If a lipid selection has been done if ( id_input == \"page-2-selected-lipid-1\" or id_input == \"page-2-selected-lipid-2\" or id_input == \"page-2-selected-lipid-3\" or id_input == \"page-2-rgb-button\" or id_input == \"page-2-colormap-button\" or ( ( id_input == \"main-slider\" or id_input == \"page-2-toggle-apply-transform\" ) and ( graph_input == \"Current input: \" + \"Lipid selection colormap\" or graph_input == \"Current input: \" + \"Lipid selection RGB\" ) ) ): if lipid_1_index >= 0 or lipid_2_index >= 0 or lipid_3_index >= 0 : # Build the list of mz boundaries for each peak ll_lipid_bounds = [ [ ( float ( data . get_annotations () . iloc [ index ][ \"min\" ]), float ( data . get_annotations () . iloc [ index ][ \"max\" ]), ) ] if index != - 1 else None for index in [ lipid_1_index , lipid_2_index , lipid_3_index ] ] ll_lipid_names = [ [ data . get_annotations () . iloc [ index ][ \"name\" ] + \"_\" + data . get_annotations () . iloc [ index ][ \"structure\" ] + \"_\" + data . get_annotations () . iloc [ index ][ \"cation\" ] ] if index != - 1 else None for index in [ lipid_1_index , lipid_2_index , lipid_3_index ] ] # Check that annotations do not intercept with each other l_lipid_bounds_clean = [ x for l_lipid_bounds in ll_lipid_bounds if l_lipid_bounds is not None for x in l_lipid_bounds ] if len ( l_lipid_bounds_clean ) >= 2 : l_t_bounds_sorted = sorted ( l_lipid_bounds_clean ) for t_bounds_1 , t_bounds_2 in zip ( l_t_bounds_sorted [: - 1 ], l_t_bounds_sorted [ 1 :]): if t_bounds_1 [ 1 ] > t_bounds_2 [ 0 ]: logging . warning ( \"Some pixel annotations intercept each other\" ) # Check if the current plot must be a heatmap if ( id_input == \"page-2-colormap-button\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"Lipid selection colormap\" ) or ( id_input == \"page-2-toggle-apply-transform\" and graph_input == \"Current input: \" + \"Lipid selection colormap\" ) ): return ( figures . compute_heatmap_per_lipid_selection ( slice_index , ll_lipid_bounds , apply_transform = apply_transform , ll_lipid_names = ll_lipid_names , cache_flask = cache_flask , ), \"Current input: \" + \"Lipid selection colormap\" , ) # Or if the current plot must be an RGB image elif ( id_input == \"page-2-rgb-button\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"Lipid selection RGB\" ) or ( id_input == \"page-2-toggle-apply-transform\" and graph_input == \"Current input: \" + \"Lipid selection RGB\" ) ): return ( figures . compute_rgb_image_per_lipid_selection ( slice_index , ll_lipid_bounds , apply_transform = apply_transform , ll_lipid_names = ll_lipid_names , cache_flask = cache_flask , ), \"Current input: \" + \"Lipid selection RGB\" , ) # Plot RBG By default else : logging . info ( \"Right before calling the graphing function\" ) return ( figures . compute_rgb_image_per_lipid_selection ( slice_index , ll_lipid_bounds , apply_transform = apply_transform , ll_lipid_names = ll_lipid_names , cache_flask = cache_flask , ), \"Current input: \" + \"Lipid selection RGB\" , ) else : # No lipid has been selected, return image from boundaries if lb is not None and hb is not None : return ( figures . compute_heatmap_per_mz ( slice_index , lb , hb , cache_flask = cache_flask ), \"Current input: \" + \"m/z boundaries\" , ) else : return ( figures . compute_heatmap_per_mz ( slice_index , 500 , 500 , cache_flask = cache_flask ), \"Current input: \" + \"m/z boundaries\" , ) # Case trigger is range slider from high resolution spectrum if id_input == \"boundaries-high-resolution-mz-plot\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"Selection from high-res m/z graph\" ): if bound_high_res is not None : bound_high_res = json . loads ( bound_high_res ) return ( figures . compute_heatmap_per_mz ( slice_index , bound_high_res [ 0 ], bound_high_res [ 1 ], cache_flask = cache_flask , ), \"Current input: \" + \"Selection from high-res m/z graph\" , ) # Case trigger is range slider from low resolution spectrum if id_input == \"boundaries-low-resolution-mz-plot\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"Selection from low-res m/z graph\" ): if bound_low_res is not None : bound_low_res = json . loads ( bound_low_res ) return ( figures . compute_heatmap_per_mz ( slice_index , bound_low_res [ 0 ], bound_low_res [ 1 ], cache_flask = cache_flask , ), \"Current input: \" + \"Selection from low-res m/z graph\" , ) # If no trigger, the page has just been loaded, so load new figure with default parameters else : return dash . no_update page_2_plot_graph_high_res_spectrum ( slice_index , bound_high_res , lipid_1_index , lipid_2_index , lipid_3_index , n_clicks_rgb , n_clicks_colormap , n_clicks_button_bounds , lb , hb , graph_input , apply_transform ) This callback generates the graph of the high resolution spectrum when the current input has a small enough m/z range. Source code in pages/lipid_selection.py 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 @app . callback ( Output ( \"page-2-graph-high-resolution-spectrum\" , \"figure\" ), Input ( \"main-slider\" , \"data\" ), Input ( \"boundaries-low-resolution-mz-plot\" , \"data\" ), Input ( \"page-2-selected-lipid-1\" , \"data\" ), Input ( \"page-2-selected-lipid-2\" , \"data\" ), Input ( \"page-2-selected-lipid-3\" , \"data\" ), Input ( \"page-2-rgb-button\" , \"n_clicks\" ), Input ( \"page-2-colormap-button\" , \"n_clicks\" ), Input ( \"page-2-button-bounds\" , \"n_clicks\" ), State ( \"page-2-lower-bound\" , \"value\" ), State ( \"page-2-upper-bound\" , \"value\" ), State ( \"page-2-badge-input\" , \"children\" ), Input ( \"page-2-toggle-apply-transform\" , \"checked\" ), ) def page_2_plot_graph_high_res_spectrum ( slice_index , bound_high_res , lipid_1_index , lipid_2_index , lipid_3_index , n_clicks_rgb , n_clicks_colormap , n_clicks_button_bounds , lb , hb , graph_input , apply_transform , ): \"\"\"This callback generates the graph of the high resolution spectrum when the current input has a small enough m/z range.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If a lipid selection has been done if ( id_input == \"page-2-selected-lipid-1\" or id_input == \"page-2-selected-lipid-2\" or id_input == \"page-2-selected-lipid-3\" or id_input == \"page-2-rgb-button\" or id_input == \"page-2-colormap-button\" or id_input == \"page-2-last-selected-lipids\" or ( id_input == \"main-slider\" and ( graph_input == \"Current input: \" + \"Lipid selection colormap\" or graph_input == \"Current input: \" + \"Lipid selection RGB\" ) ) ): # If at least one lipid index has been recorded if lipid_1_index >= 0 or lipid_2_index >= 0 or lipid_3_index >= 0 : # Build the list of mz boundaries for each peak l_indexes = [ lipid_1_index , lipid_2_index , lipid_3_index ] l_lipid_bounds = [ ( float ( data . get_annotations () . iloc [ index ][ \"min\" ]), float ( data . get_annotations () . iloc [ index ][ \"max\" ]), ) if index != - 1 else None for index in l_indexes ] if lipid_3_index >= 0 : current_lipid_index = 2 elif lipid_2_index >= 0 : current_lipid_index = 1 else : current_lipid_index = 0 return figures . compute_spectrum_high_res ( slice_index , l_lipid_bounds [ current_lipid_index ][ 0 ] - 10 **- 2 , l_lipid_bounds [ current_lipid_index ][ 1 ] + 10 **- 2 , annotations = l_lipid_bounds , force_xlim = True , standardization = apply_transform , cache_flask = cache_flask , ) # If the user has selected a new m/z range elif id_input == \"page-2-button-bounds\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"m/z boundaries\" ): lb , hb = float ( lb ), float ( hb ) if lb >= 400 and hb <= 1600 and hb - lb > 0 and hb - lb < 10 : # l_lipid_bounds = [(lb, hb), None, None] return figures . compute_spectrum_high_res ( slice_index , lb - 10 **- 2 , hb + 10 **- 2 , force_xlim = True , # annotations=l_lipid_bounds, standardization = apply_transform , cache_flask = cache_flask , ) # If the figure is created at app launch or after load button is cliked, or with an empty lipid # selection, don't plot anything elif \"page-2-selected-lipid\" in id_input : return dash . no_update # Otherwise, if new boundaries have been selected on the low-resolution spectrum elif id_input == \"boundaries-low-resolution-mz-plot\" and bound_high_res is not None : bound_high_res = json . loads ( bound_high_res ) # Case the zoom is high enough if bound_high_res [ 1 ] - bound_high_res [ 0 ] <= 3 : return figures . compute_spectrum_high_res ( slice_index , bound_high_res [ 0 ], bound_high_res [ 1 ], standardization = apply_transform , cache_flask = cache_flask , ) # Otherwise just return default (empty) graph else : return dash . no_update # The page has just been loaded, no spectrum is displayed return dash . no_update page_2_plot_graph_low_res_spectrum ( slice_index , lipid_1_index , lipid_2_index , lipid_3_index , n_clicks_rgb , n_clicks_colormap , n_clicks_button_bounds , lb , hb , graph_input , relayoutData ) This callbacks generates the graph of the low resolution spectrum when the current input gets updated. Source code in pages/lipid_selection.py 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 @app . callback ( Output ( \"page-2-graph-low-resolution-spectrum\" , \"figure\" ), Input ( \"main-slider\" , \"data\" ), State ( \"page-2-selected-lipid-1\" , \"data\" ), State ( \"page-2-selected-lipid-2\" , \"data\" ), State ( \"page-2-selected-lipid-3\" , \"data\" ), Input ( \"page-2-rgb-button\" , \"n_clicks\" ), Input ( \"page-2-colormap-button\" , \"n_clicks\" ), Input ( \"page-2-button-bounds\" , \"n_clicks\" ), State ( \"page-2-lower-bound\" , \"value\" ), State ( \"page-2-upper-bound\" , \"value\" ), State ( \"page-2-badge-input\" , \"children\" ), State ( \"page-2-graph-low-resolution-spectrum\" , \"relayoutData\" ), ) def page_2_plot_graph_low_res_spectrum ( slice_index , lipid_1_index , lipid_2_index , lipid_3_index , n_clicks_rgb , n_clicks_colormap , n_clicks_button_bounds , lb , hb , graph_input , relayoutData , ): \"\"\"This callbacks generates the graph of the low resolution spectrum when the current input gets updated.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If a lipid selection has been done if ( id_input == \"page-2-selected-lipid-1\" or id_input == \"page-2-selected-lipid-2\" or id_input == \"page-2-selected-lipid-3\" or id_input == \"page-2-rgb-button\" or id_input == \"page-2-colormap-button\" or ( id_input == \"main-slider\" and ( graph_input == \"Current input: \" + \"Lipid selection colormap\" or graph_input == \"Current input: \" + \"Lipid selection RGB\" ) ) ): if lipid_1_index >= 0 or lipid_2_index >= 0 or lipid_3_index >= 0 : # build the list of mz boundaries for each peak l_lipid_bounds = [ ( float ( data . get_annotations () . iloc [ index ][ \"min\" ]), float ( data . get_annotations () . iloc [ index ][ \"max\" ]), ) if index != - 1 else None for index in [ lipid_1_index , lipid_2_index , lipid_3_index ] ] return figures . compute_spectrum_low_res ( slice_index , l_lipid_bounds ) else : # Probably the page has just been loaded, so load new figure with default parameters return dash . no_update # Or if the plot has been updated from range or slider elif id_input == \"page-2-button-bounds\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"m/z boundaries\" ): lb , hb = float ( lb ), float ( hb ) if lb >= 400 and hb <= 1600 and hb - lb > 0 and hb - lb < 10 : l_lipid_bounds = [( lb , hb ), None , None ] return figures . compute_spectrum_low_res ( slice_index , l_lipid_bounds ) elif ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"Selection from low-res m/z graph\" ): # TODO : find a way to set relayoutdata properly pass return dash . no_update page_2_store_boundaries_mz_from_graph_high_res_spectrum ( relayoutData , bound_low_res ) This callback records the m/z boundaries of the high resolution spectrum in a dcc store. Source code in pages/lipid_selection.py 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 @app . callback ( Output ( \"boundaries-high-resolution-mz-plot\" , \"data\" ), Input ( \"page-2-graph-high-resolution-spectrum\" , \"relayoutData\" ), Input ( \"boundaries-low-resolution-mz-plot\" , \"data\" ), ) def page_2_store_boundaries_mz_from_graph_high_res_spectrum ( relayoutData , bound_low_res ): \"\"\"This callback records the m/z boundaries of the high resolution spectrum in a dcc store.\"\"\" # Primarily update high-res boundaries with high-res range slider if relayoutData is not None : if \"xaxis.range[0]\" in relayoutData : return json . dumps ([ relayoutData [ \"xaxis.range[0]\" ], relayoutData [ \"xaxis.range[1]\" ]]) elif \"xaxis.range\" in relayoutData : return json . dumps ( relayoutData [ \"xaxis.range\" ]) # If the range is re-initialized, need to explicitely pass the low-res value of the slider elif \"xaxis.autorange\" in relayoutData : if bound_low_res is not None : bound_low_res = json . loads ( bound_low_res ) if bound_low_res [ 1 ] - bound_low_res [ 0 ] <= 3 : return json . dumps ( bound_low_res ) # But also needs to be updated when low-res slider is changed and is zoomed enough elif bound_low_res is not None : bound_low_res = json . loads ( bound_low_res ) if bound_low_res [ 1 ] - bound_low_res [ 0 ] <= 3 : return json . dumps ( bound_low_res ) # Page has just been loaded, do nothing else : return dash . no_update page_2_store_boundaries_mz_from_graph_low_res_spectrum ( relayoutData , slice_index ) This callback stores in a dcc store the m/z boundaries of the low resolution spectrum when they are updated. Source code in pages/lipid_selection.py 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 @app . callback ( Output ( \"boundaries-low-resolution-mz-plot\" , \"data\" ), Input ( \"page-2-graph-low-resolution-spectrum\" , \"relayoutData\" ), State ( \"main-slider\" , \"data\" ), ) def page_2_store_boundaries_mz_from_graph_low_res_spectrum ( relayoutData , slice_index ): \"\"\"This callback stores in a dcc store the m/z boundaries of the low resolution spectrum when they are updated.\"\"\" # If the plot has been updated from the low resolution spectrum if relayoutData is not None : if \"xaxis.range[0]\" in relayoutData : return json . dumps ([ relayoutData [ \"xaxis.range[0]\" ], relayoutData [ \"xaxis.range[1]\" ]]) elif \"xaxis.range\" in relayoutData : return json . dumps ( relayoutData [ \"xaxis.range\" ]) # If the range is re-initialized, need to explicitely pass the first # and last values of the spectrum to the figure elif \"xaxis.autorange\" in relayoutData : return json . dumps ( [ data . get_array_avg_spectrum_downsampled ( slice_index )[ 0 , 0 ] . astype ( \"float\" ), data . get_array_avg_spectrum_downsampled ( slice_index )[ 0 , - 1 ] . astype ( \"float\" ), ] ) # When the app is launched, or when the plot is displayed and autoresized, # no boundaries are passed not to update the heatmap for nothing return dash . no_update toggle_offcanvas ( n1 , n2 , is_open ) This callback is used to toggle the low-res spectra drawer. Source code in pages/lipid_selection.py 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 @app . callback ( Output ( \"page-2-drawer-low-res-spectra\" , \"is_open\" ), Input ( \"page-2-show-low-res-spectrum-button\" , \"n_clicks\" ), Input ( \"page-2-close-low-res-spectrum-button\" , \"n_clicks\" ), [ State ( \"page-2-drawer-low-res-spectra\" , \"is_open\" )], ) def toggle_offcanvas ( n1 , n2 , is_open ): \"\"\"This callback is used to toggle the low-res spectra drawer.\"\"\" if n1 or n2 : return not is_open return is_open toggle_offcanvas_high_res ( n1 , n2 , is_open ) This callback is used to toggle the high-res spectra drawer. Source code in pages/lipid_selection.py 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 @app . callback ( Output ( \"page-2-drawer-high-res-spectra\" , \"is_open\" ), Input ( \"page-2-show-high-res-spectrum-button\" , \"n_clicks\" ), Input ( \"page-2-close-high-res-spectrum-button\" , \"n_clicks\" ), [ State ( \"page-2-drawer-high-res-spectra\" , \"is_open\" )], ) def toggle_offcanvas_high_res ( n1 , n2 , is_open ): \"\"\"This callback is used to toggle the high-res spectra drawer.\"\"\" if n1 or n2 : return not is_open return is_open","title":"lipid_selection"},{"location":"pages/lipid_selection/#pages.lipid_selection.page_2_active_download","text":"This callback is used to toggle on/off the display rgb and colormap buttons. Source code in pages/lipid_selection.py 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 @app . callback ( Output ( \"page-2-rgb-button\" , \"disabled\" ), Output ( \"page-2-colormap-button\" , \"disabled\" ), Input ( \"page-2-selected-lipid-1\" , \"data\" ), Input ( \"page-2-selected-lipid-2\" , \"data\" ), Input ( \"page-2-selected-lipid-3\" , \"data\" ), ) def page_2_active_download ( lipid_1_index , lipid_2_index , lipid_3_index ): \"\"\"This callback is used to toggle on/off the display rgb and colormap buttons.\"\"\" # Get the current lipid selection l_lipids_indexes = [ x for x in [ lipid_1_index , lipid_2_index , lipid_3_index ] if x is not None and x != - 1 ] # If lipids has been selected from the dropdown, activate button if len ( l_lipids_indexes ) > 0 : return False , False else : return True , True","title":"page_2_active_download()"},{"location":"pages/lipid_selection/#pages.lipid_selection.page_2_add_toast_selection","text":"This callback adds the selected lipid to the selection. Source code in pages/lipid_selection.py 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 @app . callback ( Output ( \"page-2-badge-lipid-1\" , \"children\" ), Output ( \"page-2-badge-lipid-2\" , \"children\" ), Output ( \"page-2-badge-lipid-3\" , \"children\" ), Output ( \"page-2-selected-lipid-1\" , \"data\" ), Output ( \"page-2-selected-lipid-2\" , \"data\" ), Output ( \"page-2-selected-lipid-3\" , \"data\" ), Output ( \"page-2-badge-lipid-1\" , \"class_name\" ), Output ( \"page-2-badge-lipid-2\" , \"class_name\" ), Output ( \"page-2-badge-lipid-3\" , \"class_name\" ), Input ( \"page-2-dropdown-lipids\" , \"value\" ), Input ( \"page-2-badge-lipid-1\" , \"class_name\" ), Input ( \"page-2-badge-lipid-2\" , \"class_name\" ), Input ( \"page-2-badge-lipid-3\" , \"class_name\" ), Input ( \"main-slider\" , \"data\" ), State ( \"page-2-selected-lipid-1\" , \"data\" ), State ( \"page-2-selected-lipid-2\" , \"data\" ), State ( \"page-2-selected-lipid-3\" , \"data\" ), State ( \"page-2-badge-lipid-1\" , \"children\" ), State ( \"page-2-badge-lipid-2\" , \"children\" ), State ( \"page-2-badge-lipid-3\" , \"children\" ), ) def page_2_add_toast_selection ( l_lipid_names , class_name_badge_1 , class_name_badge_2 , class_name_badge_3 , slice_index , lipid_1_index , lipid_2_index , lipid_3_index , header_1 , header_2 , header_3 , ): \"\"\"This callback adds the selected lipid to the selection.\"\"\" logging . info ( \"Entering function to update lipid data\" ) # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # if page-2-dropdown-lipids is called while there's no lipid name defined, it means the page # just got loaded if len ( id_input ) == 0 or ( id_input == \"page-2-dropdown-lipids\" and l_lipid_names is None ): return \"\" , \"\" , \"\" , - 1 , - 1 , - 1 , \"d-none\" , \"d-none\" , \"d-none\" # , None # If one or several lipids have been deleted if l_lipid_names is not None : if len ( l_lipid_names ) < len ( [ x for x in [ lipid_1_index , lipid_2_index , lipid_3_index ] if x != - 1 ] ): logging . info ( \"One or several lipids have been deleter. Cleaning lipid badges now.\" ) for idx_header , header in enumerate ([ header_1 , header_2 , header_3 ]): found = False for lipid_name in l_lipid_names : if lipid_name == header : found = True if not found : if idx_header == 0 : header_1 = \"\" lipid_1_index = - 1 class_name_badge_1 = \"d-none\" if idx_header == 1 : header_2 = \"\" lipid_2_index = - 1 class_name_badge_2 = \"d-none\" if idx_header == 2 : header_3 = \"\" lipid_3_index = - 1 class_name_badge_3 = \"d-none\" return ( header_1 , header_2 , header_3 , lipid_1_index , lipid_2_index , lipid_3_index , class_name_badge_1 , class_name_badge_2 , class_name_badge_3 , ) # Otherwise, update selection or add lipid if ( id_input == \"page-2-dropdown-lipids\" and l_lipid_names is not None ) or id_input == \"main-slider\" : # If a new slice has been selected if id_input == \"main-slider\" : # for each lipid, get lipid name, structure and cation for header in [ header_1 , header_2 , header_3 ]: if len ( header ) > 2 : name , structure , cation = header . split ( \" \" ) # Find lipid location l_lipid_loc_temp = ( data . get_annotations () . index [ ( data . get_annotations ()[ \"name\" ] == name ) & ( data . get_annotations ()[ \"structure\" ] == structure ) & ( data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) l_lipid_loc = [ l_lipid_loc_temp [ i ] for i , x in enumerate ( data . get_annotations () . iloc [ l_lipid_loc_temp ][ \"slice\" ] == slice_index ) if x ] # Fill list with first annotation that exists if it can't find one for the # current slice if len ( l_lipid_loc ) == 0 : l_lipid_loc = l_lipid_loc_temp [: 1 ] # Record location and lipid name lipid_index = l_lipid_loc [ 0 ] # If lipid has already been selected before, replace the index if header_1 == header : lipid_1_index = lipid_index elif header_2 == header : lipid_2_index = lipid_index elif header_3 == header : lipid_3_index = lipid_index logging . info ( \"Returning updated lipid data\" ) return ( header_1 , header_2 , header_3 , lipid_1_index , lipid_2_index , lipid_3_index , class_name_badge_1 , class_name_badge_2 , class_name_badge_3 , ) # If lipids have been added from dropdown menu elif id_input == \"page-2-dropdown-lipids\" : # Get the lipid name and structure name , structure , cation = l_lipid_names [ - 1 ] . split ( \" \" ) # Find lipid location l_lipid_loc = ( data . get_annotations () . index [ ( data . get_annotations ()[ \"name\" ] == name ) & ( data . get_annotations ()[ \"structure\" ] == structure ) & ( data . get_annotations ()[ \"slice\" ] == slice_index ) & ( data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) > 1 : logging . warning ( \"More than one lipid corresponds to the selection\" ) l_lipid_loc = [ l_lipid_loc [ - 1 ]] if len ( l_lipid_loc ) < 1 : logging . warning ( \"No lipid annotation exist. Taking another slice annotation\" ) l_lipid_loc = ( data . get_annotations () . index [ ( data . get_annotations ()[ \"name\" ] == name ) & ( data . get_annotations ()[ \"structure\" ] == structure ) & ( data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () )[: 1 ] # return dash.no_update # Record location and lipid name lipid_index = l_lipid_loc [ 0 ] lipid_string = name + \" \" + structure + \" \" + cation change_made = False # If lipid has already been selected before, replace the index if header_1 == lipid_string : lipid_1_index = lipid_index change_made = True elif header_2 == lipid_string : lipid_2_index = lipid_index change_made = True elif header_3 == lipid_string : lipid_3_index = lipid_index change_made = True # If it's a new lipid selection, fill the first available header if lipid_string not in [ header_1 , header_2 , header_2 ]: # Check first slot available if class_name_badge_1 == \"d-none\" : header_1 = lipid_string lipid_1_index = lipid_index class_name_badge_1 = \"position-absolute\" elif class_name_badge_2 == \"d-none\" : header_2 = lipid_string lipid_2_index = lipid_index class_name_badge_2 = \"position-absolute\" elif class_name_badge_3 == \"d-none\" : header_3 = lipid_string lipid_3_index = lipid_index class_name_badge_3 = \"position-absolute\" else : logging . warning ( \"More than 3 lipids have been selected\" ) return dash . no_update change_made = True if change_made : logging . info ( \"Changes have been made to the lipid selection or indexation,\" + \" propagating callback.\" ) return ( header_1 , header_2 , header_3 , lipid_1_index , lipid_2_index , lipid_3_index , class_name_badge_1 , class_name_badge_2 , class_name_badge_3 , # None, ) else : return dash . no_update return dash . no_update","title":"page_2_add_toast_selection()"},{"location":"pages/lipid_selection/#pages.lipid_selection.page_2_button_window","text":"This callaback is used to toggle on/off the display heatmap from bounds button. Source code in pages/lipid_selection.py 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 @app . callback ( Output ( \"page-2-button-bounds\" , \"disabled\" ), Input ( \"page-2-lower-bound\" , \"value\" ), Input ( \"page-2-upper-bound\" , \"value\" ), ) def page_2_button_window ( lb , hb ): \"\"\"This callaback is used to toggle on/off the display heatmap from bounds button.\"\"\" # Check that the user has inputted something if lb is not None and hb is not None : lb , hb = float ( lb ), float ( hb ) if lb >= 400 and hb <= 1600 and hb - lb > 0 and hb - lb < 10 : return False return True","title":"page_2_button_window()"},{"location":"pages/lipid_selection/#pages.lipid_selection.page_2_display_alert","text":"This callback is used to turn visible the alert regarding the high-res m/z plot. Source code in pages/lipid_selection.py 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 @app . callback ( Output ( \"page-2-alert\" , \"style\" ), Input ( \"page-2-graph-high-resolution-spectrum\" , \"figure\" ), ) def page_2_display_alert ( figure ): \"\"\"This callback is used to turn visible the alert regarding the high-res m/z plot.\"\"\" if figure is not None : if figure [ \"data\" ][ 0 ][ \"x\" ] != [[]]: return { \"display\" : \"none\" } return {}","title":"page_2_display_alert()"},{"location":"pages/lipid_selection/#pages.lipid_selection.page_2_display_high_res_mz_plot","text":"This callback is used to turn visible the high-resolution m/z plot. Source code in pages/lipid_selection.py 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 @app . callback ( Output ( \"page-2-graph-high-resolution-spectrum\" , \"style\" ), Input ( \"page-2-graph-high-resolution-spectrum\" , \"figure\" ), ) def page_2_display_high_res_mz_plot ( figure ): \"\"\"This callback is used to turn visible the high-resolution m/z plot.\"\"\" if figure is not None : if figure [ \"data\" ][ 0 ][ \"x\" ] != [[]]: return { \"height\" : 280 } return { \"display\" : \"none\" }","title":"page_2_display_high_res_mz_plot()"},{"location":"pages/lipid_selection/#pages.lipid_selection.page_2_download","text":"This callback is used to generate and download the data in proper format. Source code in pages/lipid_selection.py 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 @app . callback ( Output ( \"page-2-download-data\" , \"data\" ), Input ( \"page-2-download-data-button\" , \"n_clicks\" ), State ( \"page-2-selected-lipid-1\" , \"data\" ), State ( \"page-2-selected-lipid-2\" , \"data\" ), State ( \"page-2-selected-lipid-3\" , \"data\" ), State ( \"main-slider\" , \"data\" ), State ( \"page-2-toggle-apply-transform\" , \"checked\" ), State ( \"page-2-badge-input\" , \"children\" ), State ( \"boundaries-low-resolution-mz-plot\" , \"data\" ), State ( \"page-2-lower-bound\" , \"value\" ), State ( \"page-2-upper-bound\" , \"value\" ), prevent_initial_call = True , ) def page_2_download ( n_clicks , lipid_1_index , lipid_2_index , lipid_3_index , slice_index , apply_transform , graph_input , bound_high_res , lb , hb , ): \"\"\"This callback is used to generate and download the data in proper format.\"\"\" # Current input is lipid selection if ( graph_input == \"Current input: \" + \"Lipid selection colormap\" or graph_input == \"Current input: \" + \"Lipid selection RGB\" ): l_lipids_indexes = [ x for x in [ lipid_1_index , lipid_2_index , lipid_3_index ] if x is not None and x != - 1 ] # If lipids has been selected from the dropdown, filter them in the df and download them if len ( l_lipids_indexes ) > 0 : def to_excel ( bytes_io ): xlsx_writer = pd . ExcelWriter ( bytes_io , engine = \"xlsxwriter\" ) data . get_annotations () . iloc [ l_lipids_indexes ] . to_excel ( xlsx_writer , index = False , sheet_name = \"Selected lipids\" ) for i , index in enumerate ( l_lipids_indexes ): name = ( data . get_annotations () . iloc [ index ][ \"name\" ] + \"_\" + data . get_annotations () . iloc [ index ][ \"structure\" ] + \"_\" + data . get_annotations () . iloc [ index ][ \"cation\" ] ) # Need to clean name to use it as a sheet name name = name . replace ( \":\" , \"\" ) . replace ( \"/\" , \"\" ) lb = float ( data . get_annotations () . iloc [ index ][ \"min\" ]) - 10 **- 2 hb = float ( data . get_annotations () . iloc [ index ][ \"max\" ]) + 10 **- 2 x , y = figures . compute_spectrum_high_res ( slice_index , lb , hb , plot = False , standardization = apply_transform , cache_flask = cache_flask , ) df = pd . DataFrame . from_dict ({ \"m/z\" : x , \"Intensity\" : y }) df . to_excel ( xlsx_writer , index = False , sheet_name = name [: 31 ]) xlsx_writer . save () return dcc . send_data_frame ( to_excel , \"my_lipid_selection.xlsx\" ) # Current input is manual boundaries selection from input box if graph_input == \"Current input: \" + \"m/z boundaries\" : lb , hb = float ( lb ), float ( hb ) if lb >= 400 and hb <= 1600 and hb - lb > 0 and hb - lb < 10 : def to_excel ( bytes_io ): # Get spectral data mz , intensity = figures . compute_spectrum_high_res ( slice_index , lb - 10 **- 2 , hb + 10 **- 2 , force_xlim = True , standardization = apply_transform , cache_flask = cache_flask , plot = False , ) # Turn to dataframe dataset = pd . DataFrame . from_dict ({ \"m/z\" : mz , \"Intensity\" : intensity }) # Export to excel xlsx_writer = pd . ExcelWriter ( bytes_io , engine = \"xlsxwriter\" ) dataset . to_excel ( xlsx_writer , index = False , sheet_name = \"mz selection\" ) xlsx_writer . save () return dcc . send_data_frame ( to_excel , \"my_boundaries_selection.xlsx\" ) # Current input is boundaries from the low-res m/z plot elif graph_input == \"Current input: \" + \"Selection from high-res m/z graph\" : if bound_high_res is not None : # Case the zoom is high enough if bound_high_res [ 1 ] - bound_high_res [ 0 ] <= 3 : def to_excel ( bytes_io ): # Get spectral data bound_high_res = json . loads ( bound_high_res ) mz , intensity = figures . compute_spectrum_high_res ( slice_index , bound_high_res [ 0 ], bound_high_res [ 1 ], standardization = apply_transform , cache_flask = cache_flask , plot = False , ) # Turn to dataframe dataset = pd . DataFrame . from_dict ({ \"m/z\" : mz , \"Intensity\" : intensity }) # Export to excel xlsx_writer = pd . ExcelWriter ( bytes_io , engine = \"xlsxwriter\" ) dataset . to_excel ( xlsx_writer , index = False , sheet_name = \"mz selection\" ) xlsx_writer . save () return dcc . send_data_frame ( to_excel , \"my_boundaries_selection.xlsx\" ) return dash . no_update","title":"page_2_download()"},{"location":"pages/lipid_selection/#pages.lipid_selection.page_2_plot_graph_heatmap_mz_selection","text":"This callback plots the heatmap of the selected lipid(s) or m/z range. Source code in pages/lipid_selection.py 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 @app . callback ( Output ( \"page-2-graph-heatmap-mz-selection\" , \"figure\" ), Output ( \"page-2-badge-input\" , \"children\" ), Input ( \"main-slider\" , \"data\" ), Input ( \"boundaries-high-resolution-mz-plot\" , \"data\" ), Input ( \"boundaries-low-resolution-mz-plot\" , \"data\" ), Input ( \"page-2-selected-lipid-1\" , \"data\" ), Input ( \"page-2-selected-lipid-2\" , \"data\" ), Input ( \"page-2-selected-lipid-3\" , \"data\" ), Input ( \"page-2-rgb-button\" , \"n_clicks\" ), Input ( \"page-2-colormap-button\" , \"n_clicks\" ), Input ( \"page-2-button-bounds\" , \"n_clicks\" ), State ( \"page-2-lower-bound\" , \"value\" ), State ( \"page-2-upper-bound\" , \"value\" ), State ( \"page-2-badge-input\" , \"children\" ), Input ( \"page-2-toggle-apply-transform\" , \"checked\" ), ) def page_2_plot_graph_heatmap_mz_selection ( slice_index , bound_high_res , bound_low_res , lipid_1_index , lipid_2_index , lipid_3_index , n_clicks_button_rgb , n_clicks_button_colormap , n_clicks_button_bounds , lb , hb , graph_input , apply_transform , ): \"\"\"This callback plots the heatmap of the selected lipid(s) or m/z range.\"\"\" logging . info ( \"Entering function to plot heatmap or RGB depending on lipid selection\" ) # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # Case a two mz bounds values have been inputed if id_input == \"page-2-button-bounds\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"m/z boundaries\" ): if lb is not None and hb is not None : lb , hb = float ( lb ), float ( hb ) if lb >= 400 and hb <= 1600 and hb - lb > 0 and hb - lb < 10 : return ( figures . compute_heatmap_per_mz ( slice_index , lb , hb , cache_flask = cache_flask ), \"Current input: \" + \"m/z boundaries\" , ) return dash . no_update # If a lipid selection has been done if ( id_input == \"page-2-selected-lipid-1\" or id_input == \"page-2-selected-lipid-2\" or id_input == \"page-2-selected-lipid-3\" or id_input == \"page-2-rgb-button\" or id_input == \"page-2-colormap-button\" or ( ( id_input == \"main-slider\" or id_input == \"page-2-toggle-apply-transform\" ) and ( graph_input == \"Current input: \" + \"Lipid selection colormap\" or graph_input == \"Current input: \" + \"Lipid selection RGB\" ) ) ): if lipid_1_index >= 0 or lipid_2_index >= 0 or lipid_3_index >= 0 : # Build the list of mz boundaries for each peak ll_lipid_bounds = [ [ ( float ( data . get_annotations () . iloc [ index ][ \"min\" ]), float ( data . get_annotations () . iloc [ index ][ \"max\" ]), ) ] if index != - 1 else None for index in [ lipid_1_index , lipid_2_index , lipid_3_index ] ] ll_lipid_names = [ [ data . get_annotations () . iloc [ index ][ \"name\" ] + \"_\" + data . get_annotations () . iloc [ index ][ \"structure\" ] + \"_\" + data . get_annotations () . iloc [ index ][ \"cation\" ] ] if index != - 1 else None for index in [ lipid_1_index , lipid_2_index , lipid_3_index ] ] # Check that annotations do not intercept with each other l_lipid_bounds_clean = [ x for l_lipid_bounds in ll_lipid_bounds if l_lipid_bounds is not None for x in l_lipid_bounds ] if len ( l_lipid_bounds_clean ) >= 2 : l_t_bounds_sorted = sorted ( l_lipid_bounds_clean ) for t_bounds_1 , t_bounds_2 in zip ( l_t_bounds_sorted [: - 1 ], l_t_bounds_sorted [ 1 :]): if t_bounds_1 [ 1 ] > t_bounds_2 [ 0 ]: logging . warning ( \"Some pixel annotations intercept each other\" ) # Check if the current plot must be a heatmap if ( id_input == \"page-2-colormap-button\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"Lipid selection colormap\" ) or ( id_input == \"page-2-toggle-apply-transform\" and graph_input == \"Current input: \" + \"Lipid selection colormap\" ) ): return ( figures . compute_heatmap_per_lipid_selection ( slice_index , ll_lipid_bounds , apply_transform = apply_transform , ll_lipid_names = ll_lipid_names , cache_flask = cache_flask , ), \"Current input: \" + \"Lipid selection colormap\" , ) # Or if the current plot must be an RGB image elif ( id_input == \"page-2-rgb-button\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"Lipid selection RGB\" ) or ( id_input == \"page-2-toggle-apply-transform\" and graph_input == \"Current input: \" + \"Lipid selection RGB\" ) ): return ( figures . compute_rgb_image_per_lipid_selection ( slice_index , ll_lipid_bounds , apply_transform = apply_transform , ll_lipid_names = ll_lipid_names , cache_flask = cache_flask , ), \"Current input: \" + \"Lipid selection RGB\" , ) # Plot RBG By default else : logging . info ( \"Right before calling the graphing function\" ) return ( figures . compute_rgb_image_per_lipid_selection ( slice_index , ll_lipid_bounds , apply_transform = apply_transform , ll_lipid_names = ll_lipid_names , cache_flask = cache_flask , ), \"Current input: \" + \"Lipid selection RGB\" , ) else : # No lipid has been selected, return image from boundaries if lb is not None and hb is not None : return ( figures . compute_heatmap_per_mz ( slice_index , lb , hb , cache_flask = cache_flask ), \"Current input: \" + \"m/z boundaries\" , ) else : return ( figures . compute_heatmap_per_mz ( slice_index , 500 , 500 , cache_flask = cache_flask ), \"Current input: \" + \"m/z boundaries\" , ) # Case trigger is range slider from high resolution spectrum if id_input == \"boundaries-high-resolution-mz-plot\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"Selection from high-res m/z graph\" ): if bound_high_res is not None : bound_high_res = json . loads ( bound_high_res ) return ( figures . compute_heatmap_per_mz ( slice_index , bound_high_res [ 0 ], bound_high_res [ 1 ], cache_flask = cache_flask , ), \"Current input: \" + \"Selection from high-res m/z graph\" , ) # Case trigger is range slider from low resolution spectrum if id_input == \"boundaries-low-resolution-mz-plot\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"Selection from low-res m/z graph\" ): if bound_low_res is not None : bound_low_res = json . loads ( bound_low_res ) return ( figures . compute_heatmap_per_mz ( slice_index , bound_low_res [ 0 ], bound_low_res [ 1 ], cache_flask = cache_flask , ), \"Current input: \" + \"Selection from low-res m/z graph\" , ) # If no trigger, the page has just been loaded, so load new figure with default parameters else : return dash . no_update","title":"page_2_plot_graph_heatmap_mz_selection()"},{"location":"pages/lipid_selection/#pages.lipid_selection.page_2_plot_graph_high_res_spectrum","text":"This callback generates the graph of the high resolution spectrum when the current input has a small enough m/z range. Source code in pages/lipid_selection.py 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 @app . callback ( Output ( \"page-2-graph-high-resolution-spectrum\" , \"figure\" ), Input ( \"main-slider\" , \"data\" ), Input ( \"boundaries-low-resolution-mz-plot\" , \"data\" ), Input ( \"page-2-selected-lipid-1\" , \"data\" ), Input ( \"page-2-selected-lipid-2\" , \"data\" ), Input ( \"page-2-selected-lipid-3\" , \"data\" ), Input ( \"page-2-rgb-button\" , \"n_clicks\" ), Input ( \"page-2-colormap-button\" , \"n_clicks\" ), Input ( \"page-2-button-bounds\" , \"n_clicks\" ), State ( \"page-2-lower-bound\" , \"value\" ), State ( \"page-2-upper-bound\" , \"value\" ), State ( \"page-2-badge-input\" , \"children\" ), Input ( \"page-2-toggle-apply-transform\" , \"checked\" ), ) def page_2_plot_graph_high_res_spectrum ( slice_index , bound_high_res , lipid_1_index , lipid_2_index , lipid_3_index , n_clicks_rgb , n_clicks_colormap , n_clicks_button_bounds , lb , hb , graph_input , apply_transform , ): \"\"\"This callback generates the graph of the high resolution spectrum when the current input has a small enough m/z range.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If a lipid selection has been done if ( id_input == \"page-2-selected-lipid-1\" or id_input == \"page-2-selected-lipid-2\" or id_input == \"page-2-selected-lipid-3\" or id_input == \"page-2-rgb-button\" or id_input == \"page-2-colormap-button\" or id_input == \"page-2-last-selected-lipids\" or ( id_input == \"main-slider\" and ( graph_input == \"Current input: \" + \"Lipid selection colormap\" or graph_input == \"Current input: \" + \"Lipid selection RGB\" ) ) ): # If at least one lipid index has been recorded if lipid_1_index >= 0 or lipid_2_index >= 0 or lipid_3_index >= 0 : # Build the list of mz boundaries for each peak l_indexes = [ lipid_1_index , lipid_2_index , lipid_3_index ] l_lipid_bounds = [ ( float ( data . get_annotations () . iloc [ index ][ \"min\" ]), float ( data . get_annotations () . iloc [ index ][ \"max\" ]), ) if index != - 1 else None for index in l_indexes ] if lipid_3_index >= 0 : current_lipid_index = 2 elif lipid_2_index >= 0 : current_lipid_index = 1 else : current_lipid_index = 0 return figures . compute_spectrum_high_res ( slice_index , l_lipid_bounds [ current_lipid_index ][ 0 ] - 10 **- 2 , l_lipid_bounds [ current_lipid_index ][ 1 ] + 10 **- 2 , annotations = l_lipid_bounds , force_xlim = True , standardization = apply_transform , cache_flask = cache_flask , ) # If the user has selected a new m/z range elif id_input == \"page-2-button-bounds\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"m/z boundaries\" ): lb , hb = float ( lb ), float ( hb ) if lb >= 400 and hb <= 1600 and hb - lb > 0 and hb - lb < 10 : # l_lipid_bounds = [(lb, hb), None, None] return figures . compute_spectrum_high_res ( slice_index , lb - 10 **- 2 , hb + 10 **- 2 , force_xlim = True , # annotations=l_lipid_bounds, standardization = apply_transform , cache_flask = cache_flask , ) # If the figure is created at app launch or after load button is cliked, or with an empty lipid # selection, don't plot anything elif \"page-2-selected-lipid\" in id_input : return dash . no_update # Otherwise, if new boundaries have been selected on the low-resolution spectrum elif id_input == \"boundaries-low-resolution-mz-plot\" and bound_high_res is not None : bound_high_res = json . loads ( bound_high_res ) # Case the zoom is high enough if bound_high_res [ 1 ] - bound_high_res [ 0 ] <= 3 : return figures . compute_spectrum_high_res ( slice_index , bound_high_res [ 0 ], bound_high_res [ 1 ], standardization = apply_transform , cache_flask = cache_flask , ) # Otherwise just return default (empty) graph else : return dash . no_update # The page has just been loaded, no spectrum is displayed return dash . no_update","title":"page_2_plot_graph_high_res_spectrum()"},{"location":"pages/lipid_selection/#pages.lipid_selection.page_2_plot_graph_low_res_spectrum","text":"This callbacks generates the graph of the low resolution spectrum when the current input gets updated. Source code in pages/lipid_selection.py 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 @app . callback ( Output ( \"page-2-graph-low-resolution-spectrum\" , \"figure\" ), Input ( \"main-slider\" , \"data\" ), State ( \"page-2-selected-lipid-1\" , \"data\" ), State ( \"page-2-selected-lipid-2\" , \"data\" ), State ( \"page-2-selected-lipid-3\" , \"data\" ), Input ( \"page-2-rgb-button\" , \"n_clicks\" ), Input ( \"page-2-colormap-button\" , \"n_clicks\" ), Input ( \"page-2-button-bounds\" , \"n_clicks\" ), State ( \"page-2-lower-bound\" , \"value\" ), State ( \"page-2-upper-bound\" , \"value\" ), State ( \"page-2-badge-input\" , \"children\" ), State ( \"page-2-graph-low-resolution-spectrum\" , \"relayoutData\" ), ) def page_2_plot_graph_low_res_spectrum ( slice_index , lipid_1_index , lipid_2_index , lipid_3_index , n_clicks_rgb , n_clicks_colormap , n_clicks_button_bounds , lb , hb , graph_input , relayoutData , ): \"\"\"This callbacks generates the graph of the low resolution spectrum when the current input gets updated.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If a lipid selection has been done if ( id_input == \"page-2-selected-lipid-1\" or id_input == \"page-2-selected-lipid-2\" or id_input == \"page-2-selected-lipid-3\" or id_input == \"page-2-rgb-button\" or id_input == \"page-2-colormap-button\" or ( id_input == \"main-slider\" and ( graph_input == \"Current input: \" + \"Lipid selection colormap\" or graph_input == \"Current input: \" + \"Lipid selection RGB\" ) ) ): if lipid_1_index >= 0 or lipid_2_index >= 0 or lipid_3_index >= 0 : # build the list of mz boundaries for each peak l_lipid_bounds = [ ( float ( data . get_annotations () . iloc [ index ][ \"min\" ]), float ( data . get_annotations () . iloc [ index ][ \"max\" ]), ) if index != - 1 else None for index in [ lipid_1_index , lipid_2_index , lipid_3_index ] ] return figures . compute_spectrum_low_res ( slice_index , l_lipid_bounds ) else : # Probably the page has just been loaded, so load new figure with default parameters return dash . no_update # Or if the plot has been updated from range or slider elif id_input == \"page-2-button-bounds\" or ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"m/z boundaries\" ): lb , hb = float ( lb ), float ( hb ) if lb >= 400 and hb <= 1600 and hb - lb > 0 and hb - lb < 10 : l_lipid_bounds = [( lb , hb ), None , None ] return figures . compute_spectrum_low_res ( slice_index , l_lipid_bounds ) elif ( id_input == \"main-slider\" and graph_input == \"Current input: \" + \"Selection from low-res m/z graph\" ): # TODO : find a way to set relayoutdata properly pass return dash . no_update","title":"page_2_plot_graph_low_res_spectrum()"},{"location":"pages/lipid_selection/#pages.lipid_selection.page_2_store_boundaries_mz_from_graph_high_res_spectrum","text":"This callback records the m/z boundaries of the high resolution spectrum in a dcc store. Source code in pages/lipid_selection.py 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 @app . callback ( Output ( \"boundaries-high-resolution-mz-plot\" , \"data\" ), Input ( \"page-2-graph-high-resolution-spectrum\" , \"relayoutData\" ), Input ( \"boundaries-low-resolution-mz-plot\" , \"data\" ), ) def page_2_store_boundaries_mz_from_graph_high_res_spectrum ( relayoutData , bound_low_res ): \"\"\"This callback records the m/z boundaries of the high resolution spectrum in a dcc store.\"\"\" # Primarily update high-res boundaries with high-res range slider if relayoutData is not None : if \"xaxis.range[0]\" in relayoutData : return json . dumps ([ relayoutData [ \"xaxis.range[0]\" ], relayoutData [ \"xaxis.range[1]\" ]]) elif \"xaxis.range\" in relayoutData : return json . dumps ( relayoutData [ \"xaxis.range\" ]) # If the range is re-initialized, need to explicitely pass the low-res value of the slider elif \"xaxis.autorange\" in relayoutData : if bound_low_res is not None : bound_low_res = json . loads ( bound_low_res ) if bound_low_res [ 1 ] - bound_low_res [ 0 ] <= 3 : return json . dumps ( bound_low_res ) # But also needs to be updated when low-res slider is changed and is zoomed enough elif bound_low_res is not None : bound_low_res = json . loads ( bound_low_res ) if bound_low_res [ 1 ] - bound_low_res [ 0 ] <= 3 : return json . dumps ( bound_low_res ) # Page has just been loaded, do nothing else : return dash . no_update","title":"page_2_store_boundaries_mz_from_graph_high_res_spectrum()"},{"location":"pages/lipid_selection/#pages.lipid_selection.page_2_store_boundaries_mz_from_graph_low_res_spectrum","text":"This callback stores in a dcc store the m/z boundaries of the low resolution spectrum when they are updated. Source code in pages/lipid_selection.py 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 @app . callback ( Output ( \"boundaries-low-resolution-mz-plot\" , \"data\" ), Input ( \"page-2-graph-low-resolution-spectrum\" , \"relayoutData\" ), State ( \"main-slider\" , \"data\" ), ) def page_2_store_boundaries_mz_from_graph_low_res_spectrum ( relayoutData , slice_index ): \"\"\"This callback stores in a dcc store the m/z boundaries of the low resolution spectrum when they are updated.\"\"\" # If the plot has been updated from the low resolution spectrum if relayoutData is not None : if \"xaxis.range[0]\" in relayoutData : return json . dumps ([ relayoutData [ \"xaxis.range[0]\" ], relayoutData [ \"xaxis.range[1]\" ]]) elif \"xaxis.range\" in relayoutData : return json . dumps ( relayoutData [ \"xaxis.range\" ]) # If the range is re-initialized, need to explicitely pass the first # and last values of the spectrum to the figure elif \"xaxis.autorange\" in relayoutData : return json . dumps ( [ data . get_array_avg_spectrum_downsampled ( slice_index )[ 0 , 0 ] . astype ( \"float\" ), data . get_array_avg_spectrum_downsampled ( slice_index )[ 0 , - 1 ] . astype ( \"float\" ), ] ) # When the app is launched, or when the plot is displayed and autoresized, # no boundaries are passed not to update the heatmap for nothing return dash . no_update","title":"page_2_store_boundaries_mz_from_graph_low_res_spectrum()"},{"location":"pages/lipid_selection/#pages.lipid_selection.toggle_offcanvas","text":"This callback is used to toggle the low-res spectra drawer. Source code in pages/lipid_selection.py 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 @app . callback ( Output ( \"page-2-drawer-low-res-spectra\" , \"is_open\" ), Input ( \"page-2-show-low-res-spectrum-button\" , \"n_clicks\" ), Input ( \"page-2-close-low-res-spectrum-button\" , \"n_clicks\" ), [ State ( \"page-2-drawer-low-res-spectra\" , \"is_open\" )], ) def toggle_offcanvas ( n1 , n2 , is_open ): \"\"\"This callback is used to toggle the low-res spectra drawer.\"\"\" if n1 or n2 : return not is_open return is_open","title":"toggle_offcanvas()"},{"location":"pages/lipid_selection/#pages.lipid_selection.toggle_offcanvas_high_res","text":"This callback is used to toggle the high-res spectra drawer. Source code in pages/lipid_selection.py 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 @app . callback ( Output ( \"page-2-drawer-high-res-spectra\" , \"is_open\" ), Input ( \"page-2-show-high-res-spectrum-button\" , \"n_clicks\" ), Input ( \"page-2-close-high-res-spectrum-button\" , \"n_clicks\" ), [ State ( \"page-2-drawer-high-res-spectra\" , \"is_open\" )], ) def toggle_offcanvas_high_res ( n1 , n2 , is_open ): \"\"\"This callback is used to toggle the high-res spectra drawer.\"\"\" if n1 or n2 : return not is_open return is_open","title":"toggle_offcanvas_high_res()"},{"location":"pages/load_slice/","text":"This file contains the page used to explore the images of the MALDI acquisition in the app. page_1_hover ( hoverData , slice_index ) This callback is used to update the text displayed when hovering over the slice image. Source code in pages/load_slice.py 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 @app . callback ( Output ( \"page-1-graph-hover-text\" , \"children\" ), Input ( \"page-1-graph-slice-selection\" , \"hoverData\" ), State ( \"main-slider\" , \"data\" ), ) def page_1_hover ( hoverData , slice_index ): \"\"\"This callback is used to update the text displayed when hovering over the slice image.\"\"\" # If there is a region hovered, find out the region name with the current coordinates if hoverData is not None : if len ( hoverData [ \"points\" ]) > 0 : x = int ( slice_index ) - 1 z = hoverData [ \"points\" ][ 0 ][ \"x\" ] y = hoverData [ \"points\" ][ 0 ][ \"y\" ] slice_coor_rescaled = np . asarray ( ( atlas . array_coordinates_warped_data [ x , y , z ] * 1000 / atlas . resolution ) . round ( 0 ), dtype = np . int16 , ) try : label = atlas . labels [ tuple ( slice_coor_rescaled )] except : label = \"undefined\" return \"Hovered region: \" + label return dash . no_update page_1_plot_graph_modal ( n1 , brain ) This callback is used to plot the figure representing the slices in 3D in the modal. Source code in pages/load_slice.py 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 @app . callback ( Output ( \"page-1-graph-modal\" , \"figure\" ), Input ( \"page-1-modal-button\" , \"n_clicks\" ), Input ( \"main-brain\" , \"value\" ), prevent_initial_call = True , ) def page_1_plot_graph_modal ( n1 , brain ): \"\"\"This callback is used to plot the figure representing the slices in 3D in the modal.\"\"\" if n1 : return storage . return_shelved_object ( \"figures/3D_page\" , \"slices_3D\" , force_update = False , compute_function = figures . compute_figure_slices_3D , brain = brain , ) return dash . no_update page_1_visibilty_hover ( active_tab ) This callback is used to update the visibility of the text displayed when hovering over the slice image. Source code in pages/load_slice.py 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 @app . callback ( Output ( \"page-1-graph-hover-text\" , \"class_name\" ), Input ( \"page-1-card-tabs\" , \"value\" ), ) def page_1_visibilty_hover ( active_tab ): \"\"\"This callback is used to update the visibility of the text displayed when hovering over the slice image.\"\"\" # Find out which input triggered the function id_input , value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" ) if len ( id_input ) > 0 : if active_tab == \"0\" : return \"d-none\" else : return \"mt-5\" else : return dash . no_update tab_1_load_image ( value_slider , active_tab , display_annotations ) This callback is used to update the image in page-1-graph-slice-selection from the slider. Source code in pages/load_slice.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 @app . callback ( Output ( \"page-1-graph-slice-selection\" , \"figure\" ), Output ( \"page-1-toggle-annotations\" , \"disabled\" ), Input ( \"main-slider\" , \"data\" ), Input ( \"page-1-card-tabs\" , \"value\" ), Input ( \"page-1-toggle-annotations\" , \"checked\" ), ) def tab_1_load_image ( value_slider , active_tab , display_annotations ): \"\"\"This callback is used to update the image in page-1-graph-slice-selection from the slider.\"\"\" # Find out which input triggered the function id_input , value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" ) if active_tab == \"0\" : disabled = True else : disabled = False if len ( id_input ) > 0 : logging . info ( \"Slider changed to value \" + str ( value_slider )) # Mapping between tab indices and type figure dic_mapping_tab_indices = { \"0\" : \"original_data\" , \"1\" : \"warped_data\" , \"2\" : \"projection_corrected\" , \"3\" : \"atlas\" , } # Force no annotation for the original data return ( storage . return_shelved_object ( \"figures/load_page\" , \"figure_basic_image\" , force_update = False , compute_function = figures . compute_figure_basic_image , type_figure = dic_mapping_tab_indices [ active_tab ], index_image = value_slider - 1 , plot_atlas_contours = display_annotations if active_tab != \"0\" else False , ), disabled , ) return dash . no_update toggle_modal ( n1 , is_open ) This callback is used to open the modal displaying the slices in 3D. Source code in pages/load_slice.py 270 271 272 273 274 275 276 277 278 279 @app . callback ( Output ( \"page-1-modal\" , \"is_open\" ), Input ( \"page-1-modal-button\" , \"n_clicks\" ), State ( \"page-1-modal\" , \"is_open\" ), ) def toggle_modal ( n1 , is_open ): \"\"\"This callback is used to open the modal displaying the slices in 3D.\"\"\" if n1 : return not is_open return is_open","title":"load_slice"},{"location":"pages/load_slice/#pages.load_slice.page_1_hover","text":"This callback is used to update the text displayed when hovering over the slice image. Source code in pages/load_slice.py 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 @app . callback ( Output ( \"page-1-graph-hover-text\" , \"children\" ), Input ( \"page-1-graph-slice-selection\" , \"hoverData\" ), State ( \"main-slider\" , \"data\" ), ) def page_1_hover ( hoverData , slice_index ): \"\"\"This callback is used to update the text displayed when hovering over the slice image.\"\"\" # If there is a region hovered, find out the region name with the current coordinates if hoverData is not None : if len ( hoverData [ \"points\" ]) > 0 : x = int ( slice_index ) - 1 z = hoverData [ \"points\" ][ 0 ][ \"x\" ] y = hoverData [ \"points\" ][ 0 ][ \"y\" ] slice_coor_rescaled = np . asarray ( ( atlas . array_coordinates_warped_data [ x , y , z ] * 1000 / atlas . resolution ) . round ( 0 ), dtype = np . int16 , ) try : label = atlas . labels [ tuple ( slice_coor_rescaled )] except : label = \"undefined\" return \"Hovered region: \" + label return dash . no_update","title":"page_1_hover()"},{"location":"pages/load_slice/#pages.load_slice.page_1_plot_graph_modal","text":"This callback is used to plot the figure representing the slices in 3D in the modal. Source code in pages/load_slice.py 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 @app . callback ( Output ( \"page-1-graph-modal\" , \"figure\" ), Input ( \"page-1-modal-button\" , \"n_clicks\" ), Input ( \"main-brain\" , \"value\" ), prevent_initial_call = True , ) def page_1_plot_graph_modal ( n1 , brain ): \"\"\"This callback is used to plot the figure representing the slices in 3D in the modal.\"\"\" if n1 : return storage . return_shelved_object ( \"figures/3D_page\" , \"slices_3D\" , force_update = False , compute_function = figures . compute_figure_slices_3D , brain = brain , ) return dash . no_update","title":"page_1_plot_graph_modal()"},{"location":"pages/load_slice/#pages.load_slice.page_1_visibilty_hover","text":"This callback is used to update the visibility of the text displayed when hovering over the slice image. Source code in pages/load_slice.py 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 @app . callback ( Output ( \"page-1-graph-hover-text\" , \"class_name\" ), Input ( \"page-1-card-tabs\" , \"value\" ), ) def page_1_visibilty_hover ( active_tab ): \"\"\"This callback is used to update the visibility of the text displayed when hovering over the slice image.\"\"\" # Find out which input triggered the function id_input , value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" ) if len ( id_input ) > 0 : if active_tab == \"0\" : return \"d-none\" else : return \"mt-5\" else : return dash . no_update","title":"page_1_visibilty_hover()"},{"location":"pages/load_slice/#pages.load_slice.tab_1_load_image","text":"This callback is used to update the image in page-1-graph-slice-selection from the slider. Source code in pages/load_slice.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 @app . callback ( Output ( \"page-1-graph-slice-selection\" , \"figure\" ), Output ( \"page-1-toggle-annotations\" , \"disabled\" ), Input ( \"main-slider\" , \"data\" ), Input ( \"page-1-card-tabs\" , \"value\" ), Input ( \"page-1-toggle-annotations\" , \"checked\" ), ) def tab_1_load_image ( value_slider , active_tab , display_annotations ): \"\"\"This callback is used to update the image in page-1-graph-slice-selection from the slider.\"\"\" # Find out which input triggered the function id_input , value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" ) if active_tab == \"0\" : disabled = True else : disabled = False if len ( id_input ) > 0 : logging . info ( \"Slider changed to value \" + str ( value_slider )) # Mapping between tab indices and type figure dic_mapping_tab_indices = { \"0\" : \"original_data\" , \"1\" : \"warped_data\" , \"2\" : \"projection_corrected\" , \"3\" : \"atlas\" , } # Force no annotation for the original data return ( storage . return_shelved_object ( \"figures/load_page\" , \"figure_basic_image\" , force_update = False , compute_function = figures . compute_figure_basic_image , type_figure = dic_mapping_tab_indices [ active_tab ], index_image = value_slider - 1 , plot_atlas_contours = display_annotations if active_tab != \"0\" else False , ), disabled , ) return dash . no_update","title":"tab_1_load_image()"},{"location":"pages/load_slice/#pages.load_slice.toggle_modal","text":"This callback is used to open the modal displaying the slices in 3D. Source code in pages/load_slice.py 270 271 272 273 274 275 276 277 278 279 @app . callback ( Output ( \"page-1-modal\" , \"is_open\" ), Input ( \"page-1-modal-button\" , \"n_clicks\" ), State ( \"page-1-modal\" , \"is_open\" ), ) def toggle_modal ( n1 , is_open ): \"\"\"This callback is used to open the modal displaying the slices in 3D.\"\"\" if n1 : return not is_open return is_open","title":"toggle_modal()"},{"location":"pages/region_analysis/","text":"This file contains the page used to explore the lipid data from either pre-existing annotated structures or human-selected in the app. draw_modal_graph ( n1 , cliked_reset , boolean_mask , slice_index , l_red_lipids , l_green_lipids , l_blue_lipids , l_shapes_and_masks , l_mask_name , l_color_mask , session_id ) This callback is used to draw the heatmap for differential lipid expression comparison. Source code in pages/region_analysis.py 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 @app . callback ( Output ( \"page-3-heatmap-lipid-comparison\" , \"figure\" ), Input ( \"page-3-open-modal\" , \"n_clicks\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"page-3-toggle-mask\" , \"checked\" ), Input ( \"main-slider\" , \"data\" ), State ( \"page-3-dropdown-red\" , \"value\" ), State ( \"page-3-dropdown-green\" , \"value\" ), State ( \"page-3-dropdown-blue\" , \"value\" ), State ( \"dcc-store-shapes-and-masks\" , \"data\" ), State ( \"page-3-dropdown-brain-regions\" , \"value\" ), State ( \"dcc-store-color-mask\" , \"data\" ), State ( \"session-id\" , \"data\" ), prevent_initial_call = True , ) def draw_modal_graph ( n1 , cliked_reset , boolean_mask , slice_index , l_red_lipids , l_green_lipids , l_blue_lipids , l_shapes_and_masks , l_mask_name , l_color_mask , session_id , ): \"\"\"This callback is used to draw the heatmap for differential lipid expression comparison.\"\"\" # Deactivated switches as_enrichment = False log_transform = False # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] logging . info ( \"Modal graph function triggered with input \" + str ( id_input )) # Delete everything when clicking reset or changing slice index if id_input == \"page-3-reset-button\" or id_input == \"main-slider\" : logging . info ( \"Resetting modal graph\" ) return figures . return_empty_spectrum () # Check that at least one lipid has been selected if len ( l_red_lipids + l_green_lipids + l_blue_lipids ) > 0 : logging . info ( \"At least one lipid has been selected, starting computing modal graph now.\" ) df_names = data . get_annotations ()[ data . get_annotations ()[ \"slice\" ] == slice_index ] # Build the list of mz boundaries for each peak l_lipid_bounds = [ [ ( float ( df_names . iloc [ int ( index )][ \"min\" ]), float ( df_names . iloc [ int ( index )][ \"max\" ]), ) if int ( index ) != - 1 else None for index in l_lipids ] for l_lipids in [ l_red_lipids , l_green_lipids , l_blue_lipids ] ] # Compute the corresponding RGB image fig = figures . compute_rgb_image_per_lipid_selection ( slice_index , l_lipid_bounds , log = log_transform , cache_flask = cache_flask , ) # Display the user-drawn region(s) or pre-computed mask(s) if boolean_mask : if l_shapes_and_masks is not None : l_draw = [] for shape in l_shapes_and_masks : if shape [ 0 ] == \"mask\" : base64_string = shape [ 2 ] fig . add_trace ( go . Image ( visible = True , source = base64_string , hoverinfo = \"skip\" ) ) elif shape [ 0 ] == \"shape\" : draw = shape [ 2 ] l_draw . append ( draw ) fig [ \"layout\" ][ \"shapes\" ] = tuple ( l_draw ) logging . info ( \"Modal graph computed. Returning it now\" ) return fig logging . info ( \"No lipid were selected, ignoring update.\" ) return dash . no_update global_spectrum_store ( slice_index , l_shapes_and_masks , l_mask_name , relayoutData , as_enrichment , log_transform ) This function computes and returns the average spectra for the selected regions. Parameters: Name Type Description Default slice_index int Index of the selected slice. required l_shapes_and_masks list A list of either user-draw regions, or pre-existing masks coming from annotations (both custom objects). required l_mask_name list(str If masks are present in l_shapes_and_masks, this list contains the corresponding names of the masks. required relayoutData _type_ If user-draw regions are present in l_shapes_and_masks, this list contains the corresponding relayout data, which itself contains the path used to define the drawn shapes. required as_enrichment bool If True, the average spectrum in the selected region is normalized with respect to the average spectrum of the whole slice. required log_transform bool If True, the average spectrum is computed from log-transformed data. required Returns: Type Description list ( np . ndarray ) A list of numpy arrays, each corresponding to the spectral data of a user-draw region, or pre-existing mask. Source code in pages/region_analysis.py 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 @cache_flask . memoize () def global_spectrum_store ( slice_index , l_shapes_and_masks , l_mask_name , relayoutData , as_enrichment , log_transform ): \"\"\"This function computes and returns the average spectra for the selected regions. Args: slice_index (int): Index of the selected slice. l_shapes_and_masks (list): A list of either user-draw regions, or pre-existing masks coming from annotations (both custom objects). l_mask_name (list(str)): If masks are present in l_shapes_and_masks, this list contains the corresponding names of the masks. relayoutData (_type_): If user-draw regions are present in l_shapes_and_masks, this list contains the corresponding relayout data, which itself contains the path used to define the drawn shapes. as_enrichment (bool): If True, the average spectrum in the selected region is normalized with respect to the average spectrum of the whole slice. log_transform (bool): If True, the average spectrum is computed from log-transformed data. Returns: (list(np.ndarray)): A list of numpy arrays, each corresponding to the spectral data of a user-draw region, or pre-existing mask. \"\"\" # Empty variables before computing the average spectra l_spectra = [] idx_mask = - 1 idx_path = - 1 logging . info ( \"Computing spectra now\" ) # Loop over all user-draw regions and pre-existing masks for shape in l_shapes_and_masks : grah_scattergl_data = None # Compute average spectrum from mask if shape [ 0 ] == \"mask\" : idx_mask += 1 mask_name = l_mask_name [ idx_mask ] id_name = atlas . dic_name_acronym [ mask_name ] if id_name in atlas . dic_existing_masks [ slice_index - 1 ]: grah_scattergl_data = atlas . get_projected_mask_and_spectrum ( slice_index - 1 , mask_name , MAIA_correction = False )[ 1 ] else : logging . warning ( \"Bug, the selected mask does't exist\" ) return dash . no_update elif shape [ 0 ] == \"shape\" : idx_path += 1 logging . info ( \"Start computing path\" ) l_paths = [] for shape in relayoutData [ \"shapes\" ]: if \"path\" in shape : # Get condensed path version of the annotation parsed_path = shape [ \"path\" ][ 1 : - 1 ] . replace ( \"L\" , \",\" ) . split ( \",\" ) path = [ round ( float ( x )) for x in parsed_path ] # Work with image projection (check previous version if need to work with # original image) path = [ ( int ( atlas . array_projection_correspondence_corrected [ slice_index - 1 , y , x , 0 ] ), # Must explicitely cast to int for serialization as numpy int are # not accepted int ( atlas . array_projection_correspondence_corrected [ slice_index - 1 , y , x , 1 ] ), ) for x , y in zip ( path [: - 1 : 2 ], path [ 1 :: 2 ]) ] # Clean path from artefacts due to projection path = [ t for t in list ( dict . fromkeys ( path )) if - 1 not in t ] # Use dic key to remove duplicates created by the correction of the # projection if len ( path ) > 0 : path . append ( path [ 0 ]) # to close the path l_paths . append ( path ) logging . info ( \"Computing path finished\" ) # Compute the average spectrum from the selected path try : path = l_paths [ idx_path ] if len ( path ) > 0 : list_index_bound_rows , list_index_bound_column_per_row = sample_rows_from_path ( np . array ( path , dtype = np . int32 ) ) grah_scattergl_data = compute_thread_safe_function ( compute_spectrum_per_row_selection , cache_flask , data , slice_index , list_index_bound_rows , list_index_bound_column_per_row , data . get_array_spectra ( slice_index ), data . get_array_lookup_pixels ( slice_index ), data . get_image_shape ( slice_index ), data . get_array_peaks_transformed_lipids ( slice_index ), data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), zeros_extend = False , apply_correction = False , ) except Exception as e : logging . warning ( \"Bug, the selected path does't exist\" ) logging . warning ( e ) return None else : logging . warning ( \"Bug, the shape type doesn't exit\" ) return None # Do the selected transformations if grah_scattergl_data is not None : if as_enrichment : # First normalize with respect to itself grah_scattergl_data [ 1 , :] /= np . sum ( grah_scattergl_data [ 1 , :]) # Then convert to uncompressed version grah_scattergl_data = convert_array_to_fine_grained ( grah_scattergl_data , 10 **- 3 , lb = 350 , hb = 1250 , ) # Then normalize to the sum of all pixels grah_scattergl_data [ 1 , :] /= ( compute_thread_safe_function ( convert_array_to_fine_grained , cache_flask , data , slice_index - 1 , data . get_array_spectra ( slice_index - 1 ), 10 **- 3 , lb = 350 , hb = 1250 , )[ 1 , :] + 1 ) # Go back to compressed grah_scattergl_data = strip_zeros ( cache_flask , grah_scattergl_data ) # Re-normalize with respect to the number of values in the spectrum # so that pixels with more lipids do no have lower peaks grah_scattergl_data [ 1 , :] *= len ( grah_scattergl_data [ 1 , :]) # Log-transform if log_transform : grah_scattergl_data [ 1 , :] = np . log ( grah_scattergl_data [ 1 , :] + 1 ) l_spectra . append ( grah_scattergl_data ) else : return None return l_spectra page_3_button_compute_spectra ( relayoutData , clicked_reset , mask ) This callback disables the button to compute spectra if no region has been selected or drawn. Source code in pages/region_analysis.py 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 @app . callback ( Output ( \"page-3-button-compute-spectra\" , \"disabled\" ), Input ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"page-3-dropdown-brain-regions\" , \"value\" ), prevent_intial_call = True , ) def page_3_button_compute_spectra ( relayoutData , clicked_reset , mask ): \"\"\"This callback disables the button to compute spectra if no region has been selected or drawn.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # In case of reset, disable button if id_input == \"page-3-reset-button\" : return True # If at least one mask, activate button if mask is not None : if mask != []: return False # If at least one drawn shape, activate button if relayoutData is not None : if \"shapes\" in relayoutData : if len ( relayoutData [ \"shapes\" ]) > 0 : return False return True page_3_disable_dropdown ( l_selection , clicked_reset ) This callback disables the dropdown options for the brain regions if more than four regions have already been selected. Source code in pages/region_analysis.py 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 @app . callback ( Output ( \"page-3-dropdown-brain-regions\" , \"disabled\" ), Input ( \"page-3-dropdown-brain-regions\" , \"value\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), prevent_intial_call = True , ) def page_3_disable_dropdown ( l_selection , clicked_reset ): \"\"\"This callback disables the dropdown options for the brain regions if more than four regions have already been selected.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] if id_input == \"page-3-reset-button\" : return False if l_selection is not None : if len ( l_selection ) > 0 and len ( l_selection ) < 4 : return False elif len ( l_selection ) >= 4 : return True return dash . no_update page_3_display_alert ( clicked_compute , clicked_reset , relayoutData , mask ) This callback hides or displays the alerts of the plots linked to lipid analytics, depending if the latters show data or not. Source code in pages/region_analysis.py 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 @app . callback ( Output ( \"page-3-alert\" , \"style\" ), Output ( \"page-3-alert-3\" , \"style\" ), Output ( \"page-3-alert-5\" , \"style\" ), Input ( \"page-3-button-compute-spectra\" , \"n_clicks\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), State ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), State ( \"page-3-dropdown-brain-regions\" , \"value\" ), prevent_initial_call = True , ) def page_3_display_alert ( clicked_compute , clicked_reset , relayoutData , mask ): \"\"\"This callback hides or displays the alerts of the plots linked to lipid analytics, depending if the latters show data or not.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If reset button has been clicked, leave all alert if id_input == \"page-3-reset-button\" : return {}, {}, {} # If the button to compute spectra has been clicked, hide the alerts elif id_input == \"page-3-button-compute-spectra\" : # If at least one mask selected if mask is not None : if mask != []: return ( { \"display\" : \"none\" }, { \"display\" : \"none\" }, { \"display\" : \"none\" }, ) # Or at least one drawn region if relayoutData is not None : if \"shapes\" in relayoutData : if len ( relayoutData [ \"shapes\" ]) > 0 : return ( { \"display\" : \"none\" }, { \"display\" : \"none\" }, { \"display\" : \"none\" }, ) return dash . no_update page_3_display_high_res_mz_plot ( clicked_reset , clicked_compute , mask , relayoutData ) This callback displays the m/z plot and heatmap when clicking on the compute spectra button (and hide the corresponding alert). Source code in pages/region_analysis.py 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 @app . callback ( Output ( \"page-3-graph-spectrum-per-pixel\" , \"style\" ), Output ( \"page-3-alert-2\" , \"style\" ), Output ( \"page-3-graph-heatmap-per-lipid\" , \"style\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"page-3-button-compute-spectra\" , \"n_clicks\" ), State ( \"page-3-dropdown-brain-regions\" , \"value\" ), State ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), prevent_initial_call = True , ) def page_3_display_high_res_mz_plot ( clicked_reset , clicked_compute , mask , relayoutData ): \"\"\"This callback displays the m/z plot and heatmap when clicking on the compute spectra button (and hide the corresponding alert).\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If reset button has been clicked, hide all plot if id_input == \"page-3-reset-button\" : return { \"display\" : \"none\" }, { \"display\" : \"none\" }, { \"display\" : \"none\" } # If the button to compute spectra has been clicked, display the plots elif id_input == \"page-3-button-compute-spectra\" : logging . info ( \"Compute spectra button has been clicked\" ) # If at least one mask, display the plots if mask is not None : if mask != []: logging . info ( \"One or several masks have been selected, displaying graphs\" ) return ( { \"height\" : HEIGHT_PLOTS }, { \"display\" : \"none\" }, { \"height\" : 2 * HEIGHT_PLOTS , \"background-color\" : \"#1d1c1f\" , }, ) # If at least one drawn region, display the plots if relayoutData is not None : if \"shapes\" in relayoutData : if len ( relayoutData [ \"shapes\" ]) > 0 : if len ( relayoutData [ \"shapes\" ]) <= 4 : logging . info ( \"One or several shapes have been selected, displaying graphs\" ) return ( { \"height\" : HEIGHT_PLOTS }, { \"display\" : \"none\" }, { \"height\" : 2 * HEIGHT_PLOTS , \"background-color\" : \"#1d1c1f\" , }, ) else : return { \"display\" : \"none\" }, {}, { \"display\" : \"none\" } return dash . no_update page_3_display_switch ( clicked_reset , fig_heatmap , relayoutData ) This callback displays the sorting switch for the lipid heatmap when the corresponding heatmap shows data. Source code in pages/region_analysis.py 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 @app . callback ( Output ( \"page-3-switches\" , \"className\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"page-3-graph-heatmap-per-lipid\" , \"figure\" ), State ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), prevent_initial_call = True , ) def page_3_display_switch ( clicked_reset , fig_heatmap , relayoutData ): \"\"\"This callback displays the sorting switch for the lipid heatmap when the corresponding heatmap shows data.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If reset button has been clicked, hide switch if id_input == \"page-3-reset-button\" : return \"d-none\" # If limit number of selection is done, just hide it if relayoutData is not None : if \"shapes\" in relayoutData : if len ( relayoutData [ \"shapes\" ]) > 0 : if len ( relayoutData [ \"shapes\" ]) > 4 : return \"d-none\" # Else, display it if more than 1 selection recorded if fig_heatmap is not None : if len ( fig_heatmap [ \"data\" ]) > 0 : # If more than 1 selection recorded in the heatmap, display switch if len ( fig_heatmap [ \"data\" ][ 0 ][ \"x\" ]) > 1 : return \"ml-1 d-flex align-items-center justify-content-center\" else : return \"d-none\" return dash . no_update page_3_download ( n_clicks , fig_mz ) This callback is used to download the spectra of the selected regions when clicking the corresponding button. Source code in pages/region_analysis.py 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 @app . callback ( Output ( \"page-3-download-data\" , \"data\" ), Input ( \"page-3-download-data-button\" , \"n_clicks\" ), State ( \"page-3-graph-spectrum-per-pixel\" , \"figure\" ), prevent_initial_call = True , ) def page_3_download ( n_clicks , fig_mz ): \"\"\"This callback is used to download the spectra of the selected regions when clicking the corresponding button.\"\"\" # Check that there's spectral data to download in the first place if fig_mz is not None : fig_mz = go . Figure ( data = fig_mz ) if len ( fig_mz . data ) > 1 : # Excel writer for download def to_excel ( bytes_io ): xlsx_writer = pd . ExcelWriter ( bytes_io , engine = \"xlsxwriter\" ) for i , data in enumerate ( fig_mz . data ): if i % 2 == 0 : df = pd . DataFrame . from_dict ( { \"m/z\" : data [ \"x\" ], \"Intensity\" : data [ \"y\" ], \"Lipid\" : data [ \"text\" ], } ) df . to_excel ( xlsx_writer , index = False , sheet_name = \"Annotated spectrum sel \" + str ( i // 2 + 1 ), ) else : df = pd . DataFrame . from_dict ({ \"m/z\" : data [ \"x\" ], \"Intensity\" : data [ \"y\" ]}) df . to_excel ( xlsx_writer , index = False , sheet_name = \"Remaining spectrum sel \" + str ( i // 2 + 1 ), ) xlsx_writer . save () return dcc . send_data_frame ( to_excel , \"my_region_selection_data.xlsx\" ) return dash . no_update page_3_draw_heatmap_per_lipid_selection ( cliked_reset , sort_switch , percentile , slice_index , l_spectra , l_mask_name , l_shapes_and_masks , relayoutData , session_id ) This callback is used to plot the heatmap representing the differential lipid expression in the different regions of the current selection. Source code in pages/region_analysis.py 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 @app . callback ( Output ( \"page-3-graph-heatmap-per-lipid\" , \"figure\" ), Output ( \"page-3-dcc-store-lipids-region\" , \"data\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"page-3-sort-by-diff-switch\" , \"checked\" ), Input ( \"page-4-slider\" , \"value\" ), Input ( \"main-slider\" , \"data\" ), Input ( \"dcc-store-list-mz-spectra\" , \"data\" ), State ( \"page-3-dropdown-brain-regions\" , \"value\" ), State ( \"dcc-store-shapes-and-masks\" , \"data\" ), State ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), State ( \"session-id\" , \"data\" ), prevent_intial_call = True , ) def page_3_draw_heatmap_per_lipid_selection ( cliked_reset , sort_switch , percentile , slice_index , l_spectra , l_mask_name , l_shapes_and_masks , relayoutData , session_id , ): \"\"\"This callback is used to plot the heatmap representing the differential lipid expression in the different regions of the current selection.\"\"\" # Deactivated switches as_enrichment = False log_transform = False # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # If a new slice is loaded or the page just got loaded, do nothing if len ( id_input ) == 0 : return dash . no_update # Delete everything when clicking reset elif id_input == \"page-3-reset-button\" : return figures . return_heatmap_lipid (), [] # Otherwise compute lipid expression heatmap from spectrum elif ( id_input == \"dcc-store-list-idx-lipids\" or id_input == \"page-3-sort-by-diff-switch\" or id_input == \"page-3-scale-by-mean-switch\" or id_input == \"page-4-slider\" or id_input == \"dcc-store-list-mz-spectra\" ): scale_switch = False # Load figure if l_spectra == \"ok\" : logging . info ( \"Starting computing heatmap now\" ) # Get the actual values for l_spectra and ll_idx_labels and not just the dummy fillings l_spectra = global_spectrum_store ( slice_index , l_shapes_and_masks , l_mask_name , relayoutData , as_enrichment , log_transform , ) ll_idx_labels = global_lipid_index_store ( data , slice_index , l_spectra ) if len ( l_spectra ) > 0 : if len ( ll_idx_labels ) != len ( l_spectra ): print ( \"BUG: the number of received spectra is different from the number of\" \" received annotations\" ) return dash . no_update # Compute average expression for each lipid and each selection set_lipids_idx = set () ll_lipids_idx = [] ll_avg_intensity = [] n_sel = len ( l_spectra ) for spectrum , l_idx_labels in zip ( l_spectra , ll_idx_labels ): array_intensity_with_lipids = np . array ( spectrum , dtype = np . float32 )[ 1 , :] array_idx_labels = np . array ( l_idx_labels , dtype = np . int32 ) l_lipids_idx , l_avg_intensity = compute_avg_intensity_per_lipid ( array_intensity_with_lipids , array_idx_labels ) set_lipids_idx . update ( l_lipids_idx ) ll_lipids_idx . append ( l_lipids_idx ) ll_avg_intensity . append ( l_avg_intensity ) dic_avg_lipids = { idx : [ 0 ] * n_sel for idx in set_lipids_idx } for i , ( l_lipids , l_avg_intensity ) in enumerate ( zip ( ll_lipids_idx , ll_avg_intensity ) ): for lipid , intensity in zip ( l_lipids , l_avg_intensity ): dic_avg_lipids [ lipid ][ i ] = intensity l_sel = [ \"Blue sel.\" , \"Green sel.\" , \"Orange sel.\" , \"Red sel.\" ] df_avg_intensity_lipids = pd . DataFrame . from_dict ( dic_avg_lipids , orient = \"index\" , columns = [ l_sel [ i ] for i in range ( n_sel )] ) # Exclude very lowly expressed lipids df_min_expression = df_avg_intensity_lipids . min ( axis = 1 ) df_avg_intensity_lipids = df_avg_intensity_lipids [ df_min_expression > df_min_expression . quantile ( q = int ( percentile ) / 100 ) ] # Rescale according to row mean if scale_switch and n_sel > 1 : df_avg_intensity_lipids = df_avg_intensity_lipids . divide ( df_avg_intensity_lipids . mean ( axis = 1 ), axis = 0 ) # Sort by relative std if sort_switch and n_sel > 1 : df_avg_intensity_lipids = df_avg_intensity_lipids . iloc [ ( df_avg_intensity_lipids . std ( axis = 1 ) / df_avg_intensity_lipids . mean ( axis = 1 ) ) . argsort (), :, ] else : if n_sel > 1 : df_avg_intensity_lipids = df_avg_intensity_lipids . iloc [ ( df_avg_intensity_lipids . mean ( axis = 1 )) . argsort (), : ] else : df_avg_intensity_lipids . sort_values ( by = l_sel [ 0 ], inplace = True ) l_idx_lipids = list ( df_avg_intensity_lipids . index ) # Replace idx_lipids by actual name df_names = data . get_annotations ()[ data . get_annotations ()[ \"slice\" ] == slice_index ] df_avg_intensity_lipids . index = df_avg_intensity_lipids . index . map ( lambda idx : df_names . iloc [ idx ][ \"name\" ] + \"_\" + df_names . iloc [ idx ][ \"structure\" ] + \"_\" + df_names . iloc [ idx ][ \"cation\" ] ) # Plot fig_heatmap_lipids = go . Figure ( data = go . Heatmap ( z = df_avg_intensity_lipids . to_numpy (), y = df_avg_intensity_lipids . index , x = df_avg_intensity_lipids . columns , ygap = 0.2 , colorscale = \"Blues\" , ) ) fig_heatmap_lipids = figures . return_heatmap_lipid ( fig_heatmap_lipids ) logging . info ( \"Heatmap computed. Returning it now\" ) return fig_heatmap_lipids , l_idx_lipids return dash . no_update page_3_empty_dropdown ( clicked_reset , slice_index ) This callback empties the dropdown options for the brain regions when clicking reset or changing slice. Source code in pages/region_analysis.py 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 @app . callback ( Output ( \"page-3-dropdown-brain-regions\" , \"value\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"main-slider\" , \"data\" ), prevent_initial_call = True , ) def page_3_empty_dropdown ( clicked_reset , slice_index ): \"\"\"This callback empties the dropdown options for the brain regions when clicking reset or changing slice.\"\"\" return [] page_3_fill_dropdown_options ( l_idx_lipids , cliked_reset , slice_index , n_clicks ) This callback is used to fill the dropdown options with the most differentially expressed lipids in the corresponding heatmap. Source code in pages/region_analysis.py 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 @app . callback ( Output ( \"page-3-dropdown-red\" , \"options\" ), Output ( \"page-3-dropdown-green\" , \"options\" ), Output ( \"page-3-dropdown-blue\" , \"options\" ), Output ( \"page-3-dropdown-red\" , \"value\" ), Output ( \"page-3-dropdown-green\" , \"value\" ), Output ( \"page-3-dropdown-blue\" , \"value\" ), Output ( \"page-3-open-modal\" , \"n_clicks\" ), Input ( \"page-3-dcc-store-lipids-region\" , \"data\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"main-slider\" , \"data\" ), State ( \"page-3-open-modal\" , \"n_clicks\" ), prevent_initial_call = True , ) def page_3_fill_dropdown_options ( l_idx_lipids , cliked_reset , slice_index , n_clicks ): \"\"\"This callback is used to fill the dropdown options with the most differentially expressed lipids in the corresponding heatmap.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # If a new slice is loaded or the page just got loaded, do nothing if len ( id_input ) == 0 : return dash . no_update # Delete everything when clicking reset elif id_input == \"page-3-reset-button\" : return [], [], [], [], [], [], None # Otherwise compute lipid expression heatmap from spectrum elif id_input == \"page-3-dcc-store-lipids-region\" : if l_idx_lipids is not None : if len ( l_idx_lipids ) > 0 : logging . info ( \"Starting computing lipid dropdown now.\" ) df_names = data . get_annotations ()[ data . get_annotations ()[ \"slice\" ] == slice_index ] l_names = [ df_names . iloc [ idx ][ \"name\" ] + \"_\" + df_names . iloc [ idx ][ \"structure\" ] + \"_\" + df_names . iloc [ idx ][ \"cation\" ] for idx in l_idx_lipids ] options = [ { \"label\" : name , \"value\" : str ( idx )} for name , idx in zip ( l_names , l_idx_lipids ) ] # dropdown is displayed in reversed order options . reverse () if n_clicks is None : n_clicks = 0 if len ( options ) > 0 : logging . info ( \"Dropdown values computed. Updating it with new lipids now.\" ) return ( options , options , options , [ options [ 0 ][ \"value\" ]], [ options [ 1 ][ \"value\" ]], [ options [ 2 ][ \"value\" ]], n_clicks + 1 , ) return dash . no_update page_3_hover ( hoverData , slice_index ) This callback is used to update the text displayed when hovering over the slice image. Source code in pages/region_analysis.py 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 @app . callback ( Output ( \"page-3-graph-hover-text\" , \"children\" ), Input ( \"page-3-graph-heatmap-per-sel\" , \"hoverData\" ), Input ( \"main-slider\" , \"data\" ), ) def page_3_hover ( hoverData , slice_index ): \"\"\"This callback is used to update the text displayed when hovering over the slice image.\"\"\" # If there is a region hovered, find out the region name with the current coordinates if hoverData is not None : if len ( hoverData [ \"points\" ]) > 0 : x = int ( slice_index ) - 1 z = hoverData [ \"points\" ][ 0 ][ \"x\" ] y = hoverData [ \"points\" ][ 0 ][ \"y\" ] slice_coor_rescaled = np . asarray ( ( atlas . array_coordinates_warped_data [ x , y , z ] * 1000 / atlas . resolution ) . round ( 0 ), dtype = np . int16 , ) try : label = atlas . labels [ tuple ( slice_coor_rescaled )] except : label = \"undefined\" return \"Hovered region: \" + label return dash . no_update page_3_plot_heatmap ( relayoutData , slice_index , cliked_reset , l_mask_name , url , l_color_mask , reset , l_shapes_and_masks ) This callback is used to plot the main heatmap of the page. Source code in pages/region_analysis.py 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 @app . callback ( Output ( \"page-3-graph-heatmap-per-sel\" , \"figure\" ), Output ( \"dcc-store-color-mask\" , \"data\" ), Output ( \"dcc-store-reset\" , \"data\" ), Output ( \"dcc-store-shapes-and-masks\" , \"data\" ), Input ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), Input ( \"main-slider\" , \"data\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"page-3-dropdown-brain-regions\" , \"value\" ), Input ( \"url\" , \"pathname\" ), State ( \"dcc-store-color-mask\" , \"data\" ), State ( \"dcc-store-reset\" , \"data\" ), State ( \"dcc-store-shapes-and-masks\" , \"data\" ), prevent_inital_call = True , ) def page_3_plot_heatmap ( relayoutData , slice_index , cliked_reset , l_mask_name , url , l_color_mask , reset , l_shapes_and_masks , ): \"\"\"This callback is used to plot the main heatmap of the page.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # If a new slice is loaded or the page just got loaded # do nothing because of automatic relayout of the heatmap which is automatically triggered when # the page is loaded if ( id_input == \"main-slider\" or len ( id_input ) == 0 or id_input == \"page-3-reset-button\" or id_input == \"url\" ): fig = storage . return_shelved_object ( \"figures/load_page\" , \"figure_basic_image\" , force_update = False , compute_function = figures . compute_figure_basic_image , type_figure = \"projection_corrected\" , index_image = slice_index - 1 , plot_atlas_contours = False , ) fig . update_layout ( dragmode = \"drawclosedpath\" , newshape = dict ( fillcolor = config . l_colors [ 0 ], opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ) ), autosize = True , ) return fig , [], True , [] # Fix bug with automatic relayout if value_input == \"relayoutData\" and relayoutData == { \"autosize\" : True }: return dash . no_update # Fix other bug with automatic dropdown selection if ( id_input == \"page-3-dropdown-brain-regions \" and relayoutData is None and cliked_reset is None and ( l_mask_name is None or len ( l_mask_name ) == 0 ) ): fig = storage . return_shelved_object ( \"figures/load_page\" , \"figure_basic_image\" , force_update = False , compute_function = figures . compute_figure_basic_image , type_figure = \"projection_corrected\" , index_image = slice_index - 1 , plot_atlas_contours = False , ) fig . update_layout ( dragmode = \"drawclosedpath\" , newshape = dict ( fillcolor = config . l_colors [ 0 ], opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ) ), autosize = True , ) return fig , [], True , [] # If the user selected a new mask or drew on the plot if id_input == \"page-3-graph-heatmap-per-sel\" or id_input == \"page-3-dropdown-brain-regions\" : # Check that a mask has actually been selected if l_mask_name is not None or relayoutData is not None : # Rebuild figure fig = storage . return_shelved_object ( \"figures/load_page\" , \"figure_basic_image\" , force_update = False , compute_function = figures . compute_figure_basic_image , type_figure = \"projection_corrected\" , index_image = slice_index - 1 , plot_atlas_contours = False , ) color_idx = None col_next = None if l_mask_name is not None : # If a mask has been selected if len ( l_mask_name ) > 0 : for idx_mask , mask_name in enumerate ( l_mask_name ): id_name = atlas . dic_name_acronym [ mask_name ] if id_name in atlas . dic_existing_masks [ slice_index - 1 ]: projected_mask = atlas . get_projected_mask_and_spectrum ( slice_index - 1 , mask_name , MAIA_correction = False )[ 0 ] else : logging . warning ( \"The mask \" + str ( mask_name ) + \" couldn't be found\" ) # Build a list of empty images and add selected lipids for each channel normalized_projected_mask = projected_mask / np . max ( projected_mask ) # Correct bug with atlas projection normalized_projected_mask [:, : 10 ] = 0 if idx_mask < len ( l_color_mask ): color_rgb = l_color_mask [ idx_mask ] else : color_idx = len ( l_color_mask ) if relayoutData is not None : if \"shapes\" in relayoutData : color_idx += len ( relayoutData [ \"shapes\" ]) color = config . l_colors [ color_idx % 4 ][ 1 :] color_rgb = [ int ( color [ i : i + 2 ], 16 ) for i in ( 0 , 2 , 4 )] + [ 200 ] l_color_mask . append ( color_rgb ) l_images = [ normalized_projected_mask * color for c , color in zip ([ \"r\" , \"g\" , \"b\" , \"a\" ], color_rgb ) ] # Reoder axis to match plotly go.image requirements array_image = np . moveaxis ( np . array ( l_images , dtype = np . uint8 ), 0 , 2 ) # Convert image to string to save space (new image as each mask must have a # different color) base64_string = convert_image_to_base64 ( array_image , optimize = True , format = \"webp\" , type = \"RGBA\" ) fig . add_trace ( go . Image ( visible = True , source = base64_string , hoverinfo = \"skip\" ) ) fig . update_layout ( dragmode = \"drawclosedpath\" , ) if id_input == \"page-3-dropdown-brain-regions\" and color_idx is not None : # Save in l_shapes_and_masks l_shapes_and_masks . append ([ \"mask\" , mask_name , base64_string , color_idx ]) # If a region has been drawn by the user if relayoutData is not None : if \"shapes\" in relayoutData : if len ( relayoutData [ \"shapes\" ]) > 0 : if not reset or value_input == \"relayoutData\" : if \"path\" in relayoutData [ \"shapes\" ][ - 1 ]: fig [ \"layout\" ][ \"shapes\" ] = relayoutData [ \"shapes\" ] # col_next = config . l_colors [ ( len ( relayoutData [ \"shapes\" ]) + len ( l_color_mask )) % 4 ] # compute color and save in l_shapes_and_masks if id_input == \"page-3-graph-heatmap-per-sel\" : color_idx_for_registration = len ( l_color_mask ) if relayoutData is not None : if \"shapes\" in relayoutData : color_idx_for_registration += len ( relayoutData [ \"shapes\" ] ) l_shapes_and_masks . append ( [ \"shape\" , None , relayoutData [ \"shapes\" ][ - 1 ], color_idx_for_registration - 1 , ] ) # Update col_next if color_idx is not None and col_next is None : col_next = config . l_colors [( color_idx + 1 ) % 4 ] elif col_next is None : col_next = config . l_colors [ 0 ] fig . update_layout ( dragmode = \"drawclosedpath\" , newshape = dict ( fillcolor = col_next , opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ), ), ) # Update drag mode if relayoutData is not None : if \"shapes\" in relayoutData : if len ( relayoutData [ \"shapes\" ]) + len ( l_color_mask ) > 3 : fig . update_layout ( dragmode = False ) if len ( l_color_mask ) > 3 : fig . update_layout ( dragmode = False ) # Return figure and corresponding data return fig , l_color_mask , False , l_shapes_and_masks # either graph is already here return dash . no_update page_3_plot_spectrum ( cliked_reset , l_spectra , slice_index , l_mask_name , l_shapes_and_masks , relayoutData ) This callback is used to plot the spectra of the selected region(s). Source code in pages/region_analysis.py 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 @app . callback ( Output ( \"page-3-graph-spectrum-per-pixel\" , \"figure\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"dcc-store-list-mz-spectra\" , \"data\" ), Input ( \"main-slider\" , \"data\" ), State ( \"page-3-dropdown-brain-regions\" , \"value\" ), State ( \"dcc-store-shapes-and-masks\" , \"data\" ), State ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), prevent_intial_call = True , ) def page_3_plot_spectrum ( cliked_reset , l_spectra , slice_index , l_mask_name , l_shapes_and_masks , relayoutData , ): \"\"\"This callback is used to plot the spectra of the selected region(s).\"\"\" # Deactivated switches as_enrichment = False log_transform = False # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # If a new slice is loaded or the page just got loaded, do nothing if len ( id_input ) == 0 : return dash . no_update # Delete everything when clicking reset elif id_input == \"page-3-reset-button\" or l_spectra is None or l_spectra == []: return figures . return_empty_spectrum () # Do nothing if l_spectra is None or [] elif id_input == \"dcc-store-list-mz-spectra\" : if len ( l_spectra ) > 0 or l_spectra == \"ok\" : logging . info ( \"Starting spectra plotting now\" ) fig_mz = go . Figure () # Compute the average spectra l_spectra = global_spectrum_store ( slice_index , l_shapes_and_masks , l_mask_name , relayoutData , as_enrichment , log_transform , ) ll_idx_labels = global_lipid_index_store ( data , slice_index , l_spectra ) for idx_spectra , ( spectrum , l_idx_labels ) in enumerate ( zip ( l_spectra , ll_idx_labels )): # Find color of the current spectrum col = config . l_colors [ idx_spectra % 4 ] # Compute (again) the numpy array of the spectrum grah_scattergl_data = np . array ( spectrum , dtype = np . float32 ) # Two different functions so that's there's a unique output for each numba function l_idx_kept = return_idx_sup ( l_idx_labels ) l_idx_unkept = return_idx_inf ( l_idx_labels ) # Pad annotated trace with zeros ( grah_scattergl_data_padded_annotated , array_index_padding , ) = add_zeros_to_spectrum ( grah_scattergl_data [:, l_idx_kept ], pad_individual_peaks = True , padding = 10 **- 4 , ) l_mz_with_lipids = grah_scattergl_data_padded_annotated [ 0 , :] l_intensity_with_lipids = grah_scattergl_data_padded_annotated [ 1 , :] l_idx_labels_kept = l_idx_labels [ l_idx_kept ] # @njit # We need to wait for the support of np.insert, still relatively fast anyway def pad_l_idx_labels ( l_idx_labels_kept , array_index_padding ): pad = 0 # The initial condition in the loop is only evaluated once so no problem with # insertion afterwards for i in range ( len ( l_idx_labels_kept )): # Array_index_padding[i] will be 0 or 2 (peaks are padded with 2 zeros, one # on each side) for j in range ( array_index_padding [ i ]): # i+1 instead of i plus insert on the right of the element i l_idx_labels_kept = np . insert ( l_idx_labels_kept , i + 1 + pad , - 1 ) pad += 1 return l_idx_labels_kept l_idx_labels_kept = list ( pad_l_idx_labels ( l_idx_labels_kept , array_index_padding )) # Rebuild lipid name from structure, cation, etc. l_labels_all_lipids = data . compute_l_labels () l_labels = [ l_labels_all_lipids [ idx ] if idx != - 1 else \"\" for idx in l_idx_labels_kept ] # Add annotated trace to plot fig_mz . add_trace ( go . Scattergl ( x = l_mz_with_lipids , y = l_intensity_with_lipids , visible = True , marker_color = col , name = \"Annotated peaks\" , showlegend = True , fill = \"tozeroy\" , hovertemplate = \"Lipid: % {text} <extra></extra>\" , text = l_labels , ) ) # Pad not annotated traces peaks with zeros grah_scattergl_data_padded , array_index_padding = add_zeros_to_spectrum ( grah_scattergl_data [:, l_idx_unkept ], pad_individual_peaks = True , padding = 10 **- 4 , ) l_mz_without_lipids = grah_scattergl_data_padded [ 0 , :] l_intensity_without_lipids = grah_scattergl_data_padded [ 1 , :] # Add not-annotated trace to plot. fig_mz . add_trace ( go . Scattergl ( x = l_mz_without_lipids , y = l_intensity_without_lipids , visible = True , marker_color = col , name = \"Unknown peaks\" , showlegend = True , fill = \"tozeroy\" , opacity = 0.2 , hoverinfo = \"skip\" , # text=l_idx_labels_kept, ) ) # Define figure layout fig_mz . update_layout ( margin = dict ( t = 5 , r = 0 , b = 10 , l = 0 ), showlegend = True , xaxis = dict ( title = \"m/z\" ), yaxis = dict ( title = \"Intensity\" ), template = \"plotly_dark\" , legend = dict ( orientation = \"h\" , yanchor = \"bottom\" , y = 1.02 , xanchor = \"right\" , x = 1.1 ), ) fig_mz . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_mz . layout . paper_bgcolor = \"rgba(0,0,0,0)\" logging . info ( \"Spectra plotted. Returning it now\" ) # Return dummy variable for ll_idx_labels to confirm that it has been computed return fig_mz return dash . no_update page_3_record_spectra ( clicked_compute , l_paths , cliked_reset , url , slice_index , l_mask_name , l_shapes_and_masks , relayoutData , session_id ) This callback is used to compute and record the average spectrum of the selected region(s). Source code in pages/region_analysis.py 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 @app . callback ( Output ( \"dcc-store-list-mz-spectra\" , \"data\" ), Input ( \"page-3-button-compute-spectra\" , \"n_clicks\" ), Input ( \"page-3-dcc-store-path-heatmap\" , \"data\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"url\" , \"pathname\" ), Input ( \"main-slider\" , \"data\" ), State ( \"page-3-dropdown-brain-regions\" , \"value\" ), State ( \"dcc-store-shapes-and-masks\" , \"data\" ), State ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), State ( \"session-id\" , \"data\" ), prevent_intial_call = True , ) def page_3_record_spectra ( clicked_compute , l_paths , cliked_reset , url , slice_index , l_mask_name , l_shapes_and_masks , relayoutData , session_id , ): \"\"\"This callback is used to compute and record the average spectrum of the selected region(s).\"\"\" # Deactivated switches as_enrichment = False log_transform = False # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # If a new slice is loaded or the page just got loaded, do nothing because # of automatic relayout of the heatmap which is automatically triggered when the page is loaded if len ( id_input ) == 0 or ( value_input == \"relayoutData\" and relayoutData == { \"autosize\" : True }): return dash . no_update # Delete everything when clicking reset elif id_input == \"page-3-reset-button\" or id_input == \"url\" : return [] # If the user clicked on the button after drawing a region and/or selecting a structure elif id_input == \"page-3-button-compute-spectra\" and len ( l_shapes_and_masks ) > 0 : logging . info ( \"Starting to compute spectrum\" ) l_spectra = global_spectrum_store ( slice_index , l_shapes_and_masks , l_mask_name , relayoutData , as_enrichment , log_transform ) if l_spectra is not None : if l_spectra != []: logging . info ( \"Spectra computed, returning it now\" ) # Return a dummy variable to indicate that the spectrum has been computed and # trigger the callback return \"ok\" logging . warning ( \"A bug appeared during spectrum computation\" ) return [] page_3_reset_download ( fig_mz ) This callback is used to deactivate the download buttons if no region has been drawn. Source code in pages/region_analysis.py 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 @app . callback ( Output ( \"page-3-download-data-button\" , \"disabled\" ), Output ( \"page-3-download-plot-button\" , \"disabled\" ), Output ( \"page-3-download-heatmap-button\" , \"disabled\" ), Input ( \"page-3-graph-spectrum-per-pixel\" , \"figure\" ), ) def page_3_reset_download ( fig_mz ): \"\"\"This callback is used to deactivate the download buttons if no region has been drawn.\"\"\" # Check the presence of spectral data in the corresponding figure if fig_mz is not None : fig_mz = go . Figure ( data = fig_mz ) if len ( fig_mz . data ) > 1 : return False , False , False return True , True , True page_3_reset_layout ( cliked_reset , url ) This callback is used to reset the layout of the heatmap. Source code in pages/region_analysis.py 872 873 874 875 876 877 878 879 880 @app . callback ( Output ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"url\" , \"pathname\" ), prevent_initial_call = True , ) def page_3_reset_layout ( cliked_reset , url ): \"\"\"This callback is used to reset the layout of the heatmap.\"\"\" return {} page_3_update_dropdown_option ( slice_index ) This callback updates the dropdown options for the brain regions. Source code in pages/region_analysis.py 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 @app . callback ( Output ( \"page-3-dropdown-brain-regions\" , \"data\" ), Input ( \"main-slider\" , \"data\" ), ) def page_3_update_dropdown_option ( slice_index ): \"\"\"This callback updates the dropdown options for the brain regions.\"\"\" if slice_index is not None : return [ { \"label\" : atlas . dic_acronym_name [ node ], \"value\" : atlas . dic_acronym_name [ node ]} for node in atlas . dic_existing_masks [ slice_index - 1 ] ] else : return dash . no_update toggle_button_modal ( l_red_lipids , l_green_lipids , l_blue_lipids ) This callback is used to activate the button to plot the graph for lipid comparison. Source code in pages/region_analysis.py 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 @app . callback ( Output ( \"page-3-open-modal\" , \"disabled\" ), Input ( \"page-3-dropdown-red\" , \"value\" ), Input ( \"page-3-dropdown-green\" , \"value\" ), Input ( \"page-3-dropdown-blue\" , \"value\" ), ) def toggle_button_modal ( l_red_lipids , l_green_lipids , l_blue_lipids ): \"\"\"This callback is used to activate the button to plot the graph for lipid comparison.\"\"\" # Check that at least one lipid has been selected if len ( l_red_lipids + l_green_lipids + l_blue_lipids ) > 0 : return False else : return True toggle_offcanvas ( n1 , n2 , is_open ) This callback is used to open the drawer containing the lipid expression analysis of the selected region. Source code in pages/region_analysis.py 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 @app . callback ( Output ( \"page-4-drawer-region-selection\" , \"is_open\" ), Input ( \"page-3-button-compute-spectra\" , \"n_clicks\" ), Input ( \"page-4-close-drawer-region-selection\" , \"n_clicks\" ), [ State ( \"page-4-drawer-region-selection\" , \"is_open\" )], ) def toggle_offcanvas ( n1 , n2 , is_open ): \"\"\"This callback is used to open the drawer containing the lipid expression analysis of the selected region.\"\"\" if n1 or n2 : return not is_open return is_open toggle_visibility_graph ( n1 , cliked_reset , l_red_lipids , l_green_lipids , l_blue_lipids ) This callback is used to display the graph for differential lipid expression comparison. Source code in pages/region_analysis.py 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 @app . callback ( Output ( \"page-3-div-graph-lipid-comparison\" , \"style\" ), Input ( \"page-3-open-modal\" , \"n_clicks\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), State ( \"page-3-dropdown-red\" , \"value\" ), State ( \"page-3-dropdown-green\" , \"value\" ), State ( \"page-3-dropdown-blue\" , \"value\" ), prevent_initial_call = True , ) def toggle_visibility_graph ( n1 , cliked_reset , l_red_lipids , l_green_lipids , l_blue_lipids ): \"\"\"This callback is used to display the graph for differential lipid expression comparison.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # Delete everything when clicking reset if id_input == \"page-3-reset-button\" : return { \"display\" : \"none\" } # Check that at least one lipid has been selected if len ( l_red_lipids + l_green_lipids + l_blue_lipids ) > 0 : return {} else : return { \"display\" : \"none\" }","title":"region_analysis"},{"location":"pages/region_analysis/#pages.region_analysis.draw_modal_graph","text":"This callback is used to draw the heatmap for differential lipid expression comparison. Source code in pages/region_analysis.py 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 @app . callback ( Output ( \"page-3-heatmap-lipid-comparison\" , \"figure\" ), Input ( \"page-3-open-modal\" , \"n_clicks\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"page-3-toggle-mask\" , \"checked\" ), Input ( \"main-slider\" , \"data\" ), State ( \"page-3-dropdown-red\" , \"value\" ), State ( \"page-3-dropdown-green\" , \"value\" ), State ( \"page-3-dropdown-blue\" , \"value\" ), State ( \"dcc-store-shapes-and-masks\" , \"data\" ), State ( \"page-3-dropdown-brain-regions\" , \"value\" ), State ( \"dcc-store-color-mask\" , \"data\" ), State ( \"session-id\" , \"data\" ), prevent_initial_call = True , ) def draw_modal_graph ( n1 , cliked_reset , boolean_mask , slice_index , l_red_lipids , l_green_lipids , l_blue_lipids , l_shapes_and_masks , l_mask_name , l_color_mask , session_id , ): \"\"\"This callback is used to draw the heatmap for differential lipid expression comparison.\"\"\" # Deactivated switches as_enrichment = False log_transform = False # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] logging . info ( \"Modal graph function triggered with input \" + str ( id_input )) # Delete everything when clicking reset or changing slice index if id_input == \"page-3-reset-button\" or id_input == \"main-slider\" : logging . info ( \"Resetting modal graph\" ) return figures . return_empty_spectrum () # Check that at least one lipid has been selected if len ( l_red_lipids + l_green_lipids + l_blue_lipids ) > 0 : logging . info ( \"At least one lipid has been selected, starting computing modal graph now.\" ) df_names = data . get_annotations ()[ data . get_annotations ()[ \"slice\" ] == slice_index ] # Build the list of mz boundaries for each peak l_lipid_bounds = [ [ ( float ( df_names . iloc [ int ( index )][ \"min\" ]), float ( df_names . iloc [ int ( index )][ \"max\" ]), ) if int ( index ) != - 1 else None for index in l_lipids ] for l_lipids in [ l_red_lipids , l_green_lipids , l_blue_lipids ] ] # Compute the corresponding RGB image fig = figures . compute_rgb_image_per_lipid_selection ( slice_index , l_lipid_bounds , log = log_transform , cache_flask = cache_flask , ) # Display the user-drawn region(s) or pre-computed mask(s) if boolean_mask : if l_shapes_and_masks is not None : l_draw = [] for shape in l_shapes_and_masks : if shape [ 0 ] == \"mask\" : base64_string = shape [ 2 ] fig . add_trace ( go . Image ( visible = True , source = base64_string , hoverinfo = \"skip\" ) ) elif shape [ 0 ] == \"shape\" : draw = shape [ 2 ] l_draw . append ( draw ) fig [ \"layout\" ][ \"shapes\" ] = tuple ( l_draw ) logging . info ( \"Modal graph computed. Returning it now\" ) return fig logging . info ( \"No lipid were selected, ignoring update.\" ) return dash . no_update","title":"draw_modal_graph()"},{"location":"pages/region_analysis/#pages.region_analysis.global_spectrum_store","text":"This function computes and returns the average spectra for the selected regions. Parameters: Name Type Description Default slice_index int Index of the selected slice. required l_shapes_and_masks list A list of either user-draw regions, or pre-existing masks coming from annotations (both custom objects). required l_mask_name list(str If masks are present in l_shapes_and_masks, this list contains the corresponding names of the masks. required relayoutData _type_ If user-draw regions are present in l_shapes_and_masks, this list contains the corresponding relayout data, which itself contains the path used to define the drawn shapes. required as_enrichment bool If True, the average spectrum in the selected region is normalized with respect to the average spectrum of the whole slice. required log_transform bool If True, the average spectrum is computed from log-transformed data. required Returns: Type Description list ( np . ndarray ) A list of numpy arrays, each corresponding to the spectral data of a user-draw region, or pre-existing mask. Source code in pages/region_analysis.py 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 @cache_flask . memoize () def global_spectrum_store ( slice_index , l_shapes_and_masks , l_mask_name , relayoutData , as_enrichment , log_transform ): \"\"\"This function computes and returns the average spectra for the selected regions. Args: slice_index (int): Index of the selected slice. l_shapes_and_masks (list): A list of either user-draw regions, or pre-existing masks coming from annotations (both custom objects). l_mask_name (list(str)): If masks are present in l_shapes_and_masks, this list contains the corresponding names of the masks. relayoutData (_type_): If user-draw regions are present in l_shapes_and_masks, this list contains the corresponding relayout data, which itself contains the path used to define the drawn shapes. as_enrichment (bool): If True, the average spectrum in the selected region is normalized with respect to the average spectrum of the whole slice. log_transform (bool): If True, the average spectrum is computed from log-transformed data. Returns: (list(np.ndarray)): A list of numpy arrays, each corresponding to the spectral data of a user-draw region, or pre-existing mask. \"\"\" # Empty variables before computing the average spectra l_spectra = [] idx_mask = - 1 idx_path = - 1 logging . info ( \"Computing spectra now\" ) # Loop over all user-draw regions and pre-existing masks for shape in l_shapes_and_masks : grah_scattergl_data = None # Compute average spectrum from mask if shape [ 0 ] == \"mask\" : idx_mask += 1 mask_name = l_mask_name [ idx_mask ] id_name = atlas . dic_name_acronym [ mask_name ] if id_name in atlas . dic_existing_masks [ slice_index - 1 ]: grah_scattergl_data = atlas . get_projected_mask_and_spectrum ( slice_index - 1 , mask_name , MAIA_correction = False )[ 1 ] else : logging . warning ( \"Bug, the selected mask does't exist\" ) return dash . no_update elif shape [ 0 ] == \"shape\" : idx_path += 1 logging . info ( \"Start computing path\" ) l_paths = [] for shape in relayoutData [ \"shapes\" ]: if \"path\" in shape : # Get condensed path version of the annotation parsed_path = shape [ \"path\" ][ 1 : - 1 ] . replace ( \"L\" , \",\" ) . split ( \",\" ) path = [ round ( float ( x )) for x in parsed_path ] # Work with image projection (check previous version if need to work with # original image) path = [ ( int ( atlas . array_projection_correspondence_corrected [ slice_index - 1 , y , x , 0 ] ), # Must explicitely cast to int for serialization as numpy int are # not accepted int ( atlas . array_projection_correspondence_corrected [ slice_index - 1 , y , x , 1 ] ), ) for x , y in zip ( path [: - 1 : 2 ], path [ 1 :: 2 ]) ] # Clean path from artefacts due to projection path = [ t for t in list ( dict . fromkeys ( path )) if - 1 not in t ] # Use dic key to remove duplicates created by the correction of the # projection if len ( path ) > 0 : path . append ( path [ 0 ]) # to close the path l_paths . append ( path ) logging . info ( \"Computing path finished\" ) # Compute the average spectrum from the selected path try : path = l_paths [ idx_path ] if len ( path ) > 0 : list_index_bound_rows , list_index_bound_column_per_row = sample_rows_from_path ( np . array ( path , dtype = np . int32 ) ) grah_scattergl_data = compute_thread_safe_function ( compute_spectrum_per_row_selection , cache_flask , data , slice_index , list_index_bound_rows , list_index_bound_column_per_row , data . get_array_spectra ( slice_index ), data . get_array_lookup_pixels ( slice_index ), data . get_image_shape ( slice_index ), data . get_array_peaks_transformed_lipids ( slice_index ), data . get_array_corrective_factors ( slice_index ) . astype ( np . float32 ), zeros_extend = False , apply_correction = False , ) except Exception as e : logging . warning ( \"Bug, the selected path does't exist\" ) logging . warning ( e ) return None else : logging . warning ( \"Bug, the shape type doesn't exit\" ) return None # Do the selected transformations if grah_scattergl_data is not None : if as_enrichment : # First normalize with respect to itself grah_scattergl_data [ 1 , :] /= np . sum ( grah_scattergl_data [ 1 , :]) # Then convert to uncompressed version grah_scattergl_data = convert_array_to_fine_grained ( grah_scattergl_data , 10 **- 3 , lb = 350 , hb = 1250 , ) # Then normalize to the sum of all pixels grah_scattergl_data [ 1 , :] /= ( compute_thread_safe_function ( convert_array_to_fine_grained , cache_flask , data , slice_index - 1 , data . get_array_spectra ( slice_index - 1 ), 10 **- 3 , lb = 350 , hb = 1250 , )[ 1 , :] + 1 ) # Go back to compressed grah_scattergl_data = strip_zeros ( cache_flask , grah_scattergl_data ) # Re-normalize with respect to the number of values in the spectrum # so that pixels with more lipids do no have lower peaks grah_scattergl_data [ 1 , :] *= len ( grah_scattergl_data [ 1 , :]) # Log-transform if log_transform : grah_scattergl_data [ 1 , :] = np . log ( grah_scattergl_data [ 1 , :] + 1 ) l_spectra . append ( grah_scattergl_data ) else : return None return l_spectra","title":"global_spectrum_store()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_button_compute_spectra","text":"This callback disables the button to compute spectra if no region has been selected or drawn. Source code in pages/region_analysis.py 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 @app . callback ( Output ( \"page-3-button-compute-spectra\" , \"disabled\" ), Input ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"page-3-dropdown-brain-regions\" , \"value\" ), prevent_intial_call = True , ) def page_3_button_compute_spectra ( relayoutData , clicked_reset , mask ): \"\"\"This callback disables the button to compute spectra if no region has been selected or drawn.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # In case of reset, disable button if id_input == \"page-3-reset-button\" : return True # If at least one mask, activate button if mask is not None : if mask != []: return False # If at least one drawn shape, activate button if relayoutData is not None : if \"shapes\" in relayoutData : if len ( relayoutData [ \"shapes\" ]) > 0 : return False return True","title":"page_3_button_compute_spectra()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_disable_dropdown","text":"This callback disables the dropdown options for the brain regions if more than four regions have already been selected. Source code in pages/region_analysis.py 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 @app . callback ( Output ( \"page-3-dropdown-brain-regions\" , \"disabled\" ), Input ( \"page-3-dropdown-brain-regions\" , \"value\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), prevent_intial_call = True , ) def page_3_disable_dropdown ( l_selection , clicked_reset ): \"\"\"This callback disables the dropdown options for the brain regions if more than four regions have already been selected.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] if id_input == \"page-3-reset-button\" : return False if l_selection is not None : if len ( l_selection ) > 0 and len ( l_selection ) < 4 : return False elif len ( l_selection ) >= 4 : return True return dash . no_update","title":"page_3_disable_dropdown()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_display_alert","text":"This callback hides or displays the alerts of the plots linked to lipid analytics, depending if the latters show data or not. Source code in pages/region_analysis.py 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 @app . callback ( Output ( \"page-3-alert\" , \"style\" ), Output ( \"page-3-alert-3\" , \"style\" ), Output ( \"page-3-alert-5\" , \"style\" ), Input ( \"page-3-button-compute-spectra\" , \"n_clicks\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), State ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), State ( \"page-3-dropdown-brain-regions\" , \"value\" ), prevent_initial_call = True , ) def page_3_display_alert ( clicked_compute , clicked_reset , relayoutData , mask ): \"\"\"This callback hides or displays the alerts of the plots linked to lipid analytics, depending if the latters show data or not.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If reset button has been clicked, leave all alert if id_input == \"page-3-reset-button\" : return {}, {}, {} # If the button to compute spectra has been clicked, hide the alerts elif id_input == \"page-3-button-compute-spectra\" : # If at least one mask selected if mask is not None : if mask != []: return ( { \"display\" : \"none\" }, { \"display\" : \"none\" }, { \"display\" : \"none\" }, ) # Or at least one drawn region if relayoutData is not None : if \"shapes\" in relayoutData : if len ( relayoutData [ \"shapes\" ]) > 0 : return ( { \"display\" : \"none\" }, { \"display\" : \"none\" }, { \"display\" : \"none\" }, ) return dash . no_update","title":"page_3_display_alert()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_display_high_res_mz_plot","text":"This callback displays the m/z plot and heatmap when clicking on the compute spectra button (and hide the corresponding alert). Source code in pages/region_analysis.py 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 @app . callback ( Output ( \"page-3-graph-spectrum-per-pixel\" , \"style\" ), Output ( \"page-3-alert-2\" , \"style\" ), Output ( \"page-3-graph-heatmap-per-lipid\" , \"style\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"page-3-button-compute-spectra\" , \"n_clicks\" ), State ( \"page-3-dropdown-brain-regions\" , \"value\" ), State ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), prevent_initial_call = True , ) def page_3_display_high_res_mz_plot ( clicked_reset , clicked_compute , mask , relayoutData ): \"\"\"This callback displays the m/z plot and heatmap when clicking on the compute spectra button (and hide the corresponding alert).\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If reset button has been clicked, hide all plot if id_input == \"page-3-reset-button\" : return { \"display\" : \"none\" }, { \"display\" : \"none\" }, { \"display\" : \"none\" } # If the button to compute spectra has been clicked, display the plots elif id_input == \"page-3-button-compute-spectra\" : logging . info ( \"Compute spectra button has been clicked\" ) # If at least one mask, display the plots if mask is not None : if mask != []: logging . info ( \"One or several masks have been selected, displaying graphs\" ) return ( { \"height\" : HEIGHT_PLOTS }, { \"display\" : \"none\" }, { \"height\" : 2 * HEIGHT_PLOTS , \"background-color\" : \"#1d1c1f\" , }, ) # If at least one drawn region, display the plots if relayoutData is not None : if \"shapes\" in relayoutData : if len ( relayoutData [ \"shapes\" ]) > 0 : if len ( relayoutData [ \"shapes\" ]) <= 4 : logging . info ( \"One or several shapes have been selected, displaying graphs\" ) return ( { \"height\" : HEIGHT_PLOTS }, { \"display\" : \"none\" }, { \"height\" : 2 * HEIGHT_PLOTS , \"background-color\" : \"#1d1c1f\" , }, ) else : return { \"display\" : \"none\" }, {}, { \"display\" : \"none\" } return dash . no_update","title":"page_3_display_high_res_mz_plot()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_display_switch","text":"This callback displays the sorting switch for the lipid heatmap when the corresponding heatmap shows data. Source code in pages/region_analysis.py 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 @app . callback ( Output ( \"page-3-switches\" , \"className\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"page-3-graph-heatmap-per-lipid\" , \"figure\" ), State ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), prevent_initial_call = True , ) def page_3_display_switch ( clicked_reset , fig_heatmap , relayoutData ): \"\"\"This callback displays the sorting switch for the lipid heatmap when the corresponding heatmap shows data.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If reset button has been clicked, hide switch if id_input == \"page-3-reset-button\" : return \"d-none\" # If limit number of selection is done, just hide it if relayoutData is not None : if \"shapes\" in relayoutData : if len ( relayoutData [ \"shapes\" ]) > 0 : if len ( relayoutData [ \"shapes\" ]) > 4 : return \"d-none\" # Else, display it if more than 1 selection recorded if fig_heatmap is not None : if len ( fig_heatmap [ \"data\" ]) > 0 : # If more than 1 selection recorded in the heatmap, display switch if len ( fig_heatmap [ \"data\" ][ 0 ][ \"x\" ]) > 1 : return \"ml-1 d-flex align-items-center justify-content-center\" else : return \"d-none\" return dash . no_update","title":"page_3_display_switch()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_download","text":"This callback is used to download the spectra of the selected regions when clicking the corresponding button. Source code in pages/region_analysis.py 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 @app . callback ( Output ( \"page-3-download-data\" , \"data\" ), Input ( \"page-3-download-data-button\" , \"n_clicks\" ), State ( \"page-3-graph-spectrum-per-pixel\" , \"figure\" ), prevent_initial_call = True , ) def page_3_download ( n_clicks , fig_mz ): \"\"\"This callback is used to download the spectra of the selected regions when clicking the corresponding button.\"\"\" # Check that there's spectral data to download in the first place if fig_mz is not None : fig_mz = go . Figure ( data = fig_mz ) if len ( fig_mz . data ) > 1 : # Excel writer for download def to_excel ( bytes_io ): xlsx_writer = pd . ExcelWriter ( bytes_io , engine = \"xlsxwriter\" ) for i , data in enumerate ( fig_mz . data ): if i % 2 == 0 : df = pd . DataFrame . from_dict ( { \"m/z\" : data [ \"x\" ], \"Intensity\" : data [ \"y\" ], \"Lipid\" : data [ \"text\" ], } ) df . to_excel ( xlsx_writer , index = False , sheet_name = \"Annotated spectrum sel \" + str ( i // 2 + 1 ), ) else : df = pd . DataFrame . from_dict ({ \"m/z\" : data [ \"x\" ], \"Intensity\" : data [ \"y\" ]}) df . to_excel ( xlsx_writer , index = False , sheet_name = \"Remaining spectrum sel \" + str ( i // 2 + 1 ), ) xlsx_writer . save () return dcc . send_data_frame ( to_excel , \"my_region_selection_data.xlsx\" ) return dash . no_update","title":"page_3_download()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_draw_heatmap_per_lipid_selection","text":"This callback is used to plot the heatmap representing the differential lipid expression in the different regions of the current selection. Source code in pages/region_analysis.py 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 @app . callback ( Output ( \"page-3-graph-heatmap-per-lipid\" , \"figure\" ), Output ( \"page-3-dcc-store-lipids-region\" , \"data\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"page-3-sort-by-diff-switch\" , \"checked\" ), Input ( \"page-4-slider\" , \"value\" ), Input ( \"main-slider\" , \"data\" ), Input ( \"dcc-store-list-mz-spectra\" , \"data\" ), State ( \"page-3-dropdown-brain-regions\" , \"value\" ), State ( \"dcc-store-shapes-and-masks\" , \"data\" ), State ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), State ( \"session-id\" , \"data\" ), prevent_intial_call = True , ) def page_3_draw_heatmap_per_lipid_selection ( cliked_reset , sort_switch , percentile , slice_index , l_spectra , l_mask_name , l_shapes_and_masks , relayoutData , session_id , ): \"\"\"This callback is used to plot the heatmap representing the differential lipid expression in the different regions of the current selection.\"\"\" # Deactivated switches as_enrichment = False log_transform = False # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # If a new slice is loaded or the page just got loaded, do nothing if len ( id_input ) == 0 : return dash . no_update # Delete everything when clicking reset elif id_input == \"page-3-reset-button\" : return figures . return_heatmap_lipid (), [] # Otherwise compute lipid expression heatmap from spectrum elif ( id_input == \"dcc-store-list-idx-lipids\" or id_input == \"page-3-sort-by-diff-switch\" or id_input == \"page-3-scale-by-mean-switch\" or id_input == \"page-4-slider\" or id_input == \"dcc-store-list-mz-spectra\" ): scale_switch = False # Load figure if l_spectra == \"ok\" : logging . info ( \"Starting computing heatmap now\" ) # Get the actual values for l_spectra and ll_idx_labels and not just the dummy fillings l_spectra = global_spectrum_store ( slice_index , l_shapes_and_masks , l_mask_name , relayoutData , as_enrichment , log_transform , ) ll_idx_labels = global_lipid_index_store ( data , slice_index , l_spectra ) if len ( l_spectra ) > 0 : if len ( ll_idx_labels ) != len ( l_spectra ): print ( \"BUG: the number of received spectra is different from the number of\" \" received annotations\" ) return dash . no_update # Compute average expression for each lipid and each selection set_lipids_idx = set () ll_lipids_idx = [] ll_avg_intensity = [] n_sel = len ( l_spectra ) for spectrum , l_idx_labels in zip ( l_spectra , ll_idx_labels ): array_intensity_with_lipids = np . array ( spectrum , dtype = np . float32 )[ 1 , :] array_idx_labels = np . array ( l_idx_labels , dtype = np . int32 ) l_lipids_idx , l_avg_intensity = compute_avg_intensity_per_lipid ( array_intensity_with_lipids , array_idx_labels ) set_lipids_idx . update ( l_lipids_idx ) ll_lipids_idx . append ( l_lipids_idx ) ll_avg_intensity . append ( l_avg_intensity ) dic_avg_lipids = { idx : [ 0 ] * n_sel for idx in set_lipids_idx } for i , ( l_lipids , l_avg_intensity ) in enumerate ( zip ( ll_lipids_idx , ll_avg_intensity ) ): for lipid , intensity in zip ( l_lipids , l_avg_intensity ): dic_avg_lipids [ lipid ][ i ] = intensity l_sel = [ \"Blue sel.\" , \"Green sel.\" , \"Orange sel.\" , \"Red sel.\" ] df_avg_intensity_lipids = pd . DataFrame . from_dict ( dic_avg_lipids , orient = \"index\" , columns = [ l_sel [ i ] for i in range ( n_sel )] ) # Exclude very lowly expressed lipids df_min_expression = df_avg_intensity_lipids . min ( axis = 1 ) df_avg_intensity_lipids = df_avg_intensity_lipids [ df_min_expression > df_min_expression . quantile ( q = int ( percentile ) / 100 ) ] # Rescale according to row mean if scale_switch and n_sel > 1 : df_avg_intensity_lipids = df_avg_intensity_lipids . divide ( df_avg_intensity_lipids . mean ( axis = 1 ), axis = 0 ) # Sort by relative std if sort_switch and n_sel > 1 : df_avg_intensity_lipids = df_avg_intensity_lipids . iloc [ ( df_avg_intensity_lipids . std ( axis = 1 ) / df_avg_intensity_lipids . mean ( axis = 1 ) ) . argsort (), :, ] else : if n_sel > 1 : df_avg_intensity_lipids = df_avg_intensity_lipids . iloc [ ( df_avg_intensity_lipids . mean ( axis = 1 )) . argsort (), : ] else : df_avg_intensity_lipids . sort_values ( by = l_sel [ 0 ], inplace = True ) l_idx_lipids = list ( df_avg_intensity_lipids . index ) # Replace idx_lipids by actual name df_names = data . get_annotations ()[ data . get_annotations ()[ \"slice\" ] == slice_index ] df_avg_intensity_lipids . index = df_avg_intensity_lipids . index . map ( lambda idx : df_names . iloc [ idx ][ \"name\" ] + \"_\" + df_names . iloc [ idx ][ \"structure\" ] + \"_\" + df_names . iloc [ idx ][ \"cation\" ] ) # Plot fig_heatmap_lipids = go . Figure ( data = go . Heatmap ( z = df_avg_intensity_lipids . to_numpy (), y = df_avg_intensity_lipids . index , x = df_avg_intensity_lipids . columns , ygap = 0.2 , colorscale = \"Blues\" , ) ) fig_heatmap_lipids = figures . return_heatmap_lipid ( fig_heatmap_lipids ) logging . info ( \"Heatmap computed. Returning it now\" ) return fig_heatmap_lipids , l_idx_lipids return dash . no_update","title":"page_3_draw_heatmap_per_lipid_selection()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_empty_dropdown","text":"This callback empties the dropdown options for the brain regions when clicking reset or changing slice. Source code in pages/region_analysis.py 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 @app . callback ( Output ( \"page-3-dropdown-brain-regions\" , \"value\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"main-slider\" , \"data\" ), prevent_initial_call = True , ) def page_3_empty_dropdown ( clicked_reset , slice_index ): \"\"\"This callback empties the dropdown options for the brain regions when clicking reset or changing slice.\"\"\" return []","title":"page_3_empty_dropdown()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_fill_dropdown_options","text":"This callback is used to fill the dropdown options with the most differentially expressed lipids in the corresponding heatmap. Source code in pages/region_analysis.py 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 @app . callback ( Output ( \"page-3-dropdown-red\" , \"options\" ), Output ( \"page-3-dropdown-green\" , \"options\" ), Output ( \"page-3-dropdown-blue\" , \"options\" ), Output ( \"page-3-dropdown-red\" , \"value\" ), Output ( \"page-3-dropdown-green\" , \"value\" ), Output ( \"page-3-dropdown-blue\" , \"value\" ), Output ( \"page-3-open-modal\" , \"n_clicks\" ), Input ( \"page-3-dcc-store-lipids-region\" , \"data\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"main-slider\" , \"data\" ), State ( \"page-3-open-modal\" , \"n_clicks\" ), prevent_initial_call = True , ) def page_3_fill_dropdown_options ( l_idx_lipids , cliked_reset , slice_index , n_clicks ): \"\"\"This callback is used to fill the dropdown options with the most differentially expressed lipids in the corresponding heatmap.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # If a new slice is loaded or the page just got loaded, do nothing if len ( id_input ) == 0 : return dash . no_update # Delete everything when clicking reset elif id_input == \"page-3-reset-button\" : return [], [], [], [], [], [], None # Otherwise compute lipid expression heatmap from spectrum elif id_input == \"page-3-dcc-store-lipids-region\" : if l_idx_lipids is not None : if len ( l_idx_lipids ) > 0 : logging . info ( \"Starting computing lipid dropdown now.\" ) df_names = data . get_annotations ()[ data . get_annotations ()[ \"slice\" ] == slice_index ] l_names = [ df_names . iloc [ idx ][ \"name\" ] + \"_\" + df_names . iloc [ idx ][ \"structure\" ] + \"_\" + df_names . iloc [ idx ][ \"cation\" ] for idx in l_idx_lipids ] options = [ { \"label\" : name , \"value\" : str ( idx )} for name , idx in zip ( l_names , l_idx_lipids ) ] # dropdown is displayed in reversed order options . reverse () if n_clicks is None : n_clicks = 0 if len ( options ) > 0 : logging . info ( \"Dropdown values computed. Updating it with new lipids now.\" ) return ( options , options , options , [ options [ 0 ][ \"value\" ]], [ options [ 1 ][ \"value\" ]], [ options [ 2 ][ \"value\" ]], n_clicks + 1 , ) return dash . no_update","title":"page_3_fill_dropdown_options()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_hover","text":"This callback is used to update the text displayed when hovering over the slice image. Source code in pages/region_analysis.py 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 @app . callback ( Output ( \"page-3-graph-hover-text\" , \"children\" ), Input ( \"page-3-graph-heatmap-per-sel\" , \"hoverData\" ), Input ( \"main-slider\" , \"data\" ), ) def page_3_hover ( hoverData , slice_index ): \"\"\"This callback is used to update the text displayed when hovering over the slice image.\"\"\" # If there is a region hovered, find out the region name with the current coordinates if hoverData is not None : if len ( hoverData [ \"points\" ]) > 0 : x = int ( slice_index ) - 1 z = hoverData [ \"points\" ][ 0 ][ \"x\" ] y = hoverData [ \"points\" ][ 0 ][ \"y\" ] slice_coor_rescaled = np . asarray ( ( atlas . array_coordinates_warped_data [ x , y , z ] * 1000 / atlas . resolution ) . round ( 0 ), dtype = np . int16 , ) try : label = atlas . labels [ tuple ( slice_coor_rescaled )] except : label = \"undefined\" return \"Hovered region: \" + label return dash . no_update","title":"page_3_hover()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_plot_heatmap","text":"This callback is used to plot the main heatmap of the page. Source code in pages/region_analysis.py 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 @app . callback ( Output ( \"page-3-graph-heatmap-per-sel\" , \"figure\" ), Output ( \"dcc-store-color-mask\" , \"data\" ), Output ( \"dcc-store-reset\" , \"data\" ), Output ( \"dcc-store-shapes-and-masks\" , \"data\" ), Input ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), Input ( \"main-slider\" , \"data\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"page-3-dropdown-brain-regions\" , \"value\" ), Input ( \"url\" , \"pathname\" ), State ( \"dcc-store-color-mask\" , \"data\" ), State ( \"dcc-store-reset\" , \"data\" ), State ( \"dcc-store-shapes-and-masks\" , \"data\" ), prevent_inital_call = True , ) def page_3_plot_heatmap ( relayoutData , slice_index , cliked_reset , l_mask_name , url , l_color_mask , reset , l_shapes_and_masks , ): \"\"\"This callback is used to plot the main heatmap of the page.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # If a new slice is loaded or the page just got loaded # do nothing because of automatic relayout of the heatmap which is automatically triggered when # the page is loaded if ( id_input == \"main-slider\" or len ( id_input ) == 0 or id_input == \"page-3-reset-button\" or id_input == \"url\" ): fig = storage . return_shelved_object ( \"figures/load_page\" , \"figure_basic_image\" , force_update = False , compute_function = figures . compute_figure_basic_image , type_figure = \"projection_corrected\" , index_image = slice_index - 1 , plot_atlas_contours = False , ) fig . update_layout ( dragmode = \"drawclosedpath\" , newshape = dict ( fillcolor = config . l_colors [ 0 ], opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ) ), autosize = True , ) return fig , [], True , [] # Fix bug with automatic relayout if value_input == \"relayoutData\" and relayoutData == { \"autosize\" : True }: return dash . no_update # Fix other bug with automatic dropdown selection if ( id_input == \"page-3-dropdown-brain-regions \" and relayoutData is None and cliked_reset is None and ( l_mask_name is None or len ( l_mask_name ) == 0 ) ): fig = storage . return_shelved_object ( \"figures/load_page\" , \"figure_basic_image\" , force_update = False , compute_function = figures . compute_figure_basic_image , type_figure = \"projection_corrected\" , index_image = slice_index - 1 , plot_atlas_contours = False , ) fig . update_layout ( dragmode = \"drawclosedpath\" , newshape = dict ( fillcolor = config . l_colors [ 0 ], opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ) ), autosize = True , ) return fig , [], True , [] # If the user selected a new mask or drew on the plot if id_input == \"page-3-graph-heatmap-per-sel\" or id_input == \"page-3-dropdown-brain-regions\" : # Check that a mask has actually been selected if l_mask_name is not None or relayoutData is not None : # Rebuild figure fig = storage . return_shelved_object ( \"figures/load_page\" , \"figure_basic_image\" , force_update = False , compute_function = figures . compute_figure_basic_image , type_figure = \"projection_corrected\" , index_image = slice_index - 1 , plot_atlas_contours = False , ) color_idx = None col_next = None if l_mask_name is not None : # If a mask has been selected if len ( l_mask_name ) > 0 : for idx_mask , mask_name in enumerate ( l_mask_name ): id_name = atlas . dic_name_acronym [ mask_name ] if id_name in atlas . dic_existing_masks [ slice_index - 1 ]: projected_mask = atlas . get_projected_mask_and_spectrum ( slice_index - 1 , mask_name , MAIA_correction = False )[ 0 ] else : logging . warning ( \"The mask \" + str ( mask_name ) + \" couldn't be found\" ) # Build a list of empty images and add selected lipids for each channel normalized_projected_mask = projected_mask / np . max ( projected_mask ) # Correct bug with atlas projection normalized_projected_mask [:, : 10 ] = 0 if idx_mask < len ( l_color_mask ): color_rgb = l_color_mask [ idx_mask ] else : color_idx = len ( l_color_mask ) if relayoutData is not None : if \"shapes\" in relayoutData : color_idx += len ( relayoutData [ \"shapes\" ]) color = config . l_colors [ color_idx % 4 ][ 1 :] color_rgb = [ int ( color [ i : i + 2 ], 16 ) for i in ( 0 , 2 , 4 )] + [ 200 ] l_color_mask . append ( color_rgb ) l_images = [ normalized_projected_mask * color for c , color in zip ([ \"r\" , \"g\" , \"b\" , \"a\" ], color_rgb ) ] # Reoder axis to match plotly go.image requirements array_image = np . moveaxis ( np . array ( l_images , dtype = np . uint8 ), 0 , 2 ) # Convert image to string to save space (new image as each mask must have a # different color) base64_string = convert_image_to_base64 ( array_image , optimize = True , format = \"webp\" , type = \"RGBA\" ) fig . add_trace ( go . Image ( visible = True , source = base64_string , hoverinfo = \"skip\" ) ) fig . update_layout ( dragmode = \"drawclosedpath\" , ) if id_input == \"page-3-dropdown-brain-regions\" and color_idx is not None : # Save in l_shapes_and_masks l_shapes_and_masks . append ([ \"mask\" , mask_name , base64_string , color_idx ]) # If a region has been drawn by the user if relayoutData is not None : if \"shapes\" in relayoutData : if len ( relayoutData [ \"shapes\" ]) > 0 : if not reset or value_input == \"relayoutData\" : if \"path\" in relayoutData [ \"shapes\" ][ - 1 ]: fig [ \"layout\" ][ \"shapes\" ] = relayoutData [ \"shapes\" ] # col_next = config . l_colors [ ( len ( relayoutData [ \"shapes\" ]) + len ( l_color_mask )) % 4 ] # compute color and save in l_shapes_and_masks if id_input == \"page-3-graph-heatmap-per-sel\" : color_idx_for_registration = len ( l_color_mask ) if relayoutData is not None : if \"shapes\" in relayoutData : color_idx_for_registration += len ( relayoutData [ \"shapes\" ] ) l_shapes_and_masks . append ( [ \"shape\" , None , relayoutData [ \"shapes\" ][ - 1 ], color_idx_for_registration - 1 , ] ) # Update col_next if color_idx is not None and col_next is None : col_next = config . l_colors [( color_idx + 1 ) % 4 ] elif col_next is None : col_next = config . l_colors [ 0 ] fig . update_layout ( dragmode = \"drawclosedpath\" , newshape = dict ( fillcolor = col_next , opacity = 0.7 , line = dict ( color = \"white\" , width = 1 ), ), ) # Update drag mode if relayoutData is not None : if \"shapes\" in relayoutData : if len ( relayoutData [ \"shapes\" ]) + len ( l_color_mask ) > 3 : fig . update_layout ( dragmode = False ) if len ( l_color_mask ) > 3 : fig . update_layout ( dragmode = False ) # Return figure and corresponding data return fig , l_color_mask , False , l_shapes_and_masks # either graph is already here return dash . no_update","title":"page_3_plot_heatmap()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_plot_spectrum","text":"This callback is used to plot the spectra of the selected region(s). Source code in pages/region_analysis.py 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 @app . callback ( Output ( \"page-3-graph-spectrum-per-pixel\" , \"figure\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"dcc-store-list-mz-spectra\" , \"data\" ), Input ( \"main-slider\" , \"data\" ), State ( \"page-3-dropdown-brain-regions\" , \"value\" ), State ( \"dcc-store-shapes-and-masks\" , \"data\" ), State ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), prevent_intial_call = True , ) def page_3_plot_spectrum ( cliked_reset , l_spectra , slice_index , l_mask_name , l_shapes_and_masks , relayoutData , ): \"\"\"This callback is used to plot the spectra of the selected region(s).\"\"\" # Deactivated switches as_enrichment = False log_transform = False # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # If a new slice is loaded or the page just got loaded, do nothing if len ( id_input ) == 0 : return dash . no_update # Delete everything when clicking reset elif id_input == \"page-3-reset-button\" or l_spectra is None or l_spectra == []: return figures . return_empty_spectrum () # Do nothing if l_spectra is None or [] elif id_input == \"dcc-store-list-mz-spectra\" : if len ( l_spectra ) > 0 or l_spectra == \"ok\" : logging . info ( \"Starting spectra plotting now\" ) fig_mz = go . Figure () # Compute the average spectra l_spectra = global_spectrum_store ( slice_index , l_shapes_and_masks , l_mask_name , relayoutData , as_enrichment , log_transform , ) ll_idx_labels = global_lipid_index_store ( data , slice_index , l_spectra ) for idx_spectra , ( spectrum , l_idx_labels ) in enumerate ( zip ( l_spectra , ll_idx_labels )): # Find color of the current spectrum col = config . l_colors [ idx_spectra % 4 ] # Compute (again) the numpy array of the spectrum grah_scattergl_data = np . array ( spectrum , dtype = np . float32 ) # Two different functions so that's there's a unique output for each numba function l_idx_kept = return_idx_sup ( l_idx_labels ) l_idx_unkept = return_idx_inf ( l_idx_labels ) # Pad annotated trace with zeros ( grah_scattergl_data_padded_annotated , array_index_padding , ) = add_zeros_to_spectrum ( grah_scattergl_data [:, l_idx_kept ], pad_individual_peaks = True , padding = 10 **- 4 , ) l_mz_with_lipids = grah_scattergl_data_padded_annotated [ 0 , :] l_intensity_with_lipids = grah_scattergl_data_padded_annotated [ 1 , :] l_idx_labels_kept = l_idx_labels [ l_idx_kept ] # @njit # We need to wait for the support of np.insert, still relatively fast anyway def pad_l_idx_labels ( l_idx_labels_kept , array_index_padding ): pad = 0 # The initial condition in the loop is only evaluated once so no problem with # insertion afterwards for i in range ( len ( l_idx_labels_kept )): # Array_index_padding[i] will be 0 or 2 (peaks are padded with 2 zeros, one # on each side) for j in range ( array_index_padding [ i ]): # i+1 instead of i plus insert on the right of the element i l_idx_labels_kept = np . insert ( l_idx_labels_kept , i + 1 + pad , - 1 ) pad += 1 return l_idx_labels_kept l_idx_labels_kept = list ( pad_l_idx_labels ( l_idx_labels_kept , array_index_padding )) # Rebuild lipid name from structure, cation, etc. l_labels_all_lipids = data . compute_l_labels () l_labels = [ l_labels_all_lipids [ idx ] if idx != - 1 else \"\" for idx in l_idx_labels_kept ] # Add annotated trace to plot fig_mz . add_trace ( go . Scattergl ( x = l_mz_with_lipids , y = l_intensity_with_lipids , visible = True , marker_color = col , name = \"Annotated peaks\" , showlegend = True , fill = \"tozeroy\" , hovertemplate = \"Lipid: % {text} <extra></extra>\" , text = l_labels , ) ) # Pad not annotated traces peaks with zeros grah_scattergl_data_padded , array_index_padding = add_zeros_to_spectrum ( grah_scattergl_data [:, l_idx_unkept ], pad_individual_peaks = True , padding = 10 **- 4 , ) l_mz_without_lipids = grah_scattergl_data_padded [ 0 , :] l_intensity_without_lipids = grah_scattergl_data_padded [ 1 , :] # Add not-annotated trace to plot. fig_mz . add_trace ( go . Scattergl ( x = l_mz_without_lipids , y = l_intensity_without_lipids , visible = True , marker_color = col , name = \"Unknown peaks\" , showlegend = True , fill = \"tozeroy\" , opacity = 0.2 , hoverinfo = \"skip\" , # text=l_idx_labels_kept, ) ) # Define figure layout fig_mz . update_layout ( margin = dict ( t = 5 , r = 0 , b = 10 , l = 0 ), showlegend = True , xaxis = dict ( title = \"m/z\" ), yaxis = dict ( title = \"Intensity\" ), template = \"plotly_dark\" , legend = dict ( orientation = \"h\" , yanchor = \"bottom\" , y = 1.02 , xanchor = \"right\" , x = 1.1 ), ) fig_mz . layout . plot_bgcolor = \"rgba(0,0,0,0)\" fig_mz . layout . paper_bgcolor = \"rgba(0,0,0,0)\" logging . info ( \"Spectra plotted. Returning it now\" ) # Return dummy variable for ll_idx_labels to confirm that it has been computed return fig_mz return dash . no_update","title":"page_3_plot_spectrum()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_record_spectra","text":"This callback is used to compute and record the average spectrum of the selected region(s). Source code in pages/region_analysis.py 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 @app . callback ( Output ( \"dcc-store-list-mz-spectra\" , \"data\" ), Input ( \"page-3-button-compute-spectra\" , \"n_clicks\" ), Input ( \"page-3-dcc-store-path-heatmap\" , \"data\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"url\" , \"pathname\" ), Input ( \"main-slider\" , \"data\" ), State ( \"page-3-dropdown-brain-regions\" , \"value\" ), State ( \"dcc-store-shapes-and-masks\" , \"data\" ), State ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), State ( \"session-id\" , \"data\" ), prevent_intial_call = True , ) def page_3_record_spectra ( clicked_compute , l_paths , cliked_reset , url , slice_index , l_mask_name , l_shapes_and_masks , relayoutData , session_id , ): \"\"\"This callback is used to compute and record the average spectrum of the selected region(s).\"\"\" # Deactivated switches as_enrichment = False log_transform = False # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # If a new slice is loaded or the page just got loaded, do nothing because # of automatic relayout of the heatmap which is automatically triggered when the page is loaded if len ( id_input ) == 0 or ( value_input == \"relayoutData\" and relayoutData == { \"autosize\" : True }): return dash . no_update # Delete everything when clicking reset elif id_input == \"page-3-reset-button\" or id_input == \"url\" : return [] # If the user clicked on the button after drawing a region and/or selecting a structure elif id_input == \"page-3-button-compute-spectra\" and len ( l_shapes_and_masks ) > 0 : logging . info ( \"Starting to compute spectrum\" ) l_spectra = global_spectrum_store ( slice_index , l_shapes_and_masks , l_mask_name , relayoutData , as_enrichment , log_transform ) if l_spectra is not None : if l_spectra != []: logging . info ( \"Spectra computed, returning it now\" ) # Return a dummy variable to indicate that the spectrum has been computed and # trigger the callback return \"ok\" logging . warning ( \"A bug appeared during spectrum computation\" ) return []","title":"page_3_record_spectra()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_reset_download","text":"This callback is used to deactivate the download buttons if no region has been drawn. Source code in pages/region_analysis.py 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 @app . callback ( Output ( \"page-3-download-data-button\" , \"disabled\" ), Output ( \"page-3-download-plot-button\" , \"disabled\" ), Output ( \"page-3-download-heatmap-button\" , \"disabled\" ), Input ( \"page-3-graph-spectrum-per-pixel\" , \"figure\" ), ) def page_3_reset_download ( fig_mz ): \"\"\"This callback is used to deactivate the download buttons if no region has been drawn.\"\"\" # Check the presence of spectral data in the corresponding figure if fig_mz is not None : fig_mz = go . Figure ( data = fig_mz ) if len ( fig_mz . data ) > 1 : return False , False , False return True , True , True","title":"page_3_reset_download()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_reset_layout","text":"This callback is used to reset the layout of the heatmap. Source code in pages/region_analysis.py 872 873 874 875 876 877 878 879 880 @app . callback ( Output ( \"page-3-graph-heatmap-per-sel\" , \"relayoutData\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), Input ( \"url\" , \"pathname\" ), prevent_initial_call = True , ) def page_3_reset_layout ( cliked_reset , url ): \"\"\"This callback is used to reset the layout of the heatmap.\"\"\" return {}","title":"page_3_reset_layout()"},{"location":"pages/region_analysis/#pages.region_analysis.page_3_update_dropdown_option","text":"This callback updates the dropdown options for the brain regions. Source code in pages/region_analysis.py 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 @app . callback ( Output ( \"page-3-dropdown-brain-regions\" , \"data\" ), Input ( \"main-slider\" , \"data\" ), ) def page_3_update_dropdown_option ( slice_index ): \"\"\"This callback updates the dropdown options for the brain regions.\"\"\" if slice_index is not None : return [ { \"label\" : atlas . dic_acronym_name [ node ], \"value\" : atlas . dic_acronym_name [ node ]} for node in atlas . dic_existing_masks [ slice_index - 1 ] ] else : return dash . no_update","title":"page_3_update_dropdown_option()"},{"location":"pages/region_analysis/#pages.region_analysis.toggle_button_modal","text":"This callback is used to activate the button to plot the graph for lipid comparison. Source code in pages/region_analysis.py 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 @app . callback ( Output ( \"page-3-open-modal\" , \"disabled\" ), Input ( \"page-3-dropdown-red\" , \"value\" ), Input ( \"page-3-dropdown-green\" , \"value\" ), Input ( \"page-3-dropdown-blue\" , \"value\" ), ) def toggle_button_modal ( l_red_lipids , l_green_lipids , l_blue_lipids ): \"\"\"This callback is used to activate the button to plot the graph for lipid comparison.\"\"\" # Check that at least one lipid has been selected if len ( l_red_lipids + l_green_lipids + l_blue_lipids ) > 0 : return False else : return True","title":"toggle_button_modal()"},{"location":"pages/region_analysis/#pages.region_analysis.toggle_offcanvas","text":"This callback is used to open the drawer containing the lipid expression analysis of the selected region. Source code in pages/region_analysis.py 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 @app . callback ( Output ( \"page-4-drawer-region-selection\" , \"is_open\" ), Input ( \"page-3-button-compute-spectra\" , \"n_clicks\" ), Input ( \"page-4-close-drawer-region-selection\" , \"n_clicks\" ), [ State ( \"page-4-drawer-region-selection\" , \"is_open\" )], ) def toggle_offcanvas ( n1 , n2 , is_open ): \"\"\"This callback is used to open the drawer containing the lipid expression analysis of the selected region.\"\"\" if n1 or n2 : return not is_open return is_open","title":"toggle_offcanvas()"},{"location":"pages/region_analysis/#pages.region_analysis.toggle_visibility_graph","text":"This callback is used to display the graph for differential lipid expression comparison. Source code in pages/region_analysis.py 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 @app . callback ( Output ( \"page-3-div-graph-lipid-comparison\" , \"style\" ), Input ( \"page-3-open-modal\" , \"n_clicks\" ), Input ( \"page-3-reset-button\" , \"n_clicks\" ), State ( \"page-3-dropdown-red\" , \"value\" ), State ( \"page-3-dropdown-green\" , \"value\" ), State ( \"page-3-dropdown-blue\" , \"value\" ), prevent_initial_call = True , ) def toggle_visibility_graph ( n1 , cliked_reset , l_red_lipids , l_green_lipids , l_blue_lipids ): \"\"\"This callback is used to display the graph for differential lipid expression comparison.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # Delete everything when clicking reset if id_input == \"page-3-reset-button\" : return { \"display\" : \"none\" } # Check that at least one lipid has been selected if len ( l_red_lipids + l_green_lipids + l_blue_lipids ) > 0 : return {} else : return { \"display\" : \"none\" }","title":"toggle_visibility_graph()"},{"location":"pages/scRNAseq/","text":"This file contains the page used to explore and compare lipid expression in three-dimensional brain structures. page_5_update_badge_names ( lipid , gene_1 , gene_2 , gene_3 , clicked , current_lipid , current_gene_1 , current_gene_2 , current_gene_3 , brain ) This callback updates the lipid and genes comparison heatmap with the selected lipid and selected genes. Source code in pages/scRNAseq.py 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 @app . callback ( Output ( \"page-5-badge-lipid\" , \"children\" ), Output ( \"page-5-badge-gene-1\" , \"children\" ), Output ( \"page-5-badge-gene-2\" , \"children\" ), Output ( \"page-5-badge-gene-3\" , \"children\" ), Input ( \"page-5-dropdown-lipid\" , \"value\" ), Input ( \"page-5-dropdown-red\" , \"value\" ), Input ( \"page-5-dropdown-green\" , \"value\" ), Input ( \"page-5-dropdown-blue\" , \"value\" ), Input ( \"page-5-display-heatmap-genes\" , \"n_clicks\" ), State ( \"page-5-badge-lipid\" , \"children\" ), State ( \"page-5-badge-gene-1\" , \"children\" ), State ( \"page-5-badge-gene-2\" , \"children\" ), State ( \"page-5-badge-gene-3\" , \"children\" ), Input ( \"main-brain\" , \"value\" ), ) def page_5_update_badge_names ( lipid , gene_1 , gene_2 , gene_3 , clicked , current_lipid , current_gene_1 , current_gene_2 , current_gene_3 , brain , ): \"\"\"This callback updates the lipid and genes comparison heatmap with the selected lipid and selected genes.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] if id_input == \"page-5-display-heatmap-genes\" or id_input == \"main-brain\" : return lipid , gene_1 , gene_2 , gene_3 if ( current_lipid == \"name-lipid-1\" and current_gene_1 == \"name-gene-1\" and current_gene_2 == \"name-gene-2\" and current_gene_3 == \"name-gene-3\" ): return lipid , gene_1 , gene_2 , gene_3 return dash . no_update page_5_update_barplots ( clickData , brain , clicked , clicked_bis ) This callback updates the barplots with the data from the selected spot. Source code in pages/scRNAseq.py 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 @app . callback ( Output ( \"page-5-graph-barplot-lipids\" , \"figure\" ), Output ( \"page-5-graph-barplot-genes\" , \"figure\" ), Output ( \"page-5-graph-barplot-lipids\" , \"className\" ), Output ( \"page-5-graph-barplot-genes\" , \"className\" ), Output ( \"page-5-dropdown-lipid\" , \"value\" ), Output ( \"page-5-dropdown-red\" , \"value\" ), Output ( \"page-5-dropdown-green\" , \"value\" ), Output ( \"page-5-dropdown-blue\" , \"value\" ), Input ( \"page-5-graph-scatter-3D\" , \"clickData\" ), Input ( \"main-brain\" , \"value\" ), Input ( \"page-5-display-avg-data\" , \"n_clicks\" ), Input ( \"page-5-display-avg-data-bis\" , \"n_clicks\" ), prevent_initial_call = False , ) def page_5_update_barplots ( clickData , brain , clicked , clicked_bis ): \"\"\"This callback updates the barplots with the data from the selected spot.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If a spot has has been clicked, update the barplot if id_input == \"page-5-graph-scatter-3D\" : if clickData is not None : if \"points\" in clickData : if len ( clickData [ \"points\" ]) > 0 : idx_dot = clickData [ \"points\" ][ 0 ][ \"pointNumber\" ] ( fig_lipids , fig_genes , l_genes , l_lipids ,) = ( figures . compute_barplots_enrichment ( brain_1 = True , idx_dot = idx_dot ) if brain == \"brain_1\" else figures . compute_barplots_enrichment ( brain_1 = False , idx_dot = idx_dot ) ) return ( fig_lipids , fig_genes , \"w-100 h-100\" , \"w-100 h-100\" , l_lipids [ 0 ], l_genes [ 0 ], l_genes [ 1 ], l_genes [ 2 ], ) elif brain is not None : ( fig_lipids , fig_genes , l_genes , l_lipids ,) = ( figures . compute_barplots_enrichment ( brain_1 = True , idx_dot = None ) if brain == \"brain_1\" else figures . compute_barplots_enrichment ( brain_1 = False , idx_dot = None ) ) return ( fig_lipids , fig_genes , \"w-100 h-100\" , \"w-100 h-100\" , l_lipids [ 0 ], l_genes [ 0 ], l_genes [ 1 ], l_genes [ 2 ], ) page_5_update_dropdown_options ( brain ) This callback updates the lipid and genes dropdown options depening on the selected brain. Source code in pages/scRNAseq.py 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 @app . callback ( Output ( \"page-5-dropdown-lipid\" , \"options\" ), Output ( \"page-5-dropdown-red\" , \"options\" ), Output ( \"page-5-dropdown-green\" , \"options\" ), Output ( \"page-5-dropdown-blue\" , \"options\" ), Input ( \"main-brain\" , \"value\" ), ) def page_5_update_dropdown_options ( brain ): \"\"\"This callback updates the lipid and genes dropdown options depening on the selected brain.\"\"\" options_genes = ( figures . _scRNAseq . l_genes_brain_1 if brain == \"brain_1\" else figures . _scRNAseq . l_genes_brain_2 ) options_lipids = ( figures . _scRNAseq . l_name_lipids_brain_1 if brain == \"brain_1\" else figures . _scRNAseq . l_name_lipids_brain_2 ) return options_lipids , options_genes , options_genes , options_genes page_5_update_heatmap_lipid ( set_progress , lipid , gene_1 , gene_2 , gene_3 , clicked , brain ) This callback updates the lipid and genes comparison heatmap with the selected lipid and selected genes. Source code in pages/scRNAseq.py 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 @app . long_callback ( output = Output ( \"page-5-graph-heatmap-lipid\" , \"figure\" ), inputs = [ State ( \"page-5-dropdown-lipid\" , \"value\" ), State ( \"page-5-dropdown-red\" , \"value\" ), State ( \"page-5-dropdown-green\" , \"value\" ), State ( \"page-5-dropdown-blue\" , \"value\" ), Input ( \"page-5-display-heatmap-genes\" , \"n_clicks\" ), Input ( \"main-brain\" , \"value\" ), ], running = [ ( Output ( \"page-5-progress-bar-structure\" , \"className\" ), \"\" , \"d-none\" , ), ( Output ( \"page-5-download-lipid-plot-button\" , \"disabled\" ), True , False ), ( Output ( \"page-5-display-heatmap-genes\" , \"disabled\" ), True , False ), ( Output ( \"page-5-graph-heatmap-lipid\" , \"className\" ), \"d-none\" , \"\" ), ], progress = [ Output ( \"page-5-progress-bar-structure\" , \"value\" ), Output ( \"page-5-progress-bar-structure\" , \"label\" ), ], prevent_initial_call = True , cache_args_to_ignore = [ 4 ], ) def page_5_update_heatmap_lipid ( set_progress , lipid , gene_1 , gene_2 , gene_3 , clicked , brain ): \"\"\"This callback updates the lipid and genes comparison heatmap with the selected lipid and selected genes.\"\"\" # If no click has been done, just return nothing if clicked is None : return dash . no_update # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If a spot has has been clicked, update the barplot if lipid is not None or gene_1 is not None or gene_2 is not None or gene_3 is not None : l_genes = [ gene_1 , gene_2 , gene_3 ] return ( figures . compute_heatmap_lipid_genes ( lipid , l_genes , brain_1 = True , set_progress = set_progress ) if brain == \"brain_1\" else figures . compute_heatmap_lipid_genes ( lipid , l_genes , brain_1 = False , set_progress = set_progress ) ) else : return {}","title":"scRNAseq"},{"location":"pages/scRNAseq/#pages.scRNAseq.page_5_update_badge_names","text":"This callback updates the lipid and genes comparison heatmap with the selected lipid and selected genes. Source code in pages/scRNAseq.py 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 @app . callback ( Output ( \"page-5-badge-lipid\" , \"children\" ), Output ( \"page-5-badge-gene-1\" , \"children\" ), Output ( \"page-5-badge-gene-2\" , \"children\" ), Output ( \"page-5-badge-gene-3\" , \"children\" ), Input ( \"page-5-dropdown-lipid\" , \"value\" ), Input ( \"page-5-dropdown-red\" , \"value\" ), Input ( \"page-5-dropdown-green\" , \"value\" ), Input ( \"page-5-dropdown-blue\" , \"value\" ), Input ( \"page-5-display-heatmap-genes\" , \"n_clicks\" ), State ( \"page-5-badge-lipid\" , \"children\" ), State ( \"page-5-badge-gene-1\" , \"children\" ), State ( \"page-5-badge-gene-2\" , \"children\" ), State ( \"page-5-badge-gene-3\" , \"children\" ), Input ( \"main-brain\" , \"value\" ), ) def page_5_update_badge_names ( lipid , gene_1 , gene_2 , gene_3 , clicked , current_lipid , current_gene_1 , current_gene_2 , current_gene_3 , brain , ): \"\"\"This callback updates the lipid and genes comparison heatmap with the selected lipid and selected genes.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] if id_input == \"page-5-display-heatmap-genes\" or id_input == \"main-brain\" : return lipid , gene_1 , gene_2 , gene_3 if ( current_lipid == \"name-lipid-1\" and current_gene_1 == \"name-gene-1\" and current_gene_2 == \"name-gene-2\" and current_gene_3 == \"name-gene-3\" ): return lipid , gene_1 , gene_2 , gene_3 return dash . no_update","title":"page_5_update_badge_names()"},{"location":"pages/scRNAseq/#pages.scRNAseq.page_5_update_barplots","text":"This callback updates the barplots with the data from the selected spot. Source code in pages/scRNAseq.py 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 @app . callback ( Output ( \"page-5-graph-barplot-lipids\" , \"figure\" ), Output ( \"page-5-graph-barplot-genes\" , \"figure\" ), Output ( \"page-5-graph-barplot-lipids\" , \"className\" ), Output ( \"page-5-graph-barplot-genes\" , \"className\" ), Output ( \"page-5-dropdown-lipid\" , \"value\" ), Output ( \"page-5-dropdown-red\" , \"value\" ), Output ( \"page-5-dropdown-green\" , \"value\" ), Output ( \"page-5-dropdown-blue\" , \"value\" ), Input ( \"page-5-graph-scatter-3D\" , \"clickData\" ), Input ( \"main-brain\" , \"value\" ), Input ( \"page-5-display-avg-data\" , \"n_clicks\" ), Input ( \"page-5-display-avg-data-bis\" , \"n_clicks\" ), prevent_initial_call = False , ) def page_5_update_barplots ( clickData , brain , clicked , clicked_bis ): \"\"\"This callback updates the barplots with the data from the selected spot.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If a spot has has been clicked, update the barplot if id_input == \"page-5-graph-scatter-3D\" : if clickData is not None : if \"points\" in clickData : if len ( clickData [ \"points\" ]) > 0 : idx_dot = clickData [ \"points\" ][ 0 ][ \"pointNumber\" ] ( fig_lipids , fig_genes , l_genes , l_lipids ,) = ( figures . compute_barplots_enrichment ( brain_1 = True , idx_dot = idx_dot ) if brain == \"brain_1\" else figures . compute_barplots_enrichment ( brain_1 = False , idx_dot = idx_dot ) ) return ( fig_lipids , fig_genes , \"w-100 h-100\" , \"w-100 h-100\" , l_lipids [ 0 ], l_genes [ 0 ], l_genes [ 1 ], l_genes [ 2 ], ) elif brain is not None : ( fig_lipids , fig_genes , l_genes , l_lipids ,) = ( figures . compute_barplots_enrichment ( brain_1 = True , idx_dot = None ) if brain == \"brain_1\" else figures . compute_barplots_enrichment ( brain_1 = False , idx_dot = None ) ) return ( fig_lipids , fig_genes , \"w-100 h-100\" , \"w-100 h-100\" , l_lipids [ 0 ], l_genes [ 0 ], l_genes [ 1 ], l_genes [ 2 ], )","title":"page_5_update_barplots()"},{"location":"pages/scRNAseq/#pages.scRNAseq.page_5_update_dropdown_options","text":"This callback updates the lipid and genes dropdown options depening on the selected brain. Source code in pages/scRNAseq.py 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 @app . callback ( Output ( \"page-5-dropdown-lipid\" , \"options\" ), Output ( \"page-5-dropdown-red\" , \"options\" ), Output ( \"page-5-dropdown-green\" , \"options\" ), Output ( \"page-5-dropdown-blue\" , \"options\" ), Input ( \"main-brain\" , \"value\" ), ) def page_5_update_dropdown_options ( brain ): \"\"\"This callback updates the lipid and genes dropdown options depening on the selected brain.\"\"\" options_genes = ( figures . _scRNAseq . l_genes_brain_1 if brain == \"brain_1\" else figures . _scRNAseq . l_genes_brain_2 ) options_lipids = ( figures . _scRNAseq . l_name_lipids_brain_1 if brain == \"brain_1\" else figures . _scRNAseq . l_name_lipids_brain_2 ) return options_lipids , options_genes , options_genes , options_genes","title":"page_5_update_dropdown_options()"},{"location":"pages/scRNAseq/#pages.scRNAseq.page_5_update_heatmap_lipid","text":"This callback updates the lipid and genes comparison heatmap with the selected lipid and selected genes. Source code in pages/scRNAseq.py 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 @app . long_callback ( output = Output ( \"page-5-graph-heatmap-lipid\" , \"figure\" ), inputs = [ State ( \"page-5-dropdown-lipid\" , \"value\" ), State ( \"page-5-dropdown-red\" , \"value\" ), State ( \"page-5-dropdown-green\" , \"value\" ), State ( \"page-5-dropdown-blue\" , \"value\" ), Input ( \"page-5-display-heatmap-genes\" , \"n_clicks\" ), Input ( \"main-brain\" , \"value\" ), ], running = [ ( Output ( \"page-5-progress-bar-structure\" , \"className\" ), \"\" , \"d-none\" , ), ( Output ( \"page-5-download-lipid-plot-button\" , \"disabled\" ), True , False ), ( Output ( \"page-5-display-heatmap-genes\" , \"disabled\" ), True , False ), ( Output ( \"page-5-graph-heatmap-lipid\" , \"className\" ), \"d-none\" , \"\" ), ], progress = [ Output ( \"page-5-progress-bar-structure\" , \"value\" ), Output ( \"page-5-progress-bar-structure\" , \"label\" ), ], prevent_initial_call = True , cache_args_to_ignore = [ 4 ], ) def page_5_update_heatmap_lipid ( set_progress , lipid , gene_1 , gene_2 , gene_3 , clicked , brain ): \"\"\"This callback updates the lipid and genes comparison heatmap with the selected lipid and selected genes.\"\"\" # If no click has been done, just return nothing if clicked is None : return dash . no_update # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If a spot has has been clicked, update the barplot if lipid is not None or gene_1 is not None or gene_2 is not None or gene_3 is not None : l_genes = [ gene_1 , gene_2 , gene_3 ] return ( figures . compute_heatmap_lipid_genes ( lipid , l_genes , brain_1 = True , set_progress = set_progress ) if brain == \"brain_1\" else figures . compute_heatmap_lipid_genes ( lipid , l_genes , brain_1 = False , set_progress = set_progress ) ) else : return {}","title":"page_5_update_heatmap_lipid()"},{"location":"pages/sidebar/","text":"This file contains the layout for the sidebar of the app.","title":"sidebar"},{"location":"pages/threeD_exploration/","text":"This file contains the page used to explore and compare lipid expression in three-dimensional brain structures. page_4_active_display ( l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , region_1_id , region_2_id , region_3_id , brain ) This callback is used to enable/disable the display buttons (for both clustergram and volume plots). Source code in pages/threeD_exploration.py 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 @app . callback ( Output ( \"page-4-display-button\" , \"disabled\" ), Output ( \"page-4-compare-structure-button\" , \"disabled\" ), Input ( \"page-4-selected-lipid-1\" , \"data\" ), Input ( \"page-4-selected-lipid-2\" , \"data\" ), Input ( \"page-4-selected-lipid-3\" , \"data\" ), Input ( \"page-4-selected-region-1\" , \"data\" ), Input ( \"page-4-selected-region-2\" , \"data\" ), Input ( \"page-4-selected-region-3\" , \"data\" ), State ( \"main-brain\" , \"value\" ), ) def page_4_active_display ( l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , region_1_id , region_2_id , region_3_id , brain ): \"\"\"This callback is used to enable/disable the display buttons (for both clustergram and volume plots).\"\"\" # Compute number of slices for current brain n_slices = len ( data . get_slice_list ( indices = brain )) # If at least two structures if ( ( region_1_id != \"\" and region_2_id != \"\" ) or ( region_1_id != \"\" and region_3_id != \"\" ) or ( region_2_id != \"\" and region_3_id != \"\" ) ): # If at least one lipid, activate both buttons, else only the clustergram button: if np . sum ( l_lipid_1_index + l_lipid_2_index + l_lipid_3_index ) > - 3 * n_slices : return False , False else : return True , False # If just one structure, deactivate clustergram button if region_1_id != \"\" or region_2_id != \"\" or region_3_id != \"\" : # If at least one lipid, activate volume plot button: if np . sum ( l_lipid_1_index + l_lipid_2_index + l_lipid_3_index ) > - 3 * n_slices : return False , True else : return True , True # Defaults is both buttons are disabled return True , True page_4_add_toast_region_selection ( clicked_add , bool_toast_1 , bool_toast_2 , bool_toast_3 , region_1_id , region_2_id , region_3_id , header_1 , header_2 , header_3 , l_selected_regions , label_region ) This callback checks for a free spot and adds the selected region to the selection when clicking on the 'add structure' button. Source code in pages/threeD_exploration.py 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 @app . callback ( Output ( \"page-4-toast-region-1\" , \"header\" ), Output ( \"page-4-toast-region-2\" , \"header\" ), Output ( \"page-4-toast-region-3\" , \"header\" ), Output ( \"page-4-selected-region-1\" , \"data\" ), Output ( \"page-4-selected-region-2\" , \"data\" ), Output ( \"page-4-selected-region-3\" , \"data\" ), Output ( \"page-4-toast-region-1\" , \"is_open\" ), Output ( \"page-4-toast-region-2\" , \"is_open\" ), Output ( \"page-4-toast-region-3\" , \"is_open\" ), Output ( \"page-4-last-selected-regions\" , \"data\" ), Input ( \"page-4-add-structure-button\" , \"n_clicks\" ), Input ( \"page-4-toast-region-1\" , \"is_open\" ), Input ( \"page-4-toast-region-2\" , \"is_open\" ), Input ( \"page-4-toast-region-3\" , \"is_open\" ), State ( \"page-4-selected-region-1\" , \"data\" ), State ( \"page-4-selected-region-2\" , \"data\" ), State ( \"page-4-selected-region-3\" , \"data\" ), State ( \"page-4-toast-region-1\" , \"header\" ), State ( \"page-4-toast-region-2\" , \"header\" ), State ( \"page-4-toast-region-3\" , \"header\" ), State ( \"page-4-last-selected-regions\" , \"data\" ), State ( \"page-4-add-structure-button\" , \"children\" ), ) def page_4_add_toast_region_selection ( clicked_add , bool_toast_1 , bool_toast_2 , bool_toast_3 , region_1_id , region_2_id , region_3_id , header_1 , header_2 , header_3 , l_selected_regions , label_region , ): \"\"\"This callback checks for a free spot and adds the selected region to the selection when clicking on the 'add structure' button.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] if len ( id_input ) == 0 : return \"\" , \"\" , \"\" , \"\" , \"\" , \"\" , False , False , False , [] # If a region has been deleted from a toast if value_input == \"is_open\" : # Delete corresponding header and index if id_input == \"page-4-toast-region-1\" : header_1 = \"\" l_selected_regions . remove ( region_1_id ) region_1_id = \"\" elif id_input == \"page-4-toast-region-2\" : header_2 = \"\" l_selected_regions . remove ( region_2_id ) region_2_id = \"\" elif id_input == \"page-4-toast-region-3\" : header_3 = \"\" l_selected_regions . remove ( region_3_id ) l_region_3_index = \"\" else : logging . warning ( \"BUG in page_2_add_dropdown_selection\" ) return ( header_1 , header_2 , header_3 , region_1_id , region_2_id , region_3_id , bool_toast_1 , bool_toast_2 , bool_toast_3 , l_selected_regions , ) # Otherwise, add region to selection elif id_input == \"page-4-add-structure-button\" : if label_region != \"Please choose a structure above\" : region = label_region . split ( \"Add \" )[ 1 ] . split ( \" to selection\" )[ 0 ] region_id = atlas . dic_name_acronym [ region ] if region_id not in l_selected_regions : l_selected_regions . append ( region_id ) # Check first slot available if not bool_toast_1 : header_1 = region region_1_id = region_id bool_toast_1 = True elif not bool_toast_2 : header_2 = region region_2_id = region_id bool_toast_2 = True elif not bool_toast_3 : header_3 = region region_3_id = region_id bool_toast_3 = True else : logging . warning ( \"BUG, more than 3 regions have been selected\" ) return dash . no_update return ( header_1 , header_2 , header_3 , region_1_id , region_2_id , region_3_id , bool_toast_1 , bool_toast_2 , bool_toast_3 , l_selected_regions , ) # It shouldn't be possible to click, so delete all else : return \"\" , \"\" , \"\" , \"\" , \"\" , \"\" , False , False , False , [] return dash . no_update page_4_add_toast_selection ( cation , n_clicks , bool_toast_1 , bool_toast_2 , bool_toast_3 , name , structure , l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , header_1 , header_2 , header_3 , l_selected_lipids , brain ) This callback is used to add the current choice of lipids (using dropdown) to the selection for further plotting, when clicking on the 'add lipid' button. Source code in pages/threeD_exploration.py 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 @app . callback ( Output ( \"page-4-toast-lipid-1\" , \"header\" ), Output ( \"page-4-toast-lipid-2\" , \"header\" ), Output ( \"page-4-toast-lipid-3\" , \"header\" ), Output ( \"page-4-selected-lipid-1\" , \"data\" ), Output ( \"page-4-selected-lipid-2\" , \"data\" ), Output ( \"page-4-selected-lipid-3\" , \"data\" ), Output ( \"page-4-toast-lipid-1\" , \"is_open\" ), Output ( \"page-4-toast-lipid-2\" , \"is_open\" ), Output ( \"page-4-toast-lipid-3\" , \"is_open\" ), Output ( \"page-4-last-selected-lipids\" , \"data\" ), State ( \"page-4-dropdown-lipid-cations\" , \"value\" ), Input ( \"page-4-add-lipid-button\" , \"n_clicks\" ), Input ( \"page-4-toast-lipid-1\" , \"is_open\" ), Input ( \"page-4-toast-lipid-2\" , \"is_open\" ), Input ( \"page-4-toast-lipid-3\" , \"is_open\" ), State ( \"page-4-dropdown-lipid-names\" , \"value\" ), State ( \"page-4-dropdown-lipid-structures\" , \"value\" ), State ( \"page-4-selected-lipid-1\" , \"data\" ), State ( \"page-4-selected-lipid-2\" , \"data\" ), State ( \"page-4-selected-lipid-3\" , \"data\" ), State ( \"page-4-toast-lipid-1\" , \"header\" ), State ( \"page-4-toast-lipid-2\" , \"header\" ), State ( \"page-4-toast-lipid-3\" , \"header\" ), State ( \"page-4-last-selected-lipids\" , \"data\" ), Input ( \"main-brain\" , \"value\" ), ) def page_4_add_toast_selection ( cation , n_clicks , bool_toast_1 , bool_toast_2 , bool_toast_3 , name , structure , l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , header_1 , header_2 , header_3 , l_selected_lipids , brain , ): \"\"\"This callback is used to add the current choice of lipids (using dropdown) to the selection for further plotting, when clicking on the 'add lipid' button.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] if brain == \"brain_1\" or brain == \"brain_2\" : # Define empty lipid list n_slices = len ( data . get_slice_list ( indices = brain )) empty_lipid_list = [ - 1 for i in range ( n_slices )] # The function shouldn't have been called if brain index is not defined else : return dash . no_update # Take advantage of dash bug that automatically triggers 'page-4-dropdown-lipid-cations' # everytime the page is loaded # If page-4-dropdown-lipid-cations is called while there's no lipid name defined, it means the # page just got loaded if len ( id_input ) == 0 or ( id_input == \"page-4-dropdown-lipid-cations\" and name is None ): return ( \"\" , \"\" , \"\" , empty_lipid_list , empty_lipid_list , empty_lipid_list , False , False , False , [], ) # If a lipid has been deleted from a toast if value_input == \"is_open\" : # Delete corresponding header and index if id_input == \"page-4-toast-lipid-1\" : header_1 = \"\" l_selected_lipids . remove ( l_lipid_1_index [ 0 ]) l_lipid_1_index = empty_lipid_list elif id_input == \"page-4-toast-lipid-2\" : header_2 = \"\" l_selected_lipids . remove ( l_lipid_2_index [ 0 ]) l_lipid_2_index = empty_lipid_list elif id_input == \"page-4-toast-lipid-3\" : header_3 = \"\" l_selected_lipids . remove ( l_lipid_3_index [ 0 ]) l_lipid_3_index = empty_lipid_list else : logging . warning ( \"BUG in page_2_add_dropdown_selection\" ) return ( header_1 , header_2 , header_3 , l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , bool_toast_1 , bool_toast_2 , bool_toast_3 , l_selected_lipids , ) # Otherwise, add lipid to selection elif cation is not None and id_input == \"page-4-add-lipid-button\" : for idx_slice_index , slice_index in enumerate ( data . get_slice_list ( indices = brain )): # Find lipid location l_lipid_loc = ( data . get_annotations () . index [ ( data . get_annotations ()[ \"name\" ] == name ) & ( data . get_annotations ()[ \"structure\" ] == structure ) & ( data . get_annotations ()[ \"slice\" ] == slice_index ) & ( data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) > 1 : logging . warning ( \"More than one lipid corresponds to the selection\" ) l_lipid_loc = [ l_lipid_loc [ - 1 ]] if len ( l_lipid_loc ) == 0 : l_lipid_loc = [ - 1 ] lipid_string = name + \" \" + structure + \" \" + cation if idx_slice_index == 0 : l_selected_lipids . append ( l_lipid_loc [ 0 ]) # Check first slot available if not bool_toast_1 : header_1 = lipid_string l_lipid_1_index [ idx_slice_index ] = l_lipid_loc [ 0 ] if slice_index == data . get_slice_list ( indices = brain )[ - 1 ]: bool_toast_1 = True elif not bool_toast_2 : header_2 = lipid_string l_lipid_2_index [ idx_slice_index ] = l_lipid_loc [ 0 ] if slice_index == data . get_slice_list ( indices = brain )[ - 1 ]: bool_toast_2 = True elif not bool_toast_3 : header_3 = lipid_string l_lipid_3_index [ idx_slice_index ] = l_lipid_loc [ 0 ] if slice_index == data . get_slice_list ( indices = brain )[ - 1 ]: bool_toast_3 = True else : logging . warning ( \"BUG, more than 3 lipids have been selected\" ) return dash . no_update return ( header_1 , header_2 , header_3 , l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , bool_toast_1 , bool_toast_2 , bool_toast_3 , l_selected_lipids , ) # If the brain index has changed, update the corresponding lipid indices elif id_input == \"main-brain\" : # Remove previous lipids information if header_1 != \"\" : l_selected_lipids . remove ( l_lipid_1_index [ 0 ]) l_lipid_1_index = copy . copy ( empty_lipid_list ) if header_2 != \"\" : l_selected_lipids . remove ( l_lipid_2_index [ 0 ]) l_lipid_2_index = copy . copy ( empty_lipid_list ) if header_3 != \"\" : l_selected_lipids . remove ( l_lipid_3_index [ 0 ]) l_lipid_3_index = copy . copy ( empty_lipid_list ) for idx_header , header in enumerate ([ header_1 , header_2 , header_3 ]): if header != \"\" : name , structure , cation = header . split ( \" \" ) for idx_slice_index , slice_index in enumerate ( data . get_slice_list ( indices = brain )): # Find lipid location l_lipid_loc = ( data . get_annotations () . index [ ( data . get_annotations ()[ \"name\" ] == name ) & ( data . get_annotations ()[ \"structure\" ] == structure ) & ( data . get_annotations ()[ \"slice\" ] == slice_index ) & ( data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) > 1 : logging . warning ( \"More than one lipid corresponds to the selection\" ) l_lipid_loc = [ l_lipid_loc [ - 1 ]] if len ( l_lipid_loc ) == 0 : l_lipid_loc = [ - 1 ] if idx_slice_index == 0 : l_selected_lipids . append ( l_lipid_loc [ 0 ]) # Check slot that are already filled if idx_header == 0 : l_lipid_1_index [ idx_slice_index ] = l_lipid_loc [ 0 ] elif idx_header == 1 : l_lipid_2_index [ idx_slice_index ] = l_lipid_loc [ 0 ] elif idx_header == 2 : l_lipid_3_index [ idx_slice_index ] = l_lipid_loc [ 0 ] return ( header_1 , header_2 , header_3 , l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , bool_toast_1 , bool_toast_2 , bool_toast_3 , l_selected_lipids , ) return dash . no_update page_4_click ( clickData , region_1_id , region_2_id , region_3_id ) This callback is used to update the label of the add structure button depending on the number of structures already selected, and the state of the corresponding widget. Source code in pages/threeD_exploration.py 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 @app . callback ( Output ( \"page-4-add-structure-button\" , \"children\" ), Output ( \"page-4-add-structure-button\" , \"disabled\" ), Input ( \"page-4-graph-region-selection\" , \"clickData\" ), Input ( \"page-4-selected-region-1\" , \"data\" ), Input ( \"page-4-selected-region-2\" , \"data\" ), Input ( \"page-4-selected-region-3\" , \"data\" ), ) def page_4_click ( clickData , region_1_id , region_2_id , region_3_id ): \"\"\"This callback is used to update the label of the add structure button depending on the number of structures already selected, and the state of the corresponding widget.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # Check if a structure has already been selected in the widget if id_input == \"page-4-graph-region-selection\" : if clickData is not None : if \"points\" in clickData : label = clickData [ \"points\" ][ 0 ][ \"label\" ] return \"Add \" + label + \" to selection\" , False return \"Please choose a structure above\" , True # If all structures have been selected, disable the button if region_1_id != \"\" and region_2_id != \"\" and region_3_id != \"\" : return \"Delete some structures to select new ones\" , True # If at least one more structure can be added to the selection, command to select one if region_1_id != \"\" or region_2_id != \"\" or region_3_id != \"\" : return \"Please choose a structure above\" , True return dash . no_update page_4_click_lipid ( header_1 , header_2 , header_3 , name , structure , cation ) This callback is used to update the label of the add lipid button, depending on the number of lipids already selected. Source code in pages/threeD_exploration.py 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 @app . callback ( Output ( \"page-4-add-lipid-button\" , \"children\" ), Output ( \"page-4-add-lipid-button\" , \"disabled\" ), Input ( \"page-4-toast-lipid-1\" , \"header\" ), Input ( \"page-4-toast-lipid-2\" , \"header\" ), Input ( \"page-4-toast-lipid-3\" , \"header\" ), State ( \"page-4-dropdown-lipid-names\" , \"value\" ), State ( \"page-4-dropdown-lipid-structures\" , \"value\" ), Input ( \"page-4-dropdown-lipid-cations\" , \"value\" ), ) def page_4_click_lipid ( header_1 , header_2 , header_3 , name , structure , cation ): \"\"\"This callback is used to update the label of the add lipid button, depending on the number of lipids already selected.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If at least one headers is free if header_1 == \"\" or header_2 == \"\" or header_3 == \"\" : if cation is not None and cation != \"\" : # Get lipid name lipid_string = name + \" \" + structure + \" \" + cation # Compare to existing headers if lipid_string not in [ header_1 , header_2 , header_3 ]: return \"Add \" + lipid_string + \" to selection\" , False else : return \"Please choose a lipid that hasn't been selected yet\" , True # If all lipids have been selected, disable the button if header_1 != \"\" and header_2 != \"\" and header_3 != \"\" : return \"Delete some lipids to select new ones\" , True # By default, command to select new lipids return \"Please choose a lipid above\" , True page_4_disable_dropdowns ( l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , brain ) This callback is triggered when a lipid is selected, and enables/disables the corresponding dropdowns. Source code in pages/threeD_exploration.py 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 @app . callback ( Output ( \"page-4-dropdown-lipid-names\" , \"disabled\" ), Output ( \"page-4-dropdown-lipid-structures\" , \"disabled\" ), Output ( \"page-4-dropdown-lipid-cations\" , \"disabled\" ), Input ( \"page-4-selected-lipid-1\" , \"data\" ), Input ( \"page-4-selected-lipid-2\" , \"data\" ), Input ( \"page-4-selected-lipid-3\" , \"data\" ), State ( \"main-brain\" , \"value\" ), ) def page_4_disable_dropdowns ( l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , brain ): \"\"\"This callback is triggered when a lipid is selected, and enables/disables the corresponding dropdowns.\"\"\" # Compute number of slices for current brain n_slices = len ( data . get_slice_list ( indices = brain )) # If all slots are taken, disable all dropdowns if ( np . sum ( l_lipid_1_index ) > - n_slices and np . sum ( l_lipid_2_index ) > - n_slices and np . sum ( l_lipid_3_index ) > - n_slices ): return True , True , True else : return False , False , False page_4_handle_dropdowns ( n_clicks , name , structure , options_names , options_structures , options_cations , brain ) This callback is used to progressively refine dropdown selection for lipid names, structures and cations. It is triggered when a new selection is made in the corresponding dropdowns. Source code in pages/threeD_exploration.py 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 @app . callback ( Output ( \"page-4-dropdown-lipid-names\" , \"data\" ), Output ( \"page-4-dropdown-lipid-structures\" , \"data\" ), Output ( \"page-4-dropdown-lipid-cations\" , \"data\" ), Output ( \"page-4-dropdown-lipid-names\" , \"value\" ), Output ( \"page-4-dropdown-lipid-structures\" , \"value\" ), Output ( \"page-4-dropdown-lipid-cations\" , \"value\" ), Input ( \"page-4-add-lipid-button\" , \"n_clicks\" ), Input ( \"page-4-dropdown-lipid-names\" , \"value\" ), Input ( \"page-4-dropdown-lipid-structures\" , \"value\" ), State ( \"page-4-dropdown-lipid-names\" , \"data\" ), State ( \"page-4-dropdown-lipid-structures\" , \"data\" ), State ( \"page-4-dropdown-lipid-cations\" , \"data\" ), Input ( \"main-brain\" , \"value\" ), ) def page_4_handle_dropdowns ( n_clicks , name , structure , options_names , options_structures , options_cations , brain ): \"\"\"This callback is used to progressively refine dropdown selection for lipid names, structures and cations. It is triggered when a new selection is made in the corresponding dropdowns.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] brain_1 = True if brain == \"brain_1\" else False # If the page just loaded or button 'add lipid' has been clicked, or brain dropdown has changed, reset selection if len ( id_input ) == 0 or id_input == \"page-4-add-lipid-button\" or id_input == \"main-brain\" : options_names = [ { \"label\" : name , \"value\" : name } for name in sorted ( data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 ) . name . unique () ) ] return options_names , [], [], None , None , None # Refine dropdown hierarchically: when first one is set, the 2 other options are computed # accordingly, when second one is set, the last one option is computed elif name is not None : if id_input == \"page-4-dropdown-lipid-names\" : structures = data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 )[ data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 )[ \"name\" ] == name ] . structure . unique () options_structures = [ { \"label\" : structure , \"value\" : structure } for structure in sorted ( structures ) ] return options_names , options_structures , [], name , None , None elif structure is not None : if id_input == \"page-4-dropdown-lipid-structures\" : cations = data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 )[ ( data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 )[ \"name\" ] == name ) & ( data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 )[ \"structure\" ] == structure ) ] . cation . unique () options_cations = [{ \"label\" : cation , \"value\" : cation } for cation in sorted ( cations )] return options_names , options_structures , options_cations , name , structure , None return dash . no_update page_4_plot_graph_heatmap_mz_selection ( set_progress , n_clicks_button_display , percentile , l_selected_regions , name_region_1 , name_region_2 , name_region_3 , brain ) This callback is used to plot the clustergram to cluster and compare lipid expression in the selected structure(s), when clicking on the corresponding button. It uses a long callback to update the progress bar as the figure gets computed. Source code in pages/threeD_exploration.py 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 @app . long_callback ( output = Output ( \"page-4-graph-heatmap\" , \"figure\" ), inputs = [ Input ( \"page-4-compare-structure-button\" , \"n_clicks\" ), Input ( \"page-4-slider-percentile\" , \"value\" ), State ( \"page-4-last-selected-regions\" , \"data\" ), State ( \"page-4-selected-region-1\" , \"data\" ), State ( \"page-4-selected-region-2\" , \"data\" ), State ( \"page-4-selected-region-3\" , \"data\" ), State ( \"main-brain\" , \"value\" ), ], running = [ ( Output ( \"page-4-progress-bar-structure\" , \"className\" ), \"\" , \"d-none\" , ), ( Output ( \"page-4-graph-heatmap\" , \"className\" ), \"d-none\" , \"\" ), ( Output ( \"page-4-slider-percentile\" , \"className\" ), \"d-none\" , \"\" ), ( Output ( \"page-4-download-clustergram-button\" , \"disabled\" ), True , False ), ], progress = [ Output ( \"page-4-progress-bar-structure\" , \"value\" ), Output ( \"page-4-progress-bar-structure\" , \"label\" ), ], prevent_initial_call = True , cache_args_to_ignore = [ 0 , 2 ], ) def page_4_plot_graph_heatmap_mz_selection ( set_progress , n_clicks_button_display , percentile , l_selected_regions , name_region_1 , name_region_2 , name_region_3 , brain , ): \"\"\"This callback is used to plot the clustergram to cluster and compare lipid expression in the selected structure(s), when clicking on the corresponding button. It uses a long callback to update the progress bar as the figure gets computed.\"\"\" set_progress (( 0 , \"Inspecting dataset...\" )) # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # case structures have been selected if id_input == \"page-4-compare-structure-button\" or id_input == \"page-4-slider-percentile\" : if len ( l_selected_regions ) > 1 : return figures . compute_clustergram_figure ( set_progress , cache_flask , l_selected_regions , percentile = percentile , brain_1 = True if brain == \"brain_1\" else False , ) return dash . no_update page_4_plot_graph_volume ( set_progress , l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , n_clicks_button_display , name_lipid_1 , name_lipid_2 , name_lipid_3 , l_selected_regions , name_region_1 , name_region_2 , name_region_3 , is_open_modal , brain ) This callback is used to plot the volume graph of expression of the selected lipid(s) in the selected structure(s), when clicking on the corresponding button. Source code in pages/threeD_exploration.py 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 @app . long_callback ( output = Output ( \"page-4-graph-volume\" , \"figure\" ), inputs = [ State ( \"page-4-selected-lipid-1\" , \"data\" ), State ( \"page-4-selected-lipid-2\" , \"data\" ), State ( \"page-4-selected-lipid-3\" , \"data\" ), Input ( \"page-4-display-button\" , \"n_clicks\" ), State ( \"page-4-toast-lipid-1\" , \"header\" ), State ( \"page-4-toast-lipid-2\" , \"header\" ), State ( \"page-4-toast-lipid-3\" , \"header\" ), State ( \"page-4-last-selected-regions\" , \"data\" ), State ( \"page-4-selected-region-1\" , \"data\" ), State ( \"page-4-selected-region-2\" , \"data\" ), State ( \"page-4-selected-region-3\" , \"data\" ), Input ( \"page-4-modal-volume\" , \"is_open\" ), State ( \"main-brain\" , \"value\" ), ], running = [ ( Output ( \"page-4-progress-bar-volume\" , \"className\" ), \"\" , \"d-none\" , ), ( Output ( \"page-4-graph-volume\" , \"className\" ), \"d-none\" , \"\" ), ], progress = [ Output ( \"page-4-progress-bar-volume\" , \"value\" ), Output ( \"page-4-progress-bar-volume\" , \"label\" ), ], prevent_initial_call = True , cache_args_to_ignore = [ 0 , 1 , 2 , 3 , 7 , 8 ], ) def page_4_plot_graph_volume ( set_progress , l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , n_clicks_button_display , name_lipid_1 , name_lipid_2 , name_lipid_3 , l_selected_regions , name_region_1 , name_region_2 , name_region_3 , is_open_modal , brain , ): \"\"\"This callback is used to plot the volume graph of expression of the selected lipid(s) in the selected structure(s), when clicking on the corresponding button.\"\"\" set_progress (( 0 , \"Inspecting dataset...\" )) # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # If the modal is closed, delete the graph if is_open_modal == False : logging . info ( \"Modal closed, deleting graph\" ) return {} # Compute set of ids for the volume plot if it is going to be plotted if id_input == \"page-4-display-button\" : set_id = set ([]) for acronym in l_selected_regions : set_id = set_id . union ( atlas . dic_acronym_children_id [ acronym ]) if len ( set_id ) < 5 : decrease_resolution_factor = 3 elif len ( set_id ) < 10 : decrease_resolution_factor = 5 elif len ( set_id ) < 50 : decrease_resolution_factor = 7 elif len ( set_id ) < 100 : decrease_resolution_factor = 10 else : decrease_resolution_factor = 12 # # If no region was selected, put them all if len ( set_id ) == 0 : set_id = None decrease_resolution_factor = 12 # Set the default decrease_resolution_factor to 10, regardless of the number of regions # decrease_resolution_factor = 10 logging . info ( \"For the computation of 3D volume, decrease_resolution_factor is \" + str ( decrease_resolution_factor ) ) n_slices = len ( data . get_slice_list ( indices = brain )) if ( np . sum ( l_lipid_1_index ) > - n_slices or np . sum ( l_lipid_2_index ) > - n_slices or np . sum ( l_lipid_3_index ) > - n_slices ): # Build the list of mz boundaries for each peak and each index lll_lipid_bounds = [ [ [ ( float ( data . get_annotations () . iloc [ index ][ \"min\" ]), float ( data . get_annotations () . iloc [ index ][ \"max\" ]), ) ] if index != - 1 else None for index in [ lipid_1_index , lipid_2_index , lipid_3_index ] ] for lipid_1_index , lipid_2_index , lipid_3_index in zip ( l_lipid_1_index , l_lipid_2_index , l_lipid_3_index ) ] return figures . compute_3D_volume_figure ( set_progress = set_progress , ll_t_bounds = lll_lipid_bounds , name_lipid_1 = name_lipid_1 , name_lipid_2 = name_lipid_2 , name_lipid_3 = name_lipid_3 , set_id_regions = set_id , decrease_dimensionality_factor = decrease_resolution_factor , cache_flask = cache_flask , brain_1 = True if brain == \"brain_1\" else False , ) else : # probably the page has just been loaded, so do nothing return dash . no_update return dash . no_update page_4_toggle_modal_clustergram ( n1 , is_open ) This callback is used to toggle the modal window for clustergram plot Source code in pages/threeD_exploration.py 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 @app . callback ( Output ( \"page-4-modal-heatmap\" , \"is_open\" ), Input ( \"page-4-compare-structure-button\" , \"n_clicks\" ), [ State ( \"page-4-modal-heatmap\" , \"is_open\" )], ) def page_4_toggle_modal_clustergram ( n1 , is_open ): \"\"\"This callback is used to toggle the modal window for clustergram plot\"\"\" if n1 : return not is_open return is_open page_4_toggle_modal_volume ( n1 , is_open ) This callback is used to toggle the modal window for volume plot Source code in pages/threeD_exploration.py 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 @app . callback ( Output ( \"page-4-modal-volume\" , \"is_open\" ), Input ( \"page-4-display-button\" , \"n_clicks\" ), [ State ( \"page-4-modal-volume\" , \"is_open\" )], ) def page_4_toggle_modal_volume ( n1 , is_open ): \"\"\"This callback is used to toggle the modal window for volume plot\"\"\" if n1 : return not is_open return is_open","title":"threeD_exploration"},{"location":"pages/threeD_exploration/#pages.threeD_exploration.page_4_active_display","text":"This callback is used to enable/disable the display buttons (for both clustergram and volume plots). Source code in pages/threeD_exploration.py 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 @app . callback ( Output ( \"page-4-display-button\" , \"disabled\" ), Output ( \"page-4-compare-structure-button\" , \"disabled\" ), Input ( \"page-4-selected-lipid-1\" , \"data\" ), Input ( \"page-4-selected-lipid-2\" , \"data\" ), Input ( \"page-4-selected-lipid-3\" , \"data\" ), Input ( \"page-4-selected-region-1\" , \"data\" ), Input ( \"page-4-selected-region-2\" , \"data\" ), Input ( \"page-4-selected-region-3\" , \"data\" ), State ( \"main-brain\" , \"value\" ), ) def page_4_active_display ( l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , region_1_id , region_2_id , region_3_id , brain ): \"\"\"This callback is used to enable/disable the display buttons (for both clustergram and volume plots).\"\"\" # Compute number of slices for current brain n_slices = len ( data . get_slice_list ( indices = brain )) # If at least two structures if ( ( region_1_id != \"\" and region_2_id != \"\" ) or ( region_1_id != \"\" and region_3_id != \"\" ) or ( region_2_id != \"\" and region_3_id != \"\" ) ): # If at least one lipid, activate both buttons, else only the clustergram button: if np . sum ( l_lipid_1_index + l_lipid_2_index + l_lipid_3_index ) > - 3 * n_slices : return False , False else : return True , False # If just one structure, deactivate clustergram button if region_1_id != \"\" or region_2_id != \"\" or region_3_id != \"\" : # If at least one lipid, activate volume plot button: if np . sum ( l_lipid_1_index + l_lipid_2_index + l_lipid_3_index ) > - 3 * n_slices : return False , True else : return True , True # Defaults is both buttons are disabled return True , True","title":"page_4_active_display()"},{"location":"pages/threeD_exploration/#pages.threeD_exploration.page_4_add_toast_region_selection","text":"This callback checks for a free spot and adds the selected region to the selection when clicking on the 'add structure' button. Source code in pages/threeD_exploration.py 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 @app . callback ( Output ( \"page-4-toast-region-1\" , \"header\" ), Output ( \"page-4-toast-region-2\" , \"header\" ), Output ( \"page-4-toast-region-3\" , \"header\" ), Output ( \"page-4-selected-region-1\" , \"data\" ), Output ( \"page-4-selected-region-2\" , \"data\" ), Output ( \"page-4-selected-region-3\" , \"data\" ), Output ( \"page-4-toast-region-1\" , \"is_open\" ), Output ( \"page-4-toast-region-2\" , \"is_open\" ), Output ( \"page-4-toast-region-3\" , \"is_open\" ), Output ( \"page-4-last-selected-regions\" , \"data\" ), Input ( \"page-4-add-structure-button\" , \"n_clicks\" ), Input ( \"page-4-toast-region-1\" , \"is_open\" ), Input ( \"page-4-toast-region-2\" , \"is_open\" ), Input ( \"page-4-toast-region-3\" , \"is_open\" ), State ( \"page-4-selected-region-1\" , \"data\" ), State ( \"page-4-selected-region-2\" , \"data\" ), State ( \"page-4-selected-region-3\" , \"data\" ), State ( \"page-4-toast-region-1\" , \"header\" ), State ( \"page-4-toast-region-2\" , \"header\" ), State ( \"page-4-toast-region-3\" , \"header\" ), State ( \"page-4-last-selected-regions\" , \"data\" ), State ( \"page-4-add-structure-button\" , \"children\" ), ) def page_4_add_toast_region_selection ( clicked_add , bool_toast_1 , bool_toast_2 , bool_toast_3 , region_1_id , region_2_id , region_3_id , header_1 , header_2 , header_3 , l_selected_regions , label_region , ): \"\"\"This callback checks for a free spot and adds the selected region to the selection when clicking on the 'add structure' button.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] if len ( id_input ) == 0 : return \"\" , \"\" , \"\" , \"\" , \"\" , \"\" , False , False , False , [] # If a region has been deleted from a toast if value_input == \"is_open\" : # Delete corresponding header and index if id_input == \"page-4-toast-region-1\" : header_1 = \"\" l_selected_regions . remove ( region_1_id ) region_1_id = \"\" elif id_input == \"page-4-toast-region-2\" : header_2 = \"\" l_selected_regions . remove ( region_2_id ) region_2_id = \"\" elif id_input == \"page-4-toast-region-3\" : header_3 = \"\" l_selected_regions . remove ( region_3_id ) l_region_3_index = \"\" else : logging . warning ( \"BUG in page_2_add_dropdown_selection\" ) return ( header_1 , header_2 , header_3 , region_1_id , region_2_id , region_3_id , bool_toast_1 , bool_toast_2 , bool_toast_3 , l_selected_regions , ) # Otherwise, add region to selection elif id_input == \"page-4-add-structure-button\" : if label_region != \"Please choose a structure above\" : region = label_region . split ( \"Add \" )[ 1 ] . split ( \" to selection\" )[ 0 ] region_id = atlas . dic_name_acronym [ region ] if region_id not in l_selected_regions : l_selected_regions . append ( region_id ) # Check first slot available if not bool_toast_1 : header_1 = region region_1_id = region_id bool_toast_1 = True elif not bool_toast_2 : header_2 = region region_2_id = region_id bool_toast_2 = True elif not bool_toast_3 : header_3 = region region_3_id = region_id bool_toast_3 = True else : logging . warning ( \"BUG, more than 3 regions have been selected\" ) return dash . no_update return ( header_1 , header_2 , header_3 , region_1_id , region_2_id , region_3_id , bool_toast_1 , bool_toast_2 , bool_toast_3 , l_selected_regions , ) # It shouldn't be possible to click, so delete all else : return \"\" , \"\" , \"\" , \"\" , \"\" , \"\" , False , False , False , [] return dash . no_update","title":"page_4_add_toast_region_selection()"},{"location":"pages/threeD_exploration/#pages.threeD_exploration.page_4_add_toast_selection","text":"This callback is used to add the current choice of lipids (using dropdown) to the selection for further plotting, when clicking on the 'add lipid' button. Source code in pages/threeD_exploration.py 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 @app . callback ( Output ( \"page-4-toast-lipid-1\" , \"header\" ), Output ( \"page-4-toast-lipid-2\" , \"header\" ), Output ( \"page-4-toast-lipid-3\" , \"header\" ), Output ( \"page-4-selected-lipid-1\" , \"data\" ), Output ( \"page-4-selected-lipid-2\" , \"data\" ), Output ( \"page-4-selected-lipid-3\" , \"data\" ), Output ( \"page-4-toast-lipid-1\" , \"is_open\" ), Output ( \"page-4-toast-lipid-2\" , \"is_open\" ), Output ( \"page-4-toast-lipid-3\" , \"is_open\" ), Output ( \"page-4-last-selected-lipids\" , \"data\" ), State ( \"page-4-dropdown-lipid-cations\" , \"value\" ), Input ( \"page-4-add-lipid-button\" , \"n_clicks\" ), Input ( \"page-4-toast-lipid-1\" , \"is_open\" ), Input ( \"page-4-toast-lipid-2\" , \"is_open\" ), Input ( \"page-4-toast-lipid-3\" , \"is_open\" ), State ( \"page-4-dropdown-lipid-names\" , \"value\" ), State ( \"page-4-dropdown-lipid-structures\" , \"value\" ), State ( \"page-4-selected-lipid-1\" , \"data\" ), State ( \"page-4-selected-lipid-2\" , \"data\" ), State ( \"page-4-selected-lipid-3\" , \"data\" ), State ( \"page-4-toast-lipid-1\" , \"header\" ), State ( \"page-4-toast-lipid-2\" , \"header\" ), State ( \"page-4-toast-lipid-3\" , \"header\" ), State ( \"page-4-last-selected-lipids\" , \"data\" ), Input ( \"main-brain\" , \"value\" ), ) def page_4_add_toast_selection ( cation , n_clicks , bool_toast_1 , bool_toast_2 , bool_toast_3 , name , structure , l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , header_1 , header_2 , header_3 , l_selected_lipids , brain , ): \"\"\"This callback is used to add the current choice of lipids (using dropdown) to the selection for further plotting, when clicking on the 'add lipid' button.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] if brain == \"brain_1\" or brain == \"brain_2\" : # Define empty lipid list n_slices = len ( data . get_slice_list ( indices = brain )) empty_lipid_list = [ - 1 for i in range ( n_slices )] # The function shouldn't have been called if brain index is not defined else : return dash . no_update # Take advantage of dash bug that automatically triggers 'page-4-dropdown-lipid-cations' # everytime the page is loaded # If page-4-dropdown-lipid-cations is called while there's no lipid name defined, it means the # page just got loaded if len ( id_input ) == 0 or ( id_input == \"page-4-dropdown-lipid-cations\" and name is None ): return ( \"\" , \"\" , \"\" , empty_lipid_list , empty_lipid_list , empty_lipid_list , False , False , False , [], ) # If a lipid has been deleted from a toast if value_input == \"is_open\" : # Delete corresponding header and index if id_input == \"page-4-toast-lipid-1\" : header_1 = \"\" l_selected_lipids . remove ( l_lipid_1_index [ 0 ]) l_lipid_1_index = empty_lipid_list elif id_input == \"page-4-toast-lipid-2\" : header_2 = \"\" l_selected_lipids . remove ( l_lipid_2_index [ 0 ]) l_lipid_2_index = empty_lipid_list elif id_input == \"page-4-toast-lipid-3\" : header_3 = \"\" l_selected_lipids . remove ( l_lipid_3_index [ 0 ]) l_lipid_3_index = empty_lipid_list else : logging . warning ( \"BUG in page_2_add_dropdown_selection\" ) return ( header_1 , header_2 , header_3 , l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , bool_toast_1 , bool_toast_2 , bool_toast_3 , l_selected_lipids , ) # Otherwise, add lipid to selection elif cation is not None and id_input == \"page-4-add-lipid-button\" : for idx_slice_index , slice_index in enumerate ( data . get_slice_list ( indices = brain )): # Find lipid location l_lipid_loc = ( data . get_annotations () . index [ ( data . get_annotations ()[ \"name\" ] == name ) & ( data . get_annotations ()[ \"structure\" ] == structure ) & ( data . get_annotations ()[ \"slice\" ] == slice_index ) & ( data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) > 1 : logging . warning ( \"More than one lipid corresponds to the selection\" ) l_lipid_loc = [ l_lipid_loc [ - 1 ]] if len ( l_lipid_loc ) == 0 : l_lipid_loc = [ - 1 ] lipid_string = name + \" \" + structure + \" \" + cation if idx_slice_index == 0 : l_selected_lipids . append ( l_lipid_loc [ 0 ]) # Check first slot available if not bool_toast_1 : header_1 = lipid_string l_lipid_1_index [ idx_slice_index ] = l_lipid_loc [ 0 ] if slice_index == data . get_slice_list ( indices = brain )[ - 1 ]: bool_toast_1 = True elif not bool_toast_2 : header_2 = lipid_string l_lipid_2_index [ idx_slice_index ] = l_lipid_loc [ 0 ] if slice_index == data . get_slice_list ( indices = brain )[ - 1 ]: bool_toast_2 = True elif not bool_toast_3 : header_3 = lipid_string l_lipid_3_index [ idx_slice_index ] = l_lipid_loc [ 0 ] if slice_index == data . get_slice_list ( indices = brain )[ - 1 ]: bool_toast_3 = True else : logging . warning ( \"BUG, more than 3 lipids have been selected\" ) return dash . no_update return ( header_1 , header_2 , header_3 , l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , bool_toast_1 , bool_toast_2 , bool_toast_3 , l_selected_lipids , ) # If the brain index has changed, update the corresponding lipid indices elif id_input == \"main-brain\" : # Remove previous lipids information if header_1 != \"\" : l_selected_lipids . remove ( l_lipid_1_index [ 0 ]) l_lipid_1_index = copy . copy ( empty_lipid_list ) if header_2 != \"\" : l_selected_lipids . remove ( l_lipid_2_index [ 0 ]) l_lipid_2_index = copy . copy ( empty_lipid_list ) if header_3 != \"\" : l_selected_lipids . remove ( l_lipid_3_index [ 0 ]) l_lipid_3_index = copy . copy ( empty_lipid_list ) for idx_header , header in enumerate ([ header_1 , header_2 , header_3 ]): if header != \"\" : name , structure , cation = header . split ( \" \" ) for idx_slice_index , slice_index in enumerate ( data . get_slice_list ( indices = brain )): # Find lipid location l_lipid_loc = ( data . get_annotations () . index [ ( data . get_annotations ()[ \"name\" ] == name ) & ( data . get_annotations ()[ \"structure\" ] == structure ) & ( data . get_annotations ()[ \"slice\" ] == slice_index ) & ( data . get_annotations ()[ \"cation\" ] == cation ) ] . tolist () ) # If several lipids correspond to the selection, we have a problem... if len ( l_lipid_loc ) > 1 : logging . warning ( \"More than one lipid corresponds to the selection\" ) l_lipid_loc = [ l_lipid_loc [ - 1 ]] if len ( l_lipid_loc ) == 0 : l_lipid_loc = [ - 1 ] if idx_slice_index == 0 : l_selected_lipids . append ( l_lipid_loc [ 0 ]) # Check slot that are already filled if idx_header == 0 : l_lipid_1_index [ idx_slice_index ] = l_lipid_loc [ 0 ] elif idx_header == 1 : l_lipid_2_index [ idx_slice_index ] = l_lipid_loc [ 0 ] elif idx_header == 2 : l_lipid_3_index [ idx_slice_index ] = l_lipid_loc [ 0 ] return ( header_1 , header_2 , header_3 , l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , bool_toast_1 , bool_toast_2 , bool_toast_3 , l_selected_lipids , ) return dash . no_update","title":"page_4_add_toast_selection()"},{"location":"pages/threeD_exploration/#pages.threeD_exploration.page_4_click","text":"This callback is used to update the label of the add structure button depending on the number of structures already selected, and the state of the corresponding widget. Source code in pages/threeD_exploration.py 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 @app . callback ( Output ( \"page-4-add-structure-button\" , \"children\" ), Output ( \"page-4-add-structure-button\" , \"disabled\" ), Input ( \"page-4-graph-region-selection\" , \"clickData\" ), Input ( \"page-4-selected-region-1\" , \"data\" ), Input ( \"page-4-selected-region-2\" , \"data\" ), Input ( \"page-4-selected-region-3\" , \"data\" ), ) def page_4_click ( clickData , region_1_id , region_2_id , region_3_id ): \"\"\"This callback is used to update the label of the add structure button depending on the number of structures already selected, and the state of the corresponding widget.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # Check if a structure has already been selected in the widget if id_input == \"page-4-graph-region-selection\" : if clickData is not None : if \"points\" in clickData : label = clickData [ \"points\" ][ 0 ][ \"label\" ] return \"Add \" + label + \" to selection\" , False return \"Please choose a structure above\" , True # If all structures have been selected, disable the button if region_1_id != \"\" and region_2_id != \"\" and region_3_id != \"\" : return \"Delete some structures to select new ones\" , True # If at least one more structure can be added to the selection, command to select one if region_1_id != \"\" or region_2_id != \"\" or region_3_id != \"\" : return \"Please choose a structure above\" , True return dash . no_update","title":"page_4_click()"},{"location":"pages/threeD_exploration/#pages.threeD_exploration.page_4_click_lipid","text":"This callback is used to update the label of the add lipid button, depending on the number of lipids already selected. Source code in pages/threeD_exploration.py 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 @app . callback ( Output ( \"page-4-add-lipid-button\" , \"children\" ), Output ( \"page-4-add-lipid-button\" , \"disabled\" ), Input ( \"page-4-toast-lipid-1\" , \"header\" ), Input ( \"page-4-toast-lipid-2\" , \"header\" ), Input ( \"page-4-toast-lipid-3\" , \"header\" ), State ( \"page-4-dropdown-lipid-names\" , \"value\" ), State ( \"page-4-dropdown-lipid-structures\" , \"value\" ), Input ( \"page-4-dropdown-lipid-cations\" , \"value\" ), ) def page_4_click_lipid ( header_1 , header_2 , header_3 , name , structure , cation ): \"\"\"This callback is used to update the label of the add lipid button, depending on the number of lipids already selected.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] # If at least one headers is free if header_1 == \"\" or header_2 == \"\" or header_3 == \"\" : if cation is not None and cation != \"\" : # Get lipid name lipid_string = name + \" \" + structure + \" \" + cation # Compare to existing headers if lipid_string not in [ header_1 , header_2 , header_3 ]: return \"Add \" + lipid_string + \" to selection\" , False else : return \"Please choose a lipid that hasn't been selected yet\" , True # If all lipids have been selected, disable the button if header_1 != \"\" and header_2 != \"\" and header_3 != \"\" : return \"Delete some lipids to select new ones\" , True # By default, command to select new lipids return \"Please choose a lipid above\" , True","title":"page_4_click_lipid()"},{"location":"pages/threeD_exploration/#pages.threeD_exploration.page_4_disable_dropdowns","text":"This callback is triggered when a lipid is selected, and enables/disables the corresponding dropdowns. Source code in pages/threeD_exploration.py 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 @app . callback ( Output ( \"page-4-dropdown-lipid-names\" , \"disabled\" ), Output ( \"page-4-dropdown-lipid-structures\" , \"disabled\" ), Output ( \"page-4-dropdown-lipid-cations\" , \"disabled\" ), Input ( \"page-4-selected-lipid-1\" , \"data\" ), Input ( \"page-4-selected-lipid-2\" , \"data\" ), Input ( \"page-4-selected-lipid-3\" , \"data\" ), State ( \"main-brain\" , \"value\" ), ) def page_4_disable_dropdowns ( l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , brain ): \"\"\"This callback is triggered when a lipid is selected, and enables/disables the corresponding dropdowns.\"\"\" # Compute number of slices for current brain n_slices = len ( data . get_slice_list ( indices = brain )) # If all slots are taken, disable all dropdowns if ( np . sum ( l_lipid_1_index ) > - n_slices and np . sum ( l_lipid_2_index ) > - n_slices and np . sum ( l_lipid_3_index ) > - n_slices ): return True , True , True else : return False , False , False","title":"page_4_disable_dropdowns()"},{"location":"pages/threeD_exploration/#pages.threeD_exploration.page_4_handle_dropdowns","text":"This callback is used to progressively refine dropdown selection for lipid names, structures and cations. It is triggered when a new selection is made in the corresponding dropdowns. Source code in pages/threeD_exploration.py 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 @app . callback ( Output ( \"page-4-dropdown-lipid-names\" , \"data\" ), Output ( \"page-4-dropdown-lipid-structures\" , \"data\" ), Output ( \"page-4-dropdown-lipid-cations\" , \"data\" ), Output ( \"page-4-dropdown-lipid-names\" , \"value\" ), Output ( \"page-4-dropdown-lipid-structures\" , \"value\" ), Output ( \"page-4-dropdown-lipid-cations\" , \"value\" ), Input ( \"page-4-add-lipid-button\" , \"n_clicks\" ), Input ( \"page-4-dropdown-lipid-names\" , \"value\" ), Input ( \"page-4-dropdown-lipid-structures\" , \"value\" ), State ( \"page-4-dropdown-lipid-names\" , \"data\" ), State ( \"page-4-dropdown-lipid-structures\" , \"data\" ), State ( \"page-4-dropdown-lipid-cations\" , \"data\" ), Input ( \"main-brain\" , \"value\" ), ) def page_4_handle_dropdowns ( n_clicks , name , structure , options_names , options_structures , options_cations , brain ): \"\"\"This callback is used to progressively refine dropdown selection for lipid names, structures and cations. It is triggered when a new selection is made in the corresponding dropdowns.\"\"\" # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] brain_1 = True if brain == \"brain_1\" else False # If the page just loaded or button 'add lipid' has been clicked, or brain dropdown has changed, reset selection if len ( id_input ) == 0 or id_input == \"page-4-add-lipid-button\" or id_input == \"main-brain\" : options_names = [ { \"label\" : name , \"value\" : name } for name in sorted ( data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 ) . name . unique () ) ] return options_names , [], [], None , None , None # Refine dropdown hierarchically: when first one is set, the 2 other options are computed # accordingly, when second one is set, the last one option is computed elif name is not None : if id_input == \"page-4-dropdown-lipid-names\" : structures = data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 )[ data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 )[ \"name\" ] == name ] . structure . unique () options_structures = [ { \"label\" : structure , \"value\" : structure } for structure in sorted ( structures ) ] return options_names , options_structures , [], name , None , None elif structure is not None : if id_input == \"page-4-dropdown-lipid-structures\" : cations = data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 )[ ( data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 )[ \"name\" ] == name ) & ( data . get_annotations_MAIA_transformed_lipids ( brain_1 = brain_1 )[ \"structure\" ] == structure ) ] . cation . unique () options_cations = [{ \"label\" : cation , \"value\" : cation } for cation in sorted ( cations )] return options_names , options_structures , options_cations , name , structure , None return dash . no_update","title":"page_4_handle_dropdowns()"},{"location":"pages/threeD_exploration/#pages.threeD_exploration.page_4_plot_graph_heatmap_mz_selection","text":"This callback is used to plot the clustergram to cluster and compare lipid expression in the selected structure(s), when clicking on the corresponding button. It uses a long callback to update the progress bar as the figure gets computed. Source code in pages/threeD_exploration.py 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 @app . long_callback ( output = Output ( \"page-4-graph-heatmap\" , \"figure\" ), inputs = [ Input ( \"page-4-compare-structure-button\" , \"n_clicks\" ), Input ( \"page-4-slider-percentile\" , \"value\" ), State ( \"page-4-last-selected-regions\" , \"data\" ), State ( \"page-4-selected-region-1\" , \"data\" ), State ( \"page-4-selected-region-2\" , \"data\" ), State ( \"page-4-selected-region-3\" , \"data\" ), State ( \"main-brain\" , \"value\" ), ], running = [ ( Output ( \"page-4-progress-bar-structure\" , \"className\" ), \"\" , \"d-none\" , ), ( Output ( \"page-4-graph-heatmap\" , \"className\" ), \"d-none\" , \"\" ), ( Output ( \"page-4-slider-percentile\" , \"className\" ), \"d-none\" , \"\" ), ( Output ( \"page-4-download-clustergram-button\" , \"disabled\" ), True , False ), ], progress = [ Output ( \"page-4-progress-bar-structure\" , \"value\" ), Output ( \"page-4-progress-bar-structure\" , \"label\" ), ], prevent_initial_call = True , cache_args_to_ignore = [ 0 , 2 ], ) def page_4_plot_graph_heatmap_mz_selection ( set_progress , n_clicks_button_display , percentile , l_selected_regions , name_region_1 , name_region_2 , name_region_3 , brain , ): \"\"\"This callback is used to plot the clustergram to cluster and compare lipid expression in the selected structure(s), when clicking on the corresponding button. It uses a long callback to update the progress bar as the figure gets computed.\"\"\" set_progress (( 0 , \"Inspecting dataset...\" )) # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # case structures have been selected if id_input == \"page-4-compare-structure-button\" or id_input == \"page-4-slider-percentile\" : if len ( l_selected_regions ) > 1 : return figures . compute_clustergram_figure ( set_progress , cache_flask , l_selected_regions , percentile = percentile , brain_1 = True if brain == \"brain_1\" else False , ) return dash . no_update","title":"page_4_plot_graph_heatmap_mz_selection()"},{"location":"pages/threeD_exploration/#pages.threeD_exploration.page_4_plot_graph_volume","text":"This callback is used to plot the volume graph of expression of the selected lipid(s) in the selected structure(s), when clicking on the corresponding button. Source code in pages/threeD_exploration.py 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 @app . long_callback ( output = Output ( \"page-4-graph-volume\" , \"figure\" ), inputs = [ State ( \"page-4-selected-lipid-1\" , \"data\" ), State ( \"page-4-selected-lipid-2\" , \"data\" ), State ( \"page-4-selected-lipid-3\" , \"data\" ), Input ( \"page-4-display-button\" , \"n_clicks\" ), State ( \"page-4-toast-lipid-1\" , \"header\" ), State ( \"page-4-toast-lipid-2\" , \"header\" ), State ( \"page-4-toast-lipid-3\" , \"header\" ), State ( \"page-4-last-selected-regions\" , \"data\" ), State ( \"page-4-selected-region-1\" , \"data\" ), State ( \"page-4-selected-region-2\" , \"data\" ), State ( \"page-4-selected-region-3\" , \"data\" ), Input ( \"page-4-modal-volume\" , \"is_open\" ), State ( \"main-brain\" , \"value\" ), ], running = [ ( Output ( \"page-4-progress-bar-volume\" , \"className\" ), \"\" , \"d-none\" , ), ( Output ( \"page-4-graph-volume\" , \"className\" ), \"d-none\" , \"\" ), ], progress = [ Output ( \"page-4-progress-bar-volume\" , \"value\" ), Output ( \"page-4-progress-bar-volume\" , \"label\" ), ], prevent_initial_call = True , cache_args_to_ignore = [ 0 , 1 , 2 , 3 , 7 , 8 ], ) def page_4_plot_graph_volume ( set_progress , l_lipid_1_index , l_lipid_2_index , l_lipid_3_index , n_clicks_button_display , name_lipid_1 , name_lipid_2 , name_lipid_3 , l_selected_regions , name_region_1 , name_region_2 , name_region_3 , is_open_modal , brain , ): \"\"\"This callback is used to plot the volume graph of expression of the selected lipid(s) in the selected structure(s), when clicking on the corresponding button.\"\"\" set_progress (( 0 , \"Inspecting dataset...\" )) # Find out which input triggered the function id_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 0 ] value_input = dash . callback_context . triggered [ 0 ][ \"prop_id\" ] . split ( \".\" )[ 1 ] # If the modal is closed, delete the graph if is_open_modal == False : logging . info ( \"Modal closed, deleting graph\" ) return {} # Compute set of ids for the volume plot if it is going to be plotted if id_input == \"page-4-display-button\" : set_id = set ([]) for acronym in l_selected_regions : set_id = set_id . union ( atlas . dic_acronym_children_id [ acronym ]) if len ( set_id ) < 5 : decrease_resolution_factor = 3 elif len ( set_id ) < 10 : decrease_resolution_factor = 5 elif len ( set_id ) < 50 : decrease_resolution_factor = 7 elif len ( set_id ) < 100 : decrease_resolution_factor = 10 else : decrease_resolution_factor = 12 # # If no region was selected, put them all if len ( set_id ) == 0 : set_id = None decrease_resolution_factor = 12 # Set the default decrease_resolution_factor to 10, regardless of the number of regions # decrease_resolution_factor = 10 logging . info ( \"For the computation of 3D volume, decrease_resolution_factor is \" + str ( decrease_resolution_factor ) ) n_slices = len ( data . get_slice_list ( indices = brain )) if ( np . sum ( l_lipid_1_index ) > - n_slices or np . sum ( l_lipid_2_index ) > - n_slices or np . sum ( l_lipid_3_index ) > - n_slices ): # Build the list of mz boundaries for each peak and each index lll_lipid_bounds = [ [ [ ( float ( data . get_annotations () . iloc [ index ][ \"min\" ]), float ( data . get_annotations () . iloc [ index ][ \"max\" ]), ) ] if index != - 1 else None for index in [ lipid_1_index , lipid_2_index , lipid_3_index ] ] for lipid_1_index , lipid_2_index , lipid_3_index in zip ( l_lipid_1_index , l_lipid_2_index , l_lipid_3_index ) ] return figures . compute_3D_volume_figure ( set_progress = set_progress , ll_t_bounds = lll_lipid_bounds , name_lipid_1 = name_lipid_1 , name_lipid_2 = name_lipid_2 , name_lipid_3 = name_lipid_3 , set_id_regions = set_id , decrease_dimensionality_factor = decrease_resolution_factor , cache_flask = cache_flask , brain_1 = True if brain == \"brain_1\" else False , ) else : # probably the page has just been loaded, so do nothing return dash . no_update return dash . no_update","title":"page_4_plot_graph_volume()"},{"location":"pages/threeD_exploration/#pages.threeD_exploration.page_4_toggle_modal_clustergram","text":"This callback is used to toggle the modal window for clustergram plot Source code in pages/threeD_exploration.py 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 @app . callback ( Output ( \"page-4-modal-heatmap\" , \"is_open\" ), Input ( \"page-4-compare-structure-button\" , \"n_clicks\" ), [ State ( \"page-4-modal-heatmap\" , \"is_open\" )], ) def page_4_toggle_modal_clustergram ( n1 , is_open ): \"\"\"This callback is used to toggle the modal window for clustergram plot\"\"\" if n1 : return not is_open return is_open","title":"page_4_toggle_modal_clustergram()"},{"location":"pages/threeD_exploration/#pages.threeD_exploration.page_4_toggle_modal_volume","text":"This callback is used to toggle the modal window for volume plot Source code in pages/threeD_exploration.py 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 @app . callback ( Output ( \"page-4-modal-volume\" , \"is_open\" ), Input ( \"page-4-display-button\" , \"n_clicks\" ), [ State ( \"page-4-modal-volume\" , \"is_open\" )], ) def page_4_toggle_modal_volume ( n1 , is_open ): \"\"\"This callback is used to toggle the modal window for volume plot\"\"\" if n1 : return not is_open return is_open","title":"page_4_toggle_modal_volume()"}]}